---
title: Learning To-do List
usemathjax: true
---

> This is an ever changing to-do list of topics I would like to learn and notes to create. 

---
ðŸš§ is where my focus currently is.


# Current

## Dimensionality reduction ðŸš§


### Classic linear methods

- [ ] PCA ðŸš§
- [x] [[probabilistic PCA]]
- [ ] Bayesian PCA
- [ ] Factor Analysis (FA) ðŸš§
	- [ ] Some examples from Neuroscience?
- [ ] Gaussian Process Factor Analysis (GPFA) ðŸš§
- [ ] Canonical correlation analysis (CCA)
- [ ] jPCA
- [ ]  seqPCA

![[for_exceptional_broski.png]]

#### Regression?
- [ ] Partial least squares (PLS)
- [ ] Fisher's linear discriminant (FLD)
- [ ] Linear discriminant analysis (LDA)
- [ ] Principal component regression (PCR)
- [ ] Independent component analysis (ICA)
- [ ] GLM methods for dimensionality reduction?

### Targeted approaches

Methods that seek subspaces that are relate to behavior or task variables (i.e., measured experimental variables)

- [ ] Demixed PCA
- [ ] Targeted dimensionality reduction (TDR)
- [ ] Model-based targeted dimensionality reduction (mTDR)
- [ ] Preferential subspace identification (PSID)
- [ ] Subspace identification for linear systems (SID)

### Latent dynamics 

- [ ] LFADS 
- [ ] VAEs

### Nonlinear methods

- [ ] Kernel PCA
- [ ] Isomap
- [ ] T-SNE
- [ ] UMAP
- [ ] Multi-dimensional scaling

- [ ] GLM methods for dimensionality reduction
	

# Future

- [ ] Fix, expand, and post predictive coding notes
- [ ] Topological data analysis
	- [ ] persistent homology
	- [ ] mapper algorithm
- [ ] Causal inference



