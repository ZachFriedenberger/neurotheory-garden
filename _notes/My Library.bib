
@online{5f04e48f3e184600cbc92a05,
  title = {5f04e48f3e184600cbc92a05},
  url = {https://mfr.ca-1.osf.io/render?url=https://osf.io/9hkg2/?direct%26mode=render%26action=download%26mode=render},
  urldate = {2020-10-16},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2LUDM9CC\\render.html}
}

@article{allenAstrocyteRegulationSynaptic2014,
  title = {Astrocyte {{Regulation}} of {{Synaptic Behavior}}},
  author = {Allen, Nicola J.},
  date = {2014},
  journaltitle = {Annual Review of Cell and Developmental Biology},
  volume = {30},
  number = {1},
  eprint = {25288116},
  eprinttype = {pmid},
  pages = {439--463},
  doi = {10.1146/annurev-cellbio-100913-013053},
  url = {https://doi.org/10.1146/annurev-cellbio-100913-013053},
  urldate = {2020-11-24},
  abstract = {Astrocytes regulate multiple aspects of neuronal and synaptic function from development through to adulthood. Instead of addressing each function independently, this review provides a comprehensive overview of the different ways astrocytes modulate neuronal synaptic function throughout life, with a particular focus on recent findings in each area. It includes the emerging functions of astrocytes, such as a role in synapse formation, as well as more established roles, including the uptake and recycling of neurotransmitters. This broad approach covers the many ways astrocytes and neurons constantly interact to maintain the correct functioning of the brain. It is important to consider all of these diverse functions of astrocytes when investigating how astrocyte-neuron interactions regulate synaptic behavior to appreciate the complexity of these ongoing interactions.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-cellbio-100913-013053},
  file = {C\:\\Users\\Zach Friedenberger\\Downloads\\annurev-cellbio-100913-013053.pdf}
}

@article{allenStarPowerAstrocytes2019,
  title = {Star {{Power}}: {{Astrocytes Regulate Behavior}}},
  shorttitle = {Star {{Power}}},
  author = {Allen, Nicola J.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31100265},
  eprinttype = {pmid},
  pages = {1091--1093},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.04.042},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30494-5},
  urldate = {2020-11-21},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2C7XMJ66\\Allen - 2019 - Star Power Astrocytes Regulate Behavior.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JF9TY9EP\\S0092-8674(19)30494-5.html}
}

@article{aruCellularMechanismsConscious2020,
  title = {Cellular {{Mechanisms}} of {{Conscious Processing}}},
  author = {Aru, Jaan and Suzuki, Mototaka and Larkum, Matthew E.},
  date = {2020-10-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {10},
  pages = {814--825},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.07.006},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320301753},
  urldate = {2020-10-29},
  abstract = {Recent breakthroughs in neurobiology indicate that the time is ripe to understand how cellular-level mechanisms are related to conscious experience. Here, we highlight the biophysical properties of pyramidal cells, which allow them to act as gates that control the evolution of global activation patterns. In conscious states, this cellular mechanism enables complex sustained dynamics within the thalamocortical system, whereas during unconscious states, such signal propagation is prohibited. We suggest that the hallmark of conscious processing is the flexible integration of bottom-up and top-down data streams at the cellular level. This cellular integration mechanism provides the foundation for Dendritic Information Theory, a novel neurobiological theory of consciousness},
  langid = {english},
  keywords = {anesthesia,dendrites,dendritic integration theory,pyramidal cells},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DZ4DAPD2\\Aru et al. - 2020 - Cellular Mechanisms of Conscious Processing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PM2HSWF9\\S1364661320301753.html}
}

@article{beaulieu-larocheEnhancedDendriticCompartmentalization2018,
  title = {Enhanced {{Dendritic Compartmentalization}} in {{Human Cortical Neurons}}},
  author = {Beaulieu-Laroche, Lou and Toloza, Enrique H. S. and van der Goes, Marie-Sophie and Lafourcade, Mathieu and Barnagian, Derrick and Williams, Ziv M. and Eskandar, Emad N. and Frosch, Matthew P. and Cash, Sydney S. and Harnett, Mark T.},
  date = {2018-10-18},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {175},
  number = {3},
  eprint = {30340039},
  eprinttype = {pmid},
  pages = {643-651.e14},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2018.08.045},
  url = {https://www.cell.com/cell/abstract/S0092-8674(18)31106-1},
  urldate = {2020-10-29},
  langid = {english},
  keywords = {biophysics,compartmentalization,computation,cortex,dendrite,human,ion channels,neuron,patch-clamp},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M8YNL7TK\\Beaulieu-Laroche et al. - 2018 - Enhanced Dendritic Compartmentalization in Human C.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\49985XDW\\S0092-8674(18)31106-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RTATAXEM\\S0092-8674(18)31106-1.html}
}

@article{bellInformationMaximizationApproachBlind,
  title = {An {{Information-Maximization Approach}} to {{Blind Separation}} and {{Blind Deconvolution}}},
  author = {Bell, A J and Sejnowski, T J},
  pages = {31},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8EAQ9LIA\\Bell and Sejnowski - An Information-Maximization Approach to Blind Sepa.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4PGXM8TC\\Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{botvinickDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} and {{Its Neuroscientific Implications}}},
  author = {Botvinick, Matthew and Wang, Jane X. and Dabney, Will and Miller, Kevin J. and Kurth-Nelson, Zeb},
  date = {2020-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {4},
  pages = {603--616},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.06.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320304682},
  urldate = {2020-08-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJIYYGYT\\Botvinick et al. - 2020 - Deep Reinforcement Learning and Its Neuroscientifi.pdf}
}

@article{bradberryMolecularBasisSynaptotagmin1Associated2020,
  title = {Molecular {{Basis}} for {{Synaptotagmin-1-Associated Neurodevelopmental Disorder}}},
  author = {Bradberry, Mazdak M. and Courtney, Nicholas A. and Dominguez, Matthew J. and Lofquist, Sydney M. and Knox, Andrew T. and Sutton, R. Bryan and Chapman, Edwin R.},
  date = {2020-07-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {1},
  eprint = {32362337},
  eprinttype = {pmid},
  pages = {52-64.e7},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.04.003},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30272-5},
  urldate = {2020-10-06},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GXHC8MCT\\Bradberry et al. - 2020 - Molecular Basis for Synaptotagmin-1-Associated Neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QGVIXQCH\\S0896-6273(20)30272-5.html}
}

@article{breakspearGenerativeModelsCortical2010,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-11-10},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A5HJA3WT\\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{breakspearGenerativeModelsCortical2010a,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-10-05},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X5BBY6BW\\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{broidoScalefreeNetworksAre2019,
  title = {Scale-Free Networks Are Rare},
  author = {Broido, Anna D. and Clauset, Aaron},
  date = {2019-03-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {10},
  eprint = {30833554},
  eprinttype = {pmid},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08746-5},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6399239/},
  urldate = {2020-09-01},
  abstract = {Real-world networks are often claimed to be scale free,~meaning that the fraction of nodes with degree k follows a power law k−α, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns., Real-world networks are often said to be ”scale free”, meaning their degree distribution follows a power law. Broido and Clauset perform statistical tests of this claim using a large and diverse corpus of real-world networks, showing that scale-free structure is far from universal.},
  pmcid = {PMC6399239},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\R7HRJLJX\\Broido and Clauset - 2019 - Scale-free networks are rare.pdf}
}

@article{buzsakiNeuronalOscillationsCortical2004,
  title = {Neuronal {{Oscillations}} in {{Cortical Networks}}},
  author = {Buzsáki, György and Draguhn, Andreas},
  date = {2004-06-25},
  journaltitle = {Science},
  volume = {304},
  number = {5679},
  eprint = {15218136},
  eprinttype = {pmid},
  pages = {1926--1929},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1099745},
  url = {https://science.sciencemag.org/content/304/5679/1926},
  urldate = {2020-11-10},
  abstract = {Clocks tick, bridges and skyscrapers vibrate, neuronal networks oscillate. Are neuronal oscillations an inevitable by-product, similar to bridge vibrations, or an essential part of the brain's design? Mammalian cortical neurons form behavior-dependent oscillating networks of various sizes, which span five orders of magnitude in frequency. These oscillations are phylogenetically preserved, suggesting that they are functionally relevant. Recent findings indicate that network oscillations bias input selection, temporally link neurons into assemblies, and facilitate synaptic plasticity, mechanisms that cooperatively support temporal representation and long-term consolidation of information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FF7ZAZVB\\Buzsáki and Draguhn - 2004 - Neuronal Oscillations in Cortical Networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U2HLRDY\\1926.html}
}

@article{cadenaDeepConvolutionalModels2019,
  title = {Deep Convolutional Models Improve Predictions of Macaque {{V1}} Responses to Natural Images},
  author = {Cadena, Santiago A. and Denfield, George H. and Walker, Edgar Y. and Gatys, Leon A. and Tolias, Andreas S. and Bethge, Matthias and Ecker, Alexander S.},
  editor = {Einhäuser, Wolfgang},
  date = {2019-04-23},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {15},
  number = {4},
  pages = {e1006897},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006897},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1006897},
  urldate = {2020-10-08},
  abstract = {Despite great efforts over several decades, our best models of primary visual cortex (V1) still predict spiking activity quite poorly when probed with natural stimuli, highlighting our limited understanding of the nonlinear computations in V1. Recently, two approaches based on deep learning have emerged for modeling these nonlinear computations: transfer learning from artificial neural networks trained on object recognition and data-driven convolutional neural network models trained end-to-end on large populations of neurons. Here, we test the ability of both approaches to predict spiking activity in response to natural images in V1 of awake monkeys. We found that the transfer learning approach performed similarly well to the data-driven approach and both outperformed classical linear-nonlinear and waveletbased feature representations that build on existing theories of V1. Notably, transfer learning using a pre-trained feature space required substantially less experimental time to achieve the same performance. In conclusion, multi-layer convolutional neural networks (CNNs) set the new state of the art for predicting neural responses to natural images in primate V1 and deep features learned for object recognition are better explanations for V1 computation than all previous filter bank theories. This finding strengthens the necessity of V1 models that are multiple nonlinearities away from the image domain and it supports the idea of explaining early visual cortex based on high-level functional goals.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8VWFCWPK\\Cadena et al. - 2019 - Deep convolutional models improve predictions of m.pdf}
}

@article{calhounUnsupervisedIdentificationInternal2019,
  title = {Unsupervised Identification of the Internal States That Shape Natural Behavior},
  author = {Calhoun, Adam J. and Pillow, Jonathan W. and Murthy, Mala},
  date = {2019-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {12},
  pages = {2040--2049},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0533-x},
  url = {http://www.nature.com/articles/s41593-019-0533-x},
  urldate = {2020-09-05},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I2GZC5RB\\Calhoun et al. - 2019 - Unsupervised identification of the internal states.pdf}
}

@article{chaudhuriIntrinsicAttractorManifold2019,
  title = {The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit across Waking and Sleep},
  author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
  date = {2019-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {9},
  pages = {1512--1520},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0460-x},
  url = {http://www.nature.com/articles/s41593-019-0460-x},
  urldate = {2020-09-06},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3D6BIVRS\\s41593-019-0460-x.pdf}
}

@article{costaModelingEffectSleep2016,
  title = {Modeling the Effect of Sleep Regulation on a Neural Mass Model},
  author = {Costa, Michael Schellenberger and Born, Jan and Claussen, Jens Christian and Martinetz, Thomas},
  date = {2016-08-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {41},
  number = {1},
  pages = {15--28},
  issn = {1573-6873},
  doi = {10.1007/s10827-016-0602-z},
  url = {https://doi.org/10.1007/s10827-016-0602-z},
  urldate = {2020-11-20},
  abstract = {In mammals, sleep is categorized by two main sleep stages, rapid eye movement (REM) and non-REM (NREM) sleep that are known to fulfill different functional roles, the most notable being the consolidation of memory. While REM sleep is characterized by brain activity similar to wakefulness, the EEG activity changes drastically with the emergence of K-complexes, sleep spindles and slow oscillations during NREM sleep. These changes are regulated by circadian and ultradian rhythms, which emerge from an intricate interplay between multiple neuronal populations in the brainstem, forebrain and hypothalamus and the resulting varying levels of neuromodulators. Recently, there has been progress in the understanding of those rhythms both from a physiological as well as theoretical perspective. However, how these neuromodulators affect the generation of the different EEG patterns and their temporal dynamics is poorly understood. Here, we build upon previous work on a neural mass model of the sleeping cortex and investigate the effect of those neuromodulators on the dynamics of the cortex and the corresponding transition between wakefulness and the different sleep stages. We show that our simplified model is sufficient to generate the essential features of human EEG over a full day. This approach builds a bridge between sleep regulatory networks and EEG generating neural mass models and provides a valuable tool for model validation.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TRDNCRCM\\Costa et al. - 2016 - Modeling the effect of sleep regulation on a neura.pdf}
}

@article{degerFluctuationsInformationFiltering2014,
  title = {Fluctuations and Information Filtering in Coupled Populations of Spiking Neurons with Adaptation},
  author = {Deger, Moritz and Schwalger, Tilo and Naud, Richard and Gerstner, Wulfram},
  date = {2014-12-01},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {90},
  number = {6},
  eprint = {1311.4206},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  pages = {062704},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.90.062704},
  url = {http://arxiv.org/abs/1311.4206},
  urldate = {2022-09-02},
  abstract = {Finite-sized populations of spiking elements are fundamental to brain function, but also used in many areas of physics. Here we present a theory of the dynamics of finite-sized populations of spiking units, based on a quasi-renewal description of neurons with adaptation. We derive an integral equation with colored noise that governs the stochastic dynamics of the population activity in response to time-dependent stimulation and calculate the spectral density in the asynchronous state. We show that systems of coupled populations with adaptation can generate a frequency band in which sensory information is preferentially encoded. The theory is applicable to fully as well as randomly connected networks, and to leaky integrate-and-fire as well as to generalized spiking neurons with adaptation on multiple time scales.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\54MR2BB8\\Deger et al. - 2014 - Fluctuations and information filtering in coupled .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YVZ863KA\\1311.html}
}

@online{DendriticComputationsCaptured,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model},
  doi = {10.1073/pnas.1904463116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GMFEWWRS\\Dendritic computations captured by an effective po.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6S27Q8Y\\pnas.html}
}

@online{DendriticComputationsCaptureda,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model | {{PNAS}}},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08}
}

@article{destexheWilsonCowanModel2009,
  title = {The {{Wilson}}–{{Cowan}} Model, 36 Years Later},
  author = {Destexhe, Alain and Sejnowski, Terrence J.},
  date = {2009-07},
  journaltitle = {Biological cybernetics},
  shortjournal = {Biol Cybern},
  volume = {101},
  number = {1},
  eprint = {19662434},
  eprinttype = {pmid},
  pages = {1--2},
  issn = {0340-1200},
  doi = {10.1007/s00422-009-0328-3},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2866289/},
  urldate = {2020-09-29},
  abstract = {The Wilson–Cowan model of interacting neurons (1973) is one of the most influential papers published in Biological Cybernetics (Kybernetik). This paper and a companion paper published in 1972 have been cited over 1000 times. Rather than focus on the microscopic properties of neurons, Wilson and Cowan analyzed the collective properties of large numbers of neurons using methods from statistical mechanics, based on the mean-field approach. New experimental techniques to measure neuronal activity at the level of large populations are now available to test these models, including optical recording of brain activity with intrinsic signals and voltage sensitive dyes, and new methods for analyzing EEG and MEG. These measurement techniques have revealed patterns of coherent activity that span centimetres of tissue in the cerebral cortex. Here the underlying ideas are reviewed in a historic context.},
  pmcid = {PMC2866289},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P5FE2M44\\Destexhe and Sejnowski - 2009 - The Wilson–Cowan model, 36 years later.pdf}
}

@article{douglasRecurrentExcitationNeocortical1995,
  title = {Recurrent {{Excitation}} in {{Neocortical Circuits}}},
  author = {Douglas, Rodney J. and Koch, Christof and Mahowald, Misha and Martin, Kevan A. C. and Suarez, Humbert H.},
  date = {1995},
  journaltitle = {Science},
  volume = {269},
  number = {5226},
  eprint = {2887714},
  eprinttype = {jstor},
  pages = {981--985},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  abstract = {The majority of synapses in the mammalian cortex originate from cortical neurons. Indeed, the largest input to cortical cells comes from neighboring excitatory cells. However, most models of cortical development and processing do not reflect the anatomy and physiology of feedback excitation and are restricted to serial feedforward excitation. This report describes how populations of neurons in cat visual cortex can use excitatory feedback, characterized as an effective "network conductance," to amplify their feedforward input signals and demonstrates how neuronal discharge can be kept proportional to stimulus strength despite strong, recurrent connections that threaten to cause runaway excitation. These principles are incorporated into models of cortical direction and orientation selectivity that emphasize the basic design principles of cortical architectures.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4HUSPB72\\Douglas et al. - 1995 - Recurrent Excitation in Neocortical Circuits.pdf}
}

@article{echevesteCorticallikeDynamicsRecurrent2020,
  title = {Cortical-like Dynamics in Recurrent Circuits Optimized for Sampling-Based Probabilistic Inference},
  author = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, Máté},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1138--1149},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0671-1},
  url = {https://www.nature.com/articles/s41593-020-0671-1},
  urldate = {2020-11-16},
  abstract = {Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory–inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function—fast sampling-based inference—and predict further properties of these motifs that can be tested in future experiments.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RNMV49VD\\Echeveste et al. - 2020 - Cortical-like dynamics in recurrent circuits optim.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MFG7WH3U\\s41593-020-0671-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V9D3A8RM\\s41593-020-0671-1.html}
}

@article{efronComputerAgeStatistical,
  title = {Computer {{Age Statistical Inference}}},
  author = {Efron, Bradley and Hastie, Trevor},
  pages = {493},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\466BVHQG\\Efron and Hastie - Computer Age Statistical Inference.pdf}
}

@unpublished{fangExploitingNeuronSynapse2020,
  title = {Exploiting {{Neuron}} and {{Synapse Filter Dynamics}} in {{Spatial Temporal Learning}} of {{Deep Spiking Neural Network}}},
  author = {Fang, Haowen and Shrestha, Amar and Zhao, Ziyi and Qiu, Qinru},
  date = {2020-07-25},
  eprint = {2003.02944},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2003.02944},
  urldate = {2020-10-16},
  abstract = {The recent discovered spatial-temporal information processing capability of bio-inspired Spiking neural networks (SNN) has enabled some interesting models and applications. However designing large-scale and high-performance model is yet a challenge due to the lack of robust training algorithms. A bio-plausible SNN model with spatial-temporal property is a complex dynamic system. Each synapse and neuron behave as filters capable of preserving temporal information. As such neuron dynamics and filter effects are ignored in existing training algorithms, the SNN downgrades into a memoryless system and loses the ability of temporal signal processing. Furthermore, spike timing plays an important role in information representation, but conventional rate-based spike coding models only consider spike trains statistically, and discard information carried by its temporal structures. To address the above issues, and exploit the temporal dynamics of SNNs, we formulate SNN as a network of infinite impulse response (IIR) filters with neuron nonlinearity. We proposed a training algorithm that is capable to learn spatial-temporal patterns by searching for the optimal synapse filter kernels and weights. The proposed model and training algorithm are applied to construct associative memories and classifiers for synthetic and public datasets including MNIST, NMNIST, DVS 128 etc.; and their accuracy outperforms state-of-art approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KHQFPTIR\\Fang et al. - 2020 - Exploiting Neuron and Synapse Filter Dynamics in S.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NDX6FBLK\\2003.html}
}

@article{fernandezMolecularAtlasAdult2020,
  title = {Molecular Atlas of\hspace{0.166em}the\hspace{0.166em}Adult Mouse Brain},
  author = {Fernandez, Jose},
  date = {2020},
  journaltitle = {SCIENCE ADVANCES},
  pages = {14},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KMUMT29G\\Fernandez - 2020 - Molecular atlas of the adult mouse brain.pdf}
}

@article{fisekAreHumanDendrites2020,
  title = {Are {{Human Dendrites Different}}?},
  author = {Fişek, Mehmet and Häusser, Michael},
  date = {2020-06-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {6},
  pages = {411--412},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.03.002},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320300693},
  urldate = {2020-10-29},
  abstract = {The first patch-clamp recordings from the dendrites of human neocortical neurons have recently been reported by Beaulieu-Laroche et al. and Gidon et al. These studies have shown that human dendrites are electrically excitable, exhibiting backpropagating action potentials and fast dendritic calcium spikes. This new frontier highlights the potential for interspecies differences in the biophysics of dendritic computation.},
  langid = {english},
  keywords = {cortex,dendrite,human,neural computation,patch clamp,pyramidal cell,rodent,synaptic integration},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YKVESYHP\\Fişek and Häusser - 2020 - Are Human Dendrites Different.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DA79YYSI\\S1364661320300693.html}
}

@article{fristonFreeenergyPrincipleUnified2010,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  date = {2010-02},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {11},
  number = {2},
  pages = {127--138},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2787},
  url = {http://www.nature.com/articles/nrn2787},
  urldate = {2020-09-07},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7PEKABBM\\Friston - 2010 - The free-energy principle a unified brain theory.pdf}
}

@article{gallegoLongtermStabilityCortical2020,
  title = {Long-Term Stability of Cortical Population Dynamics Underlying Consistent Behavior},
  author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
  date = {2020-02},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {2},
  pages = {260--270},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0555-4},
  url = {https://www.nature.com/articles/s41593-019-0555-4},
  urldate = {2020-10-06},
  abstract = {Animals readily execute learned behaviors in a consistent manner over long periods of time, and yet no equally stable neural correlate has been demonstrated. How does the cortex achieve this stable control? Using the sensorimotor system as a model of cortical processing, we investigated the hypothesis that the dynamics of neural latent activity, which captures the dominant co-variation patterns within the neural population, must be preserved across time. We recorded from populations of neurons in premotor, primary motor and somatosensory cortices as monkeys performed a reaching task, for up to 2 years. Intriguingly, despite a steady turnover in the recorded neurons, the low-dimensional latent dynamics remained stable. The stability allowed reliable decoding of behavioral features for the entire timespan, while fixed decoders based directly on the recorded neural activity degraded substantially. We posit that stable latent cortical dynamics within the manifold are the fundamental building blocks underlying consistent behavioral execution.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YXAL3Y7N\\Gallego et al. - 2020 - Long-term stability of cortical population dynamic.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KDCJ5ERA\\s41593-019-0555-4.html}
}

@article{garrettExperienceShapesActivity2020,
  title = {Experience Shapes Activity Dynamics and Stimulus Coding of {{VIP}} Inhibitory Cells},
  author = {Garrett, Marina and Manavi, Sahar and Roll, Kate and Ollerenshaw, Douglas R and Groblewski, Peter A and Ponvert, Nicholas D and Kiggins, Justin T and Casal, Linzy and Mace, Kyla and Williford, Ali and Leon, Arielle and Jia, Xiaoxuan and Ledochowitsch, Peter and Buice, Michael A and Wakeman, Wayne and Mihalas, Stefan and Olsen, Shawn R},
  editor = {Bathellier, Brice and Gold, Joshua I and Bathellier, Brice and Keller, Georg B},
  date = {2020-02-26},
  journaltitle = {eLife},
  volume = {9},
  pages = {e50340},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.50340},
  url = {https://doi.org/10.7554/eLife.50340},
  urldate = {2020-09-24},
  abstract = {Cortical circuits can flexibly change with experience and learning, but the effects on specific cell types, including distinct inhibitory types, are not well understood. Here we investigated how excitatory and VIP inhibitory cells in layer 2/3 of mouse visual cortex were impacted by visual experience in the context of a behavioral task. Mice learned a visual change detection task with a set of eight natural scene images. Subsequently, during 2-photon imaging experiments, mice performed the task with these familiar images and three sets of novel images. Strikingly, the temporal dynamics of VIP activity differed markedly between novel and familiar images: VIP cells were stimulus-driven by novel images but were suppressed by familiar stimuli and showed ramping activity when expected stimuli were omitted from a temporally predictable sequence. This prominent change in VIP activity suggests that these cells may adopt different modes of processing under novel versus familiar conditions.},
  keywords = {behavior,learning,visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZQNTX29\\Garrett et al. - 2020 - Experience shapes activity dynamics and stimulus c.pdf}
}

@article{gidonDendriticActionPotentials2020,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  date = {2020-01-03},
  journaltitle = {Science},
  volume = {367},
  number = {6473},
  eprint = {31896716},
  eprinttype = {pmid},
  pages = {83--87},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax6239},
  url = {https://science.sciencemag.org/content/367/6473/83},
  urldate = {2020-09-24},
  abstract = {Human dendrites are special A special developmental program in the human brain drives the disproportionate thickening of cortical layer 2/3. This suggests that the expansion of layer 2/3, along with its numerous neurons and their large dendrites, may contribute to what makes us human. Gidon et al. thus investigated the dendritic physiology of layer 2/3 pyramidal neurons in slices taken from surgically resected brain tissue in epilepsy patients. Dual somatodendritic recordings revealed previously unknown classes of action potentials in the dendrites of these neurons, which make their activity far more complex than has been previously thought. These action potentials allow single neurons to solve two long-standing computational problems in neuroscience that were considered to require multilayer neural networks. Science, this issue p. 83 The active electrical properties of dendrites shape neuronal input and output and are fundamental to brain function. However, our knowledge of active dendrites has been almost entirely acquired from studies of rodents. In this work, we investigated the dendrites of layer 2 and 3 (L2/3) pyramidal neurons of the human cerebral cortex ex vivo. In these neurons, we discovered a class of calcium-mediated dendritic action potentials (dCaAPs) whose waveform and effects on neuronal output have not been previously described. In contrast to typical all-or-none action potentials, dCaAPs were graded; their amplitudes were maximal for threshold-level stimuli but dampened for stronger stimuli. These dCaAPs enabled the dendrites of individual human neocortical pyramidal neurons to classify linearly nonseparable inputs—a computation conventionally thought to require multilayered networks. Dendritic action potentials extend the repertoire of computations available to human neurons. Dendritic action potentials extend the repertoire of computations available to human neurons.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCXZX7BN\\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HNZXZGEN\\83.html}
}

@article{glickfeldHigherOrderAreasMouse2017,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017-09-15},
  journaltitle = {Annual Review of Vision Science},
  shortjournal = {Annu Rev Vis Sci},
  volume = {3},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  issn = {2374-4650},
  doi = {10.1146/annurev-vision-102016-061331},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  langid = {english},
  keywords = {Animals,Behavior; Animal,Brain Mapping,connectivity,Connectome,functional specialization,hierarchical and parallel processing,higher visual area,Mice,mouse,visual cortex,Visual Cortex,Visual Pathways,Visual Perception}
}

@article{glickfeldHigherOrderAreasMouse2017a,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017},
  journaltitle = {Annual Review of Vision Science},
  volume = {3},
  number = {1},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  doi = {10.1146/annurev-vision-102016-061331},
  url = {https://doi.org/10.1146/annurev-vision-102016-061331},
  urldate = {2020-11-10},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-vision-102016-061331}
}

@article{goetzActiveDendritesEnable2021,
  title = {Active Dendrites Enable Strong but Sparse Inputs to Determine Orientation Selectivity},
  author = {Goetz, Lea and Roth, Arnd and Häusser, Michael},
  date = {2021-07-27},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {118},
  number = {30},
  pages = {e2017339118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2017339118},
  url = {https://pnas.org/doi/full/10.1073/pnas.2017339118},
  urldate = {2022-09-02},
  abstract = {Significance                            An active pyramidal cell model, constrained by physiological and anatomical data, was used to simulate dendritic integration in vivo. The model shows that small numbers of strong excitatory synapses can trigger dendritic Na               +               and NMDA spikes. Moreover, only a few dendritic spikes are sufficient to drive a single output action potential. As a consequence, as few as 1\% of the synaptic inputs to a neuron can determine the tuning of somatic output in vivo. These results suggest that dendritic spikes can help to make sensory representations more efficient and flexible: they require fewer connections to sustain them, and only a small number of connections need to be changed to encode a different stimulus and alter the response properties of a neuron.                        ,                             The dendrites of neocortical pyramidal neurons are excitable. However, it is unknown how synaptic inputs engage nonlinear dendritic mechanisms during sensory processing in vivo, and how they in turn influence action potential output. Here, we provide a quantitative account of the relationship between synaptic inputs, nonlinear dendritic events, and action potential output. We developed a detailed pyramidal neuron model constrained by in vivo dendritic recordings. We drive this model with realistic input patterns constrained by sensory responses measured in vivo and connectivity measured in vitro. We show mechanistically that under realistic conditions, dendritic Na               +               and NMDA spikes are the major determinants of neuronal output in vivo. We demonstrate that these dendritic spikes can be triggered by a surprisingly small number of strong synaptic inputs, in some cases even by single synapses. We predict that dendritic excitability allows the 1\% strongest synaptic inputs of a neuron to control the tuning of its output. Active dendrites therefore allow smaller subcircuits consisting of only a few strongly connected neurons to achieve selectivity for specific sensory features.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XQ6LMJPM\\Goetz et al. - 2021 - Active dendrites enable strong but sparse inputs t.pdf}
}

@article{golloActiveDendritesEnhance2009,
  title = {Active {{Dendrites Enhance Neuronal Dynamic Range}}},
  author = {Gollo, Leonardo L. and Kinouchi, Osame and Copelli, Mauro},
  date = {2009-06-12},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {6},
  pages = {e1000402},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000402},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000402},
  urldate = {2022-09-02},
  abstract = {Since the first experimental evidences of active conductances in dendrites, most neurons have been shown to exhibit dendritic excitability through the expression of a variety of voltage-gated ion channels. However, despite experimental and theoretical efforts undertaken in the past decades, the role of this excitability for some kind of dendritic computation has remained elusive. Here we show that, owing to very general properties of excitable media, the average output of a model of an active dendritic tree is a highly non-linear function of its afferent rate, attaining extremely large dynamic ranges (above 50 dB). Moreover, the model yields double-sigmoid response functions as experimentally observed in retinal ganglion cells. We claim that enhancement of dynamic range is the primary functional role of active dendritic conductances. We predict that neurons with larger dendritic trees should have larger dynamic range and that blocking of active conductances should lead to a decrease in dynamic range.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Neuronal dendrites,Neurons,Nonlinear dynamics,Psychophysics,Signal amplification,Synapses},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RP9KYMK6\\Gollo et al. - 2009 - Active Dendrites Enhance Neuronal Dynamic Range.pdf}
}

@article{haimFunctionalDiversityAstrocytes2017,
  title = {Functional Diversity of Astrocytes in Neural Circuit Regulation},
  author = {Haim, Lucile Ben and Rowitch, David H.},
  date = {2017-01},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {18},
  number = {1},
  pages = {31--41},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.159},
  url = {https://www.nature.com/articles/nrn.2016.159},
  urldate = {2020-11-22},
  abstract = {Astrocytes display numerous inter- and intra-regional distinctions, ranging from differences in their morphology to differential dynamics of calcium signalling.Astrocytes in specific neural circuits modulate neuronal activity, which affects a range of brain functions.Regionally encoded astrocyte functions are required for neuronal homeostasis and survival.Astrocyte heterogeneity is determined by the developmental patterning of the CNS and is refined in adulthood to produce highly specialized neuron–glia units.Under pathological conditions, reactive astrocytes display several molecular and functional changes that have a differential influence on disease outcome.New techniques will help to uncover the molecular and functional heterogeneity of astrocytes both in health and disease.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VX47A8UK\\Haim and Rowitch - 2017 - Functional diversity of astrocytes in neural circu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SHUCTZYZ\\nrn.2016.html}
}

@article{hattoriFunctionsDysfunctionsNeocortical2017,
  title = {Functions and Dysfunctions of Neocortical Inhibitory Neuron Subtypes},
  author = {Hattori, Ryoma and Kuchibhotla, Kishore V. and Froemke, Robert C. and Komiyama, Takaki},
  date = {2017-09},
  journaltitle = {Nature Neuroscience},
  volume = {20},
  number = {9},
  pages = {1199--1208},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4619},
  url = {https://www.nature.com/articles/nn.4619},
  urldate = {2020-12-18},
  abstract = {Hattori et al. review the recent advances in our understanding of the roles of inhibitory neuron subtypes in shaping the activity and plasticity states of neocortical circuits, how neuromodulators control inhibitory neuron subtypes, and the role of inhibitory neuron dysfunction in neurological disorders.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S94R3PKG\\Hattori et al. - 2017 - Functions and dysfunctions of neocortical inhibito.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FGRLI9NM\\nn.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J2RHJYGF\\nn.html}
}

@article{hawkinsWhyNeuronsHave2016,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff and Ahmad, Subutai},
  date = {2016},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {10},
  issn = {1662-5110},
  url = {https://www.frontiersin.org/articles/10.3389/fncir.2016.00023},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR88HUZS\\Hawkins and Ahmad - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018,
  title = {✅ {{Optimization}} by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.},
  keywords = {Avalanche,Optimization,Scaling Laws,Self-Organized Criticaility}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018a,
  title = {Optimization by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.}
}

@article{hubenerMouseVisualCortex2003,
  title = {Mouse Visual Cortex},
  author = {Hübener, Mark},
  date = {2003-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {13},
  number = {4},
  pages = {413--420},
  issn = {0959-4388},
  doi = {10.1016/S0959-4388(03)00102-8},
  url = {http://www.sciencedirect.com/science/article/pii/S0959438803001028},
  urldate = {2020-10-15},
  abstract = {Neurons in mouse visual cortex have diverse receptive field properties and they respond selectively to specific features of visual stimuli. Owing to the lateral position of the eyes, only about a third of the visual cortex receives input from both eyes, but many cells in this region are binocular. Similar to higher mammals, closing one eye during a critical period shifts the responses of cells, such that they are better driven by the non-deprived eye. In this review I illustrate how the combination of transgenic mouse technology with single cell recording and modern imaging techniques might lead to a further understanding of the mechanisms that underlie the development, plasticity, and function of the mammalian visual cortex.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BAN77Y2N\\Hübener - 2003 - Mouse visual cortex.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HH6QDPMT\\S0959438803001028.html}
}

@article{isomuraMulticontextBlindSource2019,
  title = {Multi-Context Blind Source Separation by Error-Gated {{Hebbian}} Rule},
  author = {Isomura, Takuya and Toyoizumi, Taro},
  date = {2019-05-09},
  journaltitle = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {7127},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-43423-z},
  url = {https://www.nature.com/articles/s41598-019-43423-z},
  urldate = {2020-10-21},
  abstract = {Animals need to adjust their inferences according to the context they are in. This is required for the multi-context blind source separation (BSS) task, where an agent needs to infer hidden sources from their context-dependent mixtures. The agent is expected to invert this mixing process for all contexts. Here, we show that a neural network that implements the error-gated Hebbian rule (EGHR) with sufficiently redundant sensory inputs can successfully learn this task. After training, the network can perform the multi-context BSS without further updating synapses, by retaining memories of all experienced contexts. This demonstrates an attractive use of the EGHR for dimensionality reduction by extracting low-dimensional sources across contexts. Finally, if there is a common feature shared across contexts, the EGHR can extract it and generalize the task to even inexperienced contexts. The results highlight the utility of the EGHR as a model for perceptual adaptation in animals.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UB5RABYB\\Isomura and Toyoizumi - 2019 - Multi-context blind source separation by error-gat.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GEK5TACD\\s41598-019-43423-z.html}
}

@article{iyerAvoidingCatastropheActive2022,
  title = {Avoiding {{Catastrophe}}: {{Active Dendrites Enable Multi-Task Learning}} in {{Dynamic Environments}}},
  shorttitle = {Avoiding {{Catastrophe}}},
  author = {Iyer, Abhiram and Grewal, Karan and Velu, Akash and Souza, Lucas Oliveira and Forest, Jeremy and Ahmad, Subutai},
  date = {2022},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {16},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2022.846219},
  urldate = {2022-09-02},
  abstract = {A key challenge for AI is to build embodied systems that operate in dynamically changing environments. Such systems must adapt to changing task contexts and learn continuously. Although standard deep learning systems achieve state of the art results on static benchmarks, they often struggle in dynamic scenarios. In these settings, error signals from multiple contexts can interfere with one another, ultimately leading to a phenomenon known as catastrophic forgetting. In this article we investigate biologically inspired architectures as solutions to these problems. Specifically, we show that the biophysical properties of dendrites and local inhibitory systems enable networks to dynamically restrict and route information in a context-specific manner. Our key contributions are as follows: first, we propose a novel artificial neural network architecture that incorporates active dendrites and sparse representations into the standard deep learning framework. Next, we study the performance of this architecture on two separate benchmarks requiring task-based adaptation: Meta-World, a multi-task reinforcement learning environment where a robotic agent must learn to solve a variety of manipulation tasks simultaneously; and a continual learning benchmark in which the model's prediction task changes throughout training. Analysis on both benchmarks demonstrates the emergence of overlapping but distinct and sparse subnetworks, allowing the system to fluidly learn multiple tasks with minimal forgetting. Our neural implementation marks the first time a single architecture has achieved competitive results in both multi-task and continual learning settings. Our research sheds light on how biological properties of neurons can inform deep learning systems to address dynamic scenarios that are typically impossible for traditional ANNs to solve.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DMC2I9KH\\Iyer et al. - 2022 - Avoiding Catastrophe Active Dendrites Enable Mult.pdf}
}

@report{jiaMultiareaFunctionalModules2020,
  type = {preprint},
  title = {Multi-Area Functional Modules Mediate Feedforward and Recurrent Processing in Visual Cortical Hierarchy},
  author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina and Olsen, Shawn R.},
  date = {2020-08-31},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.08.30.272948},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.08.30.272948},
  urldate = {2020-09-03},
  abstract = {The visual cortex is organized hierarchically, but extensive recurrent pathways make it challenging to decipher the flow of information with single neuron resolution. Here, we characterize spiking interactions in populations of neurons from six interconnected areas along the visual hierarchy in awake mice. We generated multi-area, directed graphs of neuronal communication and uncovered two spatially-distributed functional modules. One module is positioned to transmit feedforward sensory signals along the hierarchy, while the other receives convergent input and engages in recurrent processing. The modules differ in layer and area distributions, convergence and divergence, and population-level temporal dynamics. These results reveal a neuronal-resolution cortical network topology in which distinct processing modules are interlaced across multiple areas of the cortical hierarchy.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BLVG96MG\\Jia et al. - 2020 - Multi-area functional modules mediate feedforward .pdf}
}

@unpublished{jonesCanSingleNeurons2020,
  title = {Can {{Single Neurons Solve MNIST}}? {{The Computational Power}} of {{Biological Dendritic Trees}}},
  shorttitle = {Can {{Single Neurons Solve MNIST}}?},
  author = {Jones, Ilenna Simone and Kording, Konrad Paul},
  date = {2020-09-02},
  eprint = {2009.01269},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  url = {http://arxiv.org/abs/2009.01269},
  urldate = {2020-10-20},
  abstract = {Physiological experiments have highlighted how the dendrites of biological neurons can nonlinearly process distributed synaptic inputs. This is in stark contrast to units in artificial neural networks that are generally linear apart from an output nonlinearity. If dendritic trees can be nonlinear, biological neurons may have far more computational power than their artificial counterparts. Here we use a simple model where the dendrite is implemented as a sequence of thresholded linear units. We find that such dendrites can readily solve machine learning problems, such as MNIST or CIFAR-10, and that they benefit from having the same input onto several branches of the dendritic tree. This dendrite model is a special case of sparse network. This work suggests that popular neuron models may severely underestimate the computational power enabled by the biological fact of nonlinear dendrites and multiple synapses per pair of neurons. The next generation of artificial neural networks may significantly benefit from these biologically inspired dendritic architectures.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KM2A8TI3\\Jones and Kording - 2020 - Can Single Neurons Solve MNIST The Computational .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IJ669HZ2\\2009.html}
}

@article{jordanOpposingInfluenceTopdown2020,
  title = {Opposing {{Influence}} of {{Top-down}} and {{Bottom-up Input}} on {{Excitatory Layer}} 2/3 {{Neurons}} in {{Mouse Primary Visual Cortex}}},
  author = {Jordan, Rebecca and Keller, Georg B.},
  date = {2020-10-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.09.024},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627320307480},
  urldate = {2020-11-13},
  abstract = {Processing in cortical circuits is driven by combinations of cortical and subcortical inputs. These inputs are often conceptually categorized as bottom-up, conveying sensory information, and top-down, conveying contextual information. Using intracellular recordings in mouse primary visual cortex, we measured neuronal responses to visual input, locomotion, and visuomotor mismatches. We show that layer 2/3 (L2/3) neurons compute a difference between top-down motor-related input and bottom-up visual flow input. Most L2/3 neurons responded to visuomotor mismatch with either hyperpolarization or depolarization, and the size of this response was correlated with distinct physiological properties. Consistent with a subtraction of bottom-up and top-down input, visual and motor-related inputs had opposing influence on L2/3 neurons. In infragranular neurons, we found no evidence of a difference computation and responses were consistent with positive integration of visuomotor inputs. Our results provide evidence that L2/3 functions as a bidirectional comparator of top-down and bottom-up input.},
  langid = {english},
  keywords = {cortical microcircuit,prediction error,predictive processing,sensorimotor integration,visual cortex,whole cell recording},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9J66EG4S\\Jordan and Keller - 2020 - Opposing Influence of Top-down and Bottom-up Input.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ABHFGI2Q\\S0896627320307480.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RYTLFSZT\\S0896627320307480.html}
}

@article{junFullyIntegratedSilicon2017,
  title = {Fully Integrated Silicon Probes for High-Density Recording of Neural Activity},
  author = {Jun, James J. and Steinmetz, Nicholas A. and Siegle, Joshua H. and Denman, Daniel J. and Bauza, Marius and Barbarits, Brian and Lee, Albert K. and Anastassiou, Costas A. and Andrei, Alexandru and Aydın, Çağatay and Barbic, Mladen and Blanche, Timothy J. and Bonin, Vincent and Couto, João and Dutta, Barundeb and Gratiy, Sergey L. and Gutnisky, Diego A. and Häusser, Michael and Karsh, Bill and Ledochowitsch, Peter and Lopez, Carolina Mora and Mitelut, Catalin and Musa, Silke and Okun, Michael and Pachitariu, Marius and Putzeys, Jan and Rich, P. Dylan and Rossant, Cyrille and Sun, Wei-lung and Svoboda, Karel and Carandini, Matteo and Harris, Kenneth D. and Koch, Christof and O’Keefe, John and Harris, Timothy D.},
  date = {2017-11},
  journaltitle = {Nature},
  volume = {551},
  number = {7679},
  pages = {232--236},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature24636},
  url = {https://www.nature.com/articles/nature24636},
  urldate = {2020-10-15},
  abstract = {New silicon probes known as Neuropixels are shown to record from hundreds of neurons simultaneously in awake and freely moving rodents.},
  issue = {7679},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SDC74U3U\\Jun et al. - 2017 - Fully integrated silicon probes for high-density r.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9ZALZIUX\\nature24636.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EAA9FGVT\\nature24636.html}
}

@article{kampaRequirementDendriticCalcium2006,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-15},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.2006.111062},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CDGWIY7R\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5VNZ9KCI\\jphysiol.2006.html}
}

@article{kampaRequirementDendriticCalcium2006a,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-13},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.2006.111062},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\395JAX93\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UDTZJJIK\\jphysiol.2006.html}
}

@article{kaperIntroductionFocusIssue2013,
  title = {Introduction to {{Focus Issue}}: {{Rhythms}} and {{Dynamic Transitions}} in {{Neurological Disease}}: {{Modeling}}, {{Computation}}, and {{Experiment}}},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Kaper, Tasso J. and Kramer, Mark A. and Rotstein, Horacio G.},
  date = {2013-12-01},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {23},
  number = {4},
  pages = {046001},
  publisher = {{American Institute of Physics}},
  issn = {1054-1500},
  doi = {10.1063/1.4856276},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4856276},
  urldate = {2020-11-10},
  abstract = {Rhythmic neuronal oscillations across a broad range of frequencies, as well as spatiotemporal phenomena, such as waves and bumps, have been observed in various areas of the brain and proposed as critical to brain function. While there is a long and distinguished history of studying rhythms in nerve cells and neuronal networks in healthy organisms, the association and analysis of rhythms to diseases are more recent developments. Indeed, it is now thought that certain aspects of diseases of the nervous system, such as epilepsy, schizophrenia, Parkinson's, and sleep disorders, are associated with transitions or disruptions of neurological rhythms. This focus issue brings together articles presenting modeling, computational, analytical, and experimental perspectives about rhythms and dynamic transitions between them that are associated to various diseases.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5AMZ5KXF\\Kaper et al. - 2013 - Introduction to Focus Issue Rhythms and Dynamic T.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7XEGAMJP\\1.html}
}

@article{kellerFeedbackGeneratesSecond2020,
  title = {Feedback Generates a Second Receptive Field in Neurons of the Visual Cortex},
  author = {Keller, Andreas J. and Roth, Morgane M. and Scanziani, Massimo},
  date = {2020-06},
  journaltitle = {Nature},
  volume = {582},
  number = {7813},
  pages = {545--549},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2319-4},
  url = {https://www.nature.com/articles/s41586-020-2319-4},
  urldate = {2020-10-05},
  abstract = {Animals sense the environment through pathways that link sensory organs to the brain. In the visual system, these feedforward pathways define the classical feedforward receptive field (ffRF), the area in space in which visual stimuli excite a neuron1. The visual system also uses visual context—the visual scene surrounding a stimulus—to predict the content of the stimulus2, and accordingly, neurons have been identified that are excited by stimuli outside their ffRF3–8. However, the mechanisms that generate excitation to stimuli outside the ffRF are unclear. Here we show that feedback projections onto excitatory neurons in the mouse primary visual cortex generate a second receptive field that is driven by stimuli outside the ffRF. The stimulation of this feedback receptive field (fbRF) elicits responses that are slower and are delayed in comparison with those resulting from the stimulation of the ffRF. These responses are preferentially reduced by anaesthesia and by silencing higher visual areas. Feedback inputs from higher visual areas have scattered receptive fields relative to their putative targets in the primary visual cortex, which enables the generation of the fbRF. Neurons with fbRFs are located in cortical layers that receive strong feedback projections and are absent in the main input layer, which is consistent with a laminar processing hierarchy. The observation that large, uniform stimuli—which cover both the fbRF and the ffRF—suppress these responses indicates that the fbRF and the ffRF are mutually antagonistic. Whereas somatostatin-expressing inhibitory neurons are driven by these large stimuli, inhibitory neurons that express parvalbumin and vasoactive intestinal peptide have mutually antagonistic fbRF and ffRF, similar to excitatory neurons. Feedback projections may therefore enable neurons to use context to estimate information that is missing from the ffRF and to report differences in stimulus features across visual space, regardless of whether excitation occurs inside or outside the ffRF. By complementing the ffRF, the fbRF that we identify here could contribute to predictive processing.},
  issue = {7813},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PLLQV9GI\\Keller et al. - 2020 - Feedback generates a second receptive field in neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PRBPYWTW\\s41586-020-2319-4.html}
}

@article{kellerSensorimotorMismatchSignals2012,
  title = {Sensorimotor {{Mismatch Signals}} in {{Primary Visual Cortex}} of the {{Behaving Mouse}}},
  author = {Keller, Georg~B. and Bonhoeffer, Tobias and Hübener, Mark},
  date = {2012-06-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {74},
  number = {5},
  pages = {809--815},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.03.040},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627312003844},
  urldate = {2020-11-06},
  abstract = {Studies in anesthetized animals have suggested that activity in early visual cortex is mainly driven by visual input and is well described by a feedforward processing hierarchy. However, evidence from experiments on awake animals has shown that both eye movements and behavioral state can strongly modulate responses of neurons in visual cortex; the functional significance of this modulation, however, remains elusive. Using visual-flow feedback manipulations during locomotion in a virtual reality environment, we found that responses in layer 2/3 of mouse primary visual cortex are strongly driven by locomotion and by mismatch between actual and expected visual feedback. These data suggest that processing in visual cortex may be based on predictive coding strategies that use motor-related and visual input to detect mismatches between predicted and actual visual feedback.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZHN6855\\Keller et al. - 2012 - Sensorimotor Mismatch Signals in Primary Visual Co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QHCV6A7V\\S0896627312003844.html}
}

@article{kindelUsingDeepLearning2019,
  title = {Using Deep Learning to Probe the Neural Code for Images in Primary Visual Cortex},
  author = {Kindel, William F. and Christensen, Elijah D. and Zylberberg, Joel},
  date = {2019-04-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {19},
  number = {4},
  pages = {29--29},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/19.4.29},
  url = {https://jov.arvojournals.org/article.aspx?articleid=2732380},
  urldate = {2020-10-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HMCBY5QM\\Kindel et al. - 2019 - Using deep learning to probe the neural code for i.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZYD6594X\\article.html}
}

@article{kostalStatisticsInverseInterspike2018,
  title = {Statistics of Inverse Interspike Intervals: {{The}} Instantaneous Firing Rate Revisited},
  shorttitle = {Statistics of Inverse Interspike Intervals},
  author = {Kostal, Lubomir and Lansky, Petr and Stiber, Michael},
  date = {2018-10},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {28},
  number = {10},
  pages = {106305},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5036831},
  url = {http://aip.scitation.org/doi/10.1063/1.5036831},
  urldate = {2020-09-30},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KTQJDBMS\\Kostal et al. - 2018 - Statistics of inverse interspike intervals The in.pdf}
}

@article{krakauerInformationTheoryIndividuality2020,
  title = {The Information Theory of Individuality},
  author = {Krakauer, David and Bertschinger, Nils and Olbrich, Eckehard and Flack, Jessica C. and Ay, Nihat},
  date = {2020-06},
  journaltitle = {Theory in Biosciences},
  shortjournal = {Theory Biosci.},
  volume = {139},
  number = {2},
  pages = {209--223},
  issn = {1431-7613, 1611-7530},
  doi = {10.1007/s12064-020-00313-7},
  url = {http://link.springer.com/10.1007/s12064-020-00313-7},
  urldate = {2022-09-21},
  abstract = {Despite the near universal assumption of individuality in biology, there is little agreement about what individuals are and few rigorous quantitative methods for their identification. Here, we propose that individuals are aggregates that preserve a measure of temporal integrity, i.e., “propagate” information from their past into their futures. We formalize this idea using information theory and graphical models. This mathematical formulation yields three principled and distinct forms of individuality—an organismal, a colonial, and a driven form—each of which varies in the degree of environmental dependence and inherited information. This approach can be thought of as a Gestalt approach to evolution where selection makes figure-ground (agent–environment) distinctions using suitable information-theoretic lenses. A benefit of the approach is that it expands the scope of allowable individuals to include adaptive aggregations in systems that are multi-scale, highly distributed, and do not necessarily have physical boundaries such as cell walls or clonal somatic tissue. Such individuals might be visible to selection but hard to detect by observers without suitable measurement principles. The information theory of individuality allows for the identification of individuals at all levels of organization from molecular to cultural and provides a basis for testing assumptions about the natural scales of a system and argues for the importance of uncertainty reduction through coarse-graining in adaptive systems.},
  langid = {english},
  keywords = {adaptation,coarse graining,information theory,synergy},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Q9S4KETP\\Krakauer et al. - 2020 - The information theory of individuality.pdf}
}

@article{krakauerNeuroscienceNeedsBehavior2017,
  title = {Neuroscience {{Needs Behavior}}: {{Correcting}} a {{Reductionist Bias}}},
  shorttitle = {Neuroscience {{Needs Behavior}}},
  author = {Krakauer, John W. and Ghazanfar, Asif A. and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
  date = {2017-02-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {3},
  eprint = {28182904},
  eprinttype = {pmid},
  pages = {480--490},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.12.041},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31040-6},
  urldate = {2020-08-13},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9D7RDCNE\\Krakauer et al. - 2017 - Neuroscience Needs Behavior Correcting a Reductio.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9UAXXT2K\\S0896-6273(16)31040-6.html}
}

@article{lainscsekCorticalChimeraStates2019,
  title = {Cortical Chimera States Predict Epileptic Seizures},
  author = {Lainscsek, Claudia and Rungratsameetaweemana, Nuttida and Cash, Sydney S. and Sejnowski, Terrence J.},
  date = {2019-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {29},
  number = {12},
  pages = {121106},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5139654},
  url = {http://aip.scitation.org/doi/10.1063/1.5139654},
  urldate = {2020-11-10},
  abstract = {A chimera state is a spatiotemporal pattern of broken symmetry, where synchrony (coherent state) and asynchrony (incoherent state) coexist. Here, we report chimera states in electrocorticography recordings preceding, by several hours, each of seven seizures in one patient with epilepsy. Before the seizures, the onset channels are not synchronized, while the remaining channels are synchronized. During the seizures, this pattern of behavior ips and the nononset channels show a more asynchronous behavior. At a seizure o set, synchrony can be observed that might facilitate termination.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XEUFDAHA\\Lainscsek et al. - 2019 - Cortical chimera states predict epileptic seizures.pdf}
}

@article{larkumCalciumElectrogenesisDistal1999,
  title = {Calcium Electrogenesis in Distal Apical Dendrites of Layer 5 Pyramidal Cells at a Critical Frequency of Back-Propagating Action Potentials},
  author = {Larkum, M. E. and Kaiser, K. M. M. and Sakmann, B.},
  date = {1999-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {96},
  number = {25},
  pages = {14600--14604},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.96.25.14600},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.96.25.14600},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RMSCZEU\\Larkum et al. - 1999 - Calcium electrogenesis in distal apical dendrites .pdf}
}

@article{larkumCellularMechanismCortical2013,
  title = {A Cellular Mechanism for Cortical Associations: An Organizing Principle for the Cerebral Cortex},
  shorttitle = {A Cellular Mechanism for Cortical Associations},
  author = {Larkum, Matthew},
  date = {2013-03},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {36},
  number = {3},
  pages = {141--151},
  issn = {01662236},
  doi = {10.1016/j.tins.2012.11.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223612002032},
  urldate = {2021-03-23},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MILLESZH\\Larkum - 2013 - A cellular mechanism for cortical associations an.pdf}
}

@article{larkumNewCellularMechanism1999,
  title = {A New Cellular Mechanism for Coupling Inputs Arriving at Different Cortical Layers},
  author = {Larkum, Matthew E. and Zhu, J. Julius and Sakmann, Bert},
  date = {1999-03},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {398},
  number = {6725},
  pages = {338--341},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/18686},
  url = {http://www.nature.com/articles/18686},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UTWC2UTY\\Larkum et al. - 1999 - A new cellular mechanism for coupling inputs arriv.pdf}
}

@article{lavzinNonlinearDendriticProcessing2012,
  title = {Nonlinear Dendritic Processing Determines Angular Tuning of Barrel Cortex Neurons in Vivo},
  author = {Lavzin, Maria and Rapoport, Sophia and Polsky, Alon and Garion, Liora and Schiller, Jackie},
  date = {2012-10},
  journaltitle = {Nature},
  volume = {490},
  number = {7420},
  pages = {397--401},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature11451},
  url = {https://www.nature.com/articles/nature11451},
  urldate = {2022-09-02},
  abstract = {In vivo whole-cell recordings combined with an intracellular N-methyl-d-aspartate receptor (NMDAR) blocker and membrane hyperpolarization are used to examine the contribution of dendritic NMDAR-dependent regenerative responses to the angular tuning of layer 4 neurons; the results show that active dendritic processing sharpens the sensory responses of cortical neurons in vivo.},
  issue = {7420},
  langid = {english},
  keywords = {Action potential generation,Sensorimotor processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6IHP82TD\\Lavzin et al. - 2012 - Nonlinear dendritic processing determines angular .pdf}
}

@video{LectureWalkthroughMammalian,
  title = {Lecture 1: {{A Walk-through}} of the {{Mammalian Visual System}}},
  shorttitle = {Lecture 1},
  url = {https://www.youtube.com/watch?v=mtPgW1ebxmE&t=2278s},
  urldate = {2020-09-25},
  abstract = {From the retina to the superior colliculus, the lateral geniculate nucleus into primary visual cortex and beyond, R. Clay Reid gives a tour of the mammalian visual system highlighting the Nobel-prize winning discoveries of Hubel \&amp; Wiesel. This is the first lecture of a 12-part series entitled Coding \&amp; Vision 101, produced by the Allen Institute for Brain Science as an educational resource for the community.}
}

@unpublished{liStatisticalMechanicsDeep2020,
  title = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}: {{The Back-Propagating Renormalization Group}}},
  shorttitle = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}},
  author = {Li, Qianyi and Sompolinsky, Haim},
  date = {2020-12-07},
  eprint = {2012.04030},
  eprinttype = {arxiv},
  primaryclass = {physics},
  url = {http://arxiv.org/abs/2012.04030},
  urldate = {2021-03-04},
  abstract = {The success of deep learning in many real-world tasks has triggered an effort to theoretically understand the power and limitations of deep learning in training and generalization of complex tasks, so far with limited progress. In this work, we study the statistical mechanics of learning in Deep Linear Neural Networks (DLNNs) in which the input-output function of an individual unit is linear. Despite the linearity of the units, learning in DLNNs is highly nonlinear, hence studying its properties reveals some of the essential features of nonlinear Deep Neural Networks (DNNs). We solve exactly the network properties following supervised learning using an equilibrium Gibbs distribution in the weight space. To do this, we introduce the Back-Propagating Renormalization Group (BPRG) which allows for the incremental integration of the network weights layer by layer from the network output layer and progressing backward. This procedure allows us to evaluate important network properties such as its generalization error, the role of network width and depth, the impact of the size of the training set, and the effects of weight regularization and learning stochasticity. Furthermore, by performing partial integration of layers, BPRG allows us to compute the emergent properties of the neural representations across the different hidden layers. We have proposed a heuristic extension of the BPRG to nonlinear DNNs with rectified linear units (ReLU). Surprisingly, our numerical simulations reveal that despite the nonlinearity, the predictions of our theory are largely shared by ReLU networks with modest depth, in a wide regime of parameters. Our work is the first exact statistical mechanical study of learning in a family of Deep Neural Networks, and the first development of the Renormalization Group approach to the weight space of these systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Physics - Applied Physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SBDNST6E\\Li and Sompolinsky - 2020 - Statistical Mechanics of Deep Linear Neural Networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A7ID7JS8\\2012.html}
}

@article{londonDendriticComputation2005,
  title = {Dendritic {{Computation}}},
  author = {London, Michael and Häusser, Michael},
  date = {2005},
  journaltitle = {Annual Review of Neuroscience},
  volume = {28},
  number = {1},
  eprint = {16033324},
  eprinttype = {pmid},
  pages = {503--532},
  doi = {10.1146/annurev.neuro.28.061604.135703},
  url = {https://doi.org/10.1146/annurev.neuro.28.061604.135703},
  urldate = {2022-09-08},
  abstract = {One of the central questions in neuroscience is how particular tasks, or computations, are implemented by neural networks to generate behavior. The prevailing view has been that information processing in neural networks results primarily from the properties of synapses and the connectivity of neurons within the network, with the intrinsic excitability of single neurons playing a lesser role. As a consequence, the contribution of single neurons to computation in the brain has long been underestimated. Here we review recent work showing that neuronal dendrites exhibit a range of linear and nonlinear mechanisms that allow them to implement elementary computations. We discuss why these dendritic properties may be essential for the computations performed by the neuron and the network and provide theoretical and experimental examples to support this view.},
  keywords = {coding,dendrites,ion channels,spikes,synaptic integration},
  annotation = {\_eprint: https://doi.org/10.1146/annurev.neuro.28.061604.135703}
}

@article{luResynchronizationCircadianOscillators2016,
  title = {Resynchronization of Circadian Oscillators and the East-West Asymmetry of Jet-Lag},
  author = {Lu, Zhixin and Klein-Cardeña, Kevin and Lee, Steven and Antonsen, Thomas M. and Girvan, Michelle and Ott, Edward},
  date = {2016-07-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {26},
  number = {9},
  pages = {094811},
  publisher = {{American Institute of Physics}},
  issn = {1054-1500},
  doi = {10.1063/1.4954275},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4954275},
  urldate = {2020-11-10},
  abstract = {Cells in the brain's Suprachiasmatic Nucleus (SCN) are known to regulate circadian rhythms in mammals. We model synchronization of SCN cells using the forced Kuramoto model, which consists of a large population of coupled phase oscillators (modeling individual SCN cells) with heterogeneous intrinsic frequencies and external periodic forcing. Here, the periodic forcing models diurnally varying external inputs such as sunrise, sunset, and alarm clocks. We reduce the dimensionality of the system using the ansatz of Ott and Antonsen and then study the effect of a sudden change of clock phase to simulate cross-time-zone travel. We estimate model parameters from previous biological experiments. By examining the phase space dynamics of the model, we study the mechanism leading to the difference typically experienced in the severity of jet-lag resulting from eastward and westward travel.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\386DU3WN\\Lu et al. - 2016 - Resynchronization of circadian oscillators and the.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T66BF8L3\\1.html}
}

@article{lynnSyntheticLikelihoodSolution2020,
  title = {A {{Synthetic Likelihood Solution}} to the {{Silent Synapse Estimation Problem}}},
  author = {Lynn, Michael B. and Lee, Kevin F. H. and Soares, Cary and Naud, Richard and Béïque, Jean-Claude},
  date = {2020-07-21},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {32},
  number = {3},
  eprint = {32697998},
  eprinttype = {pmid},
  publisher = {{Elsevier}},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2020.107916},
  url = {https://www.cell.com/cell-reports/abstract/S2211-1247(20)30897-4},
  urldate = {2020-10-22},
  langid = {english},
  keywords = {plasticity,silent synapses,statistical inference,synthetic likelihood},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FVJHXBBC\\Lynn et al. - 2020 - A Synthetic Likelihood Solution to the Silent Syna.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V6576NK9\\S2211-1247(20)30897-4.html}
}

@article{mengualEfficientLowPassDendroSomatic2020,
  title = {Efficient {{Low-Pass Dendro-Somatic Coupling}} in the {{Apical Dendrite}} of {{Layer}} 5 {{Pyramidal Neurons}} in the {{Anterior Cingulate Cortex}}},
  author = {Mengual, Ulisses Marti and Wybo, Willem A. M. and Spierenburg, Lotte J. E. and Santello, Mirko and Senn, Walter and Nevian, Thomas},
  date = {2020-11-11},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {40},
  number = {46},
  eprint = {33046549},
  eprinttype = {pmid},
  pages = {8799--8815},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3028-19.2020},
  url = {https://www.jneurosci.org/content/40/46/8799},
  urldate = {2020-11-11},
  abstract = {Signal propagation in the dendrites of many neurons, including cortical pyramidal neurons in sensory cortex, is characterized by strong attenuation toward the soma. In contrast, using dual whole-cell recordings from the apical dendrite and soma of layer 5 (L5) pyramidal neurons in the anterior cingulate cortex (ACC) of adult male mice we found good coupling, particularly of slow subthreshold potentials like NMDA spikes or trains of EPSPs from dendrite to soma. Only the fastest EPSPs in the ACC were reduced to a similar degree as in primary somatosensory cortex, revealing differential low-pass filtering capabilities. Furthermore, L5 pyramidal neurons in the ACC did not exhibit dendritic Ca2+ spikes as prominently found in the apical dendrite of S1 (somatosensory cortex) pyramidal neurons. Fitting the experimental data to a NEURON model revealed that the specific distribution of Ileak, Iir, Im, and Ih was sufficient to explain the electrotonic dendritic structure causing a leaky distal dendritic compartment with correspondingly low input resistance and a compact perisomatic region, resulting in a decoupling of distal tuft branches from each other while at the same time efficiently connecting them to the soma. Our results give a biophysically plausible explanation of how a class of prefrontal cortical pyramidal neurons achieve efficient integration of subthreshold distal synaptic inputs compared with the same cell type in sensory cortices. SIGNIFICANCE STATEMENT Understanding cortical computation requires the understanding of its fundamental computational subunits. Layer 5 pyramidal neurons are the main output neurons of the cortex, integrating synaptic inputs across different cortical layers. Their elaborate dendritic tree receives, propagates, and transforms synaptic inputs into action potential output. We found good coupling of slow subthreshold potentials like NMDA spikes or trains of EPSPs from the distal apical dendrite to the soma in pyramidal neurons in the ACC, which was significantly better compared with S1. This suggests that frontal pyramidal neurons use a different integration scheme compared with the same cell type in somatosensory cortex, which has important implications for our understanding of information processing across different parts of the neocortex.},
  langid = {english},
  keywords = {anterior cingulate cortex,biophysical model,dendrite,electrical properties,NMDA spike,pyramidal neuron},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FHJDYBBD\\8799.html}
}

@article{milojkovicVoltageCalciumTransients2007,
  title = {Voltage and Calcium Transients in Basal Dendrites of the Rat Prefrontal Cortex},
  author = {Milojkovic, Bogdan A and Zhou, Wen-Liang and Antic, Srdjan D},
  date = {2007-12-01},
  journaltitle = {The Journal of Physiology},
  shortjournal = {J Physiol},
  volume = {585},
  eprint = {17932150},
  eprinttype = {pmid},
  pages = {447--468},
  issn = {0022-3751},
  doi = {10.1113/jphysiol.2007.142315},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2375496/},
  urldate = {2022-09-04},
  abstract = {Higher cortical functions (perception, cognition, learning and memory) are in large part based on the integration of electrical and calcium signals that takes place in thin dendritic branches of neocortical pyramidal cells (synaptic integration). The mechanisms underlying the synaptic integration in thin basal dendrites are largely unexplored. We use a recently developed technique, multisite voltage–calcium imaging, to compare voltage and calcium transients from multiple locations along individual dendritic branches. Our results reveal characteristic electrical transients (plateau potentials) that trigger and shape dendritic calcium dynamics and calcium distribution during suprathreshold glutamatergic synaptic input. We regularly observed three classes of voltage–calcium interactions occurring simultaneously in three different zones of the same dendritic branch: (1) proximal to the input site, (2) at the input site, and (3) distal to the input site. One hundred micrometers away from the synaptic input site, both proximally and distally, dendritic calcium transients are in tight temporal correlation with the dendritic plateau potential. However, on the same dendrite, at the location of excitatory input, calcium transients outlast local dendritic plateau potentials by severalfold. These Ca2+ plateaus (duration 0.5–2 s) are spatially restricted to the synaptic input site, where they cause a brief down-regulation of dendritic excitability. Ca2+ plateaus are not mediated by Ca2+ release from intracellular stores, but rather by an NMDA-dependent small-amplitude depolarization, which persists after the collapse of the dendritic plateau potential. These unique features of dendritic voltage and calcium distributions may provide distinct zones for simultaneous long-term (bidirectional) modulation of synaptic contacts along the same basal branch.},
  issue = {Pt 2},
  pmcid = {PMC2375496},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SJANQFB9\\Milojkovic et al. - 2007 - Voltage and calcium transients in basal dendrites .pdf}
}

@article{murakamiThreedimensionalSinglecellresolutionWholebrain2018,
  title = {A Three-Dimensional Single-Cell-Resolution Whole-Brain Atlas Using {{CUBIC-X}} Expansion Microscopy and Tissue Clearing},
  author = {Murakami, Tatsuya C. and Mano, Tomoyuki and Saikawa, Shu and Horiguchi, Shuhei A. and Shigeta, Daichi and Baba, Kousuke and Sekiya, Hiroshi and Shimizu, Yoshihiro and Tanaka, Kenji F. and Kiyonari, Hiroshi and Iino, Masamitsu and Mochizuki, Hideki and Tainaka, Kazuki and Ueda, Hiroki R.},
  date = {2018-04},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {4},
  pages = {625--637},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-018-0109-1},
  url = {http://www.nature.com/articles/s41593-018-0109-1},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YRT4C5FC\\Murakami et al. - 2018 - A three-dimensional single-cell-resolution whole-b.pdf}
}

@article{nagaiHyperactivityDisruptedAttention2019,
  title = {Hyperactivity with {{Disrupted Attention}} by {{Activation}} of an {{Astrocyte Synaptogenic Cue}}},
  author = {Nagai, Jun and Rajbhandari, Abha K. and Gangwani, Mohitkumar R. and Hachisuka, Ayaka and Coppola, Giovanni and Masmanidis, Sotiris C. and Fanselow, Michael S. and Khakh, Baljit S.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31031006},
  eprinttype = {pmid},
  pages = {1280-1292.e20},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.03.019},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30281-8},
  urldate = {2020-11-19},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Hyperactivity and disturbances of attention are common behavioral disorders whose underlying cellular and neural circuit causes are not understood. We report the discovery that striatal astrocytes drive such phenotypes through a hitherto unknown synaptic mechanism. We found that striatal medium spiny neurons (MSNs) triggered astrocyte signaling via γ-aminobutyric acid B (GABA\textsubscript{B}) receptors. Selective chemogenetic activation of this pathway in striatal astrocytes \emph{in vivo} resulted in acute behavioral hyperactivity and disrupted attention. Such responses also resulted in upregulation of the synaptogenic cue thrombospondin-1 (TSP1) in astrocytes, increased excitatory synapses, enhanced corticostriatal synaptic transmission, and increased MSN action potential firing \emph{in vivo}. All of these changes were reversed by blocking TSP1 effects. Our data identify a form of bidirectional neuron-astrocyte communication and demonstrate that acute reactivation of a single latent astrocyte synaptogenic cue alters striatal circuits controlling behavior, revealing astrocytes and the TSP1 pathway as therapeutic targets in hyperactivity, attention deficit, and related psychiatric disorders.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QL43PTNP\\Nagai et al. - 2019 - Hyperactivity with Disrupted Attention by Activati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EIJG9CWV\\S0092-8674(19)30281-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J9QEMWAI\\S0092-8674(19)30281-8.html}
}

@article{naudNoiseGatedDendrosomatic2017,
  title = {Noise {{Gated}} by {{Dendrosomatic Interactions Increases Information Transmission}}},
  author = {Naud, Richard and Payeur, Alexandre and Longtin, André},
  date = {2017-09-13},
  journaltitle = {Physical Review X},
  shortjournal = {Phys. Rev. X},
  volume = {7},
  number = {3},
  pages = {031045},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.7.031045},
  url = {https://link.aps.org/doi/10.1103/PhysRevX.7.031045},
  urldate = {2022-09-21},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GKLW9AKX\\Naud et al. - 2017 - Noise Gated by Dendrosomatic Interactions Increase.pdf}
}

@article{naudSparseBurstsOptimize2018,
  title = {Sparse Bursts Optimize Information Transmission in a Multiplexed Neural Code},
  author = {Naud, Richard and Sprekeler, Henning},
  date = {2018-07-03},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {115},
  number = {27},
  eprint = {29934400},
  eprinttype = {pmid},
  pages = {E6329-E6338},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1720995115},
  url = {https://www.pnas.org/content/115/27/E6329},
  urldate = {2020-08-25},
  abstract = {Many cortical neurons combine the information ascending and descending the cortical hierarchy. In the classical view, this information is combined nonlinearly to give rise to a single firing-rate output, which collapses all input streams into one. We analyze the extent to which neurons can simultaneously represent multiple input streams by using a code that distinguishes spike timing patterns at the level of a neural ensemble. Using computational simulations constrained by experimental data, we show that cortical neurons are well suited to generate such multiplexing. Interestingly, this neural code maximizes information for short and sparse bursts, a regime consistent with in vivo recordings. Neurons can also demultiplex this information, using specific connectivity patterns. The anatomy of the adult mammalian cortex suggests that these connectivity patterns are used by the nervous system to maintain sparse bursting and optimal multiplexing. Contrary to firing-rate coding, our findings indicate that the physiology and anatomy of the cortex may be interpreted as optimizing the transmission of multiple independent signals to different targets.},
  langid = {english},
  keywords = {cerebral cortex,dendritic computation,multiplexing,neural coding,short-term plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\OneDrive - University of Ottawa\\Research Paper Notes\\Notes_BurstEnsembleMultiplexing_NuadSprekeler.docx;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JTWG4V7X\\Naud and Sprekeler - 2018 - Sparse bursts optimize information transmission in.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6RKQU5B\\BEM_Supplemental.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DFQ65QTH\\E6329.html}
}

@article{naudSpiketimingPredictionCortical2014,
  title = {Spike-Timing Prediction in Cortical Neurons with Active Dendrites},
  author = {Naud, Richard and Bathellier, Brice and Gerstner, Wulfram},
  date = {2014-08-13},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front Comput Neurosci},
  volume = {8},
  eprint = {25165443},
  eprinttype = {pmid},
  issn = {1662-5188},
  doi = {10.3389/fncom.2014.00090},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4131408/},
  urldate = {2020-09-05},
  abstract = {A complete single-neuron model must correctly reproduce the firing of spikes and bursts. We present a study of a simplified model of deep pyramidal cells of the cortex with active dendrites. We hypothesized that we can model the soma and its apical dendrite with only two compartments, without significant loss in the accuracy of spike-timing predictions. The model is based on experimentally measurable impulse-response functions, which transfer the effect of current injected in one compartment to current reaching the other. Each compartment was modeled with a pair of non-linear differential equations and a small number of parameters that approximate the Hodgkin-and-Huxley equations. The predictive power of this model was tested on electrophysiological experiments where noisy current was injected in both the soma and the apical dendrite simultaneously. We conclude that a simple two-compartment model can predict spike times of pyramidal cells stimulated in the soma and dendrites simultaneously. Our results support that regenerating activity in the apical dendritic is required to properly account for the dynamics of layer 5 pyramidal cells under in-vivo-like conditions.},
  pmcid = {PMC4131408},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5NAATHCA\\Naud et al. - 2014 - Spike-timing prediction in cortical neurons with a.pdf}
}

@incollection{pachitariuFastAccurateSpike2016,
  title = {Fast and Accurate Spike Sorting of High-Channel Count Probes with {{KiloSort}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  author = {Pachitariu, Marius and Steinmetz, Nicholas A and Kadir, Shabnam N and Carandini, Matteo and Harris, Kenneth D},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  date = {2016},
  pages = {4448--4456},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.pdf},
  urldate = {2020-10-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJBHFKT6\\Pachitariu et al. - 2016 - Fast and accurate spike sorting of high-channel co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HN68L2G4\\6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.html}
}

@article{palmerNMDASpikesEnhance2014,
  title = {{{NMDA}} Spikes Enhance Action Potential Generation during Sensory Input},
  author = {Palmer, Lucy M. and Shai, Adam S. and Reeve, James E. and Anderson, Harry L. and Paulsen, Ole and Larkum, Matthew E.},
  date = {2014-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {3},
  pages = {383--390},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3646},
  url = {https://www.nature.com/articles/nn.3646},
  urldate = {2022-09-04},
  abstract = {In vitro evidence suggests that the tuft dendrites of pyramidal neurons can evoke local NMDA spikes. The authors find that these local NMDA spikes occur spontaneously and following sensory input, and influence the number of output action potentials.},
  issue = {3},
  langid = {english},
  keywords = {Cellular neuroscience,Dendritic excitability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FZIBQNTR\\Palmer et al. - 2014 - NMDA spikes enhance action potential generation du.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2LGQI8DY\\nn.html}
}

@article{pardiThalamocorticalTopdownCircuit2020,
  title = {A Thalamocortical Top-down Circuit for Associative Memory},
  author = {Pardi, M. Belén and Vogenstahl, Johanna and Dalmay, Tamas and Spanò, Teresa and Pu, De-Lin and Naumann, Laura B. and Kretschmer, Friedrich and Sprekeler, Henning and Letzkus, Johannes J.},
  date = {2020-11-13},
  journaltitle = {Science},
  volume = {370},
  number = {6518},
  eprint = {33184213},
  eprinttype = {pmid},
  pages = {844--848},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.abc2399},
  url = {https://science.sciencemag.org/content/370/6518/844},
  urldate = {2020-11-17},
  abstract = {Higher-order thalamus input to the cortex Sensory information can only be used meaningfully in the brain when integrated with and compared with internally generated top-down signals. However, we know little about the brainwide afferents that convey such top-down signals, their information content, and learning-related plasticity. Pardi et al. identified the higher-order thalamus as a major source of top-down input to mouse auditory cortex and investigated a circuit in cortical layer 1 that facilitates plastic changes and flexible responses. These results demonstrate how top-down feedback information can reach cortical areas through a noncortical structure that has received little attention despite its widespread connections with the cortex. Science, this issue p. 844 The sensory neocortex is a critical substrate for memory. Despite its strong connection with the thalamus, the role of direct thalamocortical communication in memory remains elusive. We performed chronic in vivo two-photon calcium imaging of thalamic synapses in mouse auditory cortex layer 1, a major locus of cortical associations. Combined with optogenetics, viral tracing, whole-cell recording, and computational modeling, we find that the higher-order thalamus is required for associative learning and transmits memory-related information that closely correlates with acquired behavioral relevance. In turn, these signals are tightly and dynamically controlled by local presynaptic inhibition. Our results not only identify the higher-order thalamus as a highly plastic source of cortical top-down information but also reveal a level of computational flexibility in layer 1 that goes far beyond hard-wired connectivity. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CTWAH3UM\\Pardi et al. - 2020 - A thalamocortical top-down circuit for associative.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7C8C24Q6\\844.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FA2FWMZJ\\844.html}
}

@report{parkBayesianEfficientCoding2017,
  type = {preprint},
  title = {Bayesian {{Efficient Coding}}},
  author = {Park, Il Memming and Pillow, Jonathan W.},
  date = {2017-08-22},
  institution = {{Neuroscience}},
  doi = {10.1101/178418},
  url = {http://biorxiv.org/lookup/doi/10.1101/178418},
  urldate = {2020-10-27},
  abstract = {The efficient coding hypothesis, which proposes that neurons are optimized to maximize information about the environment, has provided a guiding theoretical framework for sensory and systems neuroscience. More recently, a theory known as the Bayesian Brain hypothesis has focused on the brain’s ability to integrate sensory and prior sources of information in order to perform Bayesian inference. However, there is as yet no comprehensive theory connecting these two theoretical frameworks. We bridge this gap by formalizing a Bayesian theory of efficient coding. We define Bayesian efficient codes in terms of four basic ingredients: (1) a stimulus prior distribution; (2) an encoding model; (3) a capacity constraint, specifying a neural resource limit; and (4) a loss function, quantifying the desirability or undesirability of various posterior distributions. Classic efficient codes can be seen as a special case in which the loss function is the posterior entropy, leading to a code that maximizes mutual information, but alternate loss functions give solutions that differ dramatically from information-maximizing codes. In particular, we show that decorrelation of sensory inputs, which is optimal under classic efficient codes in low-noise settings, can be disadvantageous for loss functions that penalize large errors. Bayesian efficient coding therefore enlarges the family of normatively optimal codes and provides a more general framework for understanding the design principles of sensory systems. We examine Bayesian efficient codes for linear receptive fields and nonlinear input-output functions, and show that our theory invites reinterpretation of Laughlin’s seminal analysis of efficient coding in the blowfly visual system.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4MLSRRNP\\Park and Pillow - 2017 - Bayesian Efficient Coding.pdf}
}

@article{parkContributionApicalBasal2019,
  title = {Contribution of Apical and Basal Dendrites to Orientation Encoding in Mouse {{V1 L2}}/3 Pyramidal Neurons},
  author = {Park, Jiyoung and Papoutsi, Athanasia and Ash, Ryan T. and Marin, Miguel A. and Poirazi, Panayiota and Smirnakis, Stelios M.},
  date = {2019-11-26},
  journaltitle = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5372},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13029-0},
  url = {https://www.nature.com/articles/s41467-019-13029-0},
  urldate = {2020-10-20},
  abstract = {Pyramidal neurons integrate synaptic inputs from basal and apical dendrites to generate stimulus-specific responses. It has been proposed that feed-forward inputs to basal dendrites drive a neuron’s stimulus preference, while feedback inputs to apical dendrites sharpen selectivity. However, how a neuron’s dendritic domains relate to its functional selectivity has not been demonstrated experimentally. We performed 2-photon dendritic micro-dissection on layer-2/3 pyramidal neurons in mouse primary visual cortex. We found that removing the apical dendritic tuft did not alter orientation-tuning. Furthermore, orientation-tuning curves were remarkably robust to the removal of basal dendrites: ablation of 2 basal dendrites was needed to cause a small shift in orientation preference, without significantly altering tuning width. Computational modeling corroborated our results and put limits on how orientation preferences among basal dendrites differ in order to reproduce the post-ablation data. In conclusion, neuronal orientation-tuning appears remarkably robust to loss of dendritic input.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QJKJEM4W\\Park et al. - 2019 - Contribution of apical and basal dendrites to orie.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR34UK2M\\s41467-019-13029-0.html}
}

@report{payeurBurstdependentSynapticPlasticity2020,
  type = {preprint},
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  date = {2020-03-31},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.03.30.015511},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.03.30.015511},
  urldate = {2020-08-30},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well-established that it depends on pre and postsynaptic activity. However, models that rely solely on pre and postsynaptic activity for synaptic changes have, to date, not been able to account for learning complex tasks that demand hierarchical networks. Here, we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then neurons higher in the hierarchy can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites, and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses, and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LYLJ22WE\\Payeur et al. - 2020 - Burst-dependent synaptic plasticity can coordinate.pdf}
}

@article{payeurClassesDendriticInformation2019,
  title = {Classes of Dendritic Information Processing},
  author = {Payeur, Alexandre and Béïque, Jean-Claude and Naud, Richard},
  date = {2019-10},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {58},
  pages = {78--85},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.07.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818302162},
  urldate = {2020-10-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VCG2EM7P\\Payeur et al. - 2019 - Classes of dendritic information processing.pdf}
}

@article{pereiraSleepingBrainExcitation2020,
  title = {Sleeping through Brain Excitation and Inhibition},
  author = {Pereira, Sofia I. R. and Lewis, Penelope A.},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1037--1039},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0697-4},
  url = {https://www.nature.com/articles/s41593-020-0697-4},
  urldate = {2020-11-21},
  abstract = {Sleep is controlled by a cocktail of neurotransmitters, but it is difficult to measure these in the brain. A new study by Tamaki et al. reveals how the balance between excitation and inhibition oscillates as the brain moves through sleep stages and how this impacts upon memory consolidation and stabilization.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\H2WSKIDR\\Pereira and Lewis - 2020 - Sleeping through brain excitation and inhibition.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EPJLDYWY\\s41593-020-0697-4.html}
}

@online{PIIB978008045046901648XElsevier,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=AEB3F00B9ED104FD4F7E76606FE19588C21B83127810BF9F8C6E89BE1FCAE11CE6A6ABBA6EC91D454A1A3CDF6D25E6CB},
  urldate = {2020-10-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2B6LN9IY\\B978008045046901648X.html}
}

@online{PIIB978008045046901648XElseviera,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=14DC8ABDF47BDB43F752CBB1A87E260A22FE7927547DE250D49B496B9F9F47BEEB1A020E3297C1075FAAFF93B56178B3},
  urldate = {2020-10-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DLMW5R2M\\B978008045046901648X.html}
}

@article{poiraziIlluminatingDendriticFunction2020,
  title = {Illuminating Dendritic Function with Computational Models},
  author = {Poirazi, Panayiota and Papoutsi, Athanasia},
  date = {2020-06},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {6},
  pages = {303--321},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0301-7},
  url = {https://www.nature.com/articles/s41583-020-0301-7},
  urldate = {2020-09-17},
  abstract = {Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires — and drives — new technological advances, thus closing the loop with theory-driven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities.},
  issue = {6},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I6KH3YVI\\Poirazi and Papoutsi - 2020 - Illuminating dendritic function with computational.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NCYGZ98Z\\s41583-020-0301-7.html}
}

@article{postnovaSleepModellingPhysiological2019,
  title = {Sleep {{Modelling}} across {{Physiological Levels}}},
  author = {Postnova, Svetlana},
  date = {2019-03},
  journaltitle = {Clocks \& Sleep},
  volume = {1},
  number = {1},
  pages = {166--184},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/clockssleep1010015},
  url = {https://www.mdpi.com/2624-5175/1/1/15},
  urldate = {2020-11-20},
  abstract = {Sleep and circadian rhythms are regulated across multiple functional, spatial and temporal levels: from genes to networks of coupled neurons and glial cells, to large scale brain dynamics and behaviour. The dynamics at each of these levels are complex and the interaction between the levels is even more so, so research have mostly focused on interactions within the levels to understand the underlying mechanisms\&mdash;the so-called reductionist approach. Mathematical models were developed to test theories of sleep regulation and guide new experiments at each of these levels and have become an integral part of the field. The advantage of modelling, however, is that it allows us to simulate and test the dynamics of complex biological systems and thus provides a tool to investigate the connections between the different levels and study the system as a whole. In this paper I review key models of sleep developed at different physiological levels and discuss the potential for an integrated systems biology approach for sleep regulation across these levels. I also highlight the necessity of building mechanistic connections between models of sleep and circadian rhythms across these levels.},
  issue = {1},
  langid = {english},
  keywords = {behaviour,circadian clocks,EEG,mathematical modelling,mean field,molecular mechanisms,multi-scale,neurons,sleep,systems biology},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6FZZQ2G\\Postnova - 2019 - Sleep Modelling across Physiological Levels.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U7C9SQC\\15.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9V3LXKLZ\\15.html}
}

@online{PrefrontalCortexExhibits,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making | {{Nature Neuroscience}}},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2021-02-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C89LMXCN\\s41593-020-0696-5.html}
}

@article{priceBayesianSyntheticLikelihood2018,
  title = {Bayesian {{Synthetic Likelihood}}},
  author = {Price, L. F. and Drovandi, C. C. and Lee, A. and Nott, D. J.},
  date = {2018-01-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {27},
  number = {1},
  pages = {1--11},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1302882},
  url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1302882},
  urldate = {2020-10-26},
  abstract = {Having the ability to work with complex models can be highly beneficial. However, complex models often have intractable likelihoods, so methods that involve evaluation of the likelihood function are infeasible. In these situations, the benefits of working with likelihood-free methods become apparent. Likelihood-free methods, such as parametric Bayesian indirect likelihood that uses the likelihood of an alternative parametric auxiliary model, have been explored throughout the literature as a viable alternative when the model of interest is complex. One of these methods is called the synthetic likelihood (SL), which uses a multivariate normal approximation of the distribution of a set of summary statistics. This article explores the accuracy and computational efficiency of the Bayesian version of the synthetic likelihood (BSL) approach in comparison to a competitor known as approximate Bayesian computation (ABC) and its sensitivity to its tuning parameters and assumptions. We relate BSL to pseudo-marginal methods and propose to use an alternative SL that uses an unbiased estimator of the SL, when the summary statistics have a multivariate normal distribution. Several applications of varying complexity are considered to illustrate the findings of this article. Supplemental materials are available online. Computer code for implementing the methods on all examples is available at https://github.com/cdrovandi/Bayesian-Synthetic-Likelihood.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A8HQ55AT\\Price et al. - 2018 - Bayesian Synthetic Likelihood.pdf}
}

@article{pureswaranParadigmsEasternSpruce2016,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-12-01},
  journaltitle = {Environmental Entomology},
  shortjournal = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  urldate = {2020-12-28},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.}
}

@article{pureswaranParadigmsEasternSpruce2016a,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-09},
  journaltitle = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.},
  annotation = {\_eprint: https://academic.oup.com/ee/article-pdf/45/6/1333/8660127/nvw103.pdf}
}

@article{quirogaSpikeSorting2007,
  title = {Spike Sorting},
  author = {Quiroga, Rodrigo Quian},
  date = {2007-12-21},
  journaltitle = {Scholarpedia},
  volume = {2},
  number = {12},
  pages = {3583},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.3583},
  url = {http://www.scholarpedia.org/article/Spike_sorting},
  urldate = {2020-10-15},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HDCQMX5J\\Spike_sorting.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6AG63MP\\Spike_sorting.html}
}

@article{ranganathanActiveDendriticIntegration2018,
  title = {Active Dendritic Integration and Mixed Neocortical Network Representations during an Adaptive Sensing Behavior},
  author = {Ranganathan, Gayathri N. and Apostolides, Pierre F. and Harnett, Mark T. and Xu, Ning-Long and Druckmann, Shaul and Magee, Jeffrey C.},
  date = {2018-11},
  journaltitle = {Nature neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {11},
  eprint = {30349100},
  eprinttype = {pmid},
  pages = {1583--1590},
  issn = {1097-6256},
  doi = {10.1038/s41593-018-0254-6},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6203624/},
  urldate = {2022-09-02},
  abstract = {Animals strategically scan the environment to form an accurate perception of their surroundings. Here we investigated the neuronal representations that mediate this behavior. Ca2+ imaging and selective optogenetic manipulation during an active sensing task reveals that L5 pyramidal neurons in the vibrissae cortex produce a diverse and distributed representation that is required for mice to adapt their whisking motor strategy to changing sensory cues. The optogenetic perturbation degraded single-neuron selectivity and network population encoding through a selective inhibition of active dendritic integration. Together the data indicate that active dendritic integration in pyramidal neurons produces a nonlinearly mixed network representation of joint sensorimotor parameters that is used to transform sensory information into motor commands during adaptive behavior. The prevalence of the L5 cortical circuit motif suggests that this is a general circuit computation.},
  pmcid = {PMC6203624},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8H923HS2\\Ranganathan et al. - 2018 - Active dendritic integration and mixed neocortical.pdf}
}

@article{richardsDendriticSolutionsCredit2019,
  title = {Dendritic Solutions to the Credit Assignment Problem},
  author = {Richards, Blake A and Lillicrap, Timothy P},
  date = {2019-02},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {54},
  pages = {28--36},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.08.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818300485},
  urldate = {2020-08-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\85TNZ67Y\\Richards and Lillicrap - 2019 - Dendritic solutions to the credit assignment probl.pdf}
}

@article{ritzau-jostUltrafastActionPotentials2014,
  title = {Ultrafast {{Action Potentials Mediate Kilohertz Signaling}} at a {{Central Synapse}}},
  author = {Ritzau-Jost, Andreas and Delvendahl, Igor and Rings, Annika and Byczkowicz, Niklas and Harada, Harumi and Shigemoto, Ryuichi and Hirrlinger, Johannes and Eilers, Jens and Hallermann, Stefan},
  date = {2014-10-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {84},
  number = {1},
  pages = {152--163},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.08.036},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627314007375},
  urldate = {2020-11-10},
  abstract = {Fast synaptic transmission is important for rapid information processing. To explore the maximal rate of neuronal signaling and to analyze the presynaptic mechanisms, we focused on the input layer of the cerebellar cortex, where exceptionally high action potential (AP) frequencies have been reported in~vivo. With paired recordings between presynaptic cerebellar mossy fiber boutons and postsynaptic granule cells, we demonstrate reliable neurotransmission up~to ∼1 kHz. Presynaptic APs are ultrafast, with ∼100~μs half-duration. Both Kv1 and Kv3 potassium channels mediate the fast repolarization, rapidly inactivating sodium channels ensure metabolic efficiency, and little AP broadening occurs during bursts of up to 1.5 kHz. Presynaptic Cav2.1 (P/Q-type) calcium channels open efficiently during ultrafast APs. Furthermore, a subset of synaptic vesicles is tightly coupled to Ca2+ channels, and vesicles are rapidly recruited to the release site. These data reveal mechanisms of presynaptic AP generation and transmitter release underlying neuronal kHz signaling.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6KSPEUFF\\Ritzau-Jost et al. - 2014 - Ultrafast Action Potentials Mediate Kilohertz Sign.pdf}
}

@article{rodriguesKuramotoModelComplex2016,
  title = {The {{Kuramoto}} Model in Complex Networks},
  author = {Rodrigues, Francisco A. and Peron, Thomas K. DM. and Ji, Peng and Kurths, Jürgen},
  date = {2016-01-26},
  journaltitle = {Physics Reports},
  shortjournal = {Physics Reports},
  series = {The {{Kuramoto}} Model in Complex Networks},
  volume = {610},
  pages = {1--98},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2015.10.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0370157315004408},
  urldate = {2020-10-06},
  abstract = {Synchronization of an ensemble of oscillators is an emergent phenomenon present in several complex systems, ranging from social and physical to biological and technological systems. The most successful approach to describe how coherent behavior emerges in these complex systems is given by the paradigmatic Kuramoto model. This model has been traditionally studied in complete graphs. However, besides being intrinsically dynamical, complex systems present very heterogeneous structure, which can be represented as complex networks. This report is dedicated to review main contributions in the field of synchronization in networks of Kuramoto oscillators. In particular, we provide an overview of the impact of network patterns on the local and global dynamics of coupled phase oscillators. We cover many relevant topics, which encompass a description of the most used analytical approaches and the analysis of several numerical results. Furthermore, we discuss recent developments on variations of the Kuramoto model in networks, including the presence of noise and inertia. The rich potential for applications is discussed for special fields in engineering, neuroscience, physics and Earth science. Finally, we conclude by discussing problems that remain open after the last decade of intensive research on the Kuramoto model and point out some promising directions for future research.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SG4U2JQZ\\Rodrigues et al. - 2016 - The Kuramoto model in complex networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X3SDT4JP\\S0370157315004408.html}
}

@report{rossbroichSynapticDynamicsConvolutional2020,
  type = {preprint},
  title = {Synaptic {{Dynamics}} as {{Convolutional Units}}},
  author = {Rossbroich, Julian and Trotter, Daniel and Tóth, Katalin and Naud, Richard},
  date = {2020-06-05},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.06.04.133892},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.04.133892},
  urldate = {2020-10-08},
  abstract = {Synaptic dynamics differ markedly across connections and strongly regulate how action potentials are being communicated. To model the range of synaptic dynamics observed in experiments, we develop a flexible mathematical framework based on a linear-nonlinear operation. This model can capture various experimentally observed features of synaptic dynamics and different types of heteroskedasticity. Despite its conceptual simplicity, we show it is more adaptable than previous models. Combined with a standard maximum likelihood approach, synaptic dynamics can be accurately and efficiently characterized using naturalistic stimulation patterns. These results make explicit that synaptic processing bears algorithmic similarities with information processing in convolutional neural networks.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M74KY9B4\\Rossbroich et al. - 2020 - Synaptic Dynamics as Convolutional Units.pdf}
}

@article{sakmannHighfrequencySpikeBursts,
  title = {High-Frequency Spike Bursts in Cortical Layer 5 Thick Tufted Pyramds Provide a Brian-Wide Signal to Encode Exploratory Touch},
  author = {Sakmann, Kock},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z4PXBR88\\Sakmann - High-frequency spike bursts in cortical layer 5 th.pdf}
}

@article{santelloAstrocyteFunctionInformation2019,
  title = {Astrocyte Function from Information Processing to Cognition and Cognitive Impairment},
  author = {Santello, Mirko and Toni, Nicolas and Volterra, Andrea},
  date = {2019-02},
  journaltitle = {Nature Neuroscience},
  volume = {22},
  number = {2},
  pages = {154--166},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0325-8},
  url = {https://www.nature.com/articles/s41593-018-0325-8},
  urldate = {2020-11-21},
  abstract = {Astrocytes serve important roles that affect recruitment and function of neurons at the local and network levels. Here we review the contributions of astrocyte signaling to synaptic plasticity, neuronal network oscillations, and memory function. The roles played by astrocytes are not fully understood, but astrocytes seem to contribute to memory consolidation and seem to mediate the effects of vigilance and arousal on memory performance. Understanding the role of astrocytes in cognitive processes may also advance our understanding of how these processes go awry in pathological conditions. Indeed, abnormal astrocytic signaling can cause or contribute to synaptic and network imbalances, leading to cognitive impairment. We discuss evidence for this from animal models of Alzheimer’s disease and multiple sclerosis and from animal studies of sleep deprivation and drug abuse and addiction. Understanding the emerging roles of astrocytes in cognitive function and dysfunction will open up a large array of new therapeutic opportunities.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CK2ZG4NV\\Santello et al. - 2019 - Astrocyte function from information processing to .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\24AM7V7M\\s41593-018-0325-8.html}
}

@article{sassiCoupledNonlinearOscillators,
  title = {Coupled {{Nonlinear Oscillators}}},
  author = {Sassi, Roberto},
  pages = {26},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UUSGGFIA\\Sassi - Coupled Nonlinear Oscillators.pdf}
}

@article{schmutzMesoscopicPopulationEquations2020,
  title = {Mesoscopic Population Equations for Spiking Neural Networks with Synaptic Short-Term Plasticity},
  author = {Schmutz, Valentin and Gerstner, Wulfram and Schwalger, Tilo},
  date = {2020-04-06},
  journaltitle = {The Journal of Mathematical Neuroscience},
  shortjournal = {The Journal of Mathematical Neuroscience},
  volume = {10},
  number = {1},
  pages = {5},
  issn = {2190-8567},
  doi = {10.1186/s13408-020-00082-z},
  url = {https://doi.org/10.1186/s13408-020-00082-z},
  urldate = {2020-11-16},
  abstract = {Coarse-graining microscopic models of biological neural networks to obtain mesoscopic models of neural activities is an essential step towards multi-scale models of the brain. Here, we extend a recent theory for mesoscopic population dynamics with static synapses to the case of dynamic synapses exhibiting short-term plasticity (STP). The extended theory offers an approximate mean-field dynamics for the synaptic input currents arising from populations of spiking neurons and synapses undergoing Tsodyks–Markram STP. The approximate mean-field dynamics accounts for both finite number of synapses and correlation between the two synaptic variables of the model (utilization and available resources) and its numerical implementation is simple. Comparisons with Monte Carlo simulations of the microscopic model show that in both feedforward and recurrent networks, the mesoscopic mean-field model accurately reproduces the first- and second-order statistics of the total synaptic input into a postsynaptic neuron and accounts for stochastic switches between Up and Down states and for population spikes. The extended mesoscopic population theory of spiking neural networks with STP may be useful for a systematic reduction of detailed biophysical models of cortical microcircuits to numerically efficient and mathematically tractable mean-field models.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IPLSBJ3D\\Schmutz et al. - 2020 - Mesoscopic population equations for spiking neural.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A9YIWBE5\\s13408-020-00082-z.html}
}

@unpublished{shiComparisonTaskDriven2019,
  title = {Comparison {{Against Task Driven Artificial Neural Networks Reveals Functional Organization}} of {{Mouse Visual Cortex}}},
  author = {Shi, Jianghong and Shea-Brown, Eric and Buice, Michael A.},
  date = {2019-11-18},
  eprint = {1911.07986},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  url = {http://arxiv.org/abs/1911.07986},
  urldate = {2020-10-08},
  abstract = {Partially inspired by features of computation in visual cortex, deep neural networks compute hierarchical representations of their inputs. While these networks have been highly successful in machine learning, it remains unclear to what extent they can aid our understanding of cortical function. Several groups have developed metrics that provide a quantitative comparison between representations computed by networks and representations measured in cortex. At the same time, neuroscience is well into an unprecedented phase of large-scale data collection, as evidenced by projects such as the Allen Brain Observatory. Despite the magnitude of these efforts, in a given experiment only a fraction of units are recorded, limiting the information available about the cortical representation. Moreover, only a finite number of stimuli can be shown to an animal over the course of a realistic experiment. These limitations raise the question of how and whether metrics that compare representations of deep networks are meaningful on these datasets. Here, we empirically quantify the capabilities and limitations of these metrics due to limited image presentations and neuron samples. We find that the comparison procedure is robust to different choices of stimuli set and the level of subsampling that one might expect in a large-scale brain survey with thousands of neurons. Using these results, we compare the representations measured in the Allen Brain Observatory in response to natural image presentations to deep neural network. We show that the visual cortical areas are relatively high order representations (in that they map to deeper layers of convolutional neural networks). Furthermore, we see evidence of a broad, more parallel organization rather than a sequential hierarchy, with the primary area VISp(V1) being lower order relative to the other areas.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AKT8V8NC\\Shi et al. - 2019 - Comparison Against Task Driven Artificial Neural N.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYLHR5I9\\1911.html}
}

@article{sinhaActiveDendritesLocal2022,
  title = {Active {{Dendrites}} and {{Local Field Potentials}}: {{Biophysical Mechanisms}} and {{Computational Explorations}}},
  shorttitle = {Active {{Dendrites}} and {{Local Field Potentials}}},
  author = {Sinha, Manisha and Narayanan, Rishikesh},
  date = {2022-05-01},
  journaltitle = {Neuroscience},
  shortjournal = {Neuroscience},
  series = {Dendritic Contributions to Biological and Artificial Computations},
  volume = {489},
  pages = {111--142},
  issn = {0306-4522},
  doi = {10.1016/j.neuroscience.2021.08.035},
  url = {https://www.sciencedirect.com/science/article/pii/S0306452221004504},
  urldate = {2022-09-02},
  abstract = {Neurons and glial cells are endowed with membranes that express a rich repertoire of ion channels, transporters, and receptors. The constant flux of ions across the neuronal and glial membranes results in voltage fluctuations that can be recorded from the extracellular matrix. The high frequency components of this voltage signal contain information about the spiking activity, reflecting the output from the neurons surrounding the recording location. The low frequency components of the signal, referred to as the local field potential (LFP), have been traditionally thought to provide information about the synaptic inputs that impinge on the large dendritic trees of various neurons. In this review, we discuss recent computational and experimental studies pointing to a critical role of several active dendritic mechanisms that can influence the genesis and the location-dependent spectro-temporal dynamics of LFPs, spanning different brain regions. We strongly emphasize the need to account for the several fast and slow dendritic events and associated active mechanisms — including gradients in their expression profiles, inter- and intra-cellular spatio-temporal interactions spanning neurons and glia, heterogeneities and degeneracy across scales, neuromodulatory influences, and activitydependent plasticity — towards gaining important insights about the origins of LFP under different behavioral states in health and disease. We provide simple but essential guidelines on how to model LFPs taking into account these dendritic mechanisms, with detailed methodology on how to account for various heterogeneities and electrophysiological properties of neurons and synapses while studying LFPs.},
  langid = {english},
  keywords = {computational models,degeneracy,heterogeneity,ion channels,neural plasticity,oscillations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CH26RKTL\\Sinha and Narayanan - 2022 - Active Dendrites and Local Field Potentials Bioph.pdf}
}

@incollection{sprustonDendriticSignalIntegration2009,
  title = {Dendritic {{Signal Integration}}},
  booktitle = {Encyclopedia of {{Neuroscience}}},
  author = {Spruston, N.},
  editor = {Squire, Larry R.},
  date = {2009-01-01},
  pages = {445--452},
  publisher = {{Academic Press}},
  location = {{Oxford}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {http://www.sciencedirect.com/science/article/pii/B978008045046901648X},
  urldate = {2020-10-29},
  abstract = {Neurons integrate inputs from a large number of synapses in a process called synaptic integration. The term ‘dendritic integration’ refers to aspects of synaptic integration that occur in dendrites. To understand dendritic integration, it is necessary to understand basic principles of synaptic integration, as well as the ways in which branching dendrites affect synaptic integration. This article reviews what is known about these processes, beginning with simple examples of interactions between excitatory synapses and progressing to more complex cases, including dendritically localized excitatory and inhibitory synapses and the influence of dendritic voltage-gated channels on dendritic integration.},
  isbn = {978-0-08-045046-9},
  langid = {english},
  keywords = {Action potential,Axon,Dendrite,EPSP,Ion channel,IPSP,Synapse,Synaptic potential},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5LLI3CH2\\B978008045046901648X.html}
}

@article{sprustonPyramidalNeuronsDendritic2008,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {3},
  pages = {206--221},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2286},
  url = {http://www.nature.com/articles/nrn2286},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons are characterized by their distinct apical and basal dendritic trees and the pyramidal shape of their soma. They are found in several regions of the CNS and, although the reasons for their abundance remain unclear, functional studies — especially of CA1 hippocampal and layer V neocortical pyramidal neurons — have offered insights into the functions of their unique cellular architecture. Pyramidal neurons are not all identical, but some shared functional principles can be identified. In particular, the existence of dendritic domains with distinct synaptic inputs, excitability, modulation and plasticity appears to be a common feature that allows synapses throughout the dendritic tree to contribute to actionpotential generation. These properties support a variety of coincidence-detection mechanisms, which are likely to be crucial for synaptic integration and plasticity.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UNRPNYEG\\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf}
}

@article{sprustonPyramidalNeuronsDendritic2008a,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {9},
  number = {3},
  pages = {206--221},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn2286},
  url = {https://www.nature.com/articles/nrn2286},
  urldate = {2020-09-25},
  abstract = {Pyramidal neurons have basal and apical dendrites, including an apical tuft. This preserved core structure suggests that they have conserved core functions, whereas structural variation in other areas suggests additional functional specialization.A number of new methods for studying pyramidal-cell activation and circuitry are available. These include in vivo patch-clamp recording, optical activation and transgenic methods for activating, inactivating or labelling neurons and their connections.Synaptic inputs from distinct sources occur onto separate dendritic domains. Defining the degree to which synapses that carry different kinds of information are segregated onto different dendritic domains remains an important challenge.Most excitatory synapses onto pyramidal neurons occur on dendritic spines, but the structure of the synapses they receive differs between dendritic domains.Dendritic integration of synaptic input depends on the dendritic domain that is targeted. Synapses distant from the soma tend to produce less synaptic depolarization, but this might be countered by increasing the conductance of distal synapses or by activating voltage-gated channels in dendrites. Synapses on small-diameter dendrites cause larger local voltage changes, which reduce the effectiveness of synaptic scaling but increase the activation of voltage-gated conductances.Inhibitory synapses specifically target the axon, soma or different dendritic domains. Integration of inhibitory inputs also differs across cellular domains.The intrinsic firing properties of pyramidal neurons vary considerably. Along with variation in dendritic structure and channel distributions, such variability suggests that different pyramidal neurons might carry out specialized functions.Pyramidal-neuron dendrites contain voltage-gated channels that can influence synaptic integration. These channels can also support backpropagating action potentials and dendritically initiated spikes. Dendritic excitability is a general property of all pyramidal neurons studied so far, but the details differ between different types of pyramidal neurons. Although there is some evidence for dendritic excitability in vivo, much more work is needed in this area.Activation of a small fraction of the tens of thousands of excitatory synapses on a pyramidal neuron can probably evoke dendritic spikes, but these events do not always propagate to the soma and the axon. The coupling of dendritic spikes to axonal action-potential firing probably depends on the pattern of synaptic activation. This results in forms of coincidence detection that are determined by dendritic structure and excitability.Backpropagating action potentials and dendritic spikes are important signals for the induction of synaptic plasticity. Even single dendritic spikes can result in significant long-term potentiation or long-term depression.Neurotransmitters can modulate pyramidal-neuron function. At least some forms of modulation affect various dendritic domains and their synaptic inputs in different ways.Domain-specific properties in excitatory and inhibitory synaptic inputs, voltage-gated channels, dendritic excitability and neuromodulation all point to a multi-compartment model of pyramidal-neuron function. Elaborating simple models of pyramidal-neuron function based on these dendritic-domain-specific properties is a central challenge for the study of cortical function.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LI46IXAV\\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BPSPCV3A\\nrn2286.html}
}

@article{stephensBayesianInferenceComputational,
  title = {Bayesian {{Inference}}, {{Computational Methods}} and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  journaltitle = {Monte Carlo},
  pages = {641},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2BIY5RK6\\Stephens - Bayesian Inference, Computational Methods and Mont.pdf}
}

@article{stephensMATH598Bayesian,
  title = {{{MATH}} 598 - {{Bayesian Inference}}, {{Computational Methods}}   and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  pages = {251},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YXUD8S3Z\\Stephens - MATH 598 - Bayesian Inference, Computational Metho.pdf}
}

@article{stringerHighdimensionalGeometryPopulation2019,
  title = {High-Dimensional Geometry of Population Responses in Visual Cortex},
  author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
  date = {2019-07},
  journaltitle = {Nature},
  volume = {571},
  number = {7765},
  pages = {361--365},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1346-5},
  url = {https://www.nature.com/articles/s41586-019-1346-5},
  urldate = {2020-09-22},
  abstract = {A neuronal population encodes information most efficiently when its stimulus responses are high-dimensional and uncorrelated, and most robustly when they are lower-dimensional and correlated. Here we analysed the dimensionality of the encoding of natural images by large populations of neurons in the visual cortex of awake mice. The evoked population activity was high-dimensional, and correlations obeyed an unexpected power law: the nth principal component variance scaled as 1/n. This scaling was not inherited from the power law spectrum of natural images, because it persisted after stimulus whitening. We proved mathematically that if the variance spectrum was to decay more slowly then the population code could not be smooth, allowing small changes in input to dominate population activity. The theory also predicts larger power-law exponents for lower-dimensional stimulus ensembles, which we validated experimentally. These results suggest that coding smoothness may represent a fundamental constraint that determines correlations in neural population codes.},
  issue = {7765},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KZ4KXAA4\\Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B7ZDPWID\\s41586-019-1346-5.html}
}

@article{stuartDendriticIntegration602015,
  title = {Dendritic Integration: 60 Years of Progress},
  shorttitle = {Dendritic Integration},
  author = {Stuart, Greg J and Spruston, Nelson},
  date = {2015-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {12},
  pages = {1713--1721},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4157},
  url = {http://www.nature.com/articles/nn.4157},
  urldate = {2022-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LLV9TE6Q\\Stuart and Spruston - 2015 - Dendritic integration 60 years of progress.pdf}
}

@article{takahashiActiveDendriticCurrents2020,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-10},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {10},
  pages = {1277--1285},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2020-09-25},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  issue = {10},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DBTGY9LF\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CI6H8466\\s41593-020-0677-8.html}
}

@article{takahashiActiveDendriticCurrents2020a,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-08-03},
  journaltitle = {Nature Neuroscience},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2020-09-22},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HZSBVY3S\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RF7LAZU\\s41593-020-0677-8.html}
}

@article{tangIntroductionFocusIssue2020,
  title = {Introduction to {{Focus Issue}}: {{When}} Machine Learning Meets Complex Systems: {{Networks}}, Chaos, and Nonlinear Dynamics},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Tang, Yang and Kurths, Jürgen and Lin, Wei and Ott, Edward and Kocarev, Ljupco},
  date = {2020-06},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {30},
  number = {6},
  pages = {063151},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0016505},
  url = {http://aip.scitation.org/doi/10.1063/5.0016505},
  urldate = {2020-09-30},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7WXCVSQ8\\Tang et al. - 2020 - Introduction to Focus Issue When machine learning.pdf}
}

@article{vankempenTopdownCoordinationLocal2021,
  title = {Top-down Coordination of Local Cortical State during Selective Attention},
  author = {van Kempen, Jochem and Gieselmann, Marc A. and Boyd, Michael and Steinmetz, Nicholas A. and Moore, Tirin and Engel, Tatiana A. and Thiele, Alexander},
  options = {useprefix=true},
  date = {2021-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {5},
  pages = {894-904.e8},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.12.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320309958},
  urldate = {2021-03-11},
  abstract = {Spontaneous fluctuations in cortical excitability influence sensory processing and behavior. These fluctuations, long thought to reflect global changes in cortical state, were recently found to be modulated locally within a retinotopic map during spatially selective attention. We report that periods of vigorous (On) and faint (Off) spiking activity, the signature of cortical state fluctuations, are coordinated across brain areas with retinotopic precision. Top-down attention enhanced interareal local state coordination, traversing along the reverse cortical hierarchy. The extent of local state coordination between areas was predictive of behavioral performance. Our results show that cortical state dynamics are shared across brain regions, modulated by cognitive demands and relevant for behavior.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M9VZXM8Y\\van Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf}
}

@article{vuLectureEntropyMutual,
  title = {Lecture 2: {{Entropy}} and Mutual Information},
  author = {Vu, Mai},
  journaltitle = {Electrical and Computer Engineering},
  pages = {8},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IGNQUY2E\\Vu - Lecture 2 Entropy and mutual information.pdf}
}

@article{williamsInformationTheoreticAnalysis,
  title = {An {{Information Theoretic Analysis}} of {{Neural Multiplexing}}},
  author = {Williams, Ezekiel},
  pages = {94},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S6XESADU\\Williams - An Information Theoretic Analysis of Neural Multip.pdf}
}

@article{williamsNeuralBurstCodes2021,
  title = {Neural Burst Codes Disguised as Rate Codes},
  author = {Williams, Ezekiel and Payeur, Alexandre and Gidon, Albert and Naud, Richard},
  date = {2021-08-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {15910},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-95037-z},
  url = {https://doi.org/10.1038/s41598-021-95037-z},
  abstract = {The burst coding hypothesis posits that the occurrence of sudden high-frequency patterns of action potentials constitutes a salient syllable of the neural code. Many neurons, however, do not produce clearly demarcated bursts, an observation invoked to rule out the pervasiveness of this coding scheme across brain areas and cell types. Here we ask how detrimental ambiguous spike patterns, those that are neither clearly bursts nor isolated spikes, are for neuronal information transfer. We addressed this question using information theory and computational simulations. By quantifying how information transmission depends on firing statistics, we found that the information transmitted is not strongly influenced by the presence of clearly demarcated modes in the interspike interval distribution, a feature often used to identify the presence of burst coding. Instead, we found that neurons having unimodal interval distributions were still able to ascribe different meanings to bursts and isolated spikes. In this regime, information transmission depends on dynamical properties of the synapses as well as the length and relative frequency of bursts. Furthermore, we found that common metrics used to quantify burstiness were unable to predict the degree with which bursts could be used to carry information. Our results provide guiding principles for the implementation of coding strategies based on spike-timing patterns, and show that even unimodal firing statistics can be consistent with a bivariate neural code.}
}

@article{woodStatisticalInferenceNoisy2010,
  title = {Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems},
  author = {Wood, Simon N.},
  date = {2010-08},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {466},
  number = {7310},
  pages = {1102--1104},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature09319},
  url = {http://www.nature.com/articles/nature09319},
  urldate = {2020-10-26},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\369DUHQK\\Wood - 2010 - Statistical inference for noisy nonlinear ecologic.pdf}
}

@article{yuImprovedToolsStudy2020,
  title = {Improved Tools to Study Astrocytes},
  author = {Yu, Xinzhu and Nagai, Jun and Khakh, Baljit S.},
  date = {2020-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {3},
  pages = {121--138},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0264-8},
  url = {https://www.nature.com/articles/s41583-020-0264-8},
  urldate = {2020-11-20},
  abstract = {Astrocytes are a type of glial cell that tile the CNS. They interact with multiple cell types, including neurons, glial cells and blood vessels, and are involved or implicated in brain disorders. Progress has been made in understanding astrocytes, but the field lacks detailed information concerning how they perform their multifarious functions, and how and when they influence the operations of the neural circuits with which they interact. One recognized bottleneck to progress has been the paucity of reliable tools with which to explore astrocytes within the adult vertebrate CNS in vivo. However, improved tools for molecular, genetic, morphological and physiological assessments have been developed recently or have been adapted from their original purposes to study neurons and are now being used to systematically document and interrogate astrocyte biology in vivo. These tools, their uses and limitations, and the insights that they afford are summarized in this Review.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RZ28HLLC\\Yu et al. - 2020 - Improved tools to study astrocytes.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2EWD3J5K\\s41583-020-0264-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8VP7T2B5\\s41583-020-0264-8.html}
}

@article{yusteCommunitybasedTranscriptomicsClassification2020,
  title = {A Community-Based Transcriptomics Classification and Nomenclature of Neocortical Cell Types},
  author = {Yuste, Rafael and Hawrylycz, Michael and Aalling, Nadia and Aguilar-Valles, Argel and Arendt, Detlev and Arnedillo, Ruben Armananzas and Ascoli, Giorgio A. and Bielza, Concha and Bokharaie, Vahid and Bergmann, Tobias Borgtoft and Bystron, Irina and Capogna, Marco and Chang, Yoonjeung and Clemens, Ann and de Kock, Christiaan P. J. and DeFelipe, Javier and Dos Santos, Sandra Esmeralda and Dunville, Keagan and Feldmeyer, Dirk and Fiáth, Richárd and Fishell, Gordon James and Foggetti, Angelica and Gao, Xuefan and Ghaderi, Parviz and Goriounova, Natalia A. and Güntürkün, Onur and Hagihara, Kenta and Hall, Vanessa Jane and Helmstaedter, Moritz and Herculano, Suzana and Hilscher, Markus M. and Hirase, Hajime and Hjerling-Leffler, Jens and Hodge, Rebecca and Huang, Josh and Huda, Rafiq and Khodosevich, Konstantin and Kiehn, Ole and Koch, Henner and Kuebler, Eric S. and Kühnemund, Malte and Larrañaga, Pedro and Lelieveldt, Boudewijn and Louth, Emma Louise and Lui, Jan H. and Mansvelder, Huibert D. and Marin, Oscar and Martinez-Trujillo, Julio and Moradi Chameh, Homeira and Nath, Alok and Nedergaard, Maiken and Němec, Pavel and Ofer, Netanel and Pfisterer, Ulrich Gottfried and Pontes, Samuel and Redmond, William and Rossier, Jean and Sanes, Joshua R. and Scheuermann, Richard and Serrano-Saiz, Esther and Steiger, Jochen F. and Somogyi, Peter and Tamás, Gábor and Tolias, Andreas Savas and Tosches, Maria Antonietta and García, Miguel Turrero and Vieira, Hermany Munguba and Wozny, Christian and Wuttke, Thomas V. and Yong, Liu and Yuan, Juan and Zeng, Hongkui and Lein, Ed},
  options = {useprefix=true},
  date = {2020-08-24},
  journaltitle = {Nature Neuroscience},
  pages = {1--13},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0685-8},
  url = {https://www.nature.com/articles/s41593-020-0685-8},
  urldate = {2020-08-31},
  abstract = {To understand the function of cortical circuits, it is necessary to catalog their cellular diversity. Past attempts to do so using anatomical, physiological or molecular features of cortical cells have not resulted in a unified taxonomy of neuronal or glial cell types, partly due to limited data. Single-cell transcriptomics is enabling, for the first time, systematic high-throughput measurements of cortical cells and generation of datasets that hold the promise of being complete, accurate and permanent. Statistical analyses of these data reveal clusters that often correspond to cell types previously defined by morphological or physiological criteria and that appear conserved across cortical areas and species. To capitalize on these new methods, we propose the adoption of a transcriptome-based taxonomy of cell types for mammalian neocortex. This classification should be hierarchical and use a standardized nomenclature. It should be based on a probabilistic definition of a cell type and incorporate data from different approaches, developmental stages and species. A community-based classification and data aggregation model, such as a knowledge graph, could provide a common foundation for the study of cortical circuits. This community-based classification, nomenclature and data aggregation could serve as an example for cell type atlases in other parts of the body.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZUITQXWX\\Yuste et al. - 2020 - A community-based transcriptomics classification a.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LS9FFTT6\\s41593-020-0685-8.html}
}

@article{zeiselMolecularArchitectureMouse2018,
  title = {Molecular {{Architecture}} of the {{Mouse Nervous System}}},
  author = {Zeisel, Amit and Hochgerner, Hannah and Lönnerberg, Peter and Johnsson, Anna and Memic, Fatima and van der Zwan, Job and Häring, Martin and Braun, Emelie and Borm, Lars E. and La Manno, Gioele and Codeluppi, Simone and Furlan, Alessandro and Lee, Kawai and Skene, Nathan and Harris, Kenneth D. and Hjerling-Leffler, Jens and Arenas, Ernest and Ernfors, Patrik and Marklund, Ulrika and Linnarsson, Sten},
  options = {useprefix=true},
  date = {2018-08},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {174},
  number = {4},
  pages = {999-1014.e22},
  issn = {00928674},
  doi = {10.1016/j.cell.2018.06.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S009286741830789X},
  urldate = {2020-09-02},
  abstract = {The mammalian nervous system executes complex behaviors controlled by specialized, precisely positioned, and interacting cell types. Here, we used RNA sequencing of half a million single cells to create a detailed census of cell types in the mouse nervous system. We mapped cell types spatially and derived a hierarchical, data-driven taxonomy. Neurons were the most diverse and were grouped by developmental anatomical units and by the expression of neurotransmitters and neuropeptides. Neuronal diversity was driven by genes encoding cell identity, synaptic connectivity, neurotransmission, and membrane conductance. We discovered seven distinct, regionally restricted astrocyte types that obeyed developmental boundaries and correlated with the spatial distribution of key glutamate and glycine neurotransmitters. In contrast, oligodendrocytes showed a loss of regional identity followed by a secondary diversification. The resource presented here lays a solid foundation for understanding the molecular architecture of the mammalian nervous system and enables genetic manipulation of specific cell types.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8V6QUQWJ\\Zeisel et al. - 2018 - Molecular Architecture of the Mouse Nervous System.pdf}
}

@article{zhangConvolutionalNeuralNetwork2019,
  title = {Convolutional Neural Network Models of {{V1}} Responses to Complex Patterns},
  author = {Zhang, Yimeng and Lee, Tai Sing and Li, Ming and Liu, Fang and Tang, Shiming},
  date = {2019-02-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {46},
  number = {1},
  pages = {33--54},
  issn = {1573-6873},
  doi = {10.1007/s10827-018-0687-7},
  url = {https://doi.org/10.1007/s10827-018-0687-7},
  urldate = {2020-10-08},
  abstract = {In this study, we evaluated the convolutional neural network (CNN) method for modeling V1 neurons of awake macaque monkeys in response to a large set of complex pattern stimuli. CNN models outperformed all the other baseline models, such as Gabor-based standard models for V1 cells and various variants of generalized linear models. We then systematically dissected different components of the CNN and found two key factors that made CNNs outperform other models: thresholding nonlinearity and convolution. In addition, we fitted our data using a pre-trained deep CNN via transfer learning. The deep CNN’s higher layers, which encode more complex patterns, outperformed lower ones, and this result was consistent with our earlier work on the complexity of V1 neural code. Our study systematically evaluates the relative merits of different CNN components in the context of V1 neuron modeling.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RTJIZRDF\\Zhang et al. - 2019 - Convolutional neural network models of V1 response.pdf}
}


