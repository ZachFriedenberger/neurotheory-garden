@online{5f04e48f3e184600cbc92a05,
  title = {5f04e48f3e184600cbc92a05},
  url = {https://mfr.ca-1.osf.io/render?url=https://osf.io/9hkg2/?direct%26mode=render%26action=download%26mode=render},
  urldate = {2020-10-16},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2LUDM9CC\\render.html}
}

@article{abdolrahmaniAttentionSeparatesSensory2021,
  title = {Attention Separates Sensory and Motor Signals in the Mouse Visual Cortex},
  author = {Abdolrahmani, Mohammad and Lyamzin, Dmitry R. and Aoki, Ryo and Benucci, Andrea},
  date = {2021-07-13},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {36},
  number = {2},
  pages = {109377},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2021.109377},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124721007750},
  urldate = {2023-01-03},
  abstract = {Visually guided behaviors depend on the activity of cortical networks receiving visual inputs and transforming these signals to guide appropriate actions. However, non-retinal inputs, carrying motor signals as well as cognitive and attentional modulatory signals, also activate these cortical regions. How these networks integrate coincident signals ensuring reliable visual behaviors is poorly understood. In this study, we observe neural responses in the dorsal-parietal cortex of mice during a visual discrimination task driven by visual stimuli and movements. We find that visual and motor signals interact according to two mechanisms: divisive normalization and separation of responses. Interactions are contextually modulated by the animal’s state of sustained attention, which amplifies visual and motor signals and increases their discriminability in a low-dimensional space of neural activations. These findings reveal computational principles operating in dorsal-parietal networks that enable separation of incoming signals for reliable visually guided behaviors during interactions with the environment.},
  langid = {english},
  keywords = {behavior,decision-making,mouse,movement-related activity,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VMH2H3TK\\Abdolrahmani et al. - 2021 - Attention separates sensory and motor signals in t.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RK8ATIK5\\S2211124721007750.html}
}

@article{abdolrahmaniAttentionSeparatesSensory2021a,
  title = {Attention Separates Sensory and Motor Signals in the Mouse Visual Cortex},
  author = {Abdolrahmani, Mohammad and Lyamzin, Dmitry R. and Aoki, Ryo and Benucci, Andrea},
  date = {2021-07-13},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {36},
  number = {2},
  pages = {109377},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2021.109377},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124721007750},
  urldate = {2023-01-10},
  abstract = {Visually guided behaviors depend on the activity of cortical networks receiving visual inputs and transforming these signals to guide appropriate actions. However, non-retinal inputs, carrying motor signals as well as cognitive and attentional modulatory signals, also activate these cortical regions. How these networks integrate coincident signals ensuring reliable visual behaviors is poorly understood. In this study, we observe neural responses in the dorsal-parietal cortex of mice during a visual discrimination task driven by visual stimuli and movements. We find that visual and motor signals interact according to two mechanisms: divisive normalization and separation of responses. Interactions are contextually modulated by the animal’s state of sustained attention, which amplifies visual and motor signals and increases their discriminability in a low-dimensional space of neural activations. These findings reveal computational principles operating in dorsal-parietal networks that enable separation of incoming signals for reliable visually guided behaviors during interactions with the environment.},
  langid = {english},
  keywords = {behavior,decision-making,mouse,movement-related activity,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FB57TKTA\\Abdolrahmani et al. - 2021 - Attention separates sensory and motor signals in t.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YEJBA6SM\\S2211124721007750.html}
}

@article{allenAstrocyteRegulationSynaptic2014,
  title = {Astrocyte {{Regulation}} of {{Synaptic Behavior}}},
  author = {Allen, Nicola J.},
  date = {2014},
  journaltitle = {Annual Review of Cell and Developmental Biology},
  volume = {30},
  number = {1},
  eprint = {25288116},
  eprinttype = {pmid},
  pages = {439--463},
  doi = {10.1146/annurev-cellbio-100913-013053},
  url = {https://doi.org/10.1146/annurev-cellbio-100913-013053},
  urldate = {2020-11-24},
  abstract = {Astrocytes regulate multiple aspects of neuronal and synaptic function from development through to adulthood. Instead of addressing each function independently, this review provides a comprehensive overview of the different ways astrocytes modulate neuronal synaptic function throughout life, with a particular focus on recent findings in each area. It includes the emerging functions of astrocytes, such as a role in synapse formation, as well as more established roles, including the uptake and recycling of neurotransmitters. This broad approach covers the many ways astrocytes and neurons constantly interact to maintain the correct functioning of the brain. It is important to consider all of these diverse functions of astrocytes when investigating how astrocyte-neuron interactions regulate synaptic behavior to appreciate the complexity of these ongoing interactions.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-cellbio-100913-013053},
  file = {C\:\\Users\\Zach Friedenberger\\Downloads\\annurev-cellbio-100913-013053.pdf}
}

@article{allenStarPowerAstrocytes2019,
  title = {Star {{Power}}: {{Astrocytes Regulate Behavior}}},
  shorttitle = {Star {{Power}}},
  author = {Allen, Nicola J.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31100265},
  eprinttype = {pmid},
  pages = {1091--1093},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.04.042},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30494-5},
  urldate = {2020-11-21},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2C7XMJ66\\Allen - 2019 - Star Power Astrocytes Regulate Behavior.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JF9TY9EP\\S0092-8674(19)30494-5.html}
}

@article{andersonAttentiondependentReductionsBurstiness2013,
  title = {✅ {{Attention-dependent}} Reductions in Burstiness and Action-Potential Height in Macaque Area {{V4}}},
  author = {Anderson, Emily B. and Mitchell, Jude F. and Reynolds, John H.},
  date = {2013-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {16},
  number = {8},
  pages = {1125--1131},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3463},
  url = {https://www.nature.com/articles/nn.3463},
  urldate = {2023-01-03},
  abstract = {This study finds a counterintuitive reduction in neuron bursting during spatial attention. This is explained by a conductance-based model, which also provides a unified explanation for other forms of attentional modulation and correctly predicts the surprising finding that attention decreases action-potential amplitude.},
  issue = {8},
  langid = {english},
  keywords = {Attention},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XAUPFGPA\\Anderson et al. - 2013 - Attention-dependent reductions in burstiness and a.pdf}
}

@article{andersonPathwaysAttentionSynaptic2011,
  title = {Pathways of {{Attention}}: {{Synaptic Relationships}} of {{Frontal Eye Field}} to {{V4}}, {{Lateral Intraparietal Cortex}}, and {{Area}} 46 in {{Macaque Monkey}}},
  shorttitle = {Pathways of {{Attention}}},
  author = {Anderson, John C. and Kennedy, Henry and Martin, Kevan A. C.},
  date = {2011-07-27},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {31},
  number = {30},
  eprint = {21795539},
  eprinttype = {pmid},
  pages = {10872--10881},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0622-11.2011},
  url = {https://www.jneurosci.org/content/31/30/10872},
  urldate = {2023-01-04},
  abstract = {The frontal eye field (FEF) of the primate neocortex occupies a pivotal position in the matrix of inter-areal projections. In addition to its role in directing saccadic eye movements, it is the source of an attentional signal that modulates the activity of neurons in extrastriate and parietal cortex. Here, we tested the prediction that FEF preferentially excites inhibitory neurons in target areas during attentional modulation. Using the anterograde tracer biotinylated dextran amine, we found that the projections from FEF terminate in all cortical layers of area 46, lateral intraparietal area (LIP), and visual area V4. Axons in layer 1 spread extensively, those in layer 2/3 were most numerous, individual axons in layer 4 formed sprays of collaterals, and those of the deep layers were the finest caliber and irregular. All labeled synapses were the typical asymmetric morphology of excitatory synapses of pyramidal neurons. Dendritic spines were the most frequent synaptic target in all areas (95\% in area 46, 89\% in V4, 84\% in LIP, 78\% intrinsic local FEF). The remaining targets were one soma and dendritic shafts, most of which showed characteristics of inhibitory neurons with smooth dendrites (5\% of all targets in area 46, 2\% in V4, 9\% in LIP, and 13\% in FEF).},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ME44ZKEI\\Anderson et al. - 2011 - Pathways of Attention Synaptic Relationships of F.pdf}
}

@article{aoiPrefrontalCortexExhibits2020,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making},
  author = {Aoi, Mikio C. and Mante, Valerio and Pillow, Jonathan W.},
  date = {2020-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {11},
  pages = {1410--1420},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0696-5},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2022-09-26},
  abstract = {Recent work has suggested that the prefrontal cortex (PFC) plays a key role in context-dependent perceptual decision-making. In this study, we addressed that role using a new method for identifying task-relevant dimensions of neural population activity. Specifically, we show that the PFC has a multidimensional code for context, decisions and both relevant and irrelevant sensory information. Moreover, these representations evolve in time, with an early linear accumulation phase followed by a phase with rotational dynamics. We identify the dimensions of neural activity associated with these phases and show that they do not arise from distinct populations but from a single population with broad tuning characteristics. Finally, we use model-based decoding to show that the transition from linear to rotational dynamics coincides with a plateau in decoding accuracy, revealing that rotational dynamics in the PFC preserve sensory choice information for the duration of the stimulus integration period.},
  issue = {11},
  langid = {english},
  keywords = {Decision,Dimensionality reduction,Neural encoding,Population dynamics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GFASWP5A\\Aoi et al. - 2020 - Prefrontal cortex exhibits multidimensional dynami.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\L5F6WUAF\\s41593-020-0696-5.html}
}

@article{aruCellularMechanismsConscious2020,
  title = {Cellular {{Mechanisms}} of {{Conscious Processing}}},
  author = {Aru, Jaan and Suzuki, Mototaka and Larkum, Matthew E.},
  date = {2020-10-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {10},
  pages = {814--825},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.07.006},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320301753},
  urldate = {2020-10-29},
  abstract = {Recent breakthroughs in neurobiology indicate that the time is ripe to understand how cellular-level mechanisms are related to conscious experience. Here, we highlight the biophysical properties of pyramidal cells, which allow them to act as gates that control the evolution of global activation patterns. In conscious states, this cellular mechanism enables complex sustained dynamics within the thalamocortical system, whereas during unconscious states, such signal propagation is prohibited. We suggest that the hallmark of conscious processing is the flexible integration of bottom-up and top-down data streams at the cellular level. This cellular integration mechanism provides the foundation for Dendritic Information Theory, a novel neurobiological theory of consciousness},
  langid = {english},
  keywords = {anesthesia,dendrites,dendritic integration theory,pyramidal cells},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DZ4DAPD2\\Aru et al. - 2020 - Cellular Mechanisms of Conscious Processing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PM2HSWF9\\S1364661320301753.html}
}

@article{bairPowerSpectrumAnalysis1994,
  title = {Power Spectrum Analysis of Bursting Cells in Area {{MT}} in the Behaving Monkey},
  author = {Bair, W and Koch, C and Newsome, W and Britten, K},
  date = {1994-05-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {14},
  number = {5},
  pages = {2870--2892},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.14-05-02870.1994},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.14-05-02870.1994},
  urldate = {2023-01-16},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S8VBZBEN\\Bair et al. - 1994 - Power spectrum analysis of bursting cells in area .pdf}
}

@article{bairPowerSpectrumAnalysis1994a,
  title = {Power Spectrum Analysis of Bursting Cells in Area {{MT}} in the Behaving Monkey},
  author = {Bair, W. and Koch, C. and Newsome, W. and Britten, K.},
  date = {1994-05-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {14},
  number = {5},
  eprint = {8182445},
  eprinttype = {pmid},
  pages = {2870--2892},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.14-05-02870.1994},
  url = {https://www.jneurosci.org/content/14/5/2870},
  urldate = {2023-01-16},
  abstract = {It is widely held that visual cortical neurons encode information primarily in their mean firing rates. Some proposals, however, emphasize the information potentially available in the temporal structure of spike trains (Optican and Richmond, 1987; Bialek et al., 1991), in particular with respect to stimulus-related synchronized oscillations in the 30–70 Hz range (Eckhorn et al., 1988; Gray et al., 1989; Kreiter and Singer, 1992) as well as via bursting cells (Cattaneo et al., 1981a; Bonds, 1992). We investigate the temporal fine structure of spike trains recorded in extrastriate area MT of the trained macaque monkey, a region that plays a major role in processing motion information. The data were recorded while the monkey performed a near- threshold direction discrimination task so that both physiological and psychophysical data could be obtained on the same set of trials (Britten et al., 1992). We identify bursting cells and quantify their properties, in particular in relation to the behavior of the animal. We compute the power spectrum and the distribution of interspike intervals (ISIs) associated with individual spike trains from 212 cells, averaging these quantities across similar trials. (1) About 33\% of the cells have a relatively flat power spectrum with a dip at low temporal frequencies. We analytically derive the power spectrum of a Poisson process with refractory period and show that it matches the observed spectrum of these cells. (2) About 62\% of the cells have a peak in the 20–60 Hz frequency band. In about 10\% of all cells, this peak is at least twice the height of its base. The presence of such a peak strongly correlates with a tendency of the cell to respond in bursts, that is, two to four spikes within 2–8 msec. For 93\% of cells, the shape of the power spectrum did not change dramatically with stimulus conditions. (3) Both the ISI distribution and the power spectrum of the vast majority of bursting cells are compatible with the notion that these cells fire Poisson-distributed bursts, with a burst-related refractory period. Thus, for our stimulus conditions, no explicitly oscillating neuronal process is required to yield a peak in the power spectrum. (4) We found no statistically significant relationship between the peak in the power spectrum and psychophysical measures of the monkeys' performance on the direction discrimination task.(ABSTRACT TRUNCATED AT 400 WORDS)},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3F2N54TV\\Bair et al. - 1994 - Power spectrum analysis of bursting cells in area .pdf}
}

@article{barbieriCanAttractorNetwork2008,
  title = {Can {{Attractor Network Models Account}} for the {{Statistics}} of {{Firing During Persistent Activity}} in {{Prefrontal Cortex}}?},
  author = {Barbieri, Francesca and Brunel, Nicolas},
  date = {2008},
  journaltitle = {Frontiers in Neuroscience},
  volume = {2},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/articles/10.3389/neuro.01.003.2008},
  urldate = {2022-10-21},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\F2WS9WWD\\Barbieri and Brunel - 2008 - Can Attractor Network Models Account for the Stati.pdf}
}

@article{barzegaranFourConcurrentFeedforward2022,
  title = {Four Concurrent Feedforward and Feedback Networks with Different Roles in the Visual Cortical Hierarchy},
  author = {Barzegaran, Elham and Plomp, Gijs},
  date = {2022-02-10},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {20},
  number = {2},
  pages = {e3001534},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001534},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001534},
  urldate = {2023-01-10},
  abstract = {Visual stimuli evoke fast-evolving activity patterns that are distributed across multiple cortical areas. These areas are hierarchically structured, as indicated by their anatomical projections, but how large-scale feedforward and feedback streams are functionally organized in this system remains an important missing clue to understanding cortical processing. By analyzing visual evoked responses in laminar recordings from 6 cortical areas in awake mice, we uncovered a dominant feedforward network with scale-free interactions in the time domain. In addition, we established the simultaneous presence of a gamma band feedforward and 2 low frequency feedback networks, each with a distinct laminar functional connectivity profile, frequency spectrum, temporal dynamics, and functional hierarchy. We could identify distinct roles for each of these 4 processing streams, by leveraging stimulus contrast effects, analyzing receptive field (RF) convergency along functional interactions, and determining relationships to spiking activity. Our results support a dynamic dual counterstream view of hierarchical processing and provide new insight into how separate functional streams can simultaneously and dynamically support visual processes.},
  langid = {english},
  keywords = {Cognitive science,Mice,Neural networks,Primates,Scale-free networks,Sensory perception,Vision,Visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RBTBHDIY\\Barzegaran and Plomp - 2022 - Four concurrent feedforward and feedback networks .pdf}
}

@article{battistonPhysicsHigherorderInteractions2021,
  title = {The Physics of Higher-Order Interactions in Complex Systems},
  author = {Battiston, Federico and Amico, Enrico and Barrat, Alain and Bianconi, Ginestra and Ferraz de Arruda, Guilherme and Franceschiello, Benedetta and Iacopini, Iacopo and Kéfi, Sonia and Latora, Vito and Moreno, Yamir and Murray, Micah M. and Peixoto, Tiago P. and Vaccarino, Francesco and Petri, Giovanni},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1093--1098},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01371-4},
  url = {https://www.nature.com/articles/s41567-021-01371-4},
  urldate = {2022-10-01},
  abstract = {Complex networks have become the main paradigm for modelling the dynamics of interacting systems. However, networks are intrinsically limited to describing pairwise interactions, whereas real-world systems are often characterized by higher-order interactions involving groups of three or more units. Higher-order structures, such as hypergraphs and simplicial complexes, are therefore a better tool to map the real organization of many social, biological and man-made systems. Here, we highlight recent evidence of collective behaviours induced by higher-order interactions, and we outline three key challenges for the physics of higher-order systems.},
  issue = {10},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Information theory and computation},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BKIZNWBF\\Battiston et al. - 2021 - The physics of higher-order interactions in comple.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\39U85876\\s41567-021-01371-4.html}
}

@article{battistonPhysicsHigherorderInteractions2021a,
  title = {✅ {{The}} Physics of Higher-Order Interactions in Complex Systems},
  author = {Battiston, Federico and Amico, Enrico and Barrat, Alain and Bianconi, Ginestra and Ferraz de Arruda, Guilherme and Franceschiello, Benedetta and Iacopini, Iacopo and Kéfi, Sonia and Latora, Vito and Moreno, Yamir and Murray, Micah M. and Peixoto, Tiago P. and Vaccarino, Francesco and Petri, Giovanni},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1093--1098},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01371-4},
  url = {https://www.nature.com/articles/s41567-021-01371-4},
  urldate = {2022-10-02},
  abstract = {Complex networks have become the main paradigm for modelling the dynamics of interacting systems. However, networks are intrinsically limited to describing pairwise interactions, whereas real-world systems are often characterized by higher-order interactions involving groups of three or more units. Higher-order structures, such as hypergraphs and simplicial complexes, are therefore a better tool to map the real organization of many social, biological and man-made systems. Here, we highlight recent evidence of collective behaviours induced by higher-order interactions, and we outline three key challenges for the physics of higher-order systems.},
  issue = {10},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Information theory and computation},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FYCINRUZ\\Battiston et al. - 2021 - The physics of higher-order interactions in comple.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X2E3E3TP\\s41567-021-01371-4.html}
}

@article{beaulieu-larocheEnhancedDendriticCompartmentalization2018,
  title = {Enhanced {{Dendritic Compartmentalization}} in {{Human Cortical Neurons}}},
  author = {Beaulieu-Laroche, Lou and Toloza, Enrique H. S. and van der Goes, Marie-Sophie and Lafourcade, Mathieu and Barnagian, Derrick and Williams, Ziv M. and Eskandar, Emad N. and Frosch, Matthew P. and Cash, Sydney S. and Harnett, Mark T.},
  date = {2018-10-18},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {175},
  number = {3},
  eprint = {30340039},
  eprinttype = {pmid},
  pages = {643-651.e14},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2018.08.045},
  url = {https://www.cell.com/cell/abstract/S0092-8674(18)31106-1},
  urldate = {2020-10-29},
  langid = {english},
  keywords = {biophysics,compartmentalization,computation,cortex,dendrite,human,ion channels,neuron,patch-clamp},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M8YNL7TK\\Beaulieu-Laroche et al. - 2018 - Enhanced Dendritic Compartmentalization in Human C.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\49985XDW\\S0092-8674(18)31106-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RTATAXEM\\S0092-8674(18)31106-1.html}
}

@article{bellInformationMaximizationApproachBlind,
  title = {An {{Information-Maximization Approach}} to {{Blind Separation}} and {{Blind Deconvolution}}},
  author = {Bell, A J and Sejnowski, T J},
  pages = {31},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8EAQ9LIA\\Bell and Sejnowski - An Information-Maximization Approach to Blind Sepa.pdf}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4PGXM8TC\\Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{botvinickDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} and {{Its Neuroscientific Implications}}},
  author = {Botvinick, Matthew and Wang, Jane X. and Dabney, Will and Miller, Kevin J. and Kurth-Nelson, Zeb},
  date = {2020-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {4},
  pages = {603--616},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.06.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320304682},
  urldate = {2020-08-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJIYYGYT\\Botvinick et al. - 2020 - Deep Reinforcement Learning and Its Neuroscientifi.pdf}
}

@article{bradberryMolecularBasisSynaptotagmin1Associated2020,
  title = {Molecular {{Basis}} for {{Synaptotagmin-1-Associated Neurodevelopmental Disorder}}},
  author = {Bradberry, Mazdak M. and Courtney, Nicholas A. and Dominguez, Matthew J. and Lofquist, Sydney M. and Knox, Andrew T. and Sutton, R. Bryan and Chapman, Edwin R.},
  date = {2020-07-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {1},
  eprint = {32362337},
  eprinttype = {pmid},
  pages = {52-64.e7},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.04.003},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30272-5},
  urldate = {2020-10-06},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GXHC8MCT\\Bradberry et al. - 2020 - Molecular Basis for Synaptotagmin-1-Associated Neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QGVIXQCH\\S0896-6273(20)30272-5.html}
}

@article{breakspearGenerativeModelsCortical2010,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-11-10},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A5HJA3WT\\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{breakspearGenerativeModelsCortical2010a,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-10-05},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X5BBY6BW\\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{broidoScalefreeNetworksAre2019,
  title = {Scale-Free Networks Are Rare},
  author = {Broido, Anna D. and Clauset, Aaron},
  date = {2019-03-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {10},
  eprint = {30833554},
  eprinttype = {pmid},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08746-5},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6399239/},
  urldate = {2020-09-01},
  abstract = {Real-world networks are often claimed to be scale free,~meaning that the fraction of nodes with degree k follows a power law k−α, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns., Real-world networks are often said to be ”scale free”, meaning their degree distribution follows a power law. Broido and Clauset perform statistical tests of this claim using a large and diverse corpus of real-world networks, showing that scale-free structure is far from universal.},
  pmcid = {PMC6399239},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\R7HRJLJX\\Broido and Clauset - 2019 - Scale-free networks are rare.pdf}
}

@article{buzsakiNeuronalOscillationsCortical2004,
  title = {Neuronal {{Oscillations}} in {{Cortical Networks}}},
  author = {Buzsáki, György and Draguhn, Andreas},
  date = {2004-06-25},
  journaltitle = {Science},
  volume = {304},
  number = {5679},
  eprint = {15218136},
  eprinttype = {pmid},
  pages = {1926--1929},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1099745},
  url = {https://science.sciencemag.org/content/304/5679/1926},
  urldate = {2020-11-10},
  abstract = {Clocks tick, bridges and skyscrapers vibrate, neuronal networks oscillate. Are neuronal oscillations an inevitable by-product, similar to bridge vibrations, or an essential part of the brain's design? Mammalian cortical neurons form behavior-dependent oscillating networks of various sizes, which span five orders of magnitude in frequency. These oscillations are phylogenetically preserved, suggesting that they are functionally relevant. Recent findings indicate that network oscillations bias input selection, temporally link neurons into assemblies, and facilitate synaptic plasticity, mechanisms that cooperatively support temporal representation and long-term consolidation of information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FF7ZAZVB\\Buzsáki and Draguhn - 2004 - Neuronal Oscillations in Cortical Networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U2HLRDY\\1926.html}
}

@article{cadenaDeepConvolutionalModels2019,
  title = {Deep Convolutional Models Improve Predictions of Macaque {{V1}} Responses to Natural Images},
  author = {Cadena, Santiago A. and Denfield, George H. and Walker, Edgar Y. and Gatys, Leon A. and Tolias, Andreas S. and Bethge, Matthias and Ecker, Alexander S.},
  editor = {Einhäuser, Wolfgang},
  date = {2019-04-23},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {15},
  number = {4},
  pages = {e1006897},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006897},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1006897},
  urldate = {2020-10-08},
  abstract = {Despite great efforts over several decades, our best models of primary visual cortex (V1) still predict spiking activity quite poorly when probed with natural stimuli, highlighting our limited understanding of the nonlinear computations in V1. Recently, two approaches based on deep learning have emerged for modeling these nonlinear computations: transfer learning from artificial neural networks trained on object recognition and data-driven convolutional neural network models trained end-to-end on large populations of neurons. Here, we test the ability of both approaches to predict spiking activity in response to natural images in V1 of awake monkeys. We found that the transfer learning approach performed similarly well to the data-driven approach and both outperformed classical linear-nonlinear and waveletbased feature representations that build on existing theories of V1. Notably, transfer learning using a pre-trained feature space required substantially less experimental time to achieve the same performance. In conclusion, multi-layer convolutional neural networks (CNNs) set the new state of the art for predicting neural responses to natural images in primate V1 and deep features learned for object recognition are better explanations for V1 computation than all previous filter bank theories. This finding strengthens the necessity of V1 models that are multiple nonlinearities away from the image domain and it supports the idea of explaining early visual cortex based on high-level functional goals.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8VWFCWPK\\Cadena et al. - 2019 - Deep convolutional models improve predictions of m.pdf}
}

@article{calhounUnsupervisedIdentificationInternal2019,
  title = {Unsupervised Identification of the Internal States That Shape Natural Behavior},
  author = {Calhoun, Adam J. and Pillow, Jonathan W. and Murthy, Mala},
  date = {2019-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {12},
  pages = {2040--2049},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0533-x},
  url = {http://www.nature.com/articles/s41593-019-0533-x},
  urldate = {2020-09-05},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I2GZC5RB\\Calhoun et al. - 2019 - Unsupervised identification of the internal states.pdf}
}

@article{chakrabartiCuspApple2021,
  title = {The Cusp of an Apple},
  author = {Chakrabarti, Aditi and Michaels, Thomas C. T. and Yin, Sifan and Sun, Eric and Mahadevan, L.},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1125--1129},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01335-8},
  url = {https://www.nature.com/articles/s41567-021-01335-8},
  urldate = {2022-10-03},
  abstract = {Singularities are common in diverse physical systems1 and lead to universal structures2,3. This universality suggests that they should also naturally arise in biological systems, where active growth, autonomous motion, kinesis and taxis focus deformations in spacetime, as exemplified in the morphogenetic processes determining biological size and shape4. A familiar example of a morphogenetic singularity is seen in the humble apple, which forms in the neighbourhood of the stalk as the apple grows. Here we study the geometry and morphogenesis of the cusp of an apple by combining observations of fruit growth with a simple theory, finite element simulations and controlled swelling experiments using a physical gel simulacrum. Our observations show that the axisymmetric cusp develops into a self-similar form, which can be understood in terms of a mechanical theory for the inhomogeneous growth of a soft sphere. Physical experiments using local inhibition in swelling gels corroborate our theoretical predictions. These experiments further show that axisymmetric cusps can lose stability and become lobed. We use simulations to show that the number of cuspidal lobes depends on the ratio of the size of the stalk to the size of the sphere, as well as the amplitude and periodicity of perturbations that mimic the role of fruit anatomy, consistent with observations of multi-cusped fruits.},
  issue = {10},
  langid = {english},
  keywords = {Gels and hydrogels,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\452PPD5E\\Chakrabarti et al. - 2021 - The cusp of an apple.pdf}
}

@article{chaudhuriIntrinsicAttractorManifold2019,
  title = {The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit across Waking and Sleep},
  author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
  date = {2019-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {9},
  pages = {1512--1520},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0460-x},
  url = {http://www.nature.com/articles/s41593-019-0460-x},
  urldate = {2020-09-06},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3D6BIVRS\\s41593-019-0460-x.pdf}
}

@article{chialvoEmergentComplexNeural2010,
  title = {✅ {{Emergent}} Complex Neural Dynamics},
  author = {Chialvo, Dante R.},
  date = {2010-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {6},
  number = {10},
  pages = {744--750},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys1803},
  url = {https://www.nature.com/articles/nphys1803},
  urldate = {2022-10-01},
  abstract = {A large repertoire of spatiotemporal activity patterns in the brain is the basis for adaptive behaviour. Understanding the mechanism by which the brain’s hundred billion neurons and hundred trillion synapses manage to produce such a range of cortical configurations in a flexible manner remains a fundamental problem in neuroscience. One plausible solution is the involvement of universal mechanisms of emergent complex phenomena evident in dynamical systems poised near a critical point of a second-order phase transition. We review recent theoretical and empirical results supporting the notion that the brain is naturally poised near criticality, as well as its implications for better understanding of the brain.},
  issue = {10},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7I75I5QH\\Chialvo - 2010 - Emergent complex neural dynamics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3HGGL3KA\\nphys1803.html}
}

@article{chupeauCoverTimesRandom2015,
  title = {Cover Times of Random Searches},
  author = {Chupeau, Marie and Bénichou, Olivier and Voituriez, Raphaël},
  date = {2015-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {10},
  pages = {844--847},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys3413},
  url = {https://www.nature.com/articles/nphys3413},
  urldate = {2022-10-05},
  abstract = {The first-passage time relates the efficiency of a search process, but fails to do so for searches in which several targets are sought. Now, the distribution of times required for a random search to visit all sites has been determined analytically.},
  issue = {10},
  langid = {english},
  keywords = {Biological physics,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6KYBGX2A\\Chupeau et al. - 2015 - Cover times of random searches.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GT6HR2VD\\nphys3413.html}
}

@article{churchlandNeuralPopulationDynamics2012,
  title = {Neural Population Dynamics during Reaching},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V.},
  date = {2012-07},
  journaltitle = {Nature},
  volume = {487},
  number = {7405},
  pages = {51--56},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature11129},
  url = {https://www.nature.com/articles/nature11129},
  urldate = {2022-09-26},
  abstract = {Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses.},
  issue = {7405},
  langid = {english},
  keywords = {Motor cortex,Neuronal physiology,Population dynamics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X99ZZQW3\\Churchland et al. - 2012 - Neural population dynamics during reaching.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5HBFYAGB\\nature11129.html}
}

@article{cocinaSpikingBurstinessWorking2022,
  title = {Spiking Burstiness and Working Memory in the Human Medial Temporal Lobe},
  author = {Cocina, Francesco and Vitalis, Andreas and Caflisch, Amedeo},
  date = {2022-10-01},
  journaltitle = {Cerebral Cortex Communications},
  volume = {3},
  number = {4},
  pages = {tgac039},
  issn = {2632-7376},
  doi = {10.1093/texcom/tgac039},
  url = {https://academic.oup.com/cercorcomms/article/doi/10.1093/texcom/tgac039/6763343},
  urldate = {2023-01-16},
  abstract = {P-value for the combined LvR is given by the median of the 100 extracted ones.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QPUF7N32\\Cocina et al. - 2022 - Spiking burstiness and working memory in the human.pdf}
}

@article{cohenAttentionImprovesPerformance2009,
  title = {✅ {{Attention}} Improves Performance Primarily by Reducing Interneuronal Correlations},
  author = {Cohen, Marlene R. and Maunsell, John H. R.},
  date = {2009-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {12},
  number = {12},
  pages = {1594--1600},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.2439},
  url = {https://www.nature.com/articles/nn.2439},
  urldate = {2022-12-19},
  abstract = {Previous work has suggested that visual attention improves behavioral performance by increasing the firing rates of individual sensory neurons. Recording from populations of neurons in monkey visual area V4, this study finds that most of the attentional improvement in the population signal results from decreases in interneuronal correlations.},
  issue = {12},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XELVT9NU\\Cohen and Maunsell - 2009 - Attention improves performance primarily by reduci.pdf}
}

@article{constantinouCrackingBrainCode,
  title = {Cracking the {{Brain}}'s {{Code}}: {{How}} Do {{Brain Rhythms Support Information Processing}}?},
  author = {Constantinou, Maria},
  pages = {159},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KTE5WG73\\Constantinou - Cracking the Brain's Code How do Brain Rhythms Su.pdf}
}

@article{corriganDistinctNeuralCodes2022,
  title = {Distinct Neural Codes in Primate Hippocampus and Lateral Prefrontal Cortex during Associative Learning in Virtual Environments},
  author = {Corrigan, Benjamin W. and Gulli, Roberto A. and Doucet, Guillaume and Roussy, Megan and Luna, Rogelio and Pradeepan, Kartik S. and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
  date = {2022-07-06},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {13},
  pages = {2155-2169.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.04.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322003610},
  urldate = {2023-01-12},
  abstract = {The hippocampus (HPC) and the lateral prefrontal cortex (LPFC) are two cortical areas of the primate brain deemed essential to cognition. Here, we hypothesized that the codes mediating neuronal communication in the HPC and LPFC microcircuits have distinctively evolved to serve plasticity and memory function at different spatiotemporal scales. We used a virtual reality task in which animals selected one of the two targets in the arms of the maze, according to a learned context-color rule. Our results show that during associative learning, HPC principal cells concentrate spikes in bursts, enabling temporal summation and fast synaptic plasticity in small populations of neurons and ultimately facilitating rapid encoding of associative memories. On the other hand, layer II/III LPFC pyramidal cells fire spikes more sparsely distributed over time. The latter would facilitate broadcasting of signals loaded in short-term memory across neuronal populations without necessarily triggering fast synaptic plasticity.},
  langid = {english},
  keywords = {burst firing,hippocampus,long-term memory,neural code,prefrontal cortex,primate,short-term memory,working memory},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I8M3UEJV\\Corrigan et al. - 2022 - Distinct neural codes in primate hippocampus and l.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7JPT4A9W\\S0896627322003610.html}
}

@article{corriganDistinctNeuralCodes2022a,
  title = {Distinct Neural Codes in Primate Hippocampus and Lateral Prefrontal Cortex during Associative Learning in Virtual Environments},
  author = {Corrigan, Benjamin W. and Gulli, Roberto A. and Doucet, Guillaume and Roussy, Megan and Luna, Rogelio and Pradeepan, Kartik S. and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
  date = {2022-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {13},
  pages = {2155-2169.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2022.04.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627322003610},
  urldate = {2023-01-12},
  abstract = {The hippocampus (HPC) and the lateral prefrontal cortex (LPFC) are two cortical areas of the primate brain deemed essential to cognition. Here, we hypothesized that the codes mediating neuronal communication in the HPC and LPFC microcircuits have distinctively evolved to serve plasticity and memory function at different spatiotemporal scales. We used a virtual reality task in which animals selected one of the two targets in the arms of the maze, according to a learned context-color rule. Our results show that during associative learning, HPC principal cells concentrate spikes in bursts, enabling temporal summation and fast synaptic plasticity in small populations of neurons and ultimately facilitating rapid encoding of associative memories. On the other hand, layer II/III LPFC pyramidal cells fire spikes more sparsely distributed over time. The latter would facilitate broadcasting of signals loaded in short-term memory across neuronal populations without necessarily triggering fast synaptic plasticity.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\54T6SXXZ\\Corrigan et al. - 2022 - Distinct neural codes in primate hippocampus and l.pdf}
}

@article{costaModelingEffectSleep2016,
  title = {Modeling the Effect of Sleep Regulation on a Neural Mass Model},
  author = {Costa, Michael Schellenberger and Born, Jan and Claussen, Jens Christian and Martinetz, Thomas},
  date = {2016-08-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {41},
  number = {1},
  pages = {15--28},
  issn = {1573-6873},
  doi = {10.1007/s10827-016-0602-z},
  url = {https://doi.org/10.1007/s10827-016-0602-z},
  urldate = {2020-11-20},
  abstract = {In mammals, sleep is categorized by two main sleep stages, rapid eye movement (REM) and non-REM (NREM) sleep that are known to fulfill different functional roles, the most notable being the consolidation of memory. While REM sleep is characterized by brain activity similar to wakefulness, the EEG activity changes drastically with the emergence of K-complexes, sleep spindles and slow oscillations during NREM sleep. These changes are regulated by circadian and ultradian rhythms, which emerge from an intricate interplay between multiple neuronal populations in the brainstem, forebrain and hypothalamus and the resulting varying levels of neuromodulators. Recently, there has been progress in the understanding of those rhythms both from a physiological as well as theoretical perspective. However, how these neuromodulators affect the generation of the different EEG patterns and their temporal dynamics is poorly understood. Here, we build upon previous work on a neural mass model of the sleeping cortex and investigate the effect of those neuromodulators on the dynamics of the cortex and the corresponding transition between wakefulness and the different sleep stages. We show that our simplified model is sufficient to generate the essential features of human EEG over a full day. This approach builds a bridge between sleep regulatory networks and EEG generating neural mass models and provides a valuable tool for model validation.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TRDNCRCM\\Costa et al. - 2016 - Modeling the effect of sleep regulation on a neura.pdf}
}

@article{crutchfieldOrderChaos2012,
  title = {Between Order and Chaos},
  author = {Crutchfield, James P.},
  date = {2012-01},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {8},
  number = {1},
  pages = {17--24},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys2190},
  url = {https://www.nature.com/articles/nphys2190},
  urldate = {2022-10-01},
  abstract = {What is a pattern? How do we come to recognize patterns never seen before? Quantifying the notion of pattern and formalizing the process of pattern discovery go right to the heart of physical science. Over the past few decades physics’ view of nature’s lack of structure—its unpredictability—underwent a major renovation with the discovery of deterministic chaos, overthrowing two centuries of Laplace’s strict determinism in classical physics. Behind the veil of apparent randomness, though, many processes are highly ordered, following simple rules. Tools adapted from the theories of information and computation have brought physical science to the brink of automatically discovering hidden patterns and quantifying their structural complexity.},
  issue = {1},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QIEHIFSL\\Crutchfield - 2012 - Between order and chaos.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\F58V7STZ\\nphys2190.html}
}

@article{dacostaExplosivePercolationTransition2010,
  title = {Explosive {{Percolation Transition}} Is {{Actually Continuous}}},
  author = {da Costa, R. A. and Dorogovtsev, S. N. and Goltsev, A. V. and Mendes, J. F. F.},
  options = {useprefix=true},
  date = {2010-12-14},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {105},
  number = {25},
  pages = {255701},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.105.255701},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.105.255701},
  urldate = {2022-10-05},
  abstract = {Recently a discontinuous percolation transition was reported in a new “explosive percolation” problem for irreversible systems [D. Achlioptas, R. M. D’Souza, and J. Spencer, Science 323, 1453 (2009)] in striking contrast to ordinary percolation. We consider a representative model which shows that the explosive percolation transition is actually a continuous, second order phase transition though with a uniquely small critical exponent of the percolation cluster size. We describe the unusual scaling properties of this transition and find its critical exponents and dimensions.},
  keywords = {networks,percolation,phase transitions},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\677AC7BN\\da Costa et al. - 2010 - Explosive Percolation Transition is Actually Conti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WENV6L8P\\PhysRevLett.105.html}
}

@article{dallaportaFeedforwardFeedbackInfluences2021,
  title = {Feedforward and Feedback Influences through Distinct Frequency Bands between Two Spiking-Neuron Networks},
  author = {Dalla Porta, Leonardo and Castro, Daniel M. and Copelli, Mauro and Carelli, Pedro V. and Matias, Fernanda S.},
  date = {2021-11-11},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {5},
  pages = {054404},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.104.054404},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.054404},
  urldate = {2022-10-02},
  abstract = {Several studies on brain signals suggested that bottom-up and top-down influences are exerted through distinct frequency bands among visual cortical areas. It was recently shown that theta and gamma rhythms subserve feedforward, whereas the feedback influence is dominated by the alpha-beta rhythm in primates. A few theoretical models for reproducing these effects have been proposed so far. Here we show that a simple but biophysically plausible two-network motif composed of spiking-neuron models and chemical synapses can exhibit feedforward and feedback influences through distinct frequency bands. Different from previous studies, this kind of model allows us to study directed influences not only at the population level, by using a proxy for the local field potential, but also at the cellular level, by using the neuronal spiking series.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AQTVKU5U\\Dalla Porta et al. - 2021 - Feedforward and feedback influences through distin.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z9Q4L6KG\\PhysRevE.104.html}
}

@article{davisPhaseTransitionsInformation2020,
  title = {Phase Transitions in Information Spreading on Structured Populations},
  author = {Davis, Jessica T. and Perra, Nicola and Zhang, Qian and Moreno, Yamir and Vespignani, Alessandro},
  date = {2020-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {16},
  number = {5},
  pages = {590--596},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-020-0810-3},
  url = {https://www.nature.com/articles/s41567-020-0810-3},
  urldate = {2022-10-02},
  abstract = {Mathematical models of social contagion that incorporate networks of human interactions have become increasingly popular, however, very few approaches have tackled the challenges of including complex and realistic properties of socio-technical systems. Here, we define a framework to characterize the dynamics of the Maki–Thompson rumour spreading model in structured populations, and analytically find a previously uncharacterized dynamical phase transition that separates the local and global contagion regimes. We validate our threshold prediction through extensive Monte Carlo simulations. Furthermore, we apply this framework in two real-world systems, the European commuting and transportation network and the Digital Bibliography and Library Project collaboration network. Our findings highlight the importance of the underlying population structure in understanding social contagion phenomena and have the potential to define new intervention strategies aimed at hindering or facilitating the diffusion of information in socio-technical systems.},
  issue = {5},
  langid = {english},
  keywords = {Complex networks,Phase transitions and critical phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NSLJ53VL\\Davis et al. - 2020 - Phase transitions in information spreading on stru.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MMAGCJ6S\\s41567-020-0810-3.html}
}

@article{dedomenicoPhysicsSpreadingProcesses2016,
  title = {The Physics of Spreading Processes in Multilayer Networks},
  author = {De Domenico, Manlio and Granell, Clara and Porter, Mason A. and Arenas, Alex},
  date = {2016-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {12},
  number = {10},
  pages = {901--906},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys3865},
  url = {https://www.nature.com/articles/nphys3865},
  urldate = {2022-10-01},
  abstract = {Despite the success of traditional network analysis, standard networks provide a limited representation of complex systems, which often include different types of relationships (or ‘multiplexity’) between their components. Such structural complexity has a significant effect on both dynamics and function. Throwing away or aggregating available structural information can generate misleading results and be a major obstacle towards attempts to understand complex systems. The recent multilayer approach for modelling networked systems explicitly allows the incorporation of multiplexity and other features of realistic systems. It allows one to couple different structural relationships by encoding them in a convenient mathematical object. It also allows one to couple different dynamical processes on top of such interconnected structures. The resulting framework plays a crucial role in helping to achieve a thorough, accurate understanding of complex systems. The study of multilayer networks has also revealed new physical phenomena that remain hidden when using ordinary graphs, the traditional network representation. Here we survey progress towards attaining a deeper understanding of spreading processes on multilayer networks, and we highlight some of the physical phenomena related to spreading processes that emerge from multilayer structure.},
  issue = {10},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RT6PDM9I\\De Domenico et al. - 2016 - The physics of spreading processes in multilayer n.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZNEIYACP\\nphys3865.html}
}

@article{dedomenicoPhysicsSpreadingProcesses2016a,
  title = {The Physics of Spreading Processes in Multilayer Networks},
  author = {De Domenico, Manlio and Granell, Clara and Porter, Mason A. and Arenas, Alex},
  date = {2016-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {12},
  number = {10},
  pages = {901--906},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys3865},
  url = {https://www.nature.com/articles/nphys3865},
  urldate = {2022-10-03},
  abstract = {Despite the success of traditional network analysis, standard networks provide a limited representation of complex systems, which often include different types of relationships (or ‘multiplexity’) between their components. Such structural complexity has a significant effect on both dynamics and function. Throwing away or aggregating available structural information can generate misleading results and be a major obstacle towards attempts to understand complex systems. The recent multilayer approach for modelling networked systems explicitly allows the incorporation of multiplexity and other features of realistic systems. It allows one to couple different structural relationships by encoding them in a convenient mathematical object. It also allows one to couple different dynamical processes on top of such interconnected structures. The resulting framework plays a crucial role in helping to achieve a thorough, accurate understanding of complex systems. The study of multilayer networks has also revealed new physical phenomena that remain hidden when using ordinary graphs, the traditional network representation. Here we survey progress towards attaining a deeper understanding of spreading processes on multilayer networks, and we highlight some of the physical phenomena related to spreading processes that emerge from multilayer structure.},
  issue = {10},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KEQ5BWVY\\De Domenico et al. - 2016 - The physics of spreading processes in multilayer n.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FZYHTLX7\\nphys3865.html}
}

@article{degerFluctuationsInformationFiltering2014,
  title = {Fluctuations and Information Filtering in Coupled Populations of Spiking Neurons with Adaptation},
  author = {Deger, Moritz and Schwalger, Tilo and Naud, Richard and Gerstner, Wulfram},
  date = {2014-12-01},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {90},
  number = {6},
  eprint = {1311.4206},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  pages = {062704},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.90.062704},
  url = {http://arxiv.org/abs/1311.4206},
  urldate = {2022-09-02},
  abstract = {Finite-sized populations of spiking elements are fundamental to brain function, but also used in many areas of physics. Here we present a theory of the dynamics of finite-sized populations of spiking units, based on a quasi-renewal description of neurons with adaptation. We derive an integral equation with colored noise that governs the stochastic dynamics of the population activity in response to time-dependent stimulation and calculate the spectral density in the asynchronous state. We show that systems of coupled populations with adaptation can generate a frequency band in which sensory information is preferentially encoded. The theory is applicable to fully as well as randomly connected networks, and to leaky integrate-and-fire as well as to generalized spiking neurons with adaptation on multiple time scales.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\54MR2BB8\\Deger et al. - 2014 - Fluctuations and information filtering in coupled .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YVZ863KA\\1311.html}
}

@article{delarochaCorrelationNeuralSpike2007,
  title = {Correlation between Neural Spike Trains Increases with Firing Rate},
  author = {de la Rocha, Jaime and Doiron, Brent and Shea-Brown, Eric and Josić, Krešimir and Reyes, Alex},
  options = {useprefix=true},
  date = {2007-08},
  journaltitle = {Nature},
  volume = {448},
  number = {7155},
  pages = {802--806},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature06028},
  url = {https://www.nature.com/articles/nature06028},
  urldate = {2022-10-28},
  abstract = {Deciphering a 'neural code' usually requires measurement of either the rate of spike (electrical impulses) production or the spike synchrony. However, these two measures are not independent, as higher rates are associated with higher synchrony. It is further shown that the connection between rate and synchrony enhances information coding.},
  issue = {7155},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DM9THWWD\\de la Rocha et al. - 2007 - Correlation between neural spike trains increases .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VFM7AXJP\\nature06028.html}
}

@online{DendriticComputationsCaptured,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model},
  doi = {10.1073/pnas.1904463116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GMFEWWRS\\Dendritic computations captured by an effective po.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6S27Q8Y\\pnas.html}
}

@online{DendriticComputationsCaptureda,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model | {{PNAS}}},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08}
}

@article{denfieldAttentionalFluctuationsInduce2018,
  title = {Attentional Fluctuations Induce Shared Variability in Macaque Primary Visual Cortex},
  author = {Denfield, George H. and Ecker, Alexander S. and Shinn, Tori J. and Bethge, Matthias and Tolias, Andreas S.},
  date = {2018-07-09},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {2654},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05123-6},
  url = {https://www.nature.com/articles/s41467-018-05123-6},
  urldate = {2023-01-05},
  abstract = {Variability in neuronal responses to identical stimuli is frequently correlated across a population. Attention is thought to reduce these correlations by suppressing noisy inputs shared by the population. However, even with precise control of the visual stimulus, the subject’s attentional state varies across trials. While these state fluctuations are bound to induce some degree of correlated variability, it is currently unknown how strong their effect is, as previous studies generally do not dissociate changes in attentional strength from changes in attentional state variability. We designed a novel paradigm that does so and find both a pronounced effect of attentional fluctuations on correlated variability at long timescales and attention-dependent reductions in correlations at short timescales. These effects predominate in layers 2/3, as expected from a feedback signal such as attention. Thus, significant portions of correlated variability can be attributed to fluctuations in internally generated signals, like attention, rather than noise.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Striate cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3WR8R348\\Denfield et al. - 2018 - Attentional fluctuations induce shared variability.pdf}
}

@article{destexheWilsonCowanModel2009,
  title = {The {{Wilson}}–{{Cowan}} Model, 36 Years Later},
  author = {Destexhe, Alain and Sejnowski, Terrence J.},
  date = {2009-07},
  journaltitle = {Biological cybernetics},
  shortjournal = {Biol Cybern},
  volume = {101},
  number = {1},
  eprint = {19662434},
  eprinttype = {pmid},
  pages = {1--2},
  issn = {0340-1200},
  doi = {10.1007/s00422-009-0328-3},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2866289/},
  urldate = {2020-09-29},
  abstract = {The Wilson–Cowan model of interacting neurons (1973) is one of the most influential papers published in Biological Cybernetics (Kybernetik). This paper and a companion paper published in 1972 have been cited over 1000 times. Rather than focus on the microscopic properties of neurons, Wilson and Cowan analyzed the collective properties of large numbers of neurons using methods from statistical mechanics, based on the mean-field approach. New experimental techniques to measure neuronal activity at the level of large populations are now available to test these models, including optical recording of brain activity with intrinsic signals and voltage sensitive dyes, and new methods for analyzing EEG and MEG. These measurement techniques have revealed patterns of coherent activity that span centimetres of tissue in the cerebral cortex. Here the underlying ideas are reviewed in a historic context.},
  pmcid = {PMC2866289},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P5FE2M44\\Destexhe and Sejnowski - 2009 - The Wilson–Cowan model, 36 years later.pdf}
}

@article{diazSimilarLocalNeuronal2021,
  title = {Similar Local Neuronal Dynamics May Lead to Different Collective Behavior},
  author = {Diaz, Margarita M. Sánchez and Trejo, Eyisto J. Aguilar and Martin, Daniel A. and Cannas, Sergio A. and Grigera, Tomás S. and Chialvo, Dante R.},
  date = {2021-12-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {6},
  pages = {064309},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.104.064309},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.064309},
  urldate = {2022-10-01},
  abstract = {This report is concerned with the relevance of the microscopic rules that implement individual neuronal activation, in determining the collective dynamics, under variations of the network topology. To fix ideas we study the dynamics of two cellular automaton models, commonly used, rather in-distinctively, as the building blocks of large-scale neuronal networks. One model, due to Greenberg and Hastings (GH), can be described by evolution equations mimicking an integrate-and-fire process, while the other model, due to Kinouchi and Copelli (KC), represents an abstract branching process, where a single active neuron activates a given number of postsynaptic neurons according to a prescribed “activity” branching ratio. Despite the apparent similarity between the local neuronal dynamics of the two models, it is shown that they exhibit very different collective dynamics as a function of the network topology. The GH model shows qualitatively different dynamical regimes as the network topology is varied, including transients to a ground (inactive) state, continuous and discontinuous dynamical phase transitions. In contrast, the KC model only exhibits a continuous phase transition, independently of the network topology. These results highlight the importance of paying attention to the microscopic rules chosen to model the interneuronal interactions in large-scale numerical simulations, in particular when the network topology is far from a mean-field description. One such case is the extensive work being done in the context of the Human Connectome, where a wide variety of types of models are being used to understand the brain collective dynamics.}
}

@article{douglasRecurrentExcitationNeocortical1995,
  title = {Recurrent {{Excitation}} in {{Neocortical Circuits}}},
  author = {Douglas, Rodney J. and Koch, Christof and Mahowald, Misha and Martin, Kevan A. C. and Suarez, Humbert H.},
  date = {1995},
  journaltitle = {Science},
  volume = {269},
  number = {5226},
  eprint = {2887714},
  eprinttype = {jstor},
  pages = {981--985},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  abstract = {The majority of synapses in the mammalian cortex originate from cortical neurons. Indeed, the largest input to cortical cells comes from neighboring excitatory cells. However, most models of cortical development and processing do not reflect the anatomy and physiology of feedback excitation and are restricted to serial feedforward excitation. This report describes how populations of neurons in cat visual cortex can use excitatory feedback, characterized as an effective "network conductance," to amplify their feedforward input signals and demonstrates how neuronal discharge can be kept proportional to stimulus strength despite strong, recurrent connections that threaten to cause runaway excitation. These principles are incorporated into models of cortical direction and orientation selectivity that emphasize the basic design principles of cortical architectures.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4HUSPB72\\Douglas et al. - 1995 - Recurrent Excitation in Neocortical Circuits.pdf}
}

@article{dumoulinLayersNeuroscience2017,
  title = {Layers of {{Neuroscience}}},
  author = {Dumoulin, Serge O.},
  date = {2017-12-20},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {96},
  number = {6},
  pages = {1205--1206},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.12.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627317311273},
  urldate = {2023-01-05},
  abstract = {In a patch of cortex, laminae connect to different parts of the brain. Huber et~al. (2017) demonstrate the ability of human neuroimaging to derive laminar information flow between brain regions, paving the way for human neuroscience applications.},
  langid = {english},
  keywords = {connectivity,cortex,fMRI,lamina,layers,neuroimaging},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5R8L36T8\\Dumoulin - 2017 - Layers of Neuroscience.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3GZKTNXB\\S0896627317311273.html}
}

@online{DynamicalRegimeSensory,
  title = {The {{Dynamical Regime}} of {{Sensory Cortex}}: {{Stable Dynamics}} around a {{Single Stimulus-Tuned Attractor Account}} for {{Patterns}} of {{Noise Variability}}: {{Neuron}}},
  url = {https://www.cell.com/neuron/fulltext/S0896-6273(18)30325-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627318303258%3Fshowall%3Dtrue},
  urldate = {2023-01-03},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8QJ7MBYT\\S0896-6273(18)30325-8.html}
}

@article{echevesteCorticallikeDynamicsRecurrent2020,
  title = {Cortical-like Dynamics in Recurrent Circuits Optimized for Sampling-Based Probabilistic Inference},
  author = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, Máté},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1138--1149},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0671-1},
  url = {https://www.nature.com/articles/s41593-020-0671-1},
  urldate = {2020-11-16},
  abstract = {Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory–inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function—fast sampling-based inference—and predict further properties of these motifs that can be tested in future experiments.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RNMV49VD\\Echeveste et al. - 2020 - Cortical-like dynamics in recurrent circuits optim.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MFG7WH3U\\s41593-020-0671-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V9D3A8RM\\s41593-020-0671-1.html}
}

@misc{eckmannSynapsetypespecificCompetitiveHebbian2022,
  title = {Synapse-Type-Specific Competitive {{Hebbian}} Learning Forms Functional Recurrent Networks},
  author = {Eckmann, Samuel and Gjorgjieva, Julijana},
  date = {2022-03-14},
  pages = {2022.03.11.483899},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.03.11.483899},
  url = {https://www.biorxiv.org/content/10.1101/2022.03.11.483899v1},
  urldate = {2022-09-30},
  abstract = {Cortical networks exhibit complex stimulus-response patterns. Previous work has identified the balance between excitatory and inhibitory currents as a central component of cortical computations, but has not considered how the required synaptic connectivity emerges from biologically plausible plasticity rules. Using theory and modeling, we demonstrate how a wide range of cortical response properties can arise from Hebbian learning that is stabilized by the synapse-type-specific competition for synaptic resources. In fully plastic recurrent circuits, this competition enables the development and decorrelation of inhibition-balanced receptive fields. Networks develop an assembly structure with stronger connections between similarly tuned neurons and exhibit response normalization and surround suppression. These results demonstrate how neurons can self-organize into functional circuits and provide a foundational understanding of plasticity in recurrent networks.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5SVHD698\\Eckmann and Gjorgjieva - 2022 - Synapse-type-specific competitive Hebbian learning.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NES5VQN8\\2022.03.11.html}
}

@article{efronComputerAgeStatistical,
  title = {Computer {{Age Statistical Inference}}},
  author = {Efron, Bradley and Hastie, Trevor},
  pages = {493},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\466BVHQG\\Efron and Hastie - Computer Age Statistical Inference.pdf}
}

@article{engelSelectiveModulationCortical2016,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-03},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6DCJMHHR\\Engel et al. - 2016 - Selective modulation of cortical state during spat.pdf}
}

@article{engelSelectiveModulationCortical2016a,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-09},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S88T9JZR\\Engel et al. - 2016 - Selective modulation of cortical state during spat.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VCFYAGL3\\science.aag1420.pdf}
}

@article{engelSelectiveModulationCortical2016b,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-03},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.}
}

@unpublished{fangExploitingNeuronSynapse2020,
  title = {Exploiting {{Neuron}} and {{Synapse Filter Dynamics}} in {{Spatial Temporal Learning}} of {{Deep Spiking Neural Network}}},
  author = {Fang, Haowen and Shrestha, Amar and Zhao, Ziyi and Qiu, Qinru},
  date = {2020-07-25},
  eprint = {2003.02944},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2003.02944},
  urldate = {2020-10-16},
  abstract = {The recent discovered spatial-temporal information processing capability of bio-inspired Spiking neural networks (SNN) has enabled some interesting models and applications. However designing large-scale and high-performance model is yet a challenge due to the lack of robust training algorithms. A bio-plausible SNN model with spatial-temporal property is a complex dynamic system. Each synapse and neuron behave as filters capable of preserving temporal information. As such neuron dynamics and filter effects are ignored in existing training algorithms, the SNN downgrades into a memoryless system and loses the ability of temporal signal processing. Furthermore, spike timing plays an important role in information representation, but conventional rate-based spike coding models only consider spike trains statistically, and discard information carried by its temporal structures. To address the above issues, and exploit the temporal dynamics of SNNs, we formulate SNN as a network of infinite impulse response (IIR) filters with neuron nonlinearity. We proposed a training algorithm that is capable to learn spatial-temporal patterns by searching for the optimal synapse filter kernels and weights. The proposed model and training algorithm are applied to construct associative memories and classifiers for synthetic and public datasets including MNIST, NMNIST, DVS 128 etc.; and their accuracy outperforms state-of-art approaches.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KHQFPTIR\\Fang et al. - 2020 - Exploiting Neuron and Synapse Filter Dynamics in S.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NDX6FBLK\\2003.html}
}

@article{fergusonMechanismsUnderlyingGain2020,
  title = {Mechanisms Underlying Gain Modulation in the Cortex},
  author = {Ferguson, Katie A. and Cardin, Jessica A.},
  date = {2020-02},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {21},
  number = {2},
  pages = {80--92},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-019-0253-y},
  url = {https://www.nature.com/articles/s41583-019-0253-y},
  urldate = {2023-01-03},
  abstract = {Cortical gain regulation allows neurons to respond adaptively to changing inputs. Neural gain is modulated by internal and external influences, including attentional and arousal states, motor activity and neuromodulatory input. These influences converge to a common set of mechanisms for gain modulation, including GABAergic inhibition, synaptically driven fluctuations in membrane potential, changes in cellular conductance and changes in other biophysical neural properties. Recent work has identified GABAergic interneurons as targets of neuromodulatory input and mediators of state-dependent gain modulation. Here, we review the engagement and effects of gain modulation in the cortex. We highlight key recent findings that link phenomenological observations of gain modulation to underlying cellular and circuit-level mechanisms. Finally, we place these cellular and circuit interactions in the larger context of their impact on perception and cognition.},
  issue = {2},
  langid = {english},
  keywords = {Computational neuroscience,Neural circuits,Neuronal physiology,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8BGZB9HM\\Ferguson and Cardin - 2020 - Mechanisms underlying gain modulation in the corte.pdf}
}

@article{fernandezMolecularAtlasAdult2020,
  title = {Molecular Atlas of\hspace{0.166em}the\hspace{0.166em}Adult Mouse Brain},
  author = {Fernandez, Jose},
  date = {2020},
  journaltitle = {SCIENCE ADVANCES},
  pages = {14},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KMUMT29G\\Fernandez - 2020 - Molecular atlas of the adult mouse brain.pdf}
}

@article{festaNeuronalVariabilityReflects2021,
  title = {Neuronal Variability Reflects Probabilistic Inference Tuned to Natural Image Statistics},
  author = {Festa, Dylan and Aschner, Amir and Davila, Aida and Kohn, Adam and Coen-Cagli, Ruben},
  date = {2021-06-15},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {3635},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-23838-x},
  url = {https://www.nature.com/articles/s41467-021-23838-x},
  urldate = {2022-10-17},
  abstract = {Neuronal activity in sensory cortex fluctuates over time and across repetitions of the same input. This variability is often considered detrimental to neural coding. The theory of neural sampling proposes instead that variability encodes the uncertainty of perceptual inferences. In primary visual cortex (V1), modulation of variability by sensory and non-sensory factors supports this view. However, it is unknown whether V1 variability reflects the statistical structure of visual inputs, as would be required for inferences correctly tuned to the statistics of the natural environment. Here we combine analysis of image statistics and recordings in macaque V1 to show that probabilistic inference tuned to natural image statistics explains the widely observed dependence between spike~count variance and mean, and the modulation of V1 activity and variability by spatial context in images. Our results show that the properties of a basic aspect of cortical responses—their variability—can be explained by a probabilistic representation tuned to naturalistic inputs.},
  issue = {1},
  langid = {english},
  keywords = {Computational neuroscience,Neural encoding,Neuroscience,Striate cortex,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3U6PECBL\\Festa et al. - 2021 - Neuronal variability reflects probabilistic infere.pdf}
}

@article{filipchukAwakePerceptionAssociated2022,
  title = {Awake Perception Is Associated with Dedicated Neuronal Assemblies in the Cerebral Cortex},
  author = {Filipchuk, Anton and Schwenkgrub, Joanna and Destexhe, Alain and Bathellier, Brice},
  date = {2022-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {25},
  number = {10},
  pages = {1327--1338},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01168-5},
  url = {https://www.nature.com/articles/s41593-022-01168-5},
  urldate = {2022-12-23},
  abstract = {Neural activity in the sensory cortex combines stimulus responses and ongoing activity, but it remains unclear whether these reflect the same underlying dynamics or separate processes. In the present study, we show in mice that, during wakefulness, the neuronal assemblies evoked by sounds in the auditory cortex and thalamus are specific to the stimulus and distinct from the assemblies observed in ongoing activity. By contrast, under three different anesthetics, evoked assemblies are indistinguishable from ongoing assemblies in the cortex. However, they remain distinct in the thalamus. A strong remapping of sensory responses accompanies this dynamic state change produced by anesthesia. Together, these results show that the awake cortex engages dedicated neuronal assemblies in response to sensory inputs, which we suggest is a network correlate of sensory perception.},
  issue = {10},
  langid = {english},
  keywords = {Cortex,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IICG7LZV\\Filipchuk et al. - 2022 - Awake perception is associated with dedicated neur.pdf}
}

@article{fisekAreHumanDendrites2020,
  title = {Are {{Human Dendrites Different}}?},
  author = {Fişek, Mehmet and Häusser, Michael},
  date = {2020-06-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {6},
  pages = {411--412},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.03.002},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320300693},
  urldate = {2020-10-29},
  abstract = {The first patch-clamp recordings from the dendrites of human neocortical neurons have recently been reported by Beaulieu-Laroche et al. and Gidon et al. These studies have shown that human dendrites are electrically excitable, exhibiting backpropagating action potentials and fast dendritic calcium spikes. This new frontier highlights the potential for interspecies differences in the biophysics of dendritic computation.},
  langid = {english},
  keywords = {cortex,dendrite,human,neural computation,patch clamp,pyramidal cell,rodent,synaptic integration},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YKVESYHP\\Fişek and Häusser - 2020 - Are Human Dendrites Different.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DA79YYSI\\S1364661320300693.html}
}

@article{flackCoarsegrainingDownwardCausation2017,
  title = {Coarse-Graining as a Downward Causation Mechanism},
  author = {Flack, Jessica C.},
  date = {2017-12-28},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {375},
  number = {2109},
  pages = {20160338},
  publisher = {{Royal Society}},
  doi = {10.1098/rsta.2016.0338},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0338},
  urldate = {2022-10-01},
  abstract = {Downward causation is the controversial idea that ‘higher’ levels of organization can causally influence behaviour at ‘lower’ levels of organization. Here I propose that we can gain traction on downward causation by being operational and examining how adaptive systems identify regularities in evolutionary or learning time and use these regularities to guide behaviour. I suggest that in many adaptive systems components collectively compute their macroscopic worlds through coarse-graining. I further suggest we move from simple feedback to downward causation when components tune behaviour in response to estimates of collectively computed macroscopic properties. I introduce a weak and strong notion of downward causation and discuss the role the strong form plays in the origins of new organizational levels. I illustrate these points with examples from the study of biological and social systems and deep neural networks. This article is part of the themed issue ‘Reconceptualizing the origins of life’.},
  keywords = {biological effective theories,collective computation,endogenous coarse-graining,organizational levels,regularity estimation},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AA4AXGNL\\Flack - 2017 - Coarse-graining as a downward causation mechanism.pdf}
}

@article{fonteneleCriticalityCorticalStates2019,
  title = {Criticality between {{Cortical States}}},
  author = {Fontenele, Antonio J. and de Vasconcelos, Nivaldo A. P. and Feliciano, Thaís and Aguiar, Leandro A. A. and Soares-Cunha, Carina and Coimbra, Bárbara and Dalla Porta, Leonardo and Ribeiro, Sidarta and Rodrigues, Ana João and Sousa, Nuno and Carelli, Pedro V. and Copelli, Mauro},
  options = {useprefix=true},
  date = {2019-05-21},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {122},
  number = {20},
  pages = {208101},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.122.208101},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.122.208101},
  urldate = {2022-10-02},
  abstract = {Since the first measurements of neuronal avalanches, the critical brain hypothesis has gained traction. However, if the brain is critical, what is the phase transition? For several decades, it has been known that the cerebral cortex operates in a diversity of regimes, ranging from highly synchronous states (with higher spiking variability) to desynchronized states (with lower spiking variability). Here, using both new and publicly available data, we test independent signatures of criticality and show that a phase transition occurs in an intermediate value of spiking variability, in both anesthetized and freely moving animals. The critical exponents point to a universality class different from mean-field directed percolation. Importantly, as the cortex hovers around this critical point, the avalanche exponents follow a linear relation that encompasses previous experimental results from different setups and is reproduced by a model.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EBQABDL4\\Fontenele et al. - 2019 - Criticality between Cortical States.pdf}
}

@article{fristonFreeenergyPrincipleUnified2010,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  date = {2010-02},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {11},
  number = {2},
  pages = {127--138},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2787},
  url = {http://www.nature.com/articles/nrn2787},
  urldate = {2020-09-07},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7PEKABBM\\Friston - 2010 - The free-energy principle a unified brain theory.pdf}
}

@online{FrontiersAttentionUncertainty,
  title = {Frontiers | {{Attention}}, {{Uncertainty}}, and {{Free-Energy}}},
  url = {https://www.frontiersin.org/articles/10.3389/fnhum.2010.00215/full},
  urldate = {2022-12-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6ECFXZ6T\\Frontiers  Attention, Uncertainty, and Free-Energ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QE9EJLJI\\full.html}
}

@online{FrontiersDualCoding,
  title = {Frontiers | {{Dual Coding Theory Explains Biphasic Collective Computation}} in {{Neural Decision-Making}}},
  url = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00313/full},
  urldate = {2022-12-06},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WSZ6Q5DG\\full.html}
}

@article{fujisawaBehaviordependentShorttermAssembly2008,
  title = {Behavior-Dependent Short-Term Assembly Dynamics in the Medial Prefrontal Cortex},
  author = {Fujisawa, Shigeyoshi and Amarasingham, Asohan and Harrison, Matthew T. and Buzsáki, György},
  date = {2008-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {11},
  number = {7},
  pages = {823--833},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.2134},
  url = {https://www.nature.com/articles/nn.2134},
  urldate = {2022-11-04},
  abstract = {Fujisawa and colleagues report that during a working memory task, firing patterns in ensembles of rat medial prefrontal cortex neurons reflect behavioral outcomes on coarser time scales and short-term synaptic plasticity on finer time scales. These results suggest that short-term plasticity plays a role in the neural computations guiding behavior.},
  issue = {7},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I7RQQB9V\\Fujisawa et al. - 2008 - Behavior-dependent short-term assembly dynamics in.pdf}
}

@article{gallegoLongtermStabilityCortical2020,
  title = {Long-Term Stability of Cortical Population Dynamics Underlying Consistent Behavior},
  author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
  date = {2020-02},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {2},
  pages = {260--270},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0555-4},
  url = {https://www.nature.com/articles/s41593-019-0555-4},
  urldate = {2020-10-06},
  abstract = {Animals readily execute learned behaviors in a consistent manner over long periods of time, and yet no equally stable neural correlate has been demonstrated. How does the cortex achieve this stable control? Using the sensorimotor system as a model of cortical processing, we investigated the hypothesis that the dynamics of neural latent activity, which captures the dominant co-variation patterns within the neural population, must be preserved across time. We recorded from populations of neurons in premotor, primary motor and somatosensory cortices as monkeys performed a reaching task, for up to 2 years. Intriguingly, despite a steady turnover in the recorded neurons, the low-dimensional latent dynamics remained stable. The stability allowed reliable decoding of behavioral features for the entire timespan, while fixed decoders based directly on the recorded neural activity degraded substantially. We posit that stable latent cortical dynamics within the manifold are the fundamental building blocks underlying consistent behavioral execution.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YXAL3Y7N\\Gallego et al. - 2020 - Long-term stability of cortical population dynamic.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KDCJ5ERA\\s41593-019-0555-4.html}
}

@article{galuskeRelationGammaOscillations2019,
  title = {Relation between Gamma Oscillations and Neuronal Plasticity in the Visual Cortex},
  author = {Galuske, Ralf A. W. and Munk, Matthias H. J. and Singer, Wolf},
  date = {2019-11-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {46},
  pages = {23317--23325},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1901277116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1901277116},
  urldate = {2022-10-03},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\K3PIX3B2\\Galuske et al. - 2019 - Relation between gamma oscillations and neuronal p.pdf}
}

@article{garrettExperienceShapesActivity2020,
  title = {Experience Shapes Activity Dynamics and Stimulus Coding of {{VIP}} Inhibitory Cells},
  author = {Garrett, Marina and Manavi, Sahar and Roll, Kate and Ollerenshaw, Douglas R and Groblewski, Peter A and Ponvert, Nicholas D and Kiggins, Justin T and Casal, Linzy and Mace, Kyla and Williford, Ali and Leon, Arielle and Jia, Xiaoxuan and Ledochowitsch, Peter and Buice, Michael A and Wakeman, Wayne and Mihalas, Stefan and Olsen, Shawn R},
  editor = {Bathellier, Brice and Gold, Joshua I and Bathellier, Brice and Keller, Georg B},
  date = {2020-02-26},
  journaltitle = {eLife},
  volume = {9},
  pages = {e50340},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.50340},
  url = {https://doi.org/10.7554/eLife.50340},
  urldate = {2020-09-24},
  abstract = {Cortical circuits can flexibly change with experience and learning, but the effects on specific cell types, including distinct inhibitory types, are not well understood. Here we investigated how excitatory and VIP inhibitory cells in layer 2/3 of mouse visual cortex were impacted by visual experience in the context of a behavioral task. Mice learned a visual change detection task with a set of eight natural scene images. Subsequently, during 2-photon imaging experiments, mice performed the task with these familiar images and three sets of novel images. Strikingly, the temporal dynamics of VIP activity differed markedly between novel and familiar images: VIP cells were stimulus-driven by novel images but were suppressed by familiar stimuli and showed ramping activity when expected stimuli were omitted from a temporally predictable sequence. This prominent change in VIP activity suggests that these cells may adopt different modes of processing under novel versus familiar conditions.},
  keywords = {behavior,learning,visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZQNTX29\\Garrett et al. - 2020 - Experience shapes activity dynamics and stimulus c.pdf}
}

@online{GaussianProcessesMachine,
  title = {Gaussian {{Processes}} for {{Machine Learning}}: {{Contents}}},
  url = {http://gaussianprocess.org/gpml/chapters/},
  urldate = {2022-09-26},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SF5ES5AD\\chapters.html}
}

@article{ghavasiehStatisticalPhysicsComplex2020,
  title = {Statistical Physics of Complex Information Dynamics},
  author = {Ghavasieh, Arsham and Nicolini, Carlo and De Domenico, Manlio},
  date = {2020-11-10},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {102},
  number = {5},
  pages = {052304},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.102.052304},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.102.052304},
  urldate = {2022-10-02},
  abstract = {The constituents of a complex system exchange information to function properly. Their signaling dynamics often leads to the appearance of emergent phenomena, such as phase transitions and collective behaviors. While information exchange has been widely modeled by means of distinct spreading processes—such as continuous-time diffusion, random walks, synchronization and consensus—on top of complex networks, a unified and physically grounded framework to study information dynamics and gain insights about the macroscopic effects of microscopic interactions is still eluding us. In this paper, we present this framework in terms of a statistical field theory of information dynamics, unifying a range of dynamical processes governing the evolution of information on top of static or time-varying structures. We show that information operators form a meaningful statistical ensemble and their superposition defines a density matrix that can be used for the analysis of complex dynamics. As a direct application, we show that the von Neumann entropy of the ensemble can be a measure of the functional diversity of complex systems, defined in terms of the functional differentiation of higher-order interactions among their components. Our results suggest that modularity and hierarchy, two key features of empirical complex systems—from the human brain to social and urban networks—play a key role to guarantee functional diversity and, consequently, are favored.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5CWJQFZB\\Ghavasieh et al. - 2020 - Statistical physics of complex information dynamic.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\88XY535E\\PhysRevE.102.html}
}

@article{ghoshNeuronalCorrelatesSelective2022,
  title = {Neuronal Correlates of Selective Attention and Effort in Visual Area {{V4}} Are Invariant of Motivational Context},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2022-06-10},
  journaltitle = {Science Advances},
  volume = {8},
  number = {23},
  pages = {eabc8812},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abc8812},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abc8812},
  urldate = {2022-12-28},
  abstract = {Task demands can differentially engage two fundamental attention components: selectivity (spatial bias) and effort (total nonselective attentional intensity). The relative contributions and interactions of these components in modulating neuronal signals remain unknown. We recorded V4 neurons while monkeys’ spatially selective attention and effort were independently controlled by adjusting either task difficulty or reward size at two locations. Neurons were robustly modulated by either selective attention or effort. Notably, increasing overall effort to improve performance at a distant site reduced neuronal responses even when performance was unchanged for receptive field stimuli. This interaction between attentional selectivity and effort was evident in single-trial spiking and can be explained by divisive normalization of spatially distributed behavioral performance at the single-neuron level. Changing motivation using task difficulty or reward produced indistinguishable effects. These results provide a cellular-level mechanism of how attention components integrate to modulate sensory processing in different motivational contexts.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3ANIUNZ6\\Ghosh and Maunsell - 2022 - Neuronal correlates of selective attention and eff.pdf}
}

@article{ghoshNeuronalCorrelatesSelective2022a,
  title = {Neuronal Correlates of Selective Attention and Effort in Visual Area {{V4}} Are Invariant of Motivational Context},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2022-06-10},
  journaltitle = {Science Advances},
  volume = {8},
  number = {23},
  pages = {eabc8812},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.abc8812},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abc8812},
  urldate = {2023-01-03},
  abstract = {Task demands can differentially engage two fundamental attention components: selectivity (spatial bias) and effort (total nonselective attentional intensity). The relative contributions and interactions of these components in modulating neuronal signals remain unknown. We recorded V4 neurons while monkeys’ spatially selective attention and effort were independently controlled by adjusting either task difficulty or reward size at two locations. Neurons were robustly modulated by either selective attention or effort. Notably, increasing overall effort to improve performance at a distant site reduced neuronal responses even when performance was unchanged for receptive field stimuli. This interaction between attentional selectivity and effort was evident in single-trial spiking and can be explained by divisive normalization of spatially distributed behavioral performance at the single-neuron level. Changing motivation using task difficulty or reward produced indistinguishable effects. These results provide a cellular-level mechanism of how attention components integrate to modulate sensory processing in different motivational contexts.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XUBGK2CD\\Ghosh and Maunsell - 2022 - Neuronal correlates of selective attention and eff.pdf}
}

@article{ghoshSingleTrialNeuronal2021,
  title = {Single Trial Neuronal Activity Dynamics of Attentional Intensity in Monkey Visual Area {{V4}}},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2021-03-31},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2003},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22281-2},
  url = {https://www.nature.com/articles/s41467-021-22281-2},
  urldate = {2022-12-19},
  abstract = {Understanding how activity of visual neurons represents distinct components of attention and their dynamics that account for improved visual performance remains elusive because single-unit experiments have not isolated the intensive aspect of attention from attentional selectivity. We isolated attentional intensity and its single trial dynamics as determined by spatially non-selective attentional performance in an orientation discrimination task while recording from neurons in monkey visual area V4. We found that attentional intensity is a distinct cognitive signal that can be distinguished from spatial selectivity, reward expectations and motor actions. V4 spiking on single trials encodes a combination of sensory and cognitive signals on different time scales. Attentional intensity and the detection of behaviorally relevant sensory signals are well represented, but immediate reward expectation and behavioral choices are poorly represented in V4 spiking. These results provide a detailed representation of perceptual and cognitive signals in V4 that are crucial for attentional performance.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Extrastriate cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AGFB3YS8\\Ghosh and Maunsell - 2021 - Single trial neuronal activity dynamics of attenti.pdf}
}

@article{ghoshSingleTrialNeuronal2021a,
  title = {Single Trial Neuronal Activity Dynamics of Attentional Intensity in Monkey Visual Area {{V4}}},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2021-03-31},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2003},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22281-2},
  url = {https://www.nature.com/articles/s41467-021-22281-2},
  urldate = {2023-01-03},
  abstract = {Understanding how activity of visual neurons represents distinct components of attention and their dynamics that account for improved visual performance remains elusive because single-unit experiments have not isolated the intensive aspect of attention from attentional selectivity. We isolated attentional intensity and its single trial dynamics as determined by spatially non-selective attentional performance in an orientation discrimination task while recording from neurons in monkey visual area V4. We found that attentional intensity is a distinct cognitive signal that can be distinguished from spatial selectivity, reward expectations and motor actions. V4 spiking on single trials encodes a combination of sensory and cognitive signals on different time scales. Attentional intensity and the detection of behaviorally relevant sensory signals are well represented, but immediate reward expectation and behavioral choices are poorly represented in V4 spiking. These results provide a detailed representation of perceptual and cognitive signals in V4 that are crucial for attentional performance.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Extrastriate cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TWFEXKZF\\Ghosh and Maunsell - 2021 - Single trial neuronal activity dynamics of attenti.pdf}
}

@article{gidonDendriticActionPotentials2020,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  date = {2020-01-03},
  journaltitle = {Science},
  volume = {367},
  number = {6473},
  eprint = {31896716},
  eprinttype = {pmid},
  pages = {83--87},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax6239},
  url = {https://science.sciencemag.org/content/367/6473/83},
  urldate = {2020-09-24},
  abstract = {Human dendrites are special A special developmental program in the human brain drives the disproportionate thickening of cortical layer 2/3. This suggests that the expansion of layer 2/3, along with its numerous neurons and their large dendrites, may contribute to what makes us human. Gidon et al. thus investigated the dendritic physiology of layer 2/3 pyramidal neurons in slices taken from surgically resected brain tissue in epilepsy patients. Dual somatodendritic recordings revealed previously unknown classes of action potentials in the dendrites of these neurons, which make their activity far more complex than has been previously thought. These action potentials allow single neurons to solve two long-standing computational problems in neuroscience that were considered to require multilayer neural networks. Science, this issue p. 83 The active electrical properties of dendrites shape neuronal input and output and are fundamental to brain function. However, our knowledge of active dendrites has been almost entirely acquired from studies of rodents. In this work, we investigated the dendrites of layer 2 and 3 (L2/3) pyramidal neurons of the human cerebral cortex ex vivo. In these neurons, we discovered a class of calcium-mediated dendritic action potentials (dCaAPs) whose waveform and effects on neuronal output have not been previously described. In contrast to typical all-or-none action potentials, dCaAPs were graded; their amplitudes were maximal for threshold-level stimuli but dampened for stronger stimuli. These dCaAPs enabled the dendrites of individual human neocortical pyramidal neurons to classify linearly nonseparable inputs—a computation conventionally thought to require multilayered networks. Dendritic action potentials extend the repertoire of computations available to human neurons. Dendritic action potentials extend the repertoire of computations available to human neurons.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCXZX7BN\\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HNZXZGEN\\83.html}
}

@article{gidonDendriticActionPotentials2020a,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  date = {2020-01-03},
  journaltitle = {Science},
  volume = {367},
  number = {6473},
  pages = {83--87},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aax6239},
  url = {https://www.science.org/doi/abs/10.1126/science.aax6239},
  urldate = {2022-10-01},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JIUYSHJX\\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf}
}

@article{girardi-schappoUnifiedTheorySynaptic2021,
  title = {A Unified Theory of {{E}}/{{I}} Synaptic Balance, Quasicritical Neuronal Avalanches and Asynchronous Irregular Spiking},
  author = {Girardi-Schappo, Mauricio and Galera, Emilio F. and Carvalho, Tawan T. A. and Brochini, Ludmila and Kamiji, Nilton L. and Roque, Antonio C. and Kinouchi, Osame},
  date = {2021-10},
  journaltitle = {Journal of Physics: Complexity},
  shortjournal = {J. Phys. Complex.},
  volume = {2},
  number = {4},
  pages = {045001},
  publisher = {{IOP Publishing}},
  issn = {2632-072X},
  doi = {10.1088/2632-072X/ac2792},
  url = {https://doi.org/10.1088/2632-072x/ac2792},
  urldate = {2022-10-01},
  abstract = {Neuronal avalanches and asynchronous irregular (AI) firing patterns have been thought to represent distinct frameworks to understand the brain spontaneous activity. The former is typically present in systems where there is a balance between the slow accumulation of tension and its fast dissipation, whereas the latter is accompanied by the balance between synaptic excitation and inhibition (E/I). Here, we develop a new theory of E/I balance that relies on two homeostatic adaptation mechanisms: the short-term depression of inhibition and the spike-dependent threshold increase. First, we turn off the adaptation and show that the so-called static system has a typical critical point commonly attributed to self-organized critical models. Then, we turn on the adaptation and show that the network evolves to a dynamic regime in which: (I) E/I synapses balance for large recovery time scales; (II) an AI firing pattern emerges; and (III) neuronal avalanches display power laws. This is the first time that these three phenomena appear simultaneously in the same network activity. Thus, we show that AI activity and PL avalanches may coexist into a single dynamics, provided that adaptation mechanisms are in place. In our model, the AI firing pattern is a direct consequence of the hovering close to the critical line where external inputs are compensated by threshold growth, creating synaptic balance for any E/I weight ratio.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TLB9E879\\Girardi-Schappo et al. - 2021 - A unified theory of EI synaptic balance, quasicri.pdf}
}

@article{glickfeldHigherOrderAreasMouse2017,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017-09-15},
  journaltitle = {Annual Review of Vision Science},
  shortjournal = {Annu Rev Vis Sci},
  volume = {3},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  issn = {2374-4650},
  doi = {10.1146/annurev-vision-102016-061331},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  langid = {english},
  keywords = {Animals,Behavior; Animal,Brain Mapping,connectivity,Connectome,functional specialization,hierarchical and parallel processing,higher visual area,Mice,mouse,visual cortex,Visual Cortex,Visual Pathways,Visual Perception}
}

@article{glickfeldHigherOrderAreasMouse2017a,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017},
  journaltitle = {Annual Review of Vision Science},
  volume = {3},
  number = {1},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  doi = {10.1146/annurev-vision-102016-061331},
  url = {https://doi.org/10.1146/annurev-vision-102016-061331},
  urldate = {2020-11-10},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-vision-102016-061331}
}

@article{goetzActiveDendritesEnable2021,
  title = {Active Dendrites Enable Strong but Sparse Inputs to Determine Orientation Selectivity},
  author = {Goetz, Lea and Roth, Arnd and Häusser, Michael},
  date = {2021-07-27},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {118},
  number = {30},
  pages = {e2017339118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2017339118},
  url = {https://pnas.org/doi/full/10.1073/pnas.2017339118},
  urldate = {2022-09-02},
  abstract = {Significance                            An active pyramidal cell model, constrained by physiological and anatomical data, was used to simulate dendritic integration in vivo. The model shows that small numbers of strong excitatory synapses can trigger dendritic Na               +               and NMDA spikes. Moreover, only a few dendritic spikes are sufficient to drive a single output action potential. As a consequence, as few as 1\% of the synaptic inputs to a neuron can determine the tuning of somatic output in vivo. These results suggest that dendritic spikes can help to make sensory representations more efficient and flexible: they require fewer connections to sustain them, and only a small number of connections need to be changed to encode a different stimulus and alter the response properties of a neuron.                        ,                             The dendrites of neocortical pyramidal neurons are excitable. However, it is unknown how synaptic inputs engage nonlinear dendritic mechanisms during sensory processing in vivo, and how they in turn influence action potential output. Here, we provide a quantitative account of the relationship between synaptic inputs, nonlinear dendritic events, and action potential output. We developed a detailed pyramidal neuron model constrained by in vivo dendritic recordings. We drive this model with realistic input patterns constrained by sensory responses measured in vivo and connectivity measured in vitro. We show mechanistically that under realistic conditions, dendritic Na               +               and NMDA spikes are the major determinants of neuronal output in vivo. We demonstrate that these dendritic spikes can be triggered by a surprisingly small number of strong synaptic inputs, in some cases even by single synapses. We predict that dendritic excitability allows the 1\% strongest synaptic inputs of a neuron to control the tuning of its output. Active dendrites therefore allow smaller subcircuits consisting of only a few strongly connected neurons to achieve selectivity for specific sensory features.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XQ6LMJPM\\Goetz et al. - 2021 - Active dendrites enable strong but sparse inputs t.pdf}
}

@article{gokcenDisentanglingFlowSignals2022,
  title = {✅ {{Disentangling}} the Flow of Signals between Populations of Neurons},
  author = {Gokcen, Evren and Jasper, Anna I. and Semedo, João D. and Zandvakili, Amin and Kohn, Adam and Machens, Christian K. and Yu, Byron M.},
  date = {2022-08},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {2},
  number = {8},
  pages = {512--525},
  publisher = {{Nature Publishing Group}},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00282-5},
  url = {https://www.nature.com/articles/s43588-022-00282-5},
  urldate = {2022-09-23},
  abstract = {Technological advances now allow us to record from large populations of neurons across multiple brain areas. These recordings may illuminate how communication between areas contributes to brain function, yet a substantial barrier remains: how do we disentangle the concurrent, bidirectional flow of signals between populations of neurons? We propose here a dimensionality reduction framework, delayed latents across groups (DLAG), that disentangles signals relayed in each direction, identifies how these signals are represented by each population and characterizes how they evolve within and across trials. We demonstrate that DLAG performs well on synthetic datasets similar in scale to current neurophysiological recordings. Then we study simultaneously recorded populations in primate visual areas V1 and V2, where DLAG reveals signatures of bidirectional yet selective communication. Our framework lays a foundation for dissecting the intricate flow of signals across populations of neurons, and how this signalling contributes to cortical computation.},
  issue = {8},
  langid = {english},
  keywords = {Computational models,Computational neuroscience,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E65ZMZ2K\\43588_2022_282_MOESM1_ESM.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RLZHRGAW\\GokcenNatCompSci2022.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYST8HXS\\Gokcen et al. - 2022 - Disentangling the flow of signals between populati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\63S4J46D\\s43588-022-00282-5.html}
}

@article{golloActiveDendritesEnhance2009,
  title = {Active {{Dendrites Enhance Neuronal Dynamic Range}}},
  author = {Gollo, Leonardo L. and Kinouchi, Osame and Copelli, Mauro},
  date = {2009-06-12},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {6},
  pages = {e1000402},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000402},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000402},
  urldate = {2022-09-02},
  abstract = {Since the first experimental evidences of active conductances in dendrites, most neurons have been shown to exhibit dendritic excitability through the expression of a variety of voltage-gated ion channels. However, despite experimental and theoretical efforts undertaken in the past decades, the role of this excitability for some kind of dendritic computation has remained elusive. Here we show that, owing to very general properties of excitable media, the average output of a model of an active dendritic tree is a highly non-linear function of its afferent rate, attaining extremely large dynamic ranges (above 50 dB). Moreover, the model yields double-sigmoid response functions as experimentally observed in retinal ganglion cells. We claim that enhancement of dynamic range is the primary functional role of active dendritic conductances. We predict that neurons with larger dendritic trees should have larger dynamic range and that blocking of active conductances should lead to a decrease in dynamic range.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Neuronal dendrites,Neurons,Nonlinear dynamics,Psychophysics,Signal amplification,Synapses},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RP9KYMK6\\Gollo et al. - 2009 - Active Dendrites Enhance Neuronal Dynamic Range.pdf}
}

@article{golloActiveDendritesEnhance2009a,
  title = {Active {{Dendrites Enhance Neuronal Dynamic Range}}},
  author = {Gollo, Leonardo L. and Kinouchi, Osame and Copelli, Mauro},
  date = {2009-06-12},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {6},
  pages = {e1000402},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000402},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000402},
  urldate = {2022-10-02},
  abstract = {Since the first experimental evidences of active conductances in dendrites, most neurons have been shown to exhibit dendritic excitability through the expression of a variety of voltage-gated ion channels. However, despite experimental and theoretical efforts undertaken in the past decades, the role of this excitability for some kind of dendritic computation has remained elusive. Here we show that, owing to very general properties of excitable media, the average output of a model of an active dendritic tree is a highly non-linear function of its afferent rate, attaining extremely large dynamic ranges (above 50 dB). Moreover, the model yields double-sigmoid response functions as experimentally observed in retinal ganglion cells. We claim that enhancement of dynamic range is the primary functional role of active dendritic conductances. We predict that neurons with larger dendritic trees should have larger dynamic range and that blocking of active conductances should lead to a decrease in dynamic range.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Neuronal dendrites,Neurons,Nonlinear dynamics,Psychophysics,Signal amplification,Synapses},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G869MBJS\\Gollo et al. - 2009 - Active Dendrites Enhance Neuronal Dynamic Range.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\69TYQ2D6\\article.html}
}

@article{golloCoexistenceCriticalSensitivity2017,
  title = {Coexistence of Critical Sensitivity and Subcritical Specificity Can Yield Optimal Population Coding},
  author = {Gollo, Leonardo L.},
  date = {2017-09-30},
  journaltitle = {Journal of The Royal Society Interface},
  volume = {14},
  number = {134},
  pages = {20170207},
  publisher = {{Royal Society}},
  doi = {10.1098/rsif.2017.0207},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0207},
  urldate = {2022-10-03},
  abstract = {The vicinity of phase transitions selectively amplifies weak stimuli, yielding optimal sensitivity to distinguish external input. Along with this enhanced sensitivity, enhanced levels of fluctuations at criticality reduce the specificity of the response. Given that the specificity of the response is largely compromised when the sensitivity is maximal, the overall benefit of criticality for signal processing remains questionable. Here, it is shown that this impasse can be solved by heterogeneous systems incorporating functional diversity, in which critical and subcritical components coexist. The subnetwork of critical elements has optimal sensitivity, and the subnetwork of subcritical elements has enhanced specificity. Combining segregated features extracted from the different subgroups, the resulting collective response can maximize the trade-off between sensitivity and specificity measured by the dynamic-range-to-noise ratio. Although numerous benefits can be observed when the entire system is critical, our results highlight that optimal performance is obtained when only a small subset of the system is at criticality.},
  keywords = {complex systems,criticality,diversity,heterogeneity,subcriticality,systems neuroscience},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NSNYCRBD\\Gollo - 2017 - Coexistence of critical sensitivity and subcritica.pdf}
}

@article{gomez-navaIntermittentCollectiveMotion2022,
  title = {Intermittent Collective Motion in Sheep Results from Alternating the Role of Leader and Follower},
  author = {Gómez-Nava, Luis and Bon, Richard and Peruani, Fernando},
  date = {2022-10-20},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-022-01769-8},
  url = {https://www.nature.com/articles/s41567-022-01769-8},
  urldate = {2022-10-25},
  abstract = {Flocking behaviour is often presented as an example of a self-organized process, where individuals continuously negotiate on the direction of travel and compromise by moving along a local average velocity until the group reaches a consensus. Such a collective behaviour does not take advantage of the benefits of hierarchical organizational strategies that confer the leader of the group full control over it with a reduced information flow overhead. Here we study the spontaneous behaviour of small sheep flocks and find that sheep exhibit a collective behaviour that consists of a series of collective motion episodes interrupted by grazing phases. Each motion episode has a temporal leader that guides the group in line formation. Combining experiments and a data-driven model, we provide evidence that group coordination in these episodes results from the propagation of positional information of the temporal leader to all group members through a strongly hierarchical, directed interaction network. Furthermore, we show that group members alternate the role of leader and follower by a random process, which is independent of the navigation mechanism that regulates collective motion episodes. Our analysis suggests that it is possible to conceive intermittent collective strategies that take advantage of both hierarchical and democratic organizational schemes.},
  langid = {english},
  keywords = {Biological physics,Computational biophysics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JNQZHWT4\\Gómez-Nava et al. - 2022 - Intermittent collective motion in sheep results fr.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BZXKT952\\s41567-022-01769-8.html}
}

@article{groblewskiCharacterizationLearningMotivation2020,
  title = {Characterization of {{Learning}}, {{Motivation}}, and {{Visual Perception}} in {{Five Transgenic Mouse Lines Expressing GCaMP}} in {{Distinct Cell Populations}}},
  author = {Groblewski, Peter A. and Ollerenshaw, Douglas R. and Kiggins, Justin T. and Garrett, Marina E. and Mochizuki, Chris and Casal, Linzy and Cross, Sissy and Mace, Kyla and Swapp, Jackie and Manavi, Sahar and Williams, Derric and Mihalas, Stefan and Olsen, Shawn R.},
  date = {2020},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  volume = {14},
  issn = {1662-5153},
  url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2020.00104},
  urldate = {2023-01-09},
  abstract = {To study the mechanisms of perception and cognition, neural measurements must be made during behavior. A goal of the Allen Brain Observatory is to map the activity of distinct cortical cell classes underlying visual and behavioral processing. Here we describe standardized methodology for training head-fixed mice on a visual change detection task, and we use our paradigm to characterize learning and behavior of five GCaMP6-expressing transgenic lines. We used automated training procedures to facilitate comparisons across mice. Training times varied, but most transgenic mice learned the behavioral task. Motivation levels also varied across mice. To compare mice in similar motivational states we subdivided sessions into over-, under-, and optimally motivated periods. When motivated, the pattern of perceptual decisions were highly correlated across transgenic lines, although overall performance (d-prime) was lower in one line labeling somatostatin inhibitory cells. These results provide important context for using these mice to map neural activity underlying perception and behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJ5L3ZRX\\Groblewski et al. - 2020 - Characterization of Learning, Motivation, and Visu.pdf}
}

@article{haimFunctionalDiversityAstrocytes2017,
  title = {Functional Diversity of Astrocytes in Neural Circuit Regulation},
  author = {Haim, Lucile Ben and Rowitch, David H.},
  date = {2017-01},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {18},
  number = {1},
  pages = {31--41},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.159},
  url = {https://www.nature.com/articles/nrn.2016.159},
  urldate = {2020-11-22},
  abstract = {Astrocytes display numerous inter- and intra-regional distinctions, ranging from differences in their morphology to differential dynamics of calcium signalling.Astrocytes in specific neural circuits modulate neuronal activity, which affects a range of brain functions.Regionally encoded astrocyte functions are required for neuronal homeostasis and survival.Astrocyte heterogeneity is determined by the developmental patterning of the CNS and is refined in adulthood to produce highly specialized neuron–glia units.Under pathological conditions, reactive astrocytes display several molecular and functional changes that have a differential influence on disease outcome.New techniques will help to uncover the molecular and functional heterogeneity of astrocytes both in health and disease.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VX47A8UK\\Haim and Rowitch - 2017 - Functional diversity of astrocytes in neural circu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SHUCTZYZ\\nrn.2016.html}
}

@article{harrisCorticalStateAttention2011,
  title = {Cortical State and Attention},
  author = {Harris, Kenneth D. and Thiele, Alexander},
  date = {2011-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {12},
  number = {9},
  pages = {509--523},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn3084},
  url = {https://www.nature.com/articles/nrn3084},
  urldate = {2023-01-03},
  abstract = {Cortex operates in multiple states, which are characterized by varying amounts of fluctuation in spontaneous population activity.The classical desynchronized and synchronized states that are associated with waking and slow-wave sleep, respectively, are two points on a continuum of states; the continuum is probably multidimensional.More-desynchronized states exhibit decreases in low-frequency local field potential (LFP) power and lower pairwise spiking correlations than synchronized states.Selective attention seems to involve desynchronization operating locally in a patch of cortex that represents the attended stimulus.Local desynchronization may result from a combination of widespread neuromodulatory input, and tonic glutamatergic feedback focused on the patch representing the attended stimulus.},
  issue = {9},
  langid = {english},
  keywords = {Attention,Computational neuroscience,Neuronal physiology,Sensory systems,Sleep,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ABZYDESX\\Harris and Thiele - 2011 - Cortical state and attention.pdf}
}

@article{hattoriFunctionsDysfunctionsNeocortical2017,
  title = {Functions and Dysfunctions of Neocortical Inhibitory Neuron Subtypes},
  author = {Hattori, Ryoma and Kuchibhotla, Kishore V. and Froemke, Robert C. and Komiyama, Takaki},
  date = {2017-09},
  journaltitle = {Nature Neuroscience},
  volume = {20},
  number = {9},
  pages = {1199--1208},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4619},
  url = {https://www.nature.com/articles/nn.4619},
  urldate = {2020-12-18},
  abstract = {Hattori et al. review the recent advances in our understanding of the roles of inhibitory neuron subtypes in shaping the activity and plasticity states of neocortical circuits, how neuromodulators control inhibitory neuron subtypes, and the role of inhibitory neuron dysfunction in neurological disorders.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S94R3PKG\\Hattori et al. - 2017 - Functions and dysfunctions of neocortical inhibito.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FGRLI9NM\\nn.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J2RHJYGF\\nn.html}
}

@article{hawkinsWhyNeuronsHave2016,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff and Ahmad, Subutai},
  date = {2016},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {10},
  issn = {1662-5110},
  url = {https://www.frontiersin.org/articles/10.3389/fncir.2016.00023},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR88HUZS\\Hawkins and Ahmad - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf}
}

@article{hellerTargetedDimensionalityReduction2022,
  title = {Targeted Dimensionality Reduction Enables Reliable Estimation of Neural Population Coding Accuracy from Trial-Limited Data},
  author = {Heller, Charles R. and David, Stephen V.},
  date = {2022-07-21},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {17},
  number = {7},
  pages = {e0271136},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0271136},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0271136},
  urldate = {2022-09-26},
  abstract = {Rapidly developing technology for large scale neural recordings has allowed researchers to measure the activity of hundreds to thousands of neurons at single cell resolution in vivo. Neural decoding analyses are a widely used tool used for investigating what information is represented in this complex, high-dimensional neural population activity. Most population decoding methods assume that correlated activity between neurons has been estimated accurately. In practice, this requires large amounts of data, both across observations and across neurons. Unfortunately, most experiments are fundamentally constrained by practical variables that limit the number of times the neural population can be observed under a single stimulus and/or behavior condition. Therefore, new analytical tools are required to study neural population coding while taking into account these limitations. Here, we present a simple and interpretable method for dimensionality reduction that allows neural decoding metrics to be calculated reliably, even when experimental trial numbers are limited. We illustrate the method using simulations and compare its performance to standard approaches for dimensionality reduction and decoding by applying it to single-unit electrophysiological data collected from auditory cortex.},
  langid = {english},
  keywords = {Action potentials,Behavior,Coding mechanisms,Covariance,Eigenvectors,Neurons,Principal component analysis,Sensory perception},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V8DHKHCR\\Heller and David - 2022 - Targeted dimensionality reduction enables reliable.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GLHA4VED\\article.html}
}

@article{hennequinDynamicalRegimeSensory2018,
  title = {The {{Dynamical Regime}} of {{Sensory Cortex}}: {{Stable Dynamics}} around a {{Single Stimulus-Tuned Attractor Account}} for {{Patterns}} of {{Noise Variability}}},
  shorttitle = {The {{Dynamical Regime}} of {{Sensory Cortex}}},
  author = {Hennequin, Guillaume and Ahmadian, Yashar and Rubin, Daniel B. and Lengyel, Máté and Miller, Kenneth D.},
  date = {2018-05-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {98},
  number = {4},
  eprint = {29772203},
  eprinttype = {pmid},
  pages = {846-860.e5},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2018.04.017},
  abstract = {Correlated variability in cortical activity is ubiquitously quenched following stimulus onset, in a stimulus-dependent manner. These modulations have been attributed to circuit dynamics involving either multiple stable states ("attractors") or chaotic activity. Here we show that a qualitatively different dynamical regime, involving fluctuations about a single, stimulus-driven attractor in a loosely balanced excitatory-inhibitory network (the stochastic "stabilized supralinear network"), best explains these modulations. Given the supralinear input/output functions of cortical neurons, increased stimulus drive strengthens effective network connectivity. This shifts the balance from interactions that amplify~variability to suppressive inhibitory feedback, quenching correlated variability around more strongly driven steady states. Comparing to previously published and original data analyses, we show that this mechanism, unlike previous proposals, uniquely accounts for the spatial patterns and fast temporal dynamics of variability suppression. Specifying the cortical operating regime is key~to understanding the computations underlying perception.},
  langid = {english},
  pmcid = {PMC5971207},
  keywords = {Animals,circuit dynamics,cortical variability,Macaca,MT,Neural Inhibition,Neural Networks; Computer,Neurons,noise correlations,Nonlinear Dynamics,Occipital Lobe,theoretical neuroscience,V1,variability quenching,Visual Cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ULQ4KBNT\\Hennequin et al. - 2018 - The Dynamical Regime of Sensory Cortex Stable Dyn.pdf}
}

@article{hensSpatiotemporalSignalPropagation2019,
  title = {Spatiotemporal Signal Propagation in Complex Networks},
  author = {Hens, Chittaranjan and Harush, Uzi and Haber, Simi and Cohen, Reuven and Barzel, Baruch},
  date = {2019-04},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {15},
  number = {4},
  pages = {403--412},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-018-0409-0},
  url = {https://www.nature.com/articles/s41567-018-0409-0},
  urldate = {2022-10-02},
  abstract = {A major achievement in the study of complex networks is the realization that diverse systems, from sub-cellular biology to social networks, exhibit universal topological characteristics. Yet, such universality does not naturally translate to the dynamics of these systems, as dynamic behaviour cannot be uniquely predicted from topology alone. Rather, it depends on the interplay of the network’s topology with the dynamic mechanisms of interaction between the nodes. Hence, systems with similar structure may exhibit profoundly different dynamic behaviour. We therefore seek a general theoretical framework to help us systematically translate topological elements into their predicted dynamic outcome. Here, we offer such a translation in the context of signal propagation, linking the topology of a network to the observed spatiotemporal spread of perturbative signals across it, thus capturing the network’s role in propagating local information. For a range of nonlinear dynamic models, we predict that the propagation rules condense into three highly distinctive dynamic regimes, characterized by the interplay between network paths, degree distribution and the interaction dynamics. As a result, classifying a system’s intrinsic interaction mechanisms into the relevant dynamic regime allows us to systematically translate topology into dynamic patterns of information propagation.},
  issue = {4},
  langid = {english},
  keywords = {Complex networks,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CPMCAARD\\Hens et al. - 2019 - Spatiotemporal signal propagation in complex netwo.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X7WVIBT6\\s41567-018-0409-0.html}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018,
  title = {✅ {{Optimization}} by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.},
  keywords = {Avalanche,Optimization,Scaling Laws,Self-Organized Criticaility}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018a,
  title = {Optimization by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.}
}

@article{holovatchComplexSystemsPhysics2017,
  title = {Complex Systems: Physics beyond Physics},
  shorttitle = {Complex Systems},
  author = {Holovatch, Yurij and Kenna, Ralph and Thurner, Stefan},
  date = {2017-02},
  journaltitle = {European Journal of Physics},
  shortjournal = {Eur. J. Phys.},
  volume = {38},
  number = {2},
  pages = {023002},
  publisher = {{IOP Publishing}},
  issn = {0143-0807},
  doi = {10.1088/1361-6404/aa5a87},
  url = {https://doi.org/10.1088/1361-6404/aa5a87},
  urldate = {2022-10-01},
  abstract = {Complex systems are characterised by specific time-dependent interactions among their many constituents. As a consequence they often manifest rich, non-trivial and unexpected behaviour. Examples arise both in the physical and non-physical worlds. The study of complex systems forms a new interdisciplinary research area that cuts across physics, biology, ecology, economics, sociology, and the humanities. In this paper we review the essence of complex systems from a physicists' point of view, and try to clarify what makes them conceptually different from systems that are traditionally studied in physics. Our goal is to demonstrate how the dynamics of such systems may be conceptualised in quantitative and predictive terms by extending notions from statistical physics and how they can often be captured in a framework of co-evolving multiplex network structures. We mention three areas of complex-systems science that are currently studied extensively, the science of cities, dynamics of societies, and the representation of texts as evolutionary objects. We discuss why these areas form complex systems in the above sense. We argue that there exists plenty of new ground for physicists to explore and that methodical and conceptual progress is needed most.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7MR562TG\\Holovatch et al. - 2017 - Complex systems physics beyond physics.pdf}
}

@article{holovatchComplexSystemsPhysics2017a,
  title = {✅ {{Complex}} Systems: Physics beyond Physics},
  shorttitle = {Complex Systems},
  author = {Holovatch, Yurij and Kenna, Ralph and Thurner, Stefan},
  date = {2017-03-01},
  journaltitle = {European Journal of Physics},
  shortjournal = {Eur. J. Phys.},
  volume = {38},
  number = {2},
  eprint = {1610.01002},
  eprinttype = {arxiv},
  primaryclass = {physics},
  pages = {023002},
  issn = {0143-0807, 1361-6404},
  doi = {10.1088/1361-6404/aa5a87},
  url = {http://arxiv.org/abs/1610.01002},
  urldate = {2022-10-03},
  abstract = {Complex systems are characterized by specific time-dependent interactions among their many constituents. As a consequence they often manifest rich, non-trivial and unexpected behavior. Examples arise both in the physical and non-physical world. The study of complex systems forms a new interdisciplinary research area that cuts across physics, biology, ecology, economics, sociology, and the humanities. In this paper we review the essence of complex systems from a physicist's point of view, and try to clarify what makes them conceptually different from systems that are traditionally studied in physics. Our goal is to demonstrate how the dynamics of such systems may be conceptualized in quantitative and predictive terms by extending notions from statistical physics and how they can often be captured in a framework of co-evolving multiplex network structures. We mention three areas of complex-systems science that are currently studied extensively, the science of cities, dynamics of societies, and the representation of texts as evolutionary objects. We discuss why these areas form complex systems in the above sense. We argue that there exists plenty of new land for physicists to explore and that methodical and conceptual progress is needed most.},
  archiveprefix = {arXiv},
  keywords = {Physics - Physics and Society},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E8GX9WPR\\Holovatch et al. - 2017 - Complex systems physics beyond physics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PR853AXB\\1610.html}
}

@article{homannNovelStimuliEvoke2022,
  title = {Novel Stimuli Evoke Excess Activity in the Mouse Primary Visual Cortex},
  author = {Homann, Jan and Koay, Sue Ann and Chen, Kevin S. and Tank, David W. and Berry, Michael J.},
  date = {2022-02},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {5},
  pages = {e2108882119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2108882119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2108882119},
  urldate = {2023-01-09},
  abstract = {To explore how neural circuits represent novel versus familiar inputs, we presented mice with repeated sets of images with novel images sparsely substituted. Using two-photon calcium imaging to record from layer 2/3 neurons in the mouse primary visual cortex, we found that novel images evoked excess activity in the majority of neurons. This novelty response rapidly emerged, arising with a time constant of 2.6 ± 0.9 s. When a new image set was repeatedly presented, a majority of neurons had similarly elevated activity for the first few presentations, which decayed to steady state with a time constant of 1.4 ± 0.4 s. When we increased the number of images in the set, the novelty response’s amplitude decreased, defining a capacity to store ∼15 familiar images under our conditions. These results could be explained quantitatively using an adaptive subunit model in which presynaptic neurons have individual tuning and gain control. This result shows that local neural circuits can create different representations for novel versus familiar inputs using generic, widely available mechanisms.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TCQIV63H\\Homann et al. - 2022 - Novel stimuli evoke excess activity in the mouse p.pdf}
}

@article{hopfieldNeuralNetworksPhysical1982,
  title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities.},
  author = {Hopfield, J J},
  date = {1982-04},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {79},
  number = {8},
  eprint = {6953413},
  eprinttype = {pmid},
  pages = {2554--2558},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/},
  urldate = {2022-10-04},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  pmcid = {PMC346238},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4ISCMBCZ\\Hopfield - 1982 - Neural networks and physical systems with emergent.pdf}
}

@article{huangAttentionReducesBurstiness2021,
  title = {Attention Reduces the Burstiness of {{V1}} Neurons Involved in Attended Target Enhancement},
  author = {Huang, Dan and Xiong, Xingzhong and Chen, Yao},
  date = {2021},
  journaltitle = {European Journal of Neuroscience},
  volume = {54},
  number = {2},
  pages = {4565--4580},
  issn = {1460-9568},
  doi = {10.1111/ejn.15263},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.15263},
  urldate = {2023-01-16},
  abstract = {Attention-dependent reduction in the tendency for neurons to fire bursts (burstiness) is widely observed in the visual cortex. However, the underlying mechanism and the functional role of this phenomenon remain unclear. We recorded well-isolated single-unit activities in primary visual cortex (V1) from two primates (Macaca mulatta) while they performed a detection task engaging spatial attention with two levels of difficulty (hard/easy). We found that attention modulated burstiness of V1 neurons in a cell-type specific manner. For neurons whose net response enhanced with the increase of task difficulty (difficulty-enhanced neuron), representing their involvement in boosting the signal of the attended stimulus, attention led to a reduction in burstiness during hard task but not during easy task. In contrast, regardless of the level of task difficulty, attention-dependent reduction in burstiness was not observed in neurons that showed a net suppression in firing rate with the increase of task difficulty (difficulty-suppressed neuron), indicating their commitment in filtering out the interference of distractor. This differentiation in the effects of attentional modulation on burstiness among the cells with distinct functional roles in attention suggests that the reduction in burstiness by attention is linked to target enhancement and is not associated with distractor suppression.},
  langid = {english},
  keywords = {attention,burstiness reduction,target enhancement,V1},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/ejn.15263},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8YL4K5HF\\Huang et al. - 2021 - Attention reduces the burstiness of V1 neurons inv.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LDX74W6E\\ejn.html}
}

@article{huangCircuitModelsLowDimensional2019,
  title = {✅ {{Circuit Models}} of {{Low-Dimensional Shared Variability}} in {{Cortical Networks}}},
  author = {Huang, Chengcheng and Ruff, Douglas A. and Pyle, Ryan and Rosenbaum, Robert and Cohen, Marlene R. and Doiron, Brent},
  date = {2019-01-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {101},
  number = {2},
  eprint = {30581012},
  eprinttype = {pmid},
  pages = {337-348.e4},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.11.034},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(18)31043-2},
  urldate = {2022-12-19},
  langid = {english},
  keywords = {attention,cortical model,excitatory/inhibitory balance,low dimensional,neuronal variability,noise correlations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T974QZMN\\Huang et al. - 2019 - Circuit Models of Low-Dimensional Shared Variabili.pdf}
}

@article{hubenerMouseVisualCortex2003,
  title = {Mouse Visual Cortex},
  author = {Hübener, Mark},
  date = {2003-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {13},
  number = {4},
  pages = {413--420},
  issn = {0959-4388},
  doi = {10.1016/S0959-4388(03)00102-8},
  url = {http://www.sciencedirect.com/science/article/pii/S0959438803001028},
  urldate = {2020-10-15},
  abstract = {Neurons in mouse visual cortex have diverse receptive field properties and they respond selectively to specific features of visual stimuli. Owing to the lateral position of the eyes, only about a third of the visual cortex receives input from both eyes, but many cells in this region are binocular. Similar to higher mammals, closing one eye during a critical period shifts the responses of cells, such that they are better driven by the non-deprived eye. In this review I illustrate how the combination of transgenic mouse technology with single cell recording and modern imaging techniques might lead to a further understanding of the mechanisms that underlie the development, plasticity, and function of the mammalian visual cortex.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BAN77Y2N\\Hübener - 2003 - Mouse visual cortex.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HH6QDPMT\\S0959438803001028.html}
}

@article{huSpatialAttentionModulates2022,
  title = {Spatial {{Attention Modulates Spike Count Correlations}} and {{Granger Causality}} in the {{Primary Visual Cortex}}},
  author = {Hu, Qiyi and Zheng, Zhiyan and Sui, Xiaohong and Li, Liming and Chai, Xinyu and Chen, Yao},
  date = {2022},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {16},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2022.838049},
  urldate = {2023-01-16},
  abstract = {The influence of spatial attention on neural interactions has been revealed even in early visual information processing stages. It resolves the process of competing for sensory information about objects perceived as targets and distractors. However, the attentional modulation of the interaction between pairs of neurons with non-overlapping receptive fields (RFs) is not well known. Here, we investigated the activity of anatomically distant neurons in two behaving monkeys’ primary visual cortex (V1), when they performed a spatial attention task detecting color change. We compared attentional modulation from the perspective of spike count correlations and Granger causality among simple and complex cells. An attention-related increase in spike count correlations and a decrease in Granger causality were found. The results showed that spatial attention significantly influenced only the interactions between rather than within simple and complex cells. Furthermore, we found that the attentional modulation of neuronal interactions changed with neuronal pairs’ preferred directions differences. Thus, we found that spatial attention increased the functional communications and competing connectivities when attending to the neurons’ RFs, which impacts the interactions only between simple and complex cells. Our findings enrich the model of simple and complex cells and further understand the way that attention influences the neurons’ activities.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZRZUH2X8\\Hu et al. - 2022 - Spatial Attention Modulates Spike Count Correlatio.pdf}
}

@online{InterplayGraphTopology,
  title = {Interplay between {{Graph Topology}} and {{Correlations}} of {{Third Order}} in {{Spiking Neuronal Networks}} | {{PLOS Computational Biology}}},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004963},
  urldate = {2022-10-06},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WULVBSIY\\article.html}
}

@article{isomuraMulticontextBlindSource2019,
  title = {Multi-Context Blind Source Separation by Error-Gated {{Hebbian}} Rule},
  author = {Isomura, Takuya and Toyoizumi, Taro},
  date = {2019-05-09},
  journaltitle = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {7127},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-43423-z},
  url = {https://www.nature.com/articles/s41598-019-43423-z},
  urldate = {2020-10-21},
  abstract = {Animals need to adjust their inferences according to the context they are in. This is required for the multi-context blind source separation (BSS) task, where an agent needs to infer hidden sources from their context-dependent mixtures. The agent is expected to invert this mixing process for all contexts. Here, we show that a neural network that implements the error-gated Hebbian rule (EGHR) with sufficiently redundant sensory inputs can successfully learn this task. After training, the network can perform the multi-context BSS without further updating synapses, by retaining memories of all experienced contexts. This demonstrates an attractive use of the EGHR for dimensionality reduction by extracting low-dimensional sources across contexts. Finally, if there is a common feature shared across contexts, the EGHR can extract it and generalize the task to even inexperienced contexts. The results highlight the utility of the EGHR as a model for perceptual adaptation in animals.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UB5RABYB\\Isomura and Toyoizumi - 2019 - Multi-context blind source separation by error-gat.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GEK5TACD\\s41598-019-43423-z.html}
}

@article{iyerAvoidingCatastropheActive2022,
  title = {Avoiding {{Catastrophe}}: {{Active Dendrites Enable Multi-Task Learning}} in {{Dynamic Environments}}},
  shorttitle = {Avoiding {{Catastrophe}}},
  author = {Iyer, Abhiram and Grewal, Karan and Velu, Akash and Souza, Lucas Oliveira and Forest, Jeremy and Ahmad, Subutai},
  date = {2022},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {16},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2022.846219},
  urldate = {2022-09-02},
  abstract = {A key challenge for AI is to build embodied systems that operate in dynamically changing environments. Such systems must adapt to changing task contexts and learn continuously. Although standard deep learning systems achieve state of the art results on static benchmarks, they often struggle in dynamic scenarios. In these settings, error signals from multiple contexts can interfere with one another, ultimately leading to a phenomenon known as catastrophic forgetting. In this article we investigate biologically inspired architectures as solutions to these problems. Specifically, we show that the biophysical properties of dendrites and local inhibitory systems enable networks to dynamically restrict and route information in a context-specific manner. Our key contributions are as follows: first, we propose a novel artificial neural network architecture that incorporates active dendrites and sparse representations into the standard deep learning framework. Next, we study the performance of this architecture on two separate benchmarks requiring task-based adaptation: Meta-World, a multi-task reinforcement learning environment where a robotic agent must learn to solve a variety of manipulation tasks simultaneously; and a continual learning benchmark in which the model's prediction task changes throughout training. Analysis on both benchmarks demonstrates the emergence of overlapping but distinct and sparse subnetworks, allowing the system to fluidly learn multiple tasks with minimal forgetting. Our neural implementation marks the first time a single architecture has achieved competitive results in both multi-task and continual learning settings. Our research sheds light on how biological properties of neurons can inform deep learning systems to address dynamic scenarios that are typically impossible for traditional ANNs to solve.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DMC2I9KH\\Iyer et al. - 2022 - Avoiding Catastrophe Active Dendrites Enable Mult.pdf}
}

@article{jarvisNeuronalGainModulability2018,
  title = {Neuronal Gain Modulability Is Determined by Dendritic Morphology: {{A}} Computational Optogenetic Study},
  shorttitle = {Neuronal Gain Modulability Is Determined by Dendritic Morphology},
  author = {Jarvis, Sarah and Nikolic, Konstantin and Schultz, Simon R.},
  date = {2018-03-09},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {14},
  number = {3},
  pages = {e1006027},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006027},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006027},
  urldate = {2022-10-18},
  abstract = {The mechanisms by which the gain of the neuronal input-output function may be modulated have been the subject of much investigation. However, little is known of the role of dendrites in neuronal gain control. New optogenetic experimental paradigms based on spatial profiles or patterns of light stimulation offer the prospect of elucidating many aspects of single cell function, including the role of dendrites in gain control. We thus developed a model to investigate how competing excitatory and inhibitory input within the dendritic arbor alters neuronal gain, incorporating kinetic models of opsins into our modeling to ensure it is experimentally testable. To investigate how different topologies of the neuronal dendritic tree affect the neuron’s input-output characteristics we generate branching geometries which replicate morphological features of most common neurons, but keep the number of branches and overall area of dendrites approximately constant. We found a relationship between a neuron’s gain modulability and its dendritic morphology, with neurons with bipolar dendrites with a moderate degree of branching being most receptive to control of the gain of their input-output relationship. The theory was then tested and confirmed on two examples of realistic neurons: 1) layer V pyramidal cells—confirming their role in neural circuits as a regulator of the gain in the circuit in addition to acting as the primary excitatory neurons, and 2) stellate cells. In addition to providing testable predictions and a novel application of dual-opsins, our model suggests that innervation of all dendritic subdomains is required for full gain modulation, revealing the importance of dendritic targeting in the generation of neuronal gain control and the functions that it subserves. Finally, our study also demonstrates that neurophysiological investigations which use direct current injection into the soma and bypass the dendrites may miss some important neuronal functions, such as gain modulation.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Membrane potential,Neuronal dendrites,Neuronal morphology,Neurons,Optogenetics,Pyramidal cells},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CHUGU4I2\\Jarvis et al. - 2018 - Neuronal gain modulability is determined by dendri.pdf}
}

@report{jiaMultiareaFunctionalModules2020,
  type = {preprint},
  title = {Multi-Area Functional Modules Mediate Feedforward and Recurrent Processing in Visual Cortical Hierarchy},
  author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina and Olsen, Shawn R.},
  date = {2020-08-31},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.08.30.272948},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.08.30.272948},
  urldate = {2020-09-03},
  abstract = {The visual cortex is organized hierarchically, but extensive recurrent pathways make it challenging to decipher the flow of information with single neuron resolution. Here, we characterize spiking interactions in populations of neurons from six interconnected areas along the visual hierarchy in awake mice. We generated multi-area, directed graphs of neuronal communication and uncovered two spatially-distributed functional modules. One module is positioned to transmit feedforward sensory signals along the hierarchy, while the other receives convergent input and engages in recurrent processing. The modules differ in layer and area distributions, convergence and divergence, and population-level temporal dynamics. These results reveal a neuronal-resolution cortical network topology in which distinct processing modules are interlaced across multiple areas of the cortical hierarchy.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BLVG96MG\\Jia et al. - 2020 - Multi-area functional modules mediate feedforward .pdf}
}

@article{jiaMultiregionalModulebasedSignal2022,
  title = {Multi-Regional Module-Based Signal Transmission in Mouse Visual Cortex},
  author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina K. and Koch, Christof and Olsen, Shawn R.},
  date = {2022-05-04},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {9},
  pages = {1585-1598.e9},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.01.027},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322000848},
  urldate = {2023-01-09},
  abstract = {The visual cortex is hierarchically organized, yet the presence of extensive recurrent and parallel pathways make it challenging to decipher how signals flow between neuronal populations. Here, we tracked the flow of spiking activity recorded from six interconnected levels of the mouse visual hierarchy. By analyzing leading and lagging spike-timing relationships among pairs of simultaneously recorded neurons, we created a cellular-scale directed network graph. Using a module-detection algorithm to cluster neurons based on shared connectivity patterns, we uncovered two multi-regional communication modules distributed across the hierarchy. The direction of signal flow both between and within these modules, differences in layer and area distributions, and distinct temporal dynamics suggest that one module transmits feedforward sensory signals, whereas the other integrates inputs for recurrent processing. These results suggest that multi-regional functional modules may be a fundamental feature of organization beyond cortical areas that supports signal propagation across hierarchical recurrent networks.},
  langid = {english},
  keywords = {feedforward,functional network,modular,mouse,Neuropixels,processing stages,recurrent,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TPPP436J\\Jia et al. - 2022 - Multi-regional module-based signal transmission in.pdf}
}

@article{jiAsymptoticScalingDescribing2020,
  title = {Asymptotic Scaling Describing Signal Propagation in Complex Networks},
  author = {Ji, Peng and Lin, Wei and Kurths, Jürgen},
  date = {2020-11},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {16},
  number = {11},
  pages = {1082--1083},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-020-1025-3},
  url = {https://www.nature.com/articles/s41567-020-1025-3},
  urldate = {2022-10-02},
  issue = {11},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NBADIFTZ\\Ji et al. - 2020 - Asymptotic scaling describing signal propagation i.pdf}
}

@unpublished{jonesCanSingleNeurons2020,
  title = {Can {{Single Neurons Solve MNIST}}? {{The Computational Power}} of {{Biological Dendritic Trees}}},
  shorttitle = {Can {{Single Neurons Solve MNIST}}?},
  author = {Jones, Ilenna Simone and Kording, Konrad Paul},
  date = {2020-09-02},
  eprint = {2009.01269},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  url = {http://arxiv.org/abs/2009.01269},
  urldate = {2020-10-20},
  abstract = {Physiological experiments have highlighted how the dendrites of biological neurons can nonlinearly process distributed synaptic inputs. This is in stark contrast to units in artificial neural networks that are generally linear apart from an output nonlinearity. If dendritic trees can be nonlinear, biological neurons may have far more computational power than their artificial counterparts. Here we use a simple model where the dendrite is implemented as a sequence of thresholded linear units. We find that such dendrites can readily solve machine learning problems, such as MNIST or CIFAR-10, and that they benefit from having the same input onto several branches of the dendritic tree. This dendrite model is a special case of sparse network. This work suggests that popular neuron models may severely underestimate the computational power enabled by the biological fact of nonlinear dendrites and multiple synapses per pair of neurons. The next generation of artificial neural networks may significantly benefit from these biologically inspired dendritic architectures.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KM2A8TI3\\Jones and Kording - 2020 - Can Single Neurons Solve MNIST The Computational .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IJ669HZ2\\2009.html}
}

@article{jordanOpposingInfluenceTopdown2020,
  title = {Opposing {{Influence}} of {{Top-down}} and {{Bottom-up Input}} on {{Excitatory Layer}} 2/3 {{Neurons}} in {{Mouse Primary Visual Cortex}}},
  author = {Jordan, Rebecca and Keller, Georg B.},
  date = {2020-10-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.09.024},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627320307480},
  urldate = {2020-11-13},
  abstract = {Processing in cortical circuits is driven by combinations of cortical and subcortical inputs. These inputs are often conceptually categorized as bottom-up, conveying sensory information, and top-down, conveying contextual information. Using intracellular recordings in mouse primary visual cortex, we measured neuronal responses to visual input, locomotion, and visuomotor mismatches. We show that layer 2/3 (L2/3) neurons compute a difference between top-down motor-related input and bottom-up visual flow input. Most L2/3 neurons responded to visuomotor mismatch with either hyperpolarization or depolarization, and the size of this response was correlated with distinct physiological properties. Consistent with a subtraction of bottom-up and top-down input, visual and motor-related inputs had opposing influence on L2/3 neurons. In infragranular neurons, we found no evidence of a difference computation and responses were consistent with positive integration of visuomotor inputs. Our results provide evidence that L2/3 functions as a bidirectional comparator of top-down and bottom-up input.},
  langid = {english},
  keywords = {cortical microcircuit,prediction error,predictive processing,sensorimotor integration,visual cortex,whole cell recording},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9J66EG4S\\Jordan and Keller - 2020 - Opposing Influence of Top-down and Bottom-up Input.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ABHFGI2Q\\S0896627320307480.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RYTLFSZT\\S0896627320307480.html}
}

@article{jovanovicCumulantsHawkesPoint2015,
  title = {Cumulants of {{Hawkes}} Point Processes},
  author = {Jovanović, Stojan and Hertz, John and Rotter, Stefan},
  date = {2015-04-07},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {91},
  number = {4},
  pages = {042802},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.91.042802},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.042802},
  urldate = {2022-09-30},
  abstract = {We derive explicit, closed-form expressions for the cumulant densities of a multivariate, self-exciting Hawkes point process, generalizing a result of Hawkes in his earlier work on the covariance density and Bartlett spectrum of such processes. To do this, we represent the Hawkes process in terms of a Poisson cluster process and show how the cumulant density formulas can be derived by enumerating all possible “family trees,” representing complex interactions between point events. We also consider the problem of computing the integrated cumulants, characterizing the average measure of correlated activity between events of different types, and derive the relevant equations.},
  keywords = {Hawkes process,point process},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QXV3QYP6\\Jovanović et al. - 2015 - Cumulants of Hawkes point processes.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z8RRLX3V\\PhysRevE.91.html}
}

@article{jovanovicCumulantsHawkesPoint2015a,
  title = {Cumulants of {{Hawkes}} Point Processes},
  author = {Jovanović, Stojan and Hertz, John and Rotter, Stefan},
  date = {2015-04-07},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {91},
  number = {4},
  pages = {042802},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.91.042802},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.042802},
  urldate = {2022-09-30},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TB5WA6L5\\Jovanović et al. - 2015 - Cumulants of Hawkes point processes.pdf}
}

@article{jovanovicInterplayGraphTopology2016,
  title = {Interplay between {{Graph Topology}} and {{Correlations}} of {{Third Order}} in {{Spiking Neuronal Networks}}},
  author = {Jovanović, Stojan and Rotter, Stefan},
  date = {2016-06-06},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {6},
  pages = {e1004963},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004963},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004963},
  urldate = {2022-09-30},
  abstract = {The study of processes evolving on networks has recently become a very popular research field, not only because of the rich mathematical theory that underpins it, but also because of its many possible applications, a number of them in the field of biology. Indeed, molecular signaling pathways, gene regulation, predator-prey interactions and the communication between neurons in the brain can be seen as examples of networks with complex dynamics. The properties of such dynamics depend largely on the topology of the underlying network graph. In this work, we want to answer the following question: Knowing network connectivity, what can be said about the level of third-order correlations that will characterize the network dynamics? We consider a linear point process as a model for pulse-coded, or spiking activity in a neuronal network. Using recent results from theory of such processes, we study third-order correlations between spike trains in such a system and explain which features of the network graph (i.e. which topological motifs) are responsible for their emergence. Comparing two different models of network topology—random networks of Erdős-Rényi type and networks with highly interconnected hubs—we find that, in random networks, the average measure of third-order correlations does not depend on the local connectivity properties, but rather on global parameters, such as the connection probability. This, however, ceases to be the case in networks with a geometric out-degree distribution, where topological specificities have a strong impact on average correlations.},
  langid = {english},
  keywords = {Action potentials,Covariance,Leaves,Network analysis,Network motifs,Neural networks,Neurons,Trees},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\U49Y5CNX\\Jovanović and Rotter - 2016 - Interplay between Graph Topology and Correlations .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MEI3MJF9\\article.html}
}

@article{junFullyIntegratedSilicon2017,
  title = {Fully Integrated Silicon Probes for High-Density Recording of Neural Activity},
  author = {Jun, James J. and Steinmetz, Nicholas A. and Siegle, Joshua H. and Denman, Daniel J. and Bauza, Marius and Barbarits, Brian and Lee, Albert K. and Anastassiou, Costas A. and Andrei, Alexandru and Aydın, Çağatay and Barbic, Mladen and Blanche, Timothy J. and Bonin, Vincent and Couto, João and Dutta, Barundeb and Gratiy, Sergey L. and Gutnisky, Diego A. and Häusser, Michael and Karsh, Bill and Ledochowitsch, Peter and Lopez, Carolina Mora and Mitelut, Catalin and Musa, Silke and Okun, Michael and Pachitariu, Marius and Putzeys, Jan and Rich, P. Dylan and Rossant, Cyrille and Sun, Wei-lung and Svoboda, Karel and Carandini, Matteo and Harris, Kenneth D. and Koch, Christof and O’Keefe, John and Harris, Timothy D.},
  date = {2017-11},
  journaltitle = {Nature},
  volume = {551},
  number = {7679},
  pages = {232--236},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature24636},
  url = {https://www.nature.com/articles/nature24636},
  urldate = {2020-10-15},
  abstract = {New silicon probes known as Neuropixels are shown to record from hundreds of neurons simultaneously in awake and freely moving rodents.},
  issue = {7679},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SDC74U3U\\Jun et al. - 2017 - Fully integrated silicon probes for high-density r.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9ZALZIUX\\nature24636.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EAA9FGVT\\nature24636.html}
}

@article{kahnemanExchangeLettersRole2022,
  title = {An Exchange of Letters on the Role of Noise in Collective Intelligence},
  author = {Kahneman, Daniel and Krakauer, David C and Sibony, Olivier and Sunstein, Cass and Wolpert, David},
  date = {2022-08-01},
  journaltitle = {Collective Intelligence},
  volume = {1},
  number = {1},
  pages = {26339137221078593},
  publisher = {{SAGE Publications}},
  issn = {2633-9137},
  doi = {10.1177/26339137221078593},
  url = {https://doi.org/10.1177/26339137221078593},
  urldate = {2022-10-31},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UME9AXZ5\\Kahneman et al. - 2022 - An exchange of letters on the role of noise in col.pdf}
}

@article{kampaRequirementDendriticCalcium2006,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-15},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.2006.111062},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CDGWIY7R\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5VNZ9KCI\\jphysiol.2006.html}
}

@article{kampaRequirementDendriticCalcium2006a,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-13},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  annotation = {\_eprint: https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.2006.111062},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\395JAX93\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UDTZJJIK\\jphysiol.2006.html}
}

@article{kanamoriIndependentResponseModulation2022,
  title = {Independent Response Modulation of Visual Cortical Neurons by Attentional and Behavioral States},
  author = {Kanamori, Takahiro and Mrsic-Flogel, Thomas D.},
  date = {2022-12-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {23},
  pages = {3907-3918.e6},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.08.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322008030},
  urldate = {2022-12-23},
  abstract = {Sensory processing is influenced by cognitive and behavioral states, but how these states interact to modulate responses of individual neurons is unknown. We trained mice in a visual discrimination task wherein they attended to different locations within a hemifield while running or sitting still, enabling us to examine how visual responses are modulated by spatial attention and running behavior. We found that spatial attention improved discrimination performance and strengthened visual responses of excitatory neurons in the primary visual cortex whose receptive fields overlapped with the attended location. Although individual neurons were modulated by both spatial attention and running, the magnitudes of these influences were not correlated. While running-dependent modulation was stable across days, attentional modulation was dynamic, influencing individual neurons to different degrees after repeated changes in attentional states. Thus, despite similar effects on neural responses, spatial attention and running act independently with different dynamics, implying separable mechanisms for their implementation.},
  langid = {english},
  keywords = {brain state,mouse behavior,sensory processing,spatial attention,two-photon calcium imaging,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\N5PLNP2C\\Kanamori and Mrsic-Flogel - 2022 - Independent response modulation of visual cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZHUDC5F3\\S0896627322008030.html}
}

@article{kaperIntroductionFocusIssue2013,
  title = {Introduction to {{Focus Issue}}: {{Rhythms}} and {{Dynamic Transitions}} in {{Neurological Disease}}: {{Modeling}}, {{Computation}}, and {{Experiment}}},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Kaper, Tasso J. and Kramer, Mark A. and Rotstein, Horacio G.},
  date = {2013-12-01},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {23},
  number = {4},
  pages = {046001},
  publisher = {{American Institute of Physics}},
  issn = {1054-1500},
  doi = {10.1063/1.4856276},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4856276},
  urldate = {2020-11-10},
  abstract = {Rhythmic neuronal oscillations across a broad range of frequencies, as well as spatiotemporal phenomena, such as waves and bumps, have been observed in various areas of the brain and proposed as critical to brain function. While there is a long and distinguished history of studying rhythms in nerve cells and neuronal networks in healthy organisms, the association and analysis of rhythms to diseases are more recent developments. Indeed, it is now thought that certain aspects of diseases of the nervous system, such as epilepsy, schizophrenia, Parkinson's, and sleep disorders, are associated with transitions or disruptions of neurological rhythms. This focus issue brings together articles presenting modeling, computational, analytical, and experimental perspectives about rhythms and dynamic transitions between them that are associated to various diseases.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5AMZ5KXF\\Kaper et al. - 2013 - Introduction to Focus Issue Rhythms and Dynamic T.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7XEGAMJP\\1.html}
}

@article{kellerFeedbackGeneratesSecond2020,
  title = {Feedback Generates a Second Receptive Field in Neurons of the Visual Cortex},
  author = {Keller, Andreas J. and Roth, Morgane M. and Scanziani, Massimo},
  date = {2020-06},
  journaltitle = {Nature},
  volume = {582},
  number = {7813},
  pages = {545--549},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2319-4},
  url = {https://www.nature.com/articles/s41586-020-2319-4},
  urldate = {2020-10-05},
  abstract = {Animals sense the environment through pathways that link sensory organs to the brain. In the visual system, these feedforward pathways define the classical feedforward receptive field (ffRF), the area in space in which visual stimuli excite a neuron1. The visual system also uses visual context—the visual scene surrounding a stimulus—to predict the content of the stimulus2, and accordingly, neurons have been identified that are excited by stimuli outside their ffRF3–8. However, the mechanisms that generate excitation to stimuli outside the ffRF are unclear. Here we show that feedback projections onto excitatory neurons in the mouse primary visual cortex generate a second receptive field that is driven by stimuli outside the ffRF. The stimulation of this feedback receptive field (fbRF) elicits responses that are slower and are delayed in comparison with those resulting from the stimulation of the ffRF. These responses are preferentially reduced by anaesthesia and by silencing higher visual areas. Feedback inputs from higher visual areas have scattered receptive fields relative to their putative targets in the primary visual cortex, which enables the generation of the fbRF. Neurons with fbRFs are located in cortical layers that receive strong feedback projections and are absent in the main input layer, which is consistent with a laminar processing hierarchy. The observation that large, uniform stimuli—which cover both the fbRF and the ffRF—suppress these responses indicates that the fbRF and the ffRF are mutually antagonistic. Whereas somatostatin-expressing inhibitory neurons are driven by these large stimuli, inhibitory neurons that express parvalbumin and vasoactive intestinal peptide have mutually antagonistic fbRF and ffRF, similar to excitatory neurons. Feedback projections may therefore enable neurons to use context to estimate information that is missing from the ffRF and to report differences in stimulus features across visual space, regardless of whether excitation occurs inside or outside the ffRF. By complementing the ffRF, the fbRF that we identify here could contribute to predictive processing.},
  issue = {7813},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PLLQV9GI\\Keller et al. - 2020 - Feedback generates a second receptive field in neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PRBPYWTW\\s41586-020-2319-4.html}
}

@article{kellerSensorimotorMismatchSignals2012,
  title = {Sensorimotor {{Mismatch Signals}} in {{Primary Visual Cortex}} of the {{Behaving Mouse}}},
  author = {Keller, Georg~B. and Bonhoeffer, Tobias and Hübener, Mark},
  date = {2012-06-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {74},
  number = {5},
  pages = {809--815},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.03.040},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627312003844},
  urldate = {2020-11-06},
  abstract = {Studies in anesthetized animals have suggested that activity in early visual cortex is mainly driven by visual input and is well described by a feedforward processing hierarchy. However, evidence from experiments on awake animals has shown that both eye movements and behavioral state can strongly modulate responses of neurons in visual cortex; the functional significance of this modulation, however, remains elusive. Using visual-flow feedback manipulations during locomotion in a virtual reality environment, we found that responses in layer 2/3 of mouse primary visual cortex are strongly driven by locomotion and by mismatch between actual and expected visual feedback. These data suggest that processing in visual cortex may be based on predictive coding strategies that use motor-related and visual input to detect mismatches between predicted and actual visual feedback.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZHN6855\\Keller et al. - 2012 - Sensorimotor Mismatch Signals in Primary Visual Co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QHCV6A7V\\S0896627312003844.html}
}

@article{khaledi-nasabInformationProcessingTree2021,
  title = {Information Processing in Tree Networks of Excitable Elements},
  author = {Khaledi-Nasab, Ali and Chauhan, Kanishk and Tass, Peter A. and Neiman, Alexander B.},
  date = {2021-01-22},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {103},
  number = {1},
  pages = {012308},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.103.012308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.103.012308},
  urldate = {2022-10-03},
  abstract = {We study the collective response of small random tree networks of diffusively coupled excitable elements to stimuli applied to leaf nodes. Such networks model the morphology of certain sensory neurons that possess branched myelinated dendrites with excitable nodes of Ranvier at every branch point and at leaf nodes. Leaf nodes receive random inputs along with a stimulus and initiate action potentials that propagate through the tree. We quantify the collective response registered at the central node using mutual information. We show that in the strong-coupling limit, the statistics of the number of nodes and leaves determines the mutual information. At the same time, the collective response is insensitive to particular node connectivity and distribution of stimulus over leaf nodes. However, for intermediate coupling, the mutual information may strongly depend on the stimulus distribution among leaf nodes. We identify a mechanism behind the competition of leaf nodes that leads to nonmonotonous dependence of mutual information on coupling strength. We show that a localized stimulus given to a tree branch can be occluded by the background firing of unstimulated branches, thus suppressing mutual information. Nonetheless, the mutual information can be enhanced by a proper stimulus localization and tuning of coupling strength.}
}

@article{khamechianFrequencyModulationCortical2022,
  title = {Frequency Modulation of Cortical Rhythmicity Governs Behavioral Variability, Excitability and Synchrony of Neurons in the Visual Cortex},
  author = {Khamechian, Mohammad Bagher and Daliri, Mohammad Reza},
  date = {2022-12-03},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {20914},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-25264-5},
  url = {https://www.nature.com/articles/s41598-022-25264-5},
  urldate = {2022-12-28},
  abstract = {Research in cognitive neuroscience has renewed the idea that brain oscillations are a core organization implicated in fundamental brain functions. Growing evidence reveals that the characteristic features of these oscillations, including power, phase and frequency, are highly non-stationary, fluctuating alongside alternations in sensation, cognition and behavior. However, there is little consensus on the functional implications of the instantaneous frequency variation in cortical excitability and concomitant behavior. Here, we capitalized on intracortical electrophysiology in the macaque monkey’s visual area MT performing a visuospatial discrimination task with visual cues. We observed that the instantaneous frequency of the theta–alpha oscillations (4–13~Hz) is modulated among specific neurons whose RFs overlap with the cued stimulus location. Interestingly, we found that such frequency modulation is causally correlated with MT excitability at both scales of individual and ensemble of neurons. Moreover, studying the functional relevance of frequency variations indicated that the average theta–alpha frequencies foreshadow the monkey’s reaction time. Our results also revealed that the neural synchronization strength alters with the average frequency shift in theta–alpha oscillations, suggesting frequency modulation is critical for mutually adjusting MTs’ rhythms. Overall, our findings propose that theta–alpha frequency variations modulate MT’s excitability, regulate mutual neurons’ rhythmicity and indicate variability in behavior.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Perception,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DLBKBY9L\\Khamechian and Daliri - 2022 - Frequency modulation of cortical rhythmicity gover.pdf}
}

@article{khanContextualSignalsVisual2018,
  title = {Contextual Signals in Visual Cortex},
  author = {Khan, Adil G and Hofer, Sonja B},
  date = {2018-10-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Systems {{Neuroscience}}},
  volume = {52},
  pages = {131--138},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2018.05.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438818300825},
  urldate = {2023-01-10},
  abstract = {Vision is an active process. What we perceive strongly depends on our actions, intentions and expectations. During visual processing, these internal signals therefore need to be integrated with the visual information from the retina. The mechanisms of how this is achieved by the visual system are still poorly understood. Advances in recording and manipulating neuronal activity in specific cell types and axonal projections together with tools for circuit tracing are beginning to shed light on the neuronal circuit mechanisms of how internal, contextual signals shape sensory representations. Here we review recent work, primarily in mice, that has advanced our understanding of these processes, focusing on contextual signals related to locomotion, behavioural relevance and predictions.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PLAPVM4H\\Khan and Hofer - 2018 - Contextual signals in visual cortex.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KWVFR659\\S0959438818300825.html}
}

@article{khanDistinctLearninginducedChanges2018,
  title = {Distinct Learning-Induced Changes in Stimulus Selectivity and Interactions of {{GABAergic}} Interneuron Classes in Visual Cortex},
  author = {Khan, Adil G. and Poort, Jasper and Chadwick, Angus and Blot, Antonin and Sahani, Maneesh and Mrsic-Flogel, Thomas D. and Hofer, Sonja B.},
  date = {2018-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {6},
  pages = {851--859},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0143-z},
  url = {https://www.nature.com/articles/s41593-018-0143-z},
  urldate = {2023-01-13},
  abstract = {How learning enhances neural representations for behaviorally relevant stimuli via activity changes of cortical cell types remains unclear. We simultaneously imaged responses of pyramidal cells (PYR) along with parvalbumin (PV), somatostatin (SOM), and vasoactive intestinal peptide (VIP) inhibitory interneurons in primary visual cortex while mice learned to discriminate visual patterns. Learning increased selectivity for task-relevant stimuli of PYR, PV and SOM subsets but not VIP cells. Strikingly, PV neurons became as selective as PYR cells, and their functional interactions reorganized, leading to the emergence of stimulus-selective PYR–PV ensembles. Conversely, SOM activity became strongly decorrelated from the network, and PYR–SOM coupling before learning predicted selectivity increases in individual PYR cells. Thus, learning differentially shapes the activity and interactions of multiple cell classes: while SOM inhibition may gate selectivity changes, PV interneurons become recruited into stimulus-specific ensembles and provide more selective inhibition as the network becomes better at discriminating behaviorally relevant stimuli.},
  issue = {6},
  langid = {english},
  keywords = {Cortex,Striate cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WRKCH9GQ\\Khan et al. - 2018 - Distinct learning-induced changes in stimulus sele.pdf}
}

@article{kindelUsingDeepLearning2019,
  title = {Using Deep Learning to Probe the Neural Code for Images in Primary Visual Cortex},
  author = {Kindel, William F. and Christensen, Elijah D. and Zylberberg, Joel},
  date = {2019-04-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {19},
  number = {4},
  pages = {29--29},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/19.4.29},
  url = {https://jov.arvojournals.org/article.aspx?articleid=2732380},
  urldate = {2020-10-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HMCBY5QM\\Kindel et al. - 2019 - Using deep learning to probe the neural code for i.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZYD6594X\\article.html}
}

@article{kinouchiOptimalDynamicalRange2006,
  title = {✅ {{Optimal}} Dynamical Range of Excitable Networks at Criticality},
  author = {Kinouchi, Osame and Copelli, Mauro},
  date = {2006-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {2},
  number = {5},
  pages = {348--351},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys289},
  url = {https://www.nature.com/articles/nphys289},
  urldate = {2022-10-01},
  abstract = {A recurrent idea in the study of complex systems is that optimal information processing is to be found near phase transitions. However, this heuristic hypothesis has few (if any) concrete realizations where a standard and biologically relevant quantity is optimized at criticality. Here we give a clear example of such a phenomenon: a network of excitable elements has its sensitivity and dynamic range maximized at the critical point of a non-equilibrium phase transition. Our results are compatible with the essential role of gap junctions in olfactory glomeruli and retinal ganglionar cell output. Synchronization and global oscillations also emerge from the network dynamics. We propose that the main functional role of electrical coupling is to provide an enhancement of dynamic range, therefore allowing the coding of information spanning several orders of magnitude. The mechanism could provide a microscopic neural basis for psychophysical laws.},
  issue = {5},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4ZZQFVXT\\Kinouchi and Copelli - 2006 - Optimal dynamical range of excitable networks at c.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9SE89ZS4\\nphys289.html}
}

@article{kostalStatisticsInverseInterspike2018,
  title = {Statistics of Inverse Interspike Intervals: {{The}} Instantaneous Firing Rate Revisited},
  shorttitle = {Statistics of Inverse Interspike Intervals},
  author = {Kostal, Lubomir and Lansky, Petr and Stiber, Michael},
  date = {2018-10},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {28},
  number = {10},
  pages = {106305},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5036831},
  url = {http://aip.scitation.org/doi/10.1063/1.5036831},
  urldate = {2020-09-30},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KTQJDBMS\\Kostal et al. - 2018 - Statistics of inverse interspike intervals The in.pdf}
}

@article{krakauerInformationTheoryIndividuality2020,
  title = {The Information Theory of Individuality},
  author = {Krakauer, David and Bertschinger, Nils and Olbrich, Eckehard and Flack, Jessica C. and Ay, Nihat},
  date = {2020-06},
  journaltitle = {Theory in Biosciences},
  shortjournal = {Theory Biosci.},
  volume = {139},
  number = {2},
  pages = {209--223},
  issn = {1431-7613, 1611-7530},
  doi = {10.1007/s12064-020-00313-7},
  url = {http://link.springer.com/10.1007/s12064-020-00313-7},
  urldate = {2022-09-21},
  abstract = {Despite the near universal assumption of individuality in biology, there is little agreement about what individuals are and few rigorous quantitative methods for their identification. Here, we propose that individuals are aggregates that preserve a measure of temporal integrity, i.e., “propagate” information from their past into their futures. We formalize this idea using information theory and graphical models. This mathematical formulation yields three principled and distinct forms of individuality—an organismal, a colonial, and a driven form—each of which varies in the degree of environmental dependence and inherited information. This approach can be thought of as a Gestalt approach to evolution where selection makes figure-ground (agent–environment) distinctions using suitable information-theoretic lenses. A benefit of the approach is that it expands the scope of allowable individuals to include adaptive aggregations in systems that are multi-scale, highly distributed, and do not necessarily have physical boundaries such as cell walls or clonal somatic tissue. Such individuals might be visible to selection but hard to detect by observers without suitable measurement principles. The information theory of individuality allows for the identification of individuals at all levels of organization from molecular to cultural and provides a basis for testing assumptions about the natural scales of a system and argues for the importance of uncertainty reduction through coarse-graining in adaptive systems.},
  langid = {english},
  keywords = {adaptation,coarse graining,information theory,synergy},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Q9S4KETP\\Krakauer et al. - 2020 - The information theory of individuality.pdf}
}

@article{krakauerNeuroscienceNeedsBehavior2017,
  title = {Neuroscience {{Needs Behavior}}: {{Correcting}} a {{Reductionist Bias}}},
  shorttitle = {Neuroscience {{Needs Behavior}}},
  author = {Krakauer, John W. and Ghazanfar, Asif A. and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
  date = {2017-02-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {3},
  eprint = {28182904},
  eprinttype = {pmid},
  pages = {480--490},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.12.041},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31040-6},
  urldate = {2020-08-13},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9D7RDCNE\\Krakauer et al. - 2017 - Neuroscience Needs Behavior Correcting a Reductio.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9UAXXT2K\\S0896-6273(16)31040-6.html}
}

@article{krienerParvalbuminInterneuronDendrites2022,
  title = {Parvalbumin Interneuron Dendrites Enhance Gamma Oscillations},
  author = {Kriener, Birgit and Hu, Hua and Vervaeke, Koen},
  date = {2022-06-14},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {39},
  number = {11},
  pages = {110948},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2022.110948},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124722007306},
  urldate = {2022-10-18},
  abstract = {Dendrites are essential determinants of the input-output relationship of single neurons, but their role in network computations is not well understood. Here, we use a combination of dendritic patch-clamp recordings and in silico modeling to determine how dendrites of parvalbumin (PV)-expressing basket cells contribute to network oscillations in the gamma frequency band. Simultaneous soma-dendrite recordings from PV basket cells in the dentate gyrus reveal that the slope, or gain, of the dendritic input-output relationship is exceptionally low, thereby reducing the cell’s sensitivity to changes in its input. By simulating gamma oscillations in detailed network models, we demonstrate that the low gain is key to increase spike synchrony in PV basket cell assemblies when cells are driven by spatially and temporally heterogeneous synaptic inputs. These results highlight the role of inhibitory neuron dendrites in synchronized network oscillations.},
  langid = {english},
  keywords = {dendritic integration,gamma oscillations,inhibitory interneurons,neural gain,neural synchrony,parvalbumin basket cells,patch clamp,synaptic integration},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HHBLTVVB\\Kriener et al. - 2022 - Parvalbumin interneuron dendrites enhance gamma os.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3IP84IPZ\\S2211124722007306.html}
}

@article{kuchibhotlaParallelProcessingCortical2017,
  title = {Parallel Processing by Cortical Inhibition Enables Context-Dependent Behavior},
  author = {Kuchibhotla, Kishore V. and Gill, Jonathan V. and Lindsay, Grace W. and Papadoyannis, Eleni S. and Field, Rachel E. and Sten, Tom A. Hindmarsh and Miller, Kenneth D. and Froemke, Robert C.},
  date = {2017-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {1},
  eprint = {27798631},
  eprinttype = {pmid},
  pages = {62--71},
  issn = {1546-1726},
  doi = {10.1038/nn.4436},
  abstract = {Physical features of sensory stimuli are fixed, but sensory perception is context dependent. The precise mechanisms that govern contextual modulation remain unknown. Here, we trained mice to switch between two contexts: passively listening to pure tones and performing a recognition task for the same stimuli. Two-photon imaging showed that many excitatory neurons in auditory cortex were suppressed during behavior, while some cells became more active. Whole-cell recordings showed that excitatory inputs were affected only modestly by context, but inhibition was more sensitive, with PV+, SOM+, and VIP+ interneurons balancing inhibition and disinhibition within the network. Cholinergic modulation was involved in context switching, with cholinergic axons increasing activity during behavior and directly depolarizing inhibitory cells. Network modeling captured these findings, but only when modulation coincidently drove all three interneuron subtypes, ruling out either inhibition or disinhibition alone as sole mechanism for active engagement. Parallel processing of cholinergic modulation by cortical interneurons therefore enables context-dependent behavior.},
  langid = {english},
  pmcid = {PMC5191967},
  keywords = {Animals,Auditory Cortex,Auditory Perception,Behavior; Animal,Mice; Transgenic,Neural Inhibition,Neurons,Somatostatin,Vasoactive Intestinal Peptide,Visual Cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MQGRNT5Z\\Kuchibhotla et al. - 2017 - Parallel processing by cortical inhibition enables.pdf}
}

@article{lainscsekCorticalChimeraStates2019,
  title = {Cortical Chimera States Predict Epileptic Seizures},
  author = {Lainscsek, Claudia and Rungratsameetaweemana, Nuttida and Cash, Sydney S. and Sejnowski, Terrence J.},
  date = {2019-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {29},
  number = {12},
  pages = {121106},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5139654},
  url = {http://aip.scitation.org/doi/10.1063/1.5139654},
  urldate = {2020-11-10},
  abstract = {A chimera state is a spatiotemporal pattern of broken symmetry, where synchrony (coherent state) and asynchrony (incoherent state) coexist. Here, we report chimera states in electrocorticography recordings preceding, by several hours, each of seven seizures in one patient with epilepsy. Before the seizures, the onset channels are not synchronized, while the remaining channels are synchronized. During the seizures, this pattern of behavior ips and the nononset channels show a more asynchronous behavior. At a seizure o set, synchrony can be observed that might facilitate termination.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XEUFDAHA\\Lainscsek et al. - 2019 - Cortical chimera states predict epileptic seizures.pdf}
}

@article{lambiotteNetworksOptimalHigherorder2019,
  title = {From Networks to Optimal Higher-Order Models of Complex Systems},
  author = {Lambiotte, Renaud and Rosvall, Martin and Scholtes, Ingo},
  date = {2019-04},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {15},
  number = {4},
  pages = {313--320},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-019-0459-y},
  url = {https://www.nature.com/articles/s41567-019-0459-y},
  urldate = {2022-10-05},
  abstract = {Rich data are revealing that complex dependencies between the nodes of a network may not be captured by models based on pairwise interactions. Higher-order network models go beyond these limitations, offering new perspectives for understanding complex systems.},
  issue = {4},
  langid = {english},
  keywords = {Applied mathematics,Complex networks},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ANJ5Q7EE\\Lambiotte et al. - 2019 - From networks to optimal higher-order models of co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SZLAN4DT\\s41567-019-0459-y.html}
}

@article{larkumCalciumElectrogenesisDistal1999,
  title = {Calcium Electrogenesis in Distal Apical Dendrites of Layer 5 Pyramidal Cells at a Critical Frequency of Back-Propagating Action Potentials},
  author = {Larkum, M. E. and Kaiser, K. M. M. and Sakmann, B.},
  date = {1999-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {96},
  number = {25},
  pages = {14600--14604},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.96.25.14600},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.96.25.14600},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RMSCZEU\\Larkum et al. - 1999 - Calcium electrogenesis in distal apical dendrites .pdf}
}

@article{larkumCellularMechanismCortical2013,
  title = {A Cellular Mechanism for Cortical Associations: An Organizing Principle for the Cerebral Cortex},
  shorttitle = {A Cellular Mechanism for Cortical Associations},
  author = {Larkum, Matthew},
  date = {2013-03},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {36},
  number = {3},
  pages = {141--151},
  issn = {01662236},
  doi = {10.1016/j.tins.2012.11.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223612002032},
  urldate = {2021-03-23},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MILLESZH\\Larkum - 2013 - A cellular mechanism for cortical associations an.pdf}
}

@article{larkumNewCellularMechanism1999,
  title = {A New Cellular Mechanism for Coupling Inputs Arriving at Different Cortical Layers},
  author = {Larkum, Matthew E. and Zhu, J. Julius and Sakmann, Bert},
  date = {1999-03},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {398},
  number = {6725},
  pages = {338--341},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/18686},
  url = {http://www.nature.com/articles/18686},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UTWC2UTY\\Larkum et al. - 1999 - A new cellular mechanism for coupling inputs arriv.pdf}
}

@article{larkumTopdownDendriticInput2004,
  title = {✅ {{Top-down Dendritic Input Increases}} the {{Gain}} of {{Layer}} 5 {{Pyramidal Neurons}}},
  author = {Larkum, Matthew E. and Senn, Walter and Lüscher, Hans-R.},
  date = {2004-10-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {14},
  number = {10},
  pages = {1059--1070},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhh065},
  url = {https://doi.org/10.1093/cercor/bhh065},
  urldate = {2022-10-13},
  abstract = {The cerebral cortex is organized so that an important component of feedback input from higher to lower cortical areas arrives at the distal apical tufts of pyramidal neurons. Yet, distal inputs are predicted to have much less impact on firing than proximal inputs. Here we show that even weak asynchronous dendritic input to the distal tuft region can significantly increase the gain of layer 5 pyramidal neurons and thereby the output of columns in the primary somatosensory cortex of the rat. Noisy currents injected in ramps at different dendritic locations showed that the initial slope of the frequency–current (f/I) relationship increases with the distance of the current injection from the soma. The increase was due to the interaction of dendritic depolarization with back-propagating APs which activated dendritic calcium conductances. Gain increases were accompanied by a change of firing mode from isolated spikes to bursting where the timing of bursts coded the presence of coincident somatic and dendritic inputs. We propose that this dendritic gain modulation and the timing of bursts may serve to associate top-down and bottom-up input on different time scales.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9SL6VH6E\\Larkum et al. - 2004 - Top-down Dendritic Input Increases the Gain of Lay.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TJQPSLSR\\275677.html}
}

@article{lavzinNonlinearDendriticProcessing2012,
  title = {Nonlinear Dendritic Processing Determines Angular Tuning of Barrel Cortex Neurons in Vivo},
  author = {Lavzin, Maria and Rapoport, Sophia and Polsky, Alon and Garion, Liora and Schiller, Jackie},
  date = {2012-10},
  journaltitle = {Nature},
  volume = {490},
  number = {7420},
  pages = {397--401},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature11451},
  url = {https://www.nature.com/articles/nature11451},
  urldate = {2022-09-02},
  abstract = {In vivo whole-cell recordings combined with an intracellular N-methyl-d-aspartate receptor (NMDAR) blocker and membrane hyperpolarization are used to examine the contribution of dendritic NMDAR-dependent regenerative responses to the angular tuning of layer 4 neurons; the results show that active dendritic processing sharpens the sensory responses of cortical neurons in vivo.},
  issue = {7420},
  langid = {english},
  keywords = {Action potential generation,Sensorimotor processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6IHP82TD\\Lavzin et al. - 2012 - Nonlinear dendritic processing determines angular .pdf}
}

@video{LectureWalkthroughMammalian,
  title = {Lecture 1: {{A Walk-through}} of the {{Mammalian Visual System}}},
  shorttitle = {Lecture 1},
  url = {https://www.youtube.com/watch?v=mtPgW1ebxmE&t=2278s},
  urldate = {2020-09-25},
  abstract = {From the retina to the superior colliculus, the lateral geniculate nucleus into primary visual cortex and beyond, R. Clay Reid gives a tour of the mammalian visual system highlighting the Nobel-prize winning discoveries of Hubel \&amp; Wiesel. This is the first lecture of a 12-part series entitled Coding \&amp; Vision 101, produced by the Allen Institute for Brain Science as an educational resource for the community.}
}

@article{leeActivationSpecificInterneurons2012,
  title = {Activation of Specific Interneurons Improves {{V1}} Feature Selectivity and Visual Perception},
  author = {Lee, Seung-Hee and Kwan, Alex C. and Zhang, Siyu and Phoumthipphavong, Victoria and Flannery, John G. and Masmanidis, Sotiris C. and Taniguchi, Hiroki and Huang, Z. Josh and Zhang, Feng and Boyden, Edward S. and Deisseroth, Karl and Dan, Yang},
  date = {2012-08-16},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {488},
  number = {7411},
  eprint = {22878719},
  eprinttype = {pmid},
  pages = {379--383},
  issn = {1476-4687},
  doi = {10.1038/nature11312},
  abstract = {Inhibitory interneurons are essential components of the neural circuits underlying various brain functions. In the neocortex, a large diversity of GABA (γ-aminobutyric acid) interneurons has been identified on the basis of their morphology, molecular markers, biophysical properties and innervation pattern. However, how the activity of each subtype of interneurons contributes to sensory processing remains unclear. Here we show that optogenetic activation of parvalbumin-positive (PV+) interneurons in the mouse primary visual cortex (V1) sharpens neuronal feature selectivity and improves perceptual discrimination. Using multichannel recording with silicon probes and channelrhodopsin-2 (ChR2)-mediated optical activation, we found that increased spiking of PV+ interneurons markedly sharpened orientation tuning and enhanced direction selectivity of nearby neurons. These effects were caused by the activation of inhibitory neurons rather than a decreased spiking of excitatory neurons, as archaerhodopsin-3 (Arch)-mediated optical silencing of calcium/calmodulin-dependent protein kinase IIα (CAMKIIα)-positive excitatory neurons caused no significant change in V1 stimulus selectivity. Moreover, the improved selectivity specifically required PV+ neuron activation, as activating somatostatin or vasointestinal peptide interneurons had no significant effect. Notably, PV+ neuron activation in awake mice caused a significant improvement in their orientation discrimination, mirroring the sharpened V1 orientation tuning. Together, these results provide the first demonstration that visual coding and perception can be improved by increased spiking of a specific subtype of cortical inhibitory interneurons.},
  langid = {english},
  pmcid = {PMC3422431},
  keywords = {Animals,Calcium-Calmodulin-Dependent Protein Kinase Type 2,Channelrhodopsins,Discrimination Learning,gamma-Aminobutyric Acid,Interneurons,Mice,Models; Neurological,Neural Inhibition,Parvalbumins,Rhodopsins; Microbial,Visual Cortex,Visual Perception,Wakefulness},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\59YYI44H\\Lee et al. - 2012 - Activation of specific interneurons improves V1 fe.pdf}
}

@article{levinaDynamicalSynapsesCausing2007,
  title = {Dynamical Synapses Causing Self-Organized Criticality in Neural Networks},
  author = {Levina, A. and Herrmann, J. M. and Geisel, T.},
  date = {2007-12},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {3},
  number = {12},
  pages = {857--860},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys758},
  url = {https://www.nature.com/articles/nphys758},
  urldate = {2022-10-03},
  abstract = {Self-organized criticality1 is one of the key concepts to describe the emergence of complexity in natural systems. The concept asserts that a system self-organizes into a critical state where system observables are distributed according to a power law. Prominent examples of self-organized critical dynamics include piling of granular media2, plate tectonics3 and stick–slip motion4. Critical behaviour has been shown to bring about optimal computational capabilities5, optimal transmission6, storage of information7 and sensitivity to sensory stimuli8,9,10. In neuronal systems, the existence of critical avalanches was predicted11 and later observed experimentally6,12,13. However, whereas in the experiments generic critical avalanches were found, in the model of ref.~11 they only show up if the set of parameters is fine-tuned externally to a critical transition state. Here, we demonstrate analytically and numerically that by assuming (biologically more realistic) dynamical synapses14 in a spiking neural network, the neuronal avalanches turn from an exceptional phenomenon into a typical and robust self-organized critical behaviour, if the total resources of neurotransmitter are sufficiently large.},
  issue = {12},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7KYABN2M\\Levina et al. - 2007 - Dynamical synapses causing self-organized critical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2XEEWP6E\\nphys758.html}
}

@article{liNeuralCodeNeural2017,
  title = {Neural {{Code}}—{{Neural Self-information Theory}} on {{How Cell-Assembly Code Rises}} from {{Spike Time}} and {{Neuronal Variability}}},
  author = {Li, Meng and Tsien, Joe Z.},
  date = {2017},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {11},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2017.00236},
  urldate = {2022-10-17},
  abstract = {A major stumbling block to cracking the real-time neural code is neuronal variability - neurons discharge spikes with enormous variability not only across trials within the same experiments but also in resting states. Such variability is widely regarded as a noise which is often deliberately averaged out during data analyses. In contrast to such a dogma, we put forth the Neural Self-Information Theory that neural coding is operated based on the self-information principle under which variability in the time durations of inter-spike-intervals (ISI), or neuronal silence durations, is self-tagged with discrete information. As the self-information processor, each ISI carries a certain amount of information based on its variability-probability distribution; higher-probability ISIs which reflect the balanced excitation-inhibition ground state convey minimal information, whereas lower-probability ISIs which signify rare-occurrence surprisals in the form of extremely transient or prolonged silence carry most information. These variable silence durations are naturally coupled with intracellular biochemical cascades, energy equilibrium and dynamic regulation of protein and gene expression levels. As such, this silence variability-based self-information code is completely intrinsic to the neurons themselves, with no need for outside observers to set any reference point as typically used in the rate code, population code and temporal code models. Moreover, temporally coordinated ISI surprisals across cell population can inherently give rise to robust real-time cell-assembly codes which can be readily sensed by the downstream neural clique assemblies. One immediate utility of this self-information code is a general decoding strategy to uncover a variety of cell-assembly patterns underlying external and internal categorical or continuous variables in an unbiased manner.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C6IPDQPB\\Li and Tsien - 2017 - Neural Code—Neural Self-information Theory on How .pdf}
}

@article{liptonKuramotoModelSphere2021,
  title = {The {{Kuramoto}} Model on a Sphere: {{Explaining}} Its Low-Dimensional Dynamics with Group Theory and Hyperbolic Geometry},
  shorttitle = {The {{Kuramoto}} Model on a Sphere},
  author = {Lipton, Max and Mirollo, Renato and Strogatz, Steven H.},
  date = {2021-09},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {31},
  number = {9},
  pages = {093113},
  publisher = {{American Institute of Physics}},
  issn = {1054-1500},
  doi = {10.1063/5.0060233},
  url = {https://aip.scitation.org/doi/abs/10.1063/5.0060233},
  urldate = {2022-10-05},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZEW7R9PM\\Lipton et al. - 2021 - The Kuramoto model on a sphere Explaining its low.pdf}
}

@unpublished{liStatisticalMechanicsDeep2020,
  title = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}: {{The Back-Propagating Renormalization Group}}},
  shorttitle = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}},
  author = {Li, Qianyi and Sompolinsky, Haim},
  date = {2020-12-07},
  eprint = {2012.04030},
  eprinttype = {arxiv},
  primaryclass = {physics},
  url = {http://arxiv.org/abs/2012.04030},
  urldate = {2021-03-04},
  abstract = {The success of deep learning in many real-world tasks has triggered an effort to theoretically understand the power and limitations of deep learning in training and generalization of complex tasks, so far with limited progress. In this work, we study the statistical mechanics of learning in Deep Linear Neural Networks (DLNNs) in which the input-output function of an individual unit is linear. Despite the linearity of the units, learning in DLNNs is highly nonlinear, hence studying its properties reveals some of the essential features of nonlinear Deep Neural Networks (DNNs). We solve exactly the network properties following supervised learning using an equilibrium Gibbs distribution in the weight space. To do this, we introduce the Back-Propagating Renormalization Group (BPRG) which allows for the incremental integration of the network weights layer by layer from the network output layer and progressing backward. This procedure allows us to evaluate important network properties such as its generalization error, the role of network width and depth, the impact of the size of the training set, and the effects of weight regularization and learning stochasticity. Furthermore, by performing partial integration of layers, BPRG allows us to compute the emergent properties of the neural representations across the different hidden layers. We have proposed a heuristic extension of the BPRG to nonlinear DNNs with rectified linear units (ReLU). Surprisingly, our numerical simulations reveal that despite the nonlinearity, the predictions of our theory are largely shared by ReLU networks with modest depth, in a wide regime of parameters. Our work is the first exact statistical mechanical study of learning in a family of Deep Neural Networks, and the first development of the Renormalization Group approach to the weight space of these systems.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Physics - Applied Physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SBDNST6E\\Li and Sompolinsky - 2020 - Statistical Mechanics of Deep Linear Neural Networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A7ID7JS8\\2012.html}
}

@misc{livezeyNotOptimalJust2022,
  title = {Not Optimal, Just Noisy: The Geometry of Correlated Variability Leads to Highly Suboptimal Sensory Coding},
  shorttitle = {Not Optimal, Just Noisy},
  author = {Livezey, Jesse A. and Sachdeva, Pratik S. and Dougherty, Maximilian E. and Summers, Mathew T. and Bouchard, Kristofer E.},
  date = {2022-03-09},
  pages = {2022.03.08.483488},
  publisher = {{bioRxiv}},
  doi = {10.1101/2022.03.08.483488},
  url = {https://www.biorxiv.org/content/10.1101/2022.03.08.483488v1},
  urldate = {2023-01-13},
  abstract = {The brain represents the world through the activity of neural populations. Correlated variability across simultaneously recorded neurons (noise correlations) has been observed across cortical areas and experimental paradigms. Many studies have shown that correlated variability improves stimulus coding compared to a null model with no correlations. However, such results do not shed light on whether neural populations’ correlated variability achieves optimal coding. Here, we assess optimality of noise correlations in diverse datasets by developing two novel null models each with a unique biological interpretation: a uniform correlations null model and a factor analysis null model. We show that across datasets, the correlated variability in neural populations leads to highly suboptimal coding performance according to these null models. We demonstrate that biological constraints prevent many subsets of the neural populations from achieving optimality according to these null models, and that subselecting based on biological criteria leaves coding performance suboptimal. Finally, we show that the optimal subpopulation is exponentially small as a function of neural dimensionality. Together, these results show that the geometry of correlated variability leads to highly suboptimal sensory coding.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9E5CIKTX\\Livezey et al. - 2022 - Not optimal, just noisy the geometry of correlate.pdf}
}

@article{londonConductingSynapticMusic2004,
  title = {Conducting Synaptic Music in Dendrites},
  author = {London, Michael and Segev, Idan},
  date = {2004-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {7},
  number = {9},
  pages = {904--905},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn0904-904},
  url = {https://www.nature.com/articles/nn0904-904},
  urldate = {2022-10-05},
  abstract = {Thousands of active synapses on the dendrites drastically increase membrane conductance. Williams now shows that local processing is unaffected by conductance changes in distant regions, highlighting how functionally independent dendritic regions interact.},
  issue = {9},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FAY7K47F\\London and Segev - 2004 - Conducting synaptic music in dendrites.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\N4P8QATB\\nn0904-904.html}
}

@article{londonDendriticComputation2005,
  title = {Dendritic {{Computation}}},
  author = {London, Michael and Häusser, Michael},
  date = {2005},
  journaltitle = {Annual Review of Neuroscience},
  volume = {28},
  number = {1},
  eprint = {16033324},
  eprinttype = {pmid},
  pages = {503--532},
  doi = {10.1146/annurev.neuro.28.061604.135703},
  url = {https://doi.org/10.1146/annurev.neuro.28.061604.135703},
  urldate = {2022-09-08},
  abstract = {One of the central questions in neuroscience is how particular tasks, or computations, are implemented by neural networks to generate behavior. The prevailing view has been that information processing in neural networks results primarily from the properties of synapses and the connectivity of neurons within the network, with the intrinsic excitability of single neurons playing a lesser role. As a consequence, the contribution of single neurons to computation in the brain has long been underestimated. Here we review recent work showing that neuronal dendrites exhibit a range of linear and nonlinear mechanisms that allow them to implement elementary computations. We discuss why these dendritic properties may be essential for the computations performed by the neuron and the network and provide theoretical and experimental examples to support this view.},
  keywords = {coding,dendrites,ion channels,spikes,synaptic integration},
  annotation = {\_eprint: https://doi.org/10.1146/annurev.neuro.28.061604.135703}
}

@article{lotfiStatisticalComplexityMaximized2021,
  title = {Statistical Complexity Is Maximized Close to Criticality in Cortical Dynamics},
  author = {Lotfi, Nastaran and Feliciano, Thaís and Aguiar, Leandro A. A. and Silva, Thais Priscila Lima and Carvalho, Tawan T. A. and Rosso, Osvaldo A. and Copelli, Mauro and Matias, Fernanda S. and Carelli, Pedro V.},
  date = {2021-01-25},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {103},
  number = {1},
  pages = {012415},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.103.012415},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.103.012415},
  urldate = {2022-10-02},
  abstract = {Complex systems are typically characterized as an intermediate situation between a complete regular structure and a random system. Brain signals can be studied as a striking example of such systems: cortical states can range from highly synchronous and ordered neuronal activity (with higher spiking variability) to desynchronized and disordered regimes (with lower spiking variability). It has been recently shown, by testing independent signatures of criticality, that a phase transition occurs in a cortical state of intermediate spiking variability. Here we use a symbolic information approach to show that, despite the monotonical increase of the Shannon entropy between ordered and disordered regimes, we can determine an intermediate state of maximum complexity based on the Jensen disequilibrium measure. More specifically, we show that statistical complexity is maximized close to criticality for cortical spiking data of urethane-anesthetized rats, as well as for a network model of excitable elements that presents a critical point of a nonequilibrium phase transition.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RIL64QJ\\Lotfi et al. - 2021 - Statistical complexity is maximized close to criti.pdf}
}

@article{luczakNeuronsLearnPredicting2022,
  title = {Neurons Learn by Predicting Future Activity},
  author = {Luczak, Artur and McNaughton, Bruce L. and Kubo, Yoshimasa},
  date = {2022-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {1},
  pages = {62--72},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00430-y},
  url = {https://www.nature.com/articles/s42256-021-00430-y},
  urldate = {2022-10-03},
  abstract = {Understanding how the brain learns may lead to machines with human-like intellectual capacities. It was previously proposed that the brain may operate on the principle of predictive coding. However, it is still not well understood how a predictive system could be implemented in the brain. Here we demonstrate that the ability of a single neuron to predict its future activity may provide an effective learning mechanism. Interestingly, this predictive learning rule can be derived from a metabolic principle, whereby neurons need to minimize their own synaptic activity (cost) while maximizing their impact on local blood supply by recruiting other neurons. We show how this mathematically derived learning rule can provide a theoretical connection between diverse types of brain-inspired algorithm, thus offering a step towards the development of a general theory of neuronal learning. We tested this predictive learning rule in neural network simulations and in data recorded from awake animals. Our results also suggest that spontaneous brain activity provides ‘training data’ for neurons to learn to predict cortical dynamics. Thus, the ability of a single neuron to minimize surprise—that is, the difference between actual and expected activity—could be an important missing element to understand computation in the brain.},
  issue = {1},
  langid = {english},
  keywords = {Cortex,Learning algorithms},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KDLSWEP9\\Luczak et al. - 2022 - Neurons learn by predicting future activity.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NHM383MJ\\s42256-021-00430-y.html}
}

@article{luczakNeuronsLearnPredicting2022a,
  title = {Neurons Learn by Predicting Future Activity},
  author = {Luczak, Artur and McNaughton, Bruce L. and Kubo, Yoshimasa},
  date = {2022-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {1},
  pages = {62--72},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00430-y},
  url = {https://www.nature.com/articles/s42256-021-00430-y},
  urldate = {2022-10-24},
  abstract = {Understanding how the brain learns may lead to machines with human-like intellectual capacities. It was previously proposed that the brain may operate on the principle of predictive coding. However, it is still not well understood how a predictive system could be implemented in the brain. Here we demonstrate that the ability of a single neuron to predict its future activity may provide an effective learning mechanism. Interestingly, this predictive learning rule can be derived from a metabolic principle, whereby neurons need to minimize their own synaptic activity (cost) while maximizing their impact on local blood supply by recruiting other neurons. We show how this mathematically derived learning rule can provide a theoretical connection between diverse types of brain-inspired algorithm, thus offering a step towards the development of a general theory of neuronal learning. We tested this predictive learning rule in neural network simulations and in data recorded from awake animals. Our results also suggest that spontaneous brain activity provides ‘training data’ for neurons to learn to predict cortical dynamics. Thus, the ability of a single neuron to minimize surprise—that is, the difference between actual and expected activity—could be an important missing element to understand computation in the brain.},
  issue = {1},
  langid = {english},
  keywords = {Cortex,Learning algorithms},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G6Y5EI77\\Luczak et al. - 2022 - Neurons learn by predicting future activity.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8XCWRTU7\\s42256-021-00430-y.html}
}

@article{luResynchronizationCircadianOscillators2016,
  title = {Resynchronization of Circadian Oscillators and the East-West Asymmetry of Jet-Lag},
  author = {Lu, Zhixin and Klein-Cardeña, Kevin and Lee, Steven and Antonsen, Thomas M. and Girvan, Michelle and Ott, Edward},
  date = {2016-07-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {26},
  number = {9},
  pages = {094811},
  publisher = {{American Institute of Physics}},
  issn = {1054-1500},
  doi = {10.1063/1.4954275},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4954275},
  urldate = {2020-11-10},
  abstract = {Cells in the brain's Suprachiasmatic Nucleus (SCN) are known to regulate circadian rhythms in mammals. We model synchronization of SCN cells using the forced Kuramoto model, which consists of a large population of coupled phase oscillators (modeling individual SCN cells) with heterogeneous intrinsic frequencies and external periodic forcing. Here, the periodic forcing models diurnally varying external inputs such as sunrise, sunset, and alarm clocks. We reduce the dimensionality of the system using the ansatz of Ott and Antonsen and then study the effect of a sudden change of clock phase to simulate cross-time-zone travel. We estimate model parameters from previous biological experiments. By examining the phase space dynamics of the model, we study the mechanism leading to the difference typically experienced in the severity of jet-lag resulting from eastward and westward travel.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\386DU3WN\\Lu et al. - 2016 - Resynchronization of circadian oscillators and the.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T66BF8L3\\1.html}
}

@article{lynnSyntheticLikelihoodSolution2020,
  title = {A {{Synthetic Likelihood Solution}} to the {{Silent Synapse Estimation Problem}}},
  author = {Lynn, Michael B. and Lee, Kevin F. H. and Soares, Cary and Naud, Richard and Béïque, Jean-Claude},
  date = {2020-07-21},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {32},
  number = {3},
  eprint = {32697998},
  eprinttype = {pmid},
  publisher = {{Elsevier}},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2020.107916},
  url = {https://www.cell.com/cell-reports/abstract/S2211-1247(20)30897-4},
  urldate = {2020-10-22},
  langid = {english},
  keywords = {plasticity,silent synapses,statistical inference,synthetic likelihood},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FVJHXBBC\\Lynn et al. - 2020 - A Synthetic Likelihood Solution to the Silent Syna.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V6576NK9\\S2211-1247(20)30897-4.html}
}

@article{majdandzicSpontaneousRecoveryDynamical2014,
  title = {Spontaneous Recovery in Dynamical Networks},
  author = {Majdandzic, Antonio and Podobnik, Boris and Buldyrev, Sergey V. and Kenett, Dror Y. and Havlin, Shlomo and Eugene Stanley, H.},
  date = {2014-01},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {10},
  number = {1},
  pages = {34--38},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys2819},
  url = {https://www.nature.com/articles/nphys2819},
  urldate = {2022-10-05},
  abstract = {Networks that fail can sometimes recover spontaneously—think of traffic jams suddenly easing or people waking from a coma. A model for such recoveries reveals spontaneous ‘phase flipping’ between high-activity and low-activity modes, in analogy with first-order phase transitions near a critical point.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3I3E9APB\\Majdandzic et al. - 2014 - Spontaneous recovery in dynamical networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CPFB3Z6D\\nphys2819.html}
}

@article{markovicPhysicsNeuromorphicComputing2020,
  title = {Physics for Neuromorphic Computing},
  author = {Marković, Danijela and Mizrahi, Alice and Querlioz, Damien and Grollier, Julie},
  date = {2020-09},
  journaltitle = {Nature Reviews Physics},
  shortjournal = {Nat Rev Phys},
  volume = {2},
  number = {9},
  pages = {499--510},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5820},
  doi = {10.1038/s42254-020-0208-2},
  url = {https://www.nature.com/articles/s42254-020-0208-2},
  urldate = {2022-10-02},
  abstract = {Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Systems built with standard electronics achieve gains in speed and energy by mimicking the distributed topology of the brain. Scaling-up such systems and improving their energy usage, speed and performance by several orders of magnitude requires a revolution in hardware. We discuss how including more physics in the algorithms and nanoscale materials used for data processing could have a major impact in the field of neuromorphic computing. We review striking results that leverage physics to enhance the computing capabilities of artificial neural networks, using resistive switching materials, photonics, spintronics and other technologies. We discuss the paths that could lead these approaches to maturity, towards low-power, miniaturized chips that could infer and learn in real time.},
  issue = {9},
  langid = {english},
  keywords = {Electronics,Nanoscale devices,photonics and device physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NASQEFUD\\Marković et al. - 2020 - Physics for neuromorphic computing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9B9T3VEB\\s42254-020-0208-2.html}
}

@article{marvanApicalAmplificationCellular2021,
  title = {Apical Amplification—a Cellular Mechanism of Conscious Perception?},
  author = {Marvan, Tomáš and Polák, Michal and Bachmann, Talis and Phillips, William A},
  date = {2021-12-01},
  journaltitle = {Neuroscience of Consciousness},
  shortjournal = {Neuroscience of Consciousness},
  volume = {2021},
  number = {2},
  pages = {niab036},
  issn = {2057-2107},
  doi = {10.1093/nc/niab036},
  url = {https://doi.org/10.1093/nc/niab036},
  urldate = {2022-10-18},
  abstract = {We present a theoretical view of the cellular foundations for network-level processes involved in producing our conscious experience. Inputs to apical synapses in layer 1 of a large subset of neocortical cells are summed at an integration zone near the top of their apical trunk. These inputs come from diverse sources and provide a context within which the transmission of information abstracted from sensory input to their basal and perisomatic synapses can be amplified when relevant. We argue that apical amplification enables conscious perceptual experience and makes it more flexible, and thus more adaptive, by being sensitive to context. Apical amplification provides a possible mechanism for recurrent processing theory that avoids strong loops. It makes the broadcasting hypothesized by global neuronal workspace theories feasible while preserving the distinct contributions of the individual cells receiving the broadcast. It also provides mechanisms that contribute to the holistic aspects of integrated information theory. As apical amplification is highly dependent on cholinergic, aminergic, and other neuromodulators, it relates the specific contents of conscious experience to global mental states and to fluctuations in arousal when awake. We conclude that apical dendrites provide a cellular mechanism for the context-sensitive selective amplification that is a cardinal prerequisite of conscious perception.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GVRDU67D\\Marvan et al. - 2021 - Apical amplification—a cellular mechanism of consc.pdf}
}

@article{masoliverControlCoherenceResonance2021,
  title = {Control of Coherence Resonance in Multiplex Neural Networks},
  author = {Masoliver, Maria and Masoller, Cristina and Zakharova, Anna},
  date = {2021-04-01},
  journaltitle = {Chaos, Solitons \& Fractals},
  shortjournal = {Chaos, Solitons \& Fractals},
  volume = {145},
  pages = {110666},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2021.110666},
  url = {https://www.sciencedirect.com/science/article/pii/S0960077921000199},
  urldate = {2022-10-05},
  abstract = {We study the dynamics of two neuronal populations weakly and mutually coupled in a multiplexed ring configuration. We simulate the neuronal activity with the stochastic FitzHugh–Nagumo (FHN) model. The two neuronal populations perceive different levels of noise: one population exhibits spiking activity induced by supra-threshold noise (layer 1), while the other population is silent in the absence of inter-layer coupling because its own level of noise is sub-threshold (layer 2). We find that, for appropriate levels of noise in layer 1, weak inter-layer coupling can induce coherence resonance (CR), anti-coherence resonance (ACR) and inverse stochastic resonance (ISR) in layer 2. We also find that a small number of randomly distributed inter-layer links is sufficient to induce these phenomena in layer 2. Our results hold for small and large neuronal populations.},
  langid = {english},
  keywords = {Coherence resonance,FitzHugh–Nagumo neuron,Multiplex network,Synchronization},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V5BZCQYX\\Masoliver et al. - 2021 - Control of coherence resonance in multiplex neural.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ELYLNR22\\S0960077921000199.html}
}

@article{masoliverEmbeddedChimeraStates2022,
  title = {Embedded Chimera States in Recurrent Neural Networks},
  author = {Masoliver, Maria and Davidsen, Jörn and Nicola, Wilten},
  date = {2022-08-11},
  journaltitle = {Communications Physics},
  shortjournal = {Commun Phys},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {2399-3650},
  doi = {10.1038/s42005-022-00984-2},
  url = {https://www.nature.com/articles/s42005-022-00984-2},
  urldate = {2022-10-05},
  abstract = {Fully and partially synchronized brain activity plays a key role in normal cognition and in some neurological disorders, such as epilepsy. However, the mechanism by which synchrony and asynchrony co-exist in a population of neurons remains elusive. Chimera states, where synchrony and asynchrony coexist, have been documented only for precisely specified connectivity and network topologies. Here, we demonstrate how chimeras can emerge in recurrent neural networks by training the networks to display chimeras with machine learning. These solutions, which we refer to as embedded chimeras, are generically produced by recurrent neural networks with connectivity matrices only slightly perturbed from random networks. We also demonstrate that learning is robust to different biological constraints, such as the excitatory/inhibitory classification of neurons (Dale’s law), and the sparsity of connections in neural circuits. The recurrent neural networks can also be trained to switch chimera solutions: an input pulse can trigger the neural network to switch the synchronized and the unsynchronized groups of the embedded chimera, reminiscent of uni-hemispheric sleep in a variety of animals. Our results imply that the emergence of chimeras is quite generic at the meso- and macroscale suggesting their general relevance in neuroscience.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Computational science,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IK8LZZL6\\Masoliver et al. - 2022 - Embedded chimera states in recurrent neural networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EMBZ8G6D\\s42005-022-00984-2.html}
}

@article{mcadamsEffectsAttentionOrientationTuning1999,
  title = {Effects of {{Attention}} on {{Orientation-Tuning Functions}} of {{Single Neurons}} in {{Macaque Cortical Area V4}}},
  author = {McAdams, Carrie J. and Maunsell, John H. R.},
  date = {1999-01-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {19},
  number = {1},
  eprint = {9870971},
  eprinttype = {pmid},
  pages = {431--441},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.19-01-00431.1999},
  url = {https://www.jneurosci.org/content/19/1/431},
  urldate = {2023-01-03},
  abstract = {We examined how attention affected the orientation tuning of 262 isolated neurons in extrastriate area V4 and 135 neurons in area V1 of two rhesus monkeys. The animals were trained to perform a delayed match-to-sample task in which oriented stimuli were presented in the receptive field of the neuron being recorded. On some trials the animals were instructed to pay attention to those stimuli, and on other trials they were instructed to pay attention to other stimuli outside the receptive field. In this way, orientation-tuning curves could be constructed from neuronal responses collected in two behavioral states: one in which those stimuli were attended by the animal and one in which those stimuli were ignored by the animal. We fit Gaussians to the neuronal responses to twelve different orientations for each behavioral state. Although attention enhanced the responses of V4 neurons (median 26\% increase) and V1 neurons (median 8\% increase), selectivity, as measured by the width of its orientation-tuning curve, was not systematically altered by attention. The effects of attention were consistent with a multiplicative scaling of the driven response to all orientations. We also found that attention did not cause systematic changes in the undriven activity of the neurons.},
  langid = {english},
  keywords = {area V4,attention,cortex,extrastriate,monkey,orientation,tuning,visual},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I7CWWJ4I\\McAdams and Maunsell - 1999 - Effects of Attention on Orientation-Tuning Functio.pdf}
}

@article{mcadamsEffectsAttentionReliability1999,
  title = {✅ {{Effects}} of {{Attention}} on the {{Reliability}} of {{Individual Neurons}} in {{Monkey Visual Cortex}}},
  author = {McAdams, Carrie J. and Maunsell, John H. R.},
  date = {1999-08-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {23},
  number = {4},
  pages = {765--773},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)80034-9},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627301800349},
  urldate = {2022-12-28},
  abstract = {To determine the physiological mechanisms underlying the enhancement of performance by attention, we examined how attention affects the ability of isolated neurons to discriminate orientation by investigating the reliability of responses with and without attention. Recording from 262 neurons in cortical area V4 while two rhesus macaques did a delayed match-to-sample task with oriented stimuli, we found that attention did not produce detectable changes in the variability of neuronal responses but did improve the orientation discriminability of the neurons. We also found that attention did not change the relationship between burst rate and response rate. Our results are consistent with the idea that attention selects groups of neurons for a multiplicative enhancement in response strength.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DMA3B28A\\McAdams and Maunsell - 1999 - Effects of Attention on the Reliability of Individ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XUA8X5S8\\S0896627301800349.html}
}

@online{MemoriesTopYour,
  title = {Memories off the Top of Your Head | {{Science}}},
  url = {https://www.science.org/doi/10.1126/science.abk1859#.YXvFmCeh6kY.twitter},
  urldate = {2022-10-06},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5EAJUVSA\\science.html}
}

@article{menesseHomeostaticCriticalityNeuronal2022,
  title = {Homeostatic Criticality in Neuronal Networks},
  author = {Menesse, Gustavo and Marin, Bóris and Girardi-Schappo, Mauricio and Kinouchi, Osame},
  date = {2022-03-01},
  journaltitle = {Chaos, Solitons \& Fractals},
  shortjournal = {Chaos, Solitons \& Fractals},
  volume = {156},
  pages = {111877},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2022.111877},
  url = {https://www.sciencedirect.com/science/article/pii/S0960077922000881},
  urldate = {2022-10-03},
  abstract = {In self-organized criticality (SOC) models, as well as in standard phase transitions, criticality is only present for vanishing external fields h→0. Considering that this is rarely the case for natural systems, such a restriction poses a challenge to the explanatory power of these models. Besides that, in models of dissipative systems like earthquakes, forest fires, and neuronal networks, there is no true critical behavior, as expressed in clean power laws obeying finite-size scaling, but a scenario called “dirty” criticality or self-organized quasi-criticality (SOqC). Here, we propose simple homeostatic mechanisms which promote self-organization of coupling strengths, gains, and firing thresholds in neuronal networks. We show that with an adequate separation of the timescales for the coupling strength and firing threshold dynamics, near criticality (SOqC) can be reached and sustained even in the presence of significant external input. The firing thresholds adapt to and cancel the inputs (h decreases towards zero). Similar mechanisms can be proposed for the couplings and local thresholds in spin systems and cellular automata, which could lead to applications in earthquake, forest fire, stellar flare, voting, and epidemic modeling.},
  langid = {english},
  keywords = {Adaptive networks,Homeostasis,Neuronal avalanches,Neuronal networks,Self-organization,Self-organized criticality,Synaptic depression},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6M6DL3UY\\Menesse et al. - 2022 - Homeostatic criticality in neuronal networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WPDHJ8HH\\S0960077922000881.html}
}

@article{mengualEfficientLowPassDendroSomatic2020,
  title = {Efficient {{Low-Pass Dendro-Somatic Coupling}} in the {{Apical Dendrite}} of {{Layer}} 5 {{Pyramidal Neurons}} in the {{Anterior Cingulate Cortex}}},
  author = {Mengual, Ulisses Marti and Wybo, Willem A. M. and Spierenburg, Lotte J. E. and Santello, Mirko and Senn, Walter and Nevian, Thomas},
  date = {2020-11-11},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {40},
  number = {46},
  eprint = {33046549},
  eprinttype = {pmid},
  pages = {8799--8815},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3028-19.2020},
  url = {https://www.jneurosci.org/content/40/46/8799},
  urldate = {2020-11-11},
  abstract = {Signal propagation in the dendrites of many neurons, including cortical pyramidal neurons in sensory cortex, is characterized by strong attenuation toward the soma. In contrast, using dual whole-cell recordings from the apical dendrite and soma of layer 5 (L5) pyramidal neurons in the anterior cingulate cortex (ACC) of adult male mice we found good coupling, particularly of slow subthreshold potentials like NMDA spikes or trains of EPSPs from dendrite to soma. Only the fastest EPSPs in the ACC were reduced to a similar degree as in primary somatosensory cortex, revealing differential low-pass filtering capabilities. Furthermore, L5 pyramidal neurons in the ACC did not exhibit dendritic Ca2+ spikes as prominently found in the apical dendrite of S1 (somatosensory cortex) pyramidal neurons. Fitting the experimental data to a NEURON model revealed that the specific distribution of Ileak, Iir, Im, and Ih was sufficient to explain the electrotonic dendritic structure causing a leaky distal dendritic compartment with correspondingly low input resistance and a compact perisomatic region, resulting in a decoupling of distal tuft branches from each other while at the same time efficiently connecting them to the soma. Our results give a biophysically plausible explanation of how a class of prefrontal cortical pyramidal neurons achieve efficient integration of subthreshold distal synaptic inputs compared with the same cell type in sensory cortices. SIGNIFICANCE STATEMENT Understanding cortical computation requires the understanding of its fundamental computational subunits. Layer 5 pyramidal neurons are the main output neurons of the cortex, integrating synaptic inputs across different cortical layers. Their elaborate dendritic tree receives, propagates, and transforms synaptic inputs into action potential output. We found good coupling of slow subthreshold potentials like NMDA spikes or trains of EPSPs from the distal apical dendrite to the soma in pyramidal neurons in the ACC, which was significantly better compared with S1. This suggests that frontal pyramidal neurons use a different integration scheme compared with the same cell type in somatosensory cortex, which has important implications for our understanding of information processing across different parts of the neocortex.},
  langid = {english},
  keywords = {anterior cingulate cortex,biophysical model,dendrite,electrical properties,NMDA spike,pyramidal neuron},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FHJDYBBD\\8799.html}
}

@article{miehlFormationComputationalImplications,
  title = {Formation and Computational Implications of Assemblies in Neural Circuits},
  author = {Miehl, Christoph and Onasch, Sebastian and Festa, Dylan and Gjorgjieva, Julijana},
  journaltitle = {The Journal of Physiology},
  volume = {n/a},
  number = {n/a},
  issn = {1469-7793},
  doi = {10.1113/JP282750},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/JP282750},
  urldate = {2022-09-28},
  abstract = {In the brain, patterns of neural activity represent sensory information and store it in non-random synaptic connectivity. A prominent theoretical hypothesis states that assemblies, groups of neurons that are strongly connected to each other, are the key computational units underlying perception and memory formation. Compatible with these hypothesised assemblies, experiments have revealed groups of neurons that display synchronous activity, either spontaneously or upon stimulus presentation, and exhibit behavioural relevance. While it remains unclear how assemblies form in the brain, theoretical work has vastly contributed to the understanding of various interacting mechanisms in this process. Here, we review the recent theoretical literature on assembly formation by categorising the involved mechanisms into four components: synaptic plasticity, symmetry breaking, competition and stability. We highlight different approaches and assumptions behind assembly formation and discuss recent ideas of assemblies as the key computational unit in the brain.},
  langid = {english},
  keywords = {assemblies,assembly,network model,neural circuits,pattern formation,symmetry breaking,synaptic plasticity},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1113/JP282750},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZHIC5L9H\\Miehl et al. - Formation and computational implications of assemb.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YLU6CK92\\JP282750.html}
}

@article{millanExplosiveHigherOrderKuramoto2020,
  title = {Explosive {{Higher-Order Kuramoto Dynamics}} on {{Simplicial Complexes}}},
  author = {Millán, Ana P. and Torres, Joaquín J. and Bianconi, Ginestra},
  date = {2020-05-27},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {124},
  number = {21},
  pages = {218301},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.124.218301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.218301},
  urldate = {2022-10-05},
  abstract = {The higher-order interactions of complex systems, such as the brain, are captured by their simplicial complex structure and have a significant effect on dynamics. However, the existing dynamical models defined on simplicial complexes make the strong assumption that the dynamics resides exclusively on the nodes. Here we formulate the higher-order Kuramoto model which describes the interactions between oscillators placed not only on nodes but also on links, triangles, and so on. We show that higher-order Kuramoto dynamics can lead to an explosive synchronization transition by using an adaptive coupling dependent on the solenoidal and the irrotational component of the dynamics.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CBD2X5ZU\\Millán et al. - 2020 - Explosive Higher-Order Kuramoto Dynamics on Simpli.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AFM6KACB\\PhysRevLett.124.html}
}

@misc{millidgePredictiveCodingTheoretical2022,
  title = {Predictive {{Coding}}: A {{Theoretical}} and {{Experimental Review}}},
  shorttitle = {Predictive {{Coding}}},
  author = {Millidge, Beren and Seth, Anil and Buckley, Christopher L.},
  date = {2022-07-12},
  number = {arXiv:2107.12979},
  eprint = {2107.12979},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2107.12979},
  urldate = {2022-12-12},
  abstract = {Predictive coding offers a potentially unifying account of cortical function -- postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. A large body of research has arisen based on both empirically testing improved and extended theoretical and mathematical models of predictive coding, as well as in evaluating their potential biological plausibility for implementation in the brain and the concrete neurophysiological and psychological predictions made by the theory. Despite this enduring popularity, however, no comprehensive review of predictive coding theory, and especially of recent developments in this field, exists. Here, we provide a comprehensive review both of the core mathematical structure and logic of predictive coding, thus complementing recent tutorials in the literature. We also review a wide range of classic and recent work within the framework, ranging from the neurobiologically realistic microcircuits that could implement predictive coding, to the close relationship between predictive coding and the widely-used backpropagation of error algorithm, as well as surveying the close relationships between predictive coding and modern machine learning techniques.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZIPQ6F5M\\Millidge et al. - 2022 - Predictive Coding a Theoretical and Experimental .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZQGP24D\\2107.html}
}

@article{milojkovicVoltageCalciumTransients2007,
  title = {Voltage and Calcium Transients in Basal Dendrites of the Rat Prefrontal Cortex},
  author = {Milojkovic, Bogdan A and Zhou, Wen-Liang and Antic, Srdjan D},
  date = {2007-12-01},
  journaltitle = {The Journal of Physiology},
  shortjournal = {J Physiol},
  volume = {585},
  eprint = {17932150},
  eprinttype = {pmid},
  pages = {447--468},
  issn = {0022-3751},
  doi = {10.1113/jphysiol.2007.142315},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2375496/},
  urldate = {2022-09-04},
  abstract = {Higher cortical functions (perception, cognition, learning and memory) are in large part based on the integration of electrical and calcium signals that takes place in thin dendritic branches of neocortical pyramidal cells (synaptic integration). The mechanisms underlying the synaptic integration in thin basal dendrites are largely unexplored. We use a recently developed technique, multisite voltage–calcium imaging, to compare voltage and calcium transients from multiple locations along individual dendritic branches. Our results reveal characteristic electrical transients (plateau potentials) that trigger and shape dendritic calcium dynamics and calcium distribution during suprathreshold glutamatergic synaptic input. We regularly observed three classes of voltage–calcium interactions occurring simultaneously in three different zones of the same dendritic branch: (1) proximal to the input site, (2) at the input site, and (3) distal to the input site. One hundred micrometers away from the synaptic input site, both proximally and distally, dendritic calcium transients are in tight temporal correlation with the dendritic plateau potential. However, on the same dendrite, at the location of excitatory input, calcium transients outlast local dendritic plateau potentials by severalfold. These Ca2+ plateaus (duration 0.5–2 s) are spatially restricted to the synaptic input site, where they cause a brief down-regulation of dendritic excitability. Ca2+ plateaus are not mediated by Ca2+ release from intracellular stores, but rather by an NMDA-dependent small-amplitude depolarization, which persists after the collapse of the dendritic plateau potential. These unique features of dendritic voltage and calcium distributions may provide distinct zones for simultaneous long-term (bidirectional) modulation of synaptic contacts along the same basal branch.},
  issue = {Pt 2},
  pmcid = {PMC2375496},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SJANQFB9\\Milojkovic et al. - 2007 - Voltage and calcium transients in basal dendrites .pdf}
}

@article{mitchellSpatialAttentionDecorrelates2009,
  title = {Spatial {{Attention Decorrelates Intrinsic Activity Fluctuations}} in {{Macaque Area V4}}},
  author = {Mitchell, Jude F. and Sundberg, Kristy A. and Reynolds, John H.},
  date = {2009-09-24},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {63},
  number = {6},
  eprint = {19778515},
  eprinttype = {pmid},
  pages = {879--888},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.09.013},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(09)00695-3},
  urldate = {2023-01-16},
  langid = {english},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4B9NKDV2\\Mitchell et al. - 2009 - Spatial Attention Decorrelates Intrinsic Activity .pdf}
}

@article{mlynarskiEfficientCodingTheory2022,
  title = {Efficient Coding Theory of Dynamic Attentional Modulation},
  author = {Młynarski, Wiktor and Tkačik, Gašper},
  date = {2022-12-21},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {20},
  number = {12},
  pages = {e3001889},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001889},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001889},
  urldate = {2022-12-23},
  abstract = {Activity of sensory neurons is driven not only by external stimuli but also by feedback signals from higher brain areas. Attention is one particularly important internal signal whose presumed role is to modulate sensory representations such that they only encode information currently relevant to the organism at minimal cost. This hypothesis has, however, not yet been expressed in a normative computational framework. Here, by building on normative principles of probabilistic inference and efficient coding, we developed a model of dynamic population coding in the visual cortex. By continuously adapting the sensory code to changing demands of the perceptual observer, an attention-like modulation emerges. This modulation can dramatically reduce the amount of neural activity without deteriorating the accuracy of task-specific inferences. Our results suggest that a range of seemingly disparate cortical phenomena such as intrinsic gain modulation, attention-related tuning modulation, and response variability could be manifestations of the same underlying principles, which combine efficient sensory coding with optimal probabilistic inference in dynamic environments.},
  langid = {english},
  keywords = {Attention,Coding mechanisms,Neuronal tuning,Neurons,Sensory neurons,Sensory perception,Vision,Visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7MLMZ978\\Młynarski and Tkačik - 2022 - Efficient coding theory of dynamic attentional mod.pdf}
}

@article{montangieAutonomousEmergenceConnectivity2020,
  title = {Autonomous Emergence of Connectivity Assemblies via Spike Triplet Interactions},
  author = {Montangie, Lisandro and Miehl, Christoph and Gjorgjieva, Julijana},
  date = {2020-05-08},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {16},
  number = {5},
  pages = {e1007835},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007835},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007835},
  urldate = {2022-09-30},
  abstract = {Non-random connectivity can emerge without structured external input driven by activity-dependent mechanisms of synaptic plasticity based on precise spiking patterns. Here we analyze the emergence of global structures in recurrent networks based on a triplet model of spike timing dependent plasticity (STDP), which depends on the interactions of three precisely-timed spikes, and can describe plasticity experiments with varying spike frequency better than the classical pair-based STDP rule. We derive synaptic changes arising from correlations up to third-order and describe them as the sum of structural motifs, which determine how any spike in the network influences a given synaptic connection through possible connectivity paths. This motif expansion framework reveals novel structural motifs under the triplet STDP rule, which support the formation of bidirectional connections and ultimately the spontaneous emergence of global network structure in the form of self-connected groups of neurons, or assemblies. We propose that under triplet STDP assembly structure can emerge without the need for externally patterned inputs or assuming a symmetric pair-based STDP rule common in previous studies. The emergence of non-random network structure under triplet STDP occurs through internally-generated higher-order correlations, which are ubiquitous in natural stimuli and neuronal spiking activity, and important for coding. We further demonstrate how neuromodulatory mechanisms that modulate the shape of the triplet STDP rule or the synaptic transmission function differentially promote structural motifs underlying the emergence of assemblies, and quantify the differences using graph theoretic measures.},
  langid = {english},
  keywords = {Action potentials,Clustering coefficients,Fourier analysis,Network motifs,Neural networks,Neuronal plasticity,Neurons,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YYU8ERIK\\Montangie et al. - 2020 - Autonomous emergence of connectivity assemblies vi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CNHXWIAD\\article.html}
}

@online{MoreDifferentScience,
  title = {More {{Is Different}} | {{Science}}},
  url = {https://www.science.org/doi/10.1126/science.177.4047.393},
  urldate = {2022-10-03}
}

@article{murakamiThreedimensionalSinglecellresolutionWholebrain2018,
  title = {A Three-Dimensional Single-Cell-Resolution Whole-Brain Atlas Using {{CUBIC-X}} Expansion Microscopy and Tissue Clearing},
  author = {Murakami, Tatsuya C. and Mano, Tomoyuki and Saikawa, Shu and Horiguchi, Shuhei A. and Shigeta, Daichi and Baba, Kousuke and Sekiya, Hiroshi and Shimizu, Yoshihiro and Tanaka, Kenji F. and Kiyonari, Hiroshi and Iino, Masamitsu and Mochizuki, Hideki and Tainaka, Kazuki and Ueda, Hiroki R.},
  date = {2018-04},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {4},
  pages = {625--637},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-018-0109-1},
  url = {http://www.nature.com/articles/s41593-018-0109-1},
  urldate = {2020-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YRT4C5FC\\Murakami et al. - 2018 - A three-dimensional single-cell-resolution whole-b.pdf}
}

@article{nagaiHyperactivityDisruptedAttention2019,
  title = {Hyperactivity with {{Disrupted Attention}} by {{Activation}} of an {{Astrocyte Synaptogenic Cue}}},
  author = {Nagai, Jun and Rajbhandari, Abha K. and Gangwani, Mohitkumar R. and Hachisuka, Ayaka and Coppola, Giovanni and Masmanidis, Sotiris C. and Fanselow, Michael S. and Khakh, Baljit S.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31031006},
  eprinttype = {pmid},
  pages = {1280-1292.e20},
  publisher = {{Elsevier}},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.03.019},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30281-8},
  urldate = {2020-11-19},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Hyperactivity and disturbances of attention are common behavioral disorders whose underlying cellular and neural circuit causes are not understood. We report the discovery that striatal astrocytes drive such phenotypes through a hitherto unknown synaptic mechanism. We found that striatal medium spiny neurons (MSNs) triggered astrocyte signaling via γ-aminobutyric acid B (GABA\textsubscript{B}) receptors. Selective chemogenetic activation of this pathway in striatal astrocytes \emph{in vivo} resulted in acute behavioral hyperactivity and disrupted attention. Such responses also resulted in upregulation of the synaptogenic cue thrombospondin-1 (TSP1) in astrocytes, increased excitatory synapses, enhanced corticostriatal synaptic transmission, and increased MSN action potential firing \emph{in vivo}. All of these changes were reversed by blocking TSP1 effects. Our data identify a form of bidirectional neuron-astrocyte communication and demonstrate that acute reactivation of a single latent astrocyte synaptogenic cue alters striatal circuits controlling behavior, revealing astrocytes and the TSP1 pathway as therapeutic targets in hyperactivity, attention deficit, and related psychiatric disorders.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QL43PTNP\\Nagai et al. - 2019 - Hyperactivity with Disrupted Attention by Activati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EIJG9CWV\\S0092-8674(19)30281-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J9QEMWAI\\S0092-8674(19)30281-8.html}
}

@article{naglerImpactSingleLinks2011,
  title = {Impact of Single Links in Competitive Percolation},
  author = {Nagler, Jan and Levina, Anna and Timme, Marc},
  date = {2011-03},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {7},
  number = {3},
  pages = {265--270},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys1860},
  url = {https://www.nature.com/articles/nphys1860},
  urldate = {2022-10-01},
  abstract = {How a complex network is connected crucially impacts its dynamics and function. Percolation, the transition to extensive connectedness on gradual addition of links, was long believed to be continuous, but recent numerical evidence of ‘explosive percolation’ suggests that it might also be discontinuous if links compete for addition. Here we analyse the microscopic mechanisms underlying discontinuous percolation processes and reveal a strong impact of single-link additions. We show that in generic competitive percolation processes, including those showing explosive percolation, single links do not induce a discontinuous gap in the largest cluster size in the thermodynamic limit. Nevertheless, our results highlight that for large finite systems single links may still induce substantial gaps, because gap sizes scale weakly algebraically with system size. Several essentially macroscopic clusters coexist immediately before the transition, announcing discontinuous percolation. These results explain how single links may drastically change macroscopic connectivity in networks where links add competitively.},
  issue = {3},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Y3TTQWLS\\Nagler et al. - 2011 - Impact of single links in competitive percolation.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NLFW9HBM\\nphys1860.html}
}

@article{nandyLaminarOrganizationAttentional2017,
  title = {Laminar {{Organization}} of {{Attentional Modulation}} in {{Macaque Visual Area V4}}},
  author = {Nandy, Anirvan S. and Nassi, Jonathan J. and Reynolds, John H.},
  date = {2017-01-04},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {1},
  eprint = {27989456},
  eprinttype = {pmid},
  pages = {235--246},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2016.11.029},
  abstract = {Attention is critical to perception, serving to select behaviorally relevant information for privileged processing. To understand the neural mechanisms of attention, we must discern how attentional modulation varies by cell type and across cortical layers. Here, we test whether attention acts non-selectively across cortical layers or whether it engages the laminar circuit in specific and selective ways. We find layer- and cell-class-specific differences in several different forms of attentional modulation in area V4. Broad-spiking neurons in the superficial layers exhibit attention-mediated increases in firing rate and decreases in variability. Spike count correlations are highest in the input layer and attention serves to reduce these correlations. Superficial and input layer neurons exhibit attention-dependent decreases in low-frequency ({$<$}10~Hz) coherence, but deep layer neurons exhibit increases in coherence in the beta and gamma frequency ranges. Our study provides a template for attention-mediated laminar information processing that might be applicable across sensory modalities.},
  langid = {english},
  pmcid = {PMC5217483},
  keywords = {Animals,area V4,attention,Attention,Brain Waves,laminar circuit,Macaca mulatta,Neurons,Visual Cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2T79HJHX\\Nandy et al. - 2017 - Laminar Organization of Attentional Modulation in .pdf}
}

@article{naudNoiseGatedDendrosomatic2017,
  title = {Noise {{Gated}} by {{Dendrosomatic Interactions Increases Information Transmission}}},
  author = {Naud, Richard and Payeur, Alexandre and Longtin, André},
  date = {2017-09-13},
  journaltitle = {Physical Review X},
  shortjournal = {Phys. Rev. X},
  volume = {7},
  number = {3},
  pages = {031045},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.7.031045},
  url = {https://link.aps.org/doi/10.1103/PhysRevX.7.031045},
  urldate = {2022-09-21},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GKLW9AKX\\Naud et al. - 2017 - Noise Gated by Dendrosomatic Interactions Increase.pdf}
}

@article{naudSparseBurstsOptimize2018,
  title = {Sparse Bursts Optimize Information Transmission in a Multiplexed Neural Code},
  author = {Naud, Richard and Sprekeler, Henning},
  date = {2018-07-03},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {115},
  number = {27},
  eprint = {29934400},
  eprinttype = {pmid},
  pages = {E6329-E6338},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1720995115},
  url = {https://www.pnas.org/content/115/27/E6329},
  urldate = {2020-08-25},
  abstract = {Many cortical neurons combine the information ascending and descending the cortical hierarchy. In the classical view, this information is combined nonlinearly to give rise to a single firing-rate output, which collapses all input streams into one. We analyze the extent to which neurons can simultaneously represent multiple input streams by using a code that distinguishes spike timing patterns at the level of a neural ensemble. Using computational simulations constrained by experimental data, we show that cortical neurons are well suited to generate such multiplexing. Interestingly, this neural code maximizes information for short and sparse bursts, a regime consistent with in vivo recordings. Neurons can also demultiplex this information, using specific connectivity patterns. The anatomy of the adult mammalian cortex suggests that these connectivity patterns are used by the nervous system to maintain sparse bursting and optimal multiplexing. Contrary to firing-rate coding, our findings indicate that the physiology and anatomy of the cortex may be interpreted as optimizing the transmission of multiple independent signals to different targets.},
  langid = {english},
  keywords = {cerebral cortex,dendritic computation,multiplexing,neural coding,short-term plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\OneDrive - University of Ottawa\\Research Paper Notes\\Notes_BurstEnsembleMultiplexing_NuadSprekeler.docx;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JTWG4V7X\\Naud and Sprekeler - 2018 - Sparse bursts optimize information transmission in.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6RKQU5B\\BEM_Supplemental.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DFQ65QTH\\E6329.html}
}

@article{naudSpiketimingPredictionCortical2014,
  title = {Spike-Timing Prediction in Cortical Neurons with Active Dendrites},
  author = {Naud, Richard and Bathellier, Brice and Gerstner, Wulfram},
  date = {2014-08-13},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front Comput Neurosci},
  volume = {8},
  eprint = {25165443},
  eprinttype = {pmid},
  issn = {1662-5188},
  doi = {10.3389/fncom.2014.00090},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4131408/},
  urldate = {2020-09-05},
  abstract = {A complete single-neuron model must correctly reproduce the firing of spikes and bursts. We present a study of a simplified model of deep pyramidal cells of the cortex with active dendrites. We hypothesized that we can model the soma and its apical dendrite with only two compartments, without significant loss in the accuracy of spike-timing predictions. The model is based on experimentally measurable impulse-response functions, which transfer the effect of current injected in one compartment to current reaching the other. Each compartment was modeled with a pair of non-linear differential equations and a small number of parameters that approximate the Hodgkin-and-Huxley equations. The predictive power of this model was tested on electrophysiological experiments where noisy current was injected in both the soma and the apical dendrite simultaneously. We conclude that a simple two-compartment model can predict spike times of pyramidal cells stimulated in the soma and dendrites simultaneously. Our results support that regenerating activity in the apical dendritic is required to properly account for the dynamics of layer 5 pyramidal cells under in-vivo-like conditions.},
  pmcid = {PMC4131408},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5NAATHCA\\Naud et al. - 2014 - Spike-timing prediction in cortical neurons with a.pdf}
}

@report{naudTernaryNeuralCode2022,
  type = {preprint},
  title = {A Ternary Neural Code Resolves Error and Sharpening Signals},
  author = {Naud, Richard and Wang, Xingyun and Friedenberger, Zachary and Payeur, Alexandre and Shin, Jiyun N. and Béïque, Jean-Claude and Richards, Blake A. and Drüke, Moritz and Larkum, Matthew E. and Doron, Guy},
  date = {2022-10-07},
  institution = {{Neuroscience}},
  doi = {10.1101/2022.10.07.511138},
  url = {http://biorxiv.org/lookup/doi/10.1101/2022.10.07.511138},
  urldate = {2022-12-28},
  abstract = {Theories of attention and learning have hypothesized a central role for high-frequency bursting in cognitive functions, but experimental reports of burstmediated representations in vivo have been limited. Here we used a novel demultiplexing approach to separate independent streams of information from considering neurons as having three possible states: silent, singlet- and burst-firing. We studied this ternary neural code in vivo while animals learned to behaviorally report direct electrical stimulation of the somatosensory cortex and found two acquired yet independent representations. One code, the event rate, represented the stimulus in a small fraction of cells and showed a small modulation upon detection errors. The other code, the burst fraction, correlated more globally with stimulation and more promptly responded to detection errors. Bursting modulation was potent and its time course evolved, even in cells that were considered unresponsive based on the firing rate. During the later stages of training, this modulation in bursting happened earlier, gradually aligning temporally with the representation in event rate. The alignment of bursting and event rate modulation sharpened firing rate coded representations, and was strongly associated behavioral accuracy. Thus a fine grain separation of spike timing patterns reveals two signals that accompany stimulus representations: an error signal that can be essential to guide learning and a sharpening signal that could enact top-down attention.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Q4DNEIPU\\Naud et al. - 2022 - A ternary neural code resolves error and sharpenin.pdf}
}

@article{newmanPowerLawsPareto2005,
  title = {Power Laws, {{Pareto}} Distributions and {{Zipf}}'s Law},
  author = {Newman, Mej},
  date = {2005-09},
  journaltitle = {Contemporary Physics},
  shortjournal = {Contemporary Physics},
  volume = {46},
  number = {5},
  pages = {323--351},
  issn = {0010-7514, 1366-5812},
  doi = {10.1080/00107510500052444},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00107510500052444},
  urldate = {2022-10-03},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QVUXQUJK\\Newman - 2005 - Power laws, Pareto distributions and Zipf's law.pdf}
}

@online{NextLevelNeuromorphicComputing,
  title = {Next-{{Level Neuromorphic Computing}}: {{Intel Lab}}'s {{Loihi}} 2 {{Chip}}},
  shorttitle = {Next-{{Level Neuromorphic Computing}}},
  url = {https://www.intel.com/content/www/us/en/research/neuromorphic-computing-loihi-2-technology-brief.html},
  urldate = {2022-10-26},
  abstract = {Intel Lab’s Loihi 2 chip delivers outstanding performance \& new features, including an open-source, community-driven neuromorphic computing framework.},
  langid = {english},
  organization = {{Intel}},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3YYCCDHV\\neuromorphic-computing-loihi-2-technology-brief.html}
}

@article{niLearningAttentionReveal2018,
  title = {✅  {{Learning}} and Attention Reveal a General Relationship between Population Activity and Behavior},
  author = {Ni, A. M. and Ruff, D. A. and Alberts, J. J. and Symmonds, J. and Cohen, M. R.},
  date = {2018-01-26},
  journaltitle = {Science},
  volume = {359},
  number = {6374},
  pages = {463--465},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aao0284},
  url = {https://www.science.org/doi/abs/10.1126/science.aao0284},
  urldate = {2022-12-19},
  abstract = {Prior studies have demonstrated that correlated variability changes with cognitive processes that improve perceptual performance. We tested whether correlated variability covaries with subjects’ performance—whether performance improves quickly with attention or slowly with perceptual learning. We found a single, consistent relationship between correlated variability and behavioral performance, regardless of the time frame of correlated variability change. This correlated variability was oriented along the dimensions in population space used by the animal on a trial-by-trial basis to make decisions. That subjects’ choices were predicted by specific dimensions that were aligned with the correlated variability axis clarifies long-standing paradoxes about the relationship between shared variability and behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QL8LQ3PA\\Ni et al. - 2018 - Learning and attention reveal a general relationsh.pdf}
}

@article{ockerSelfOrganizationMicrocircuitsNetworks2015,
  title = {Self-{{Organization}} of {{Microcircuits}} in {{Networks}} of {{Spiking Neurons}} with {{Plastic Synapses}}},
  author = {Ocker, Gabriel Koch and Litwin-Kumar, Ashok and Doiron, Brent},
  date = {2015-08-20},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {11},
  number = {8},
  pages = {e1004458},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004458},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004458},
  urldate = {2022-09-30},
  abstract = {The synaptic connectivity of cortical networks features an overrepresentation of certain wiring motifs compared to simple random-network models. This structure is shaped, in part, by synaptic plasticity that promotes or suppresses connections between neurons depending on their joint spiking activity. Frequently, theoretical studies focus on how feedforward inputs drive plasticity to create this network structure. We study the complementary scenario of self-organized structure in a recurrent network, with spike timing-dependent plasticity driven by spontaneous dynamics. We develop a self-consistent theory for the evolution of network structure by combining fast spiking covariance with a slow evolution of synaptic weights. Through a finite-size expansion of network dynamics we obtain a low-dimensional set of nonlinear differential equations for the evolution of two-synapse connectivity motifs. With this theory in hand, we explore how the form of the plasticity rule drives the evolution of microcircuits in cortical networks. When potentiation and depression are in approximate balance, synaptic dynamics depend on weighted divergent, convergent, and chain motifs. For additive, Hebbian STDP these motif interactions create instabilities in synaptic dynamics that either promote or suppress the initial network structure. Our work provides a consistent theoretical framework for studying how spiking activity in recurrent networks interacts with synaptic plasticity to determine network structure.},
  langid = {english},
  keywords = {Action potentials,Covariance,Network motifs,Neural networks,Neuronal plasticity,Neurons,Synapses,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\44JAQDKB\\Ocker et al. - 2015 - Self-Organization of Microcircuits in Networks of .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FX9AXXTW\\article.html}
}

@article{ockerTrainingSpontaneousReinforcement2019,
  title = {Training and {{Spontaneous Reinforcement}} of {{Neuronal Assemblies}} by {{Spike Timing Plasticity}}},
  author = {Ocker, Gabriel Koch and Doiron, Brent},
  date = {2019-03-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {29},
  number = {3},
  pages = {937--951},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhy001},
  url = {https://doi.org/10.1093/cercor/bhy001},
  urldate = {2022-09-30},
  abstract = {The synaptic connectivity of cortex is plastic, with experience shaping the ongoing interactions between neurons. Theoretical studies of spike timing-dependent plasticity (STDP) have focused on either just pairs of neurons or large-scale simulations. A simple analytic account for how fast spike time correlations affect both microscopic and macroscopic network structure is lacking. We develop a low-dimensional mean field theory for STDP in recurrent networks and show the emergence of assemblies of strongly coupled neurons with shared stimulus preferences. After training, this connectivity is actively reinforced by spike train correlations during the spontaneous dynamics. Furthermore, the stimulus coding by cell assemblies is actively maintained by these internally generated spiking correlations, suggesting a new role for noise correlations in neural coding. Assembly formation has often been associated with firing rate-based plasticity schemes; our theory provides an alternative and complementary framework, where fine temporal correlations and STDP form and actively maintain learned structure in cortical networks.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QC2JAK6C\\Ocker and Doiron - 2019 - Training and Spontaneous Reinforcement of Neuronal.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\L3QTM8K5\\4836778.html}
}

@article{onagaBurstingTransitionLinear2014,
  title = {Bursting Transition in a Linear Self-Exciting Point Process},
  author = {Onaga, Tomokatsu and Shinomoto, Shigeru},
  date = {2014-04-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {89},
  number = {4},
  pages = {042817},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.89.042817},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.89.042817},
  urldate = {2022-10-26},
  abstract = {Self-exciting point processes describe the manner in which every event facilitates the occurrence of succeeding events, as in the case of epidemics or human activity. By increasing excitability, the event occurrences start to exhibit bursts even in the absence of external stimuli. We revealed that the transition is uniquely determined by the average number of events added by a single event, 1−1/√2≈0.2929, independently of the temporal excitation profile. We further extended the theory to multidimensional processes, to be able to incite or inhibit bursting in networks of agents by altering their connections.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCCB8TUW\\Onaga and Shinomoto - 2014 - Bursting transition in a linear self-exciting poin.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ESHW23XP\\PhysRevE.89.html}
}

@article{onoratoDistinctClassBursting2020,
  title = {A Distinct Class of Bursting Neurons with Strong Gamma Synchronization and Stimulus Selectivity in Monkey {{V1}}},
  author = {Onorato, Irene and Neuenschwander, Sergio and Hoy, Jennifer and Lima, Bruss and Rocha, Katia-Simone and Broggini, Ana Clara and Uran, Cem and Spyropoulos, Georgios and Klon-Lipok, Johanna and Womelsdorf, Thilo},
  date = {2020},
  journaltitle = {Neuron},
  volume = {105},
  number = {1},
  pages = {180--197},
  publisher = {{Elsevier}}
}

@article{onoratoDistinctClassBursting2020a,
  title = {A {{Distinct Class}} of {{Bursting Neurons}} with {{Strong Gamma Synchronization}} and {{Stimulus Selectivity}} in {{Monkey V1}}},
  author = {Onorato, Irene and Neuenschwander, Sergio and Hoy, Jennifer and Lima, Bruss and Rocha, Katia-Simone and Broggini, Ana Clara and Uran, Cem and Spyropoulos, Georgios and Klon-Lipok, Johanna and Womelsdorf, Thilo and Fries, Pascal and Niell, Cristopher and Singer, Wolf and Vinck, Martin},
  date = {2020-01-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {105},
  number = {1},
  pages = {180-197.e5},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.09.039},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319308426},
  urldate = {2023-01-17},
  abstract = {Cortical computation depends on interactions between excitatory and inhibitory neurons. The contributions of distinct neuron types to sensory processing and network synchronization in primate visual cortex remain largely undetermined. We show that in awake monkey V1, there exists a distinct cell type (››30\% of neurons) that has narrow-waveform (NW) action potentials and high spontaneous discharge rates and fires in high-frequency bursts. These neurons are more stimulus selective and phase locked to 30- to 80-Hz gamma oscillations than other neuron types. Unlike other neuron types, their gamma-phase locking is highly predictive of~orientation tuning. We find evidence for strong rhythmic inhibition in these neurons, suggesting that they interact with interneurons to act as excitatory pacemakers for the V1 gamma rhythm. We did not find a similar class of NW bursting neurons in L2-L4 of mouse V1. Given its properties, this class of NW bursting neurons should be pivotal for the encoding and transmission of stimulus information.},
  langid = {english},
  keywords = {bursting,cell class,cell type,excitatory,gamma,interneuron,orientation tuning,oscillation,synchronization,V1},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J9EVQNCV\\Onorato et al. - 2020 - A Distinct Class of Bursting Neurons with Strong G.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NU9EQFLV\\S0896627319308426.html}
}

@article{orbanNeuralVariabilitySamplingBased2016,
  title = {Neural {{Variability}} and {{Sampling-Based Probabilistic Representations}} in the {{Visual Cortex}}},
  author = {Orbán, Gergő and Berkes, Pietro and Fiser, József and Lengyel, Máté},
  date = {2016-10-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {92},
  number = {2},
  pages = {530--543},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.09.038},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627316306390},
  urldate = {2022-10-18},
  abstract = {Neural responses in the visual cortex are variable, and there is now an abundance of data characterizing how the magnitude and structure of this variability depends on the stimulus. Current theories of cortical computation fail to account for these data; they either ignore variability altogether or only model its unstructured Poisson-like aspects. We develop a theory in which the cortex performs probabilistic inference such that population activity patterns represent statistical samples from the inferred probability distribution. Our main prediction is that perceptual uncertainty is directly encoded by the variability, rather than the average, of cortical responses. Through direct comparisons to previously published data as well as original data analyses, we show that a sampling-based probabilistic representation accounts for the structure of noise, signal, and spontaneous response variability and correlations in the primary visual cortex. These results suggest a novel role for neural variability in cortical dynamics and computations.},
  langid = {english},
  keywords = {Bayesian computations,natural images,noise correlations,normative model,spontaneous activity,stochastic sampling,theory,V1,variability,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AUBIUFM2\\Orbán et al. - 2016 - Neural Variability and Sampling-Based Probabilisti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TPFG8XFD\\S0896627316306390.html}
}

@article{osatOptimalPercolationMultiplex2017,
  title = {Optimal Percolation on Multiplex Networks},
  author = {Osat, Saeed and Faqeeh, Ali and Radicchi, Filippo},
  date = {2017-11-16},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {1540},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01442-2},
  url = {https://www.nature.com/articles/s41467-017-01442-2},
  urldate = {2022-10-06},
  abstract = {Optimal percolation is the problem of finding the minimal set of nodes whose removal from a network fragments the system into non-extensive disconnected clusters. The solution to this problem is important for strategies of immunization in disease spreading, and influence maximization in opinion dynamics. Optimal percolation has received considerable attention in the context of isolated networks. However, its generalization to multiplex networks has not yet been considered. Here we show that approximating the solution of the optimal percolation problem on a multiplex network with solutions valid for single-layer networks extracted from the multiplex may have serious consequences in the characterization of the true robustness of the system. We reach this conclusion by extending many of the methods for finding approximate solutions of the optimal percolation problem from single-layer to multiplex networks, and performing a systematic analysis on synthetic and real-world multiplex networks.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Phase transitions and critical phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EVPH2CKG\\Osat et al. - 2017 - Optimal percolation on multiplex networks.pdf}
}

@incollection{pachitariuFastAccurateSpike2016,
  title = {Fast and Accurate Spike Sorting of High-Channel Count Probes with {{KiloSort}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  author = {Pachitariu, Marius and Steinmetz, Nicholas A and Kadir, Shabnam N and Carandini, Matteo and Harris, Kenneth D},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  date = {2016},
  pages = {4448--4456},
  publisher = {{Curran Associates, Inc.}},
  url = {http://papers.nips.cc/paper/6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.pdf},
  urldate = {2020-10-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJBHFKT6\\Pachitariu et al. - 2016 - Fast and accurate spike sorting of high-channel co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HN68L2G4\\6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.html}
}

@article{palmerNMDASpikesEnhance2014,
  title = {{{NMDA}} Spikes Enhance Action Potential Generation during Sensory Input},
  author = {Palmer, Lucy M. and Shai, Adam S. and Reeve, James E. and Anderson, Harry L. and Paulsen, Ole and Larkum, Matthew E.},
  date = {2014-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {3},
  pages = {383--390},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3646},
  url = {https://www.nature.com/articles/nn.3646},
  urldate = {2022-09-04},
  abstract = {In vitro evidence suggests that the tuft dendrites of pyramidal neurons can evoke local NMDA spikes. The authors find that these local NMDA spikes occur spontaneously and following sensory input, and influence the number of output action potentials.},
  issue = {3},
  langid = {english},
  keywords = {Cellular neuroscience,Dendritic excitability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FZIBQNTR\\Palmer et al. - 2014 - NMDA spikes enhance action potential generation du.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2LGQI8DY\\nn.html}
}

@article{panzeriStructuresFunctionsCorrelations2022,
  title = {The Structures and Functions of Correlations in Neural Population Codes},
  author = {Panzeri, Stefano and Moroni, Monica and Safaai, Houman and Harvey, Christopher D.},
  date = {2022-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {23},
  number = {9},
  pages = {551--567},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00606-4},
  url = {https://www.nature.com/articles/s41583-022-00606-4},
  urldate = {2022-10-05},
  abstract = {The collective activity of a population of neurons, beyond the properties of individual cells, is crucial for many brain functions. A fundamental question is how activity correlations between neurons affect how neural populations process information. Over the past 30 years, major progress has been made on how the levels and structures of correlations shape the encoding of information in population codes. Correlations influence population coding through the organization of pairwise-activity correlations with respect to the similarity of tuning of individual neurons, by their stimulus modulation and by the presence of higher-order correlations. Recent work has shown that correlations also profoundly shape other important functions performed by neural populations, including generating codes across multiple timescales and facilitating information transmission to, and readout by, downstream brain areas to guide behaviour. Here, we review this recent work and discuss how the structures of correlations can have opposite effects on the different functions of neural populations, thus creating trade-offs and constraints for the structure–function relationships of population codes. Further, we present ideas on how to combine large-scale simultaneous recordings of neural populations, computational models, analyses of behaviour, optogenetics and anatomy to unravel how the structures of correlations might be optimized to serve multiple functions.},
  issue = {9},
  langid = {english},
  keywords = {Neural decoding,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YH9MYXEJ\\Panzeri et al. - 2022 - The structures and functions of correlations in ne.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8UKVUZGD\\s41583-022-00606-4.html}
}

@article{pardiThalamocorticalTopdownCircuit2020,
  title = {A Thalamocortical Top-down Circuit for Associative Memory},
  author = {Pardi, M. Belén and Vogenstahl, Johanna and Dalmay, Tamas and Spanò, Teresa and Pu, De-Lin and Naumann, Laura B. and Kretschmer, Friedrich and Sprekeler, Henning and Letzkus, Johannes J.},
  date = {2020-11-13},
  journaltitle = {Science},
  volume = {370},
  number = {6518},
  eprint = {33184213},
  eprinttype = {pmid},
  pages = {844--848},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.abc2399},
  url = {https://science.sciencemag.org/content/370/6518/844},
  urldate = {2020-11-17},
  abstract = {Higher-order thalamus input to the cortex Sensory information can only be used meaningfully in the brain when integrated with and compared with internally generated top-down signals. However, we know little about the brainwide afferents that convey such top-down signals, their information content, and learning-related plasticity. Pardi et al. identified the higher-order thalamus as a major source of top-down input to mouse auditory cortex and investigated a circuit in cortical layer 1 that facilitates plastic changes and flexible responses. These results demonstrate how top-down feedback information can reach cortical areas through a noncortical structure that has received little attention despite its widespread connections with the cortex. Science, this issue p. 844 The sensory neocortex is a critical substrate for memory. Despite its strong connection with the thalamus, the role of direct thalamocortical communication in memory remains elusive. We performed chronic in vivo two-photon calcium imaging of thalamic synapses in mouse auditory cortex layer 1, a major locus of cortical associations. Combined with optogenetics, viral tracing, whole-cell recording, and computational modeling, we find that the higher-order thalamus is required for associative learning and transmits memory-related information that closely correlates with acquired behavioral relevance. In turn, these signals are tightly and dynamically controlled by local presynaptic inhibition. Our results not only identify the higher-order thalamus as a highly plastic source of cortical top-down information but also reveal a level of computational flexibility in layer 1 that goes far beyond hard-wired connectivity. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CTWAH3UM\\Pardi et al. - 2020 - A thalamocortical top-down circuit for associative.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7C8C24Q6\\844.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FA2FWMZJ\\844.html}
}

@report{parkBayesianEfficientCoding2017,
  type = {preprint},
  title = {Bayesian {{Efficient Coding}}},
  author = {Park, Il Memming and Pillow, Jonathan W.},
  date = {2017-08-22},
  institution = {{Neuroscience}},
  doi = {10.1101/178418},
  url = {http://biorxiv.org/lookup/doi/10.1101/178418},
  urldate = {2020-10-27},
  abstract = {The efficient coding hypothesis, which proposes that neurons are optimized to maximize information about the environment, has provided a guiding theoretical framework for sensory and systems neuroscience. More recently, a theory known as the Bayesian Brain hypothesis has focused on the brain’s ability to integrate sensory and prior sources of information in order to perform Bayesian inference. However, there is as yet no comprehensive theory connecting these two theoretical frameworks. We bridge this gap by formalizing a Bayesian theory of efficient coding. We define Bayesian efficient codes in terms of four basic ingredients: (1) a stimulus prior distribution; (2) an encoding model; (3) a capacity constraint, specifying a neural resource limit; and (4) a loss function, quantifying the desirability or undesirability of various posterior distributions. Classic efficient codes can be seen as a special case in which the loss function is the posterior entropy, leading to a code that maximizes mutual information, but alternate loss functions give solutions that differ dramatically from information-maximizing codes. In particular, we show that decorrelation of sensory inputs, which is optimal under classic efficient codes in low-noise settings, can be disadvantageous for loss functions that penalize large errors. Bayesian efficient coding therefore enlarges the family of normatively optimal codes and provides a more general framework for understanding the design principles of sensory systems. We examine Bayesian efficient codes for linear receptive fields and nonlinear input-output functions, and show that our theory invites reinterpretation of Laughlin’s seminal analysis of efficient coding in the blowfly visual system.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4MLSRRNP\\Park and Pillow - 2017 - Bayesian Efficient Coding.pdf}
}

@article{parkContributionApicalBasal2019,
  title = {Contribution of Apical and Basal Dendrites to Orientation Encoding in Mouse {{V1 L2}}/3 Pyramidal Neurons},
  author = {Park, Jiyoung and Papoutsi, Athanasia and Ash, Ryan T. and Marin, Miguel A. and Poirazi, Panayiota and Smirnakis, Stelios M.},
  date = {2019-11-26},
  journaltitle = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5372},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13029-0},
  url = {https://www.nature.com/articles/s41467-019-13029-0},
  urldate = {2020-10-20},
  abstract = {Pyramidal neurons integrate synaptic inputs from basal and apical dendrites to generate stimulus-specific responses. It has been proposed that feed-forward inputs to basal dendrites drive a neuron’s stimulus preference, while feedback inputs to apical dendrites sharpen selectivity. However, how a neuron’s dendritic domains relate to its functional selectivity has not been demonstrated experimentally. We performed 2-photon dendritic micro-dissection on layer-2/3 pyramidal neurons in mouse primary visual cortex. We found that removing the apical dendritic tuft did not alter orientation-tuning. Furthermore, orientation-tuning curves were remarkably robust to the removal of basal dendrites: ablation of 2 basal dendrites was needed to cause a small shift in orientation preference, without significantly altering tuning width. Computational modeling corroborated our results and put limits on how orientation preferences among basal dendrites differ in order to reproduce the post-ablation data. In conclusion, neuronal orientation-tuning appears remarkably robust to loss of dendritic input.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QJKJEM4W\\Park et al. - 2019 - Contribution of apical and basal dendrites to orie.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR34UK2M\\s41467-019-13029-0.html}
}

@article{parrondoThermodynamicsInformation2015,
  title = {Thermodynamics of Information},
  author = {Parrondo, Juan M. R. and Horowitz, Jordan M. and Sagawa, Takahiro},
  date = {2015-02},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {2},
  pages = {131--139},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys3230},
  url = {https://www.nature.com/articles/nphys3230},
  urldate = {2022-10-03},
  abstract = {By its very nature, the second law of thermodynamics is probabilistic, in that its formulation requires a probabilistic description of the state of a system. This raises questions about the objectivity of the second law: does it depend, for example, on what we know about the system? For over a century, much effort has been devoted to incorporating information into thermodynamics and assessing the entropic and energetic costs of manipulating information. More recently, this historically theoretical pursuit has become relevant in practical situations where information is manipulated at small scales, such as in molecular and cell biology, artificial nano-devices or quantum computation. Here we give an introduction to a novel theoretical framework for the thermodynamics of information based on stochastic thermodynamics and fluctuation theorems, review some recent experimental results, and present an overview of the state of the art in the field.},
  issue = {2},
  langid = {english},
  keywords = {Statistical physics,thermodynamics and nonlinear dynamics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NME93QIZ\\Parrondo et al. - 2015 - Thermodynamics of information.pdf}
}

@article{pavliotisSTOCHASTICPROCESSESAPPLICATIONS,
  title = {{{STOCHASTIC PROCESSES AND APPLICATIONS}}},
  author = {Pavliotis, G A},
  pages = {155},
  langid = {english},
  keywords = {Stochastic processes},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7Y9QSWS9\\Pavliotis - STOCHASTIC PROCESSES AND APPLICATIONS.pdf}
}

@report{payeurBurstdependentSynapticPlasticity2020,
  type = {preprint},
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  date = {2020-03-31},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.03.30.015511},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.03.30.015511},
  urldate = {2020-08-30},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well-established that it depends on pre and postsynaptic activity. However, models that rely solely on pre and postsynaptic activity for synaptic changes have, to date, not been able to account for learning complex tasks that demand hierarchical networks. Here, we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then neurons higher in the hierarchy can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites, and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses, and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LYLJ22WE\\Payeur et al. - 2020 - Burst-dependent synaptic plasticity can coordinate.pdf}
}

@article{payeurClassesDendriticInformation2019,
  title = {Classes of Dendritic Information Processing},
  author = {Payeur, Alexandre and Béïque, Jean-Claude and Naud, Richard},
  date = {2019-10},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {58},
  pages = {78--85},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.07.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818302162},
  urldate = {2020-10-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VCG2EM7P\\Payeur et al. - 2019 - Classes of dendritic information processing.pdf}
}

@article{pazziniNeuronalAvalanchesWattsStrogatz2021,
  title = {Neuronal Avalanches in {{Watts-Strogatz}} Networks of Stochastic Spiking Neurons},
  author = {Pazzini, Renata and Kinouchi, Osame and Costa, Ariadne A.},
  date = {2021-07-26},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {1},
  pages = {014137},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.104.014137},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.014137},
  urldate = {2022-10-01},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5YYICFYD\\Pazzini et al. - 2021 - Neuronal avalanches in Watts-Strogatz networks of .pdf}
}

@article{pazziniNeuronalAvalanchesWattsStrogatz2021a,
  title = {Neuronal Avalanches in {{Watts-Strogatz}} Networks of Stochastic Spiking Neurons},
  author = {Pazzini, Renata and Kinouchi, Osame and Costa, Ariadne A.},
  date = {2021-07-26},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {1},
  pages = {014137},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.104.014137},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.014137},
  urldate = {2022-10-01},
  abstract = {Networks of stochastic leaky integrate-and-fire neurons, both at the mean-field level and in square lattices, present a continuous absorbing phase transition with power-law neuronal avalanches at the critical point. Here we complement these results showing that small-world Watts-Strogatz networks have mean-field critical exponents for any rewiring probability p{$>$}0. For the ring (p=0), the exponents are the same from the dimension d=1 of the directed-percolation class. In the model, firings are stochastic and occur in discrete time steps, based on a sigmoidal firing probability function. Each neuron has a membrane potential that integrates the signals received from its neighbors. The membrane potentials are subject to a leakage parameter. We study topologies with a varied number of neuron connections and different values of the leakage parameter. Results indicate that the dynamic range is larger for p=0. We also study a homeostatic synaptic depression mechanism to self-organize the network towards the critical region. These stochastic oscillations are characteristic of the so-called self-organized quasicriticality.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TFDT4MUA\\PhysRevE.104.html}
}

@article{pedreschiTemporalRichClub2022,
  title = {The Temporal Rich Club Phenomenon},
  author = {Pedreschi, Nicola and Battaglia, Demian and Barrat, Alain},
  date = {2022-08},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {18},
  number = {8},
  pages = {931--938},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-022-01634-8},
  url = {https://www.nature.com/articles/s41567-022-01634-8},
  urldate = {2022-10-03},
  abstract = {Identifying the hidden organizational principles and relevant structures of complex networks is fundamental to understand their properties. To this end, uncovering the structures involving the prominent nodes in a network is an effective approach. In temporal networks, the simultaneity of connections is crucial for temporally stable structures to arise. Here, we propose a measure to quantitatively investigate the tendency of well-connected nodes to form simultaneous and stable structures in a temporal network. We refer to this tendency as the temporal rich club phenomenon, characterized by a coefficient defined as the maximal value of the density of links between nodes with a minimal required degree, which remain stable for a certain duration. We illustrate the use of this concept by analysing diverse data sets and their temporal properties, from the role of cohesive structures in relation to processes unfolding on top of the network to the study of specific moments of interest in the evolution of the network.},
  issue = {8},
  langid = {english},
  keywords = {Complex networks,Computational science,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CAQ32Q4D\\Pedreschi et al. - 2022 - The temporal rich club phenomenon.pdf}
}

@article{pereiraSleepingBrainExcitation2020,
  title = {Sleeping through Brain Excitation and Inhibition},
  author = {Pereira, Sofia I. R. and Lewis, Penelope A.},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1037--1039},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0697-4},
  url = {https://www.nature.com/articles/s41593-020-0697-4},
  urldate = {2020-11-21},
  abstract = {Sleep is controlled by a cocktail of neurotransmitters, but it is difficult to measure these in the brain. A new study by Tamaki et al. reveals how the balance between excitation and inhibition oscillates as the brain moves through sleep stages and how this impacts upon memory consolidation and stabilization.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\H2WSKIDR\\Pereira and Lewis - 2020 - Sleeping through brain excitation and inhibition.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EPJLDYWY\\s41593-020-0697-4.html}
}

@article{petriTopologicalLimitsParallel2021,
  title = {Topological Limits to the Parallel Processing Capability of Network Architectures},
  author = {Petri, Giovanni and Musslick, Sebastian and Dey, Biswadip and Özcimder, Kayhan and Turner, David and Ahmed, Nesreen K. and Willke, Theodore L. and Cohen, Jonathan D.},
  date = {2021-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {5},
  pages = {646--651},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01170-x},
  url = {https://www.nature.com/articles/s41567-021-01170-x},
  urldate = {2022-10-02},
  abstract = {The ability to learn new tasks and generalize to others is a remarkable characteristic of both human brains and recent artificial intelligence systems. The ability to perform multiple tasks simultaneously is also a key characteristic of parallel architectures, as is evident in the human brain and exploited in traditional parallel architectures. Here we show that these two characteristics reflect a fundamental tradeoff between interactive parallelism, which supports learning and generalization, and independent parallelism, which supports processing efficiency through concurrent multitasking. Although the maximum number of possible parallel tasks grows linearly with network size, under realistic scenarios their expected number grows sublinearly. Hence, even modest reliance on shared representations, which support learning and generalization, constrains the number of parallel tasks. This has profound consequences for understanding the human brain’s mix of sequential and parallel capabilities, as well as for the development of artificial intelligence systems that can optimally manage the tradeoff between learning and processing efficiency.},
  issue = {5},
  langid = {english},
  keywords = {Complex networks,Computational science,Information theory and computation,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CDGAD2EA\\Petri et al. - 2021 - Topological limits to the parallel processing capa.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RGLREJ2F\\s41567-021-01170-x.html}
}

@online{PhysicsBrainNetwork,
  title = {The Physics of Brain Network Structure, Function and Control | {{Nature Reviews Physics}}},
  url = {https://www.nature.com/articles/s42254-019-0040-8},
  urldate = {2022-10-03}
}

@online{PIIB978008045046901648XElsevier,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=AEB3F00B9ED104FD4F7E76606FE19588C21B83127810BF9F8C6E89BE1FCAE11CE6A6ABBA6EC91D454A1A3CDF6D25E6CB},
  urldate = {2020-10-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2B6LN9IY\\B978008045046901648X.html}
}

@online{PIIB978008045046901648XElseviera,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=14DC8ABDF47BDB43F752CBB1A87E260A22FE7927547DE250D49B496B9F9F47BEEB1A020E3297C1075FAAFF93B56178B3},
  urldate = {2020-10-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DLMW5R2M\\B978008045046901648X.html}
}

@article{poiraziIlluminatingDendriticFunction2020,
  title = {Illuminating Dendritic Function with Computational Models},
  author = {Poirazi, Panayiota and Papoutsi, Athanasia},
  date = {2020-06},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {6},
  pages = {303--321},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0301-7},
  url = {https://www.nature.com/articles/s41583-020-0301-7},
  urldate = {2020-09-17},
  abstract = {Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires — and drives — new technological advances, thus closing the loop with theory-driven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities.},
  issue = {6},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I6KH3YVI\\Poirazi and Papoutsi - 2020 - Illuminating dendritic function with computational.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NCYGZ98Z\\s41583-020-0301-7.html}
}

@article{poortLearningAttentionIncrease2022,
  title = {✅ {{Learning}} and Attention Increase Visual Response Selectivity through Distinct Mechanisms},
  author = {Poort, Jasper and Wilmes, Katharina A. and Blot, Antonin and Chadwick, Angus and Sahani, Maneesh and Clopath, Claudia and Mrsic-Flogel, Thomas D. and Hofer, Sonja B. and Khan, Adil G.},
  date = {2022-02-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {4},
  pages = {686-697.e6},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.11.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627321009545},
  urldate = {2022-12-23},
  abstract = {Selectivity of cortical neurons for sensory stimuli can increase across days as animals learn their behavioral relevance and across seconds when animals switch attention. While both phenomena occur in the same circuit, it is unknown whether they rely on similar mechanisms. We imaged primary visual cortex as mice learned a visual discrimination task and subsequently performed an attention switching task. Selectivity changes due to learning and attention were uncorrelated in individual neurons. Selectivity increases after learning mainly arose from selective suppression of responses to one of the stimuli but from selective enhancement and suppression during attention. Learning and attention differentially affected interactions between excitatory and PV, SOM, and VIP inhibitory cells. Circuit modeling revealed that cell class-specific top-down inputs best explained attentional modulation, while reorganization of local functional connectivity accounted for learning-related changes. Thus, distinct mechanisms underlie increased discriminability of relevant sensory stimuli across longer and shorter timescales.},
  langid = {english},
  keywords = {attention,GABAergic interneurons,learning,neural circuits,plasticity,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Q44AHZ78\\Poort et al. - 2022 - Learning and attention increase visual response se.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZN2V47JY\\S0896627321009545.html}
}

@article{popovkinaTaskContextModulates2022,
  title = {Task {{Context Modulates Feature-Selective Responses}} in {{Area V4}}},
  author = {Popovkina, Dina V. and Pasupathy, Anitha},
  date = {2022-08-17},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {42},
  number = {33},
  eprint = {35840322},
  eprinttype = {pmid},
  pages = {6408--6423},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1386-21.2022},
  url = {https://www.jneurosci.org/content/42/33/6408},
  urldate = {2023-01-16},
  abstract = {Feature selectivity of visual cortical responses measured during passive fixation provides only a partial view of selectivity because it does not account for the influence of cognitive factors. Here we focus on primate area V4 and ask how neuronal tuning is modulated by task engagement. We investigated whether responses to colored shapes during active shape discrimination are simple, stimulus-agnostic, scaled versions of responses during passive fixation, akin to results from attentional studies. Alternatively, responses could be subject to stimulus-specific scaling, that is, responses to different stimuli are modulated differently, resulting in changes in underlying shape/color selectivity. Among 83 well-isolated V4 neurons in two male macaques, only a minority (16 of 83), which were weakly tuned to both shape and color, displayed responses during fixation and discrimination tasks that could be related by stimulus-agnostic scaling. The majority (67 of 83), which were strongly tuned to shape, color, or both, displayed stimulus-dependent response changes during discrimination. For some of these neurons (39 of 83), the shape or color of the stimulus dictated the magnitude of the change, and for others (28 of 83) it was the combination of stimulus shape and color. Importantly, for neurons with one strong and one weak tuning dimension, stimulus-dependent response changes during discrimination were associated with a relative increase in selectivity along the stronger tuning dimension, without changes in tuning peak. These results reveal that more strongly tuned V4 neurons may also be more flexible in their selectivity, and imbalances in selectivity are amplified during active task contexts. SIGNIFICANCE STATEMENT Tuning for stimulus features is typically characterized by recording responses during passive fixation, but cognitive factors, including attention, influence responses in visual cortex. To determine how behavioral engagement influences neuronal responses in area V4, we compared responses to colored shapes during passive fixation and active behavior. For a large fraction of neurons, differences in responses between passive fixation and active behavior depended on the identity of the visual stimulus. For a subgroup of strongly feature-selective neurons, this response modulation was associated with enhanced selectivity for one feature at the expense of selectivity for the other. Such flexibility in tuning strength could improve performance in tasks requiring active judgment of stimuli.},
  langid = {english},
  keywords = {behavioral modulation,feature tuning,primate area V4,selectivity change,stimulus identity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DEN2DXSY\\Popovkina and Pasupathy - 2022 - Task Context Modulates Feature-Selective Responses.pdf}
}

@article{postnovaSleepModellingPhysiological2019,
  title = {Sleep {{Modelling}} across {{Physiological Levels}}},
  author = {Postnova, Svetlana},
  date = {2019-03},
  journaltitle = {Clocks \& Sleep},
  volume = {1},
  number = {1},
  pages = {166--184},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/clockssleep1010015},
  url = {https://www.mdpi.com/2624-5175/1/1/15},
  urldate = {2020-11-20},
  abstract = {Sleep and circadian rhythms are regulated across multiple functional, spatial and temporal levels: from genes to networks of coupled neurons and glial cells, to large scale brain dynamics and behaviour. The dynamics at each of these levels are complex and the interaction between the levels is even more so, so research have mostly focused on interactions within the levels to understand the underlying mechanisms\&mdash;the so-called reductionist approach. Mathematical models were developed to test theories of sleep regulation and guide new experiments at each of these levels and have become an integral part of the field. The advantage of modelling, however, is that it allows us to simulate and test the dynamics of complex biological systems and thus provides a tool to investigate the connections between the different levels and study the system as a whole. In this paper I review key models of sleep developed at different physiological levels and discuss the potential for an integrated systems biology approach for sleep regulation across these levels. I also highlight the necessity of building mechanistic connections between models of sleep and circadian rhythms across these levels.},
  issue = {1},
  langid = {english},
  keywords = {behaviour,circadian clocks,EEG,mathematical modelling,mean field,molecular mechanisms,multi-scale,neurons,sleep,systems biology},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6FZZQ2G\\Postnova - 2019 - Sleep Modelling across Physiological Levels.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U7C9SQC\\15.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9V3LXKLZ\\15.html}
}

@online{PrefrontalCortexExhibits,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making | {{Nature Neuroscience}}},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2021-02-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C89LMXCN\\s41593-020-0696-5.html}
}

@article{priceBayesianSyntheticLikelihood2018,
  title = {Bayesian {{Synthetic Likelihood}}},
  author = {Price, L. F. and Drovandi, C. C. and Lee, A. and Nott, D. J.},
  date = {2018-01-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {27},
  number = {1},
  pages = {1--11},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1302882},
  url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1302882},
  urldate = {2020-10-26},
  abstract = {Having the ability to work with complex models can be highly beneficial. However, complex models often have intractable likelihoods, so methods that involve evaluation of the likelihood function are infeasible. In these situations, the benefits of working with likelihood-free methods become apparent. Likelihood-free methods, such as parametric Bayesian indirect likelihood that uses the likelihood of an alternative parametric auxiliary model, have been explored throughout the literature as a viable alternative when the model of interest is complex. One of these methods is called the synthetic likelihood (SL), which uses a multivariate normal approximation of the distribution of a set of summary statistics. This article explores the accuracy and computational efficiency of the Bayesian version of the synthetic likelihood (BSL) approach in comparison to a competitor known as approximate Bayesian computation (ABC) and its sensitivity to its tuning parameters and assumptions. We relate BSL to pseudo-marginal methods and propose to use an alternative SL that uses an unbiased estimator of the SL, when the summary statistics have a multivariate normal distribution. Several applications of varying complexity are considered to illustrate the findings of this article. Supplemental materials are available online. Computer code for implementing the methods on all examples is available at https://github.com/cdrovandi/Bayesian-Synthetic-Likelihood.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A8HQ55AT\\Price et al. - 2018 - Bayesian Synthetic Likelihood.pdf}
}

@article{pureswaranParadigmsEasternSpruce2016,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-12-01},
  journaltitle = {Environmental Entomology},
  shortjournal = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  urldate = {2020-12-28},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.}
}

@article{pureswaranParadigmsEasternSpruce2016a,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-09},
  journaltitle = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.},
  annotation = {\_eprint: https://academic.oup.com/ee/article-pdf/45/6/1333/8660127/nvw103.pdf}
}

@article{quirogaSpikeSorting2007,
  title = {Spike Sorting},
  author = {Quiroga, Rodrigo Quian},
  date = {2007-12-21},
  journaltitle = {Scholarpedia},
  volume = {2},
  number = {12},
  pages = {3583},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.3583},
  url = {http://www.scholarpedia.org/article/Spike_sorting},
  urldate = {2020-10-15},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HDCQMX5J\\Spike_sorting.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6AG63MP\\Spike_sorting.html}
}

@article{rabinowitzAttentionStabilizesShared2015,
  title = {Attention Stabilizes the Shared Gain of {{V4}} Populations},
  author = {Rabinowitz, Neil C and Goris, Robbe L and Cohen, Marlene and Simoncelli, Eero P},
  editor = {Carandini, Matteo},
  date = {2015-11-02},
  journaltitle = {eLife},
  volume = {4},
  pages = {e08998},
  publisher = {{eLife Sciences Publications, Ltd}},
  issn = {2050-084X},
  doi = {10.7554/eLife.08998},
  url = {https://doi.org/10.7554/eLife.08998},
  urldate = {2022-12-21},
  abstract = {Responses of sensory neurons represent stimulus information, but are also influenced by internal state. For example, when monkeys direct their attention to a visual stimulus, the response gain of specific subsets of neurons in visual cortex changes. Here, we develop a functional model of population activity to investigate the structure of this effect. We fit the model to the spiking activity of bilateral neural populations in area V4, recorded while the animal performed a stimulus discrimination task under spatial attention. The model reveals four separate time-varying shared modulatory signals, the dominant two of which each target task-relevant neurons in one hemisphere. In attention-directed conditions, the associated shared modulatory signal decreases in variance. This finding provides an interpretable and parsimonious explanation for previous observations that attention reduces variability and noise correlations of sensory neurons. Finally, the recovered modulatory signals reflect previous reward, and are predictive of subsequent choice behavior.},
  keywords = {attention,computation,sensory,statistic,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G6GFNFWE\\Rabinowitz et al. - 2015 - Attention stabilizes the shared gain of V4 populat.pdf}
}

@article{ranganathanActiveDendriticIntegration2018,
  title = {Active Dendritic Integration and Mixed Neocortical Network Representations during an Adaptive Sensing Behavior},
  author = {Ranganathan, Gayathri N. and Apostolides, Pierre F. and Harnett, Mark T. and Xu, Ning-Long and Druckmann, Shaul and Magee, Jeffrey C.},
  date = {2018-11},
  journaltitle = {Nature neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {11},
  eprint = {30349100},
  eprinttype = {pmid},
  pages = {1583--1590},
  issn = {1097-6256},
  doi = {10.1038/s41593-018-0254-6},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6203624/},
  urldate = {2022-09-02},
  abstract = {Animals strategically scan the environment to form an accurate perception of their surroundings. Here we investigated the neuronal representations that mediate this behavior. Ca2+ imaging and selective optogenetic manipulation during an active sensing task reveals that L5 pyramidal neurons in the vibrissae cortex produce a diverse and distributed representation that is required for mice to adapt their whisking motor strategy to changing sensory cues. The optogenetic perturbation degraded single-neuron selectivity and network population encoding through a selective inhibition of active dendritic integration. Together the data indicate that active dendritic integration in pyramidal neurons produces a nonlinearly mixed network representation of joint sensorimotor parameters that is used to transform sensory information into motor commands during adaptive behavior. The prevalence of the L5 cortical circuit motif suggests that this is a general circuit computation.},
  pmcid = {PMC6203624},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8H923HS2\\Ranganathan et al. - 2018 - Active dendritic integration and mixed neocortical.pdf}
}

@book{rasmussenGaussianProcessesMachine2006,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-18253-9},
  langid = {english},
  pagetotal = {248},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4NSIZ4H7\\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf}
}

@book{rasmussenGaussianProcessesMachine2006a,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{MIT Press}},
  location = {{Cambridge, Mass}},
  isbn = {978-0-262-18253-9},
  langid = {english},
  pagetotal = {248},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8BTNNTU8\\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf}
}

@article{reichInterspikeIntervalsReceptive2000,
  title = {Interspike {{Intervals}}, {{Receptive Fields}}, and {{Information Encoding}} in {{Primary Visual Cortex}}},
  author = {Reich, Daniel S. and Mechler, Ferenc and Purpura, Keith P. and Victor, Jonathan D.},
  date = {2000-03-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J Neurosci},
  volume = {20},
  number = {5},
  eprint = {10684897},
  eprinttype = {pmid},
  pages = {1964--1974},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.20-05-01964.2000},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6772912/},
  urldate = {2023-01-16},
  abstract = {In the primate primary visual cortex (V1), the significance of individual action potentials has been difficult to determine, particularly in light of the considerable trial-to-trial variability of responses to visual stimuli. We show here that the information conveyed by an action potential depends on the duration of the immediately preceding interspike interval (ISI). The interspike intervals can be grouped into several different classes on the basis of reproducible features in the interspike interval histograms. Spikes in different classes bear different relationships to the visual stimulus, both qualitatively (in terms of the average stimulus preceding each spike) and quantitatively (in terms of the amount of information encoded per spike and per second). Spikes preceded by very short intervals (3 msec or less) convey information most efficiently and contribute disproportionately to the overall receptive-field properties of the neuron. Overall, V1 neurons can transmit between 5 and 30 bits of information per second in response to rapidly varying, pseudorandom stimuli, with an efficiency of ∼25\%. Although some (but not all) of our results would be expected from neurons that use a firing-rate code to transmit information, the evidence suggests that visual neurons are well equipped to decode stimulus-related information on the basis of relative spike timing and ISI duration.},
  pmcid = {PMC6772912},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5NX8KC6J\\Reich et al. - 2000 - Interspike Intervals, Receptive Fields, and Inform.pdf}
}

@article{renartMeanDrivenFluctuationDrivenPersistent2007,
  title = {Mean-{{Driven}} and {{Fluctuation-Driven Persistent Activity}} in {{Recurrent Networks}}},
  author = {Renart, Alfonso and Moreno-Bote, Rubén and Wang, Xiao-Jing and Parga, Néstor},
  date = {2007-01-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {19},
  number = {1},
  pages = {1--46},
  issn = {0899-7667},
  doi = {10.1162/neco.2007.19.1.1},
  url = {https://doi.org/10.1162/neco.2007.19.1.1},
  urldate = {2022-10-21},
  abstract = {Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this “balanced” state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LJLRG8NJ\\Renart et al. - 2007 - Mean-Driven and Fluctuation-Driven Persistent Acti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GNCJZTFV\\Mean-Driven-and-Fluctuation-Driven-Persistent.html}
}

@article{reynoldsNormalizationModelAttention2009,
  title = {The {{Normalization Model}} of {{Attention}}},
  author = {Reynolds, John H. and Heeger, David J.},
  date = {2009-01-29},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {61},
  number = {2},
  eprint = {19186161},
  eprinttype = {pmid},
  pages = {168--185},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.01.002},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(09)00003-8},
  urldate = {2023-01-16},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DAX5B7AV\\Reynolds and Heeger - 2009 - The Normalization Model of Attention.pdf}
}

@article{richardsDendriticSolutionsCredit2019,
  title = {Dendritic Solutions to the Credit Assignment Problem},
  author = {Richards, Blake A and Lillicrap, Timothy P},
  date = {2019-02},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {54},
  pages = {28--36},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.08.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818300485},
  urldate = {2020-08-29},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\85TNZ67Y\\Richards and Lillicrap - 2019 - Dendritic solutions to the credit assignment probl.pdf}
}

@report{rimehaugUncoveringCircuitMechanisms2022,
  type = {preprint},
  title = {Uncovering Circuit Mechanisms of Current Sinks and Sources with Biophysical Simulations of Primary Visual Cortex},
  author = {Rimehaug, Atle E. and Stasik, Alexander J. and Hagen, Espen and Billeh, Yazan N. and Siegle, Joshua H. and Dai, Kael and Olsen, Shawn R. and Koch, Christof and Einevoll, Gaute T. and Arkhipov, Anton},
  date = {2022-02-25},
  institution = {{Neuroscience}},
  doi = {10.1101/2022.02.22.481540},
  url = {http://biorxiv.org/lookup/doi/10.1101/2022.02.22.481540},
  urldate = {2023-01-09},
  abstract = {Abstract           Local field potential (LFP) recordings reflect the dynamics of the current source density (CSD) in brain tissue. The synaptic, cellular and circuit contributions to current sinks and sources are ill-understood. We investigated these in mouse primary visual cortex using public Neuropixels recordings and a detailed circuit model based on simulating the Hodgkin-Huxley dynamics of numerous cortical neurons belonging to 17 cell types. The model simultaneously captured spiking and CSD responses and demonstrated a two-way dissociation: Firing rates are altered with minor effects on the CSD pattern by adjusting synaptic weights, and CSD is altered with minor effects on firing rates by adjusting synaptic placement on the dendrites. We describe how thalamocortical inputs and recurrent connections sculpt specific sinks and sources early in the visual response, whereas cortical feedback crucially alters them in later stages. Our findings show that CSD analysis provides powerful constraints for modeling beyond those from considering spikes.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QAM8VKIY\\Rimehaug et al. - 2022 - Uncovering circuit mechanisms of current sinks and.pdf}
}

@article{ritzau-jostUltrafastActionPotentials2014,
  title = {Ultrafast {{Action Potentials Mediate Kilohertz Signaling}} at a {{Central Synapse}}},
  author = {Ritzau-Jost, Andreas and Delvendahl, Igor and Rings, Annika and Byczkowicz, Niklas and Harada, Harumi and Shigemoto, Ryuichi and Hirrlinger, Johannes and Eilers, Jens and Hallermann, Stefan},
  date = {2014-10-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {84},
  number = {1},
  pages = {152--163},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.08.036},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627314007375},
  urldate = {2020-11-10},
  abstract = {Fast synaptic transmission is important for rapid information processing. To explore the maximal rate of neuronal signaling and to analyze the presynaptic mechanisms, we focused on the input layer of the cerebellar cortex, where exceptionally high action potential (AP) frequencies have been reported in~vivo. With paired recordings between presynaptic cerebellar mossy fiber boutons and postsynaptic granule cells, we demonstrate reliable neurotransmission up~to ∼1 kHz. Presynaptic APs are ultrafast, with ∼100~μs half-duration. Both Kv1 and Kv3 potassium channels mediate the fast repolarization, rapidly inactivating sodium channels ensure metabolic efficiency, and little AP broadening occurs during bursts of up to 1.5 kHz. Presynaptic Cav2.1 (P/Q-type) calcium channels open efficiently during ultrafast APs. Furthermore, a subset of synaptic vesicles is tightly coupled to Ca2+ channels, and vesicles are rapidly recruited to the release site. These data reveal mechanisms of presynaptic AP generation and transmitter release underlying neuronal kHz signaling.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6KSPEUFF\\Ritzau-Jost et al. - 2014 - Ultrafast Action Potentials Mediate Kilohertz Sign.pdf}
}

@article{rodriguesKuramotoModelComplex2016,
  title = {The {{Kuramoto}} Model in Complex Networks},
  author = {Rodrigues, Francisco A. and Peron, Thomas K. DM. and Ji, Peng and Kurths, Jürgen},
  date = {2016-01-26},
  journaltitle = {Physics Reports},
  shortjournal = {Physics Reports},
  series = {The {{Kuramoto}} Model in Complex Networks},
  volume = {610},
  pages = {1--98},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2015.10.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0370157315004408},
  urldate = {2020-10-06},
  abstract = {Synchronization of an ensemble of oscillators is an emergent phenomenon present in several complex systems, ranging from social and physical to biological and technological systems. The most successful approach to describe how coherent behavior emerges in these complex systems is given by the paradigmatic Kuramoto model. This model has been traditionally studied in complete graphs. However, besides being intrinsically dynamical, complex systems present very heterogeneous structure, which can be represented as complex networks. This report is dedicated to review main contributions in the field of synchronization in networks of Kuramoto oscillators. In particular, we provide an overview of the impact of network patterns on the local and global dynamics of coupled phase oscillators. We cover many relevant topics, which encompass a description of the most used analytical approaches and the analysis of several numerical results. Furthermore, we discuss recent developments on variations of the Kuramoto model in networks, including the presence of noise and inertia. The rich potential for applications is discussed for special fields in engineering, neuroscience, physics and Earth science. Finally, we conclude by discussing problems that remain open after the last decade of intensive research on the Kuramoto model and point out some promising directions for future research.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SG4U2JQZ\\Rodrigues et al. - 2016 - The Kuramoto model in complex networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X3SDT4JP\\S0370157315004408.html}
}

@article{roelfsemaControlSynapticPlasticity2018,
  title = {Control of Synaptic Plasticity in Deep Cortical Networks},
  author = {Roelfsema, Pieter R. and Holtmaat, Anthony},
  date = {2018-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {3},
  pages = {166--180},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn.2018.6},
  url = {https://www.nature.com/articles/nrn.2018.6},
  urldate = {2023-01-13},
  abstract = {In addition to presynaptic and postsynaptic mechanisms, synaptic plasticity depends on neuromodulatory substances and feedback connections from higher-order cortical and thalamic brain regionsSynaptic plasticity in the brain depends on reward-prediction errors and on selective attention. Neuromodulatory systems code for the reward-prediction errors, and feedback connections from the response-selection stage mediate top-down attention effectsThe combined influence of feedback connections and neuromodulatory substances on plasticity enables powerful learning rules for the training of 'deep', multilayered neuronal networksFeedback connections project to cortical layers that are distinct from feedforward input, where they impinge on distal dendritic segments, separate excitatory neuronal populations or inhibitory interneuronsFeedback connections gate plasticity in cortical pyramidal neurons by promoting NMDA-receptor-driven calcium entry into dendrites and by disinhibiting the cortical column through activation of vasoactive-intestinal-peptide-positive interneurons (among others)Synaptic tags are biochemical processes that make synapses eligible for plasticity. Neuromodulators released later can interact with tagged synapses to increase or decrease synaptic strength},
  issue = {3},
  langid = {english},
  keywords = {Cortex,Neurotransmitters,Spike-timing-dependent plasticity,Synaptic plasticity,Thalamus},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NXSGAZA2\\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf}
}

@report{rossbroichSynapticDynamicsConvolutional2020,
  type = {preprint},
  title = {Synaptic {{Dynamics}} as {{Convolutional Units}}},
  author = {Rossbroich, Julian and Trotter, Daniel and Tóth, Katalin and Naud, Richard},
  date = {2020-06-05},
  institution = {{Neuroscience}},
  doi = {10.1101/2020.06.04.133892},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.04.133892},
  urldate = {2020-10-08},
  abstract = {Synaptic dynamics differ markedly across connections and strongly regulate how action potentials are being communicated. To model the range of synaptic dynamics observed in experiments, we develop a flexible mathematical framework based on a linear-nonlinear operation. This model can capture various experimentally observed features of synaptic dynamics and different types of heteroskedasticity. Despite its conceptual simplicity, we show it is more adaptable than previous models. Combined with a standard maximum likelihood approach, synaptic dynamics can be accurately and efficiently characterized using naturalistic stimulation patterns. These results make explicit that synaptic processing bears algorithmic similarities with information processing in convolutional neural networks.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M74KY9B4\\Rossbroich et al. - 2020 - Synaptic Dynamics as Convolutional Units.pdf}
}

@article{ruffAttentionIncreasesSpike2016,
  title = {Attention {{Increases Spike Count Correlations}} between {{Visual Cortical Areas}}},
  author = {Ruff, Douglas A. and Cohen, Marlene R.},
  date = {2016-07-13},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {36},
  number = {28},
  eprint = {27413161},
  eprinttype = {pmid},
  pages = {7523--7534},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0610-16.2016},
  url = {https://www.jneurosci.org/content/36/28/7523},
  urldate = {2022-12-21},
  abstract = {Visual attention, which improves perception of attended locations or objects, has long been known to affect many aspects of the responses of neuronal populations in visual cortex. There are two nonmutually exclusive hypotheses concerning the neuronal mechanisms that underlie these perceptual improvements. The first hypothesis, that attention improves the information encoded by a population of neurons in a particular cortical area, has considerable physiological support. The second hypothesis is that attention improves perception by selectively communicating relevant visual information. This idea has been tested primarily by measuring interactions between neurons on very short timescales, which are mathematically nearly independent of neuronal interactions on longer timescales. We tested the hypothesis that attention changes the way visual information is communicated between cortical areas on longer timescales by recording simultaneously from neurons in primary visual cortex (V1) and the middle temporal area (MT) in rhesus monkeys. We used two independent and complementary approaches. Our correlative experiment showed that attention increases the trial-to-trial response variability that is shared between the two areas. In our causal experiment, we electrically microstimulated V1 and found that attention increased the effect of stimulation on MT responses. Together, our results suggest that attention affects both the way visual stimuli are encoded within a cortical area and the extent to which visual information is communicated between areas on behaviorally relevant timescales. SIGNIFICANCE STATEMENT Visual attention dramatically improves the perception of attended stimuli. Attention has long been thought to act by selecting relevant visual information for further processing. It has been hypothesized that this selection is accomplished by increasing communication between neurons that encode attended information in different cortical areas. We recorded simultaneously from neurons in primary visual cortex and the middle temporal area while rhesus monkeys performed an attention task. We found that attention increased shared variability between neurons in the two areas and that attention increased the effect of microstimulation in V1 on the firing rates of MT neurons. Our results provide support for the hypothesis that attention increases communication between neurons in different brain areas on behaviorally relevant timescales.},
  langid = {english},
  keywords = {attention,middle temporal area,primary visual cortex,variability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YMZ4YLWI\\Ruff and Cohen - 2016 - Attention Increases Spike Count Correlations betwe.pdf}
}

@article{ruffLowRankMechanisms2020,
  title = {Low Rank Mechanisms Underlying Flexible Visual Representations},
  author = {Ruff, Douglas A. and Xue, Cheng and Kramer, Lily E. and Baqai, Faisal and Cohen, Marlene R.},
  date = {2020-11-24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {47},
  pages = {29321--29329},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2005797117},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2005797117},
  urldate = {2022-12-21},
  abstract = {Neuronal population responses to sensory stimuli are remarkably flexible. The responses of neurons in visual cortex have heterogeneous dependence on stimulus properties (e.g., contrast), processes that affect all stages of visual processing (e.g., adaptation), and cognitive processes (e.g., attention or task switching). Understanding whether these processes affect similar neuronal populations and whether they have similar effects on entire populations can provide insight into whether they utilize analogous mechanisms. In particular, it has recently been demonstrated that attention has low rank effects on the covariability of populations of visual neurons, which impacts perception and strongly constrains mechanistic models. We hypothesized that measuring changes in population covariability associated with other sensory and cognitive processes could clarify whether they utilize similar mechanisms or computations. Our experimental design included measurements in multiple visual areas using four distinct sensory and cognitive processes. We found that contrast, adaptation, attention, and task switching affect the variability of responses of populations of neurons in primate visual cortex in a similarly low rank way. These results suggest that a given circuit may use similar mechanisms to perform many forms of modulation and likely reflects a general principle that applies to a wide range of brain areas and sensory, cognitive, and motor processes.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z6LMCDS3\\Ruff et al. - 2020 - Low rank mechanisms underlying flexible visual rep.pdf}
}

@article{ruleSelfhealingCodesHow2022,
  title = {Self-Healing Codes: {{How}} Stable Neural Populations Can Track Continually Reconfiguring Neural Representations},
  shorttitle = {Self-Healing Codes},
  author = {Rule, Michael E. and O’Leary, Timothy},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {7},
  pages = {e2106692119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2106692119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2106692119},
  urldate = {2022-09-30},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S4P6STWA\\Rule and O’Leary - 2022 - Self-healing codes How stable neural populations .pdf}
}

@article{rustPriorityCodingVisual2022,
  title = {Priority Coding in the Visual System},
  author = {Rust, Nicole C. and Cohen, Marlene R.},
  date = {2022-06},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {23},
  number = {6},
  pages = {376--388},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00582-9},
  url = {https://www.nature.com/articles/s41583-022-00582-9},
  urldate = {2022-12-23},
  abstract = {Although we are continuously bombarded with visual input, only a fraction of incoming visual events is perceived, remembered or acted on. The neural underpinnings of various forms of visual priority coding, including perceptual expertise, goal-directed attention, visual salience, image memorability and preferential looking, have been studied. Here, we synthesize information from these different examples to review recent developments in our understanding of visual priority coding and its neural correlates, with a focus on the role of behaviour to evaluate candidate correlates. We propose that the brain combines different types of priority into a unified priority signal while also retaining the ability to differentiate between them, and that this happens by leveraging partially overlapping low-dimensional neural subspaces for each type of priority that are shared with the downstream neural populations involved in decision-making. Finally, we describe the gulfs in understanding that have resulted from different research approaches, and we point towards future directions that will lead to fundamental insights about neural coding and how prioritization influences visually guided behaviours.},
  issue = {6},
  langid = {english},
  keywords = {Extrastriate cortex,Neural encoding},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7N88UA2E\\Rust and Cohen - 2022 - Priority coding in the visual system.pdf}
}

@article{sakmannHighfrequencySpikeBursts,
  title = {High-Frequency Spike Bursts in Cortical Layer 5 Thick Tufted Pyramds Provide a Brian-Wide Signal to Encode Exploratory Touch},
  author = {Sakmann, Kock},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z4PXBR88\\Sakmann - High-frequency spike bursts in cortical layer 5 th.pdf}
}

@article{santelloAstrocyteFunctionInformation2019,
  title = {Astrocyte Function from Information Processing to Cognition and Cognitive Impairment},
  author = {Santello, Mirko and Toni, Nicolas and Volterra, Andrea},
  date = {2019-02},
  journaltitle = {Nature Neuroscience},
  volume = {22},
  number = {2},
  pages = {154--166},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0325-8},
  url = {https://www.nature.com/articles/s41593-018-0325-8},
  urldate = {2020-11-21},
  abstract = {Astrocytes serve important roles that affect recruitment and function of neurons at the local and network levels. Here we review the contributions of astrocyte signaling to synaptic plasticity, neuronal network oscillations, and memory function. The roles played by astrocytes are not fully understood, but astrocytes seem to contribute to memory consolidation and seem to mediate the effects of vigilance and arousal on memory performance. Understanding the role of astrocytes in cognitive processes may also advance our understanding of how these processes go awry in pathological conditions. Indeed, abnormal astrocytic signaling can cause or contribute to synaptic and network imbalances, leading to cognitive impairment. We discuss evidence for this from animal models of Alzheimer’s disease and multiple sclerosis and from animal studies of sleep deprivation and drug abuse and addiction. Understanding the emerging roles of astrocytes in cognitive function and dysfunction will open up a large array of new therapeutic opportunities.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CK2ZG4NV\\Santello et al. - 2019 - Astrocyte function from information processing to .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\24AM7V7M\\s41593-018-0325-8.html}
}

@article{santosTopologicalPhaseTransitions2019,
  title = {Topological Phase Transitions in Functional Brain Networks},
  author = {Santos, Fernando A. N. and Raposo, Ernesto P. and Coutinho-Filho, Maurício D. and Copelli, Mauro and Stam, Cornelis J. and Douw, Linda},
  date = {2019-09-30},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {100},
  number = {3},
  pages = {032414},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.100.032414},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.100.032414},
  urldate = {2022-10-02},
  abstract = {Functional brain networks are often constructed by quantifying correlations between time series of activity of brain regions. Their topological structure includes nodes, edges, triangles, and even higher-dimensional objects. Topological data analysis (TDA) is the emerging framework to process data sets under this perspective. In parallel, topology has proven essential for understanding fundamental questions in physics. Here we report the discovery of topological phase transitions in functional brain networks by merging concepts from TDA, topology, geometry, physics, and network theory. We show that topological phase transitions occur when the Euler entropy has a singularity, which remarkably coincides with the emergence of multidimensional topological holes in the brain network. The geometric nature of the transitions can be interpreted, under certain hypotheses, as an extension of percolation to high-dimensional objects. Due to the universal character of phase transitions and noise robustness of TDA, our findings open perspectives toward establishing reliable topological and geometrical markers for group and possibly individual differences in functional brain network organization.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ACHSARAE\\Santos et al. - 2019 - Topological phase transitions in functional brain .pdf}
}

@article{sassiCoupledNonlinearOscillators,
  title = {Coupled {{Nonlinear Oscillators}}},
  author = {Sassi, Roberto},
  pages = {26},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UUSGGFIA\\Sassi - Coupled Nonlinear Oscillators.pdf}
}

@article{schmidt-hieberActiveDendriticIntegration2017,
  title = {Active Dendritic Integration as a Mechanism for Robust and Precise Grid Cell Firing},
  author = {Schmidt-Hieber, Christoph and Toleikyte, Gabija and Aitchison, Laurence and Roth, Arnd and Clark, Beverley A. and Branco, Tiago and Häusser, Michael},
  date = {2017-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {8},
  pages = {1114--1121},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.4582},
  url = {https://www.nature.com/articles/nn.4582},
  urldate = {2022-09-30},
  abstract = {Combining electrophysiology and computational modeling, the authors show that the dendrites of entorhinal cortex stellate and pyramidal cells are electrically excitable and that this improves the robustness of grid cell firing. The results suggest that active dendrites are critical for spatial navigation, a fundamental computation in the brain.},
  issue = {8},
  langid = {english},
  keywords = {Biophysical models,Dendritic excitability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RG368HBJ\\Schmidt-Hieber et al. - 2017 - Active dendritic integration as a mechanism for ro.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RIQHMAL8\\nn.html}
}

@article{schmutzMesoscopicPopulationEquations2020,
  title = {Mesoscopic Population Equations for Spiking Neural Networks with Synaptic Short-Term Plasticity},
  author = {Schmutz, Valentin and Gerstner, Wulfram and Schwalger, Tilo},
  date = {2020-04-06},
  journaltitle = {The Journal of Mathematical Neuroscience},
  shortjournal = {The Journal of Mathematical Neuroscience},
  volume = {10},
  number = {1},
  pages = {5},
  issn = {2190-8567},
  doi = {10.1186/s13408-020-00082-z},
  url = {https://doi.org/10.1186/s13408-020-00082-z},
  urldate = {2020-11-16},
  abstract = {Coarse-graining microscopic models of biological neural networks to obtain mesoscopic models of neural activities is an essential step towards multi-scale models of the brain. Here, we extend a recent theory for mesoscopic population dynamics with static synapses to the case of dynamic synapses exhibiting short-term plasticity (STP). The extended theory offers an approximate mean-field dynamics for the synaptic input currents arising from populations of spiking neurons and synapses undergoing Tsodyks–Markram STP. The approximate mean-field dynamics accounts for both finite number of synapses and correlation between the two synaptic variables of the model (utilization and available resources) and its numerical implementation is simple. Comparisons with Monte Carlo simulations of the microscopic model show that in both feedforward and recurrent networks, the mesoscopic mean-field model accurately reproduces the first- and second-order statistics of the total synaptic input into a postsynaptic neuron and accounts for stochastic switches between Up and Down states and for population spikes. The extended mesoscopic population theory of spiking neural networks with STP may be useful for a systematic reduction of detailed biophysical models of cortical microcircuits to numerically efficient and mathematically tractable mean-field models.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IPLSBJ3D\\Schmutz et al. - 2020 - Mesoscopic population equations for spiking neural.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A9YIWBE5\\s13408-020-00082-z.html}
}

@article{schneiderNeuromodulationReducesInterindividual2022,
  title = {Neuromodulation {{Reduces Interindividual Variability}} of {{Neuronal Output}}},
  author = {Schneider, Anna C. and Itani, Omar and Bucher, Dirk and Nadim, Farzan},
  date = {2022-07-01},
  journaltitle = {eNeuro},
  shortjournal = {eNeuro},
  volume = {9},
  number = {4},
  eprint = {35853725},
  eprinttype = {pmid},
  publisher = {{Society for Neuroscience}},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0166-22.2022},
  url = {https://www.eneuro.org/content/9/4/ENEURO.0166-22.2022},
  urldate = {2022-10-17},
  abstract = {Visual Abstract {$<$}img class="highwire-fragment fragment-image" alt="Figure" src="https://www.eneuro.org/content/eneuro/9/4/ENEURO.0166-22.2022/F1.medium.gif" width="440" height="240"/{$>$}Download figureOpen in new tabDownload powerpoint In similar states, neural circuits produce similar outputs across individuals despite substantial interindividual variability in neuronal ionic conductances and synapses. Circuit states are largely shaped by neuromodulators that tune ionic conductances. It is therefore possible that, in addition to producing flexible circuit output, neuromodulators also contribute to output similarity despite varying ion channel expression. We studied whether neuromodulation at saturating concentrations can increase the output similarity of a single identified neuron across individual animals. Using the lateral pyloric (LP) neuron of the crab stomatogastric ganglion, we compared the variability of f–I (frequency–current) curves and rebound properties in the presence of neuropeptides. The two neuropeptides we used converge to activate the same target current, which increases neuronal excitability. Output variability was lower in the presence of the neuropeptides, regardless of whether the neuropeptides significantly changed the mean of the corresponding parameter or not. However, the addition of the second neuropeptide did not add further to the reduction of variability. With a family of computational LP-like models, we explored how increased excitability and target variability contribute to output similarity and found two mechanisms: saturation of the responses and a differential increase in baseline activity. Saturation alone can reduce the interindividual variability only if the population shares a similar ceiling for the responses. In contrast, the reduction of variability due to the increase in baseline activity is independent of ceiling effects.},
  langid = {english},
  keywords = {bursting neuron,central pattern generator,stomatogastric,variability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MGPDJMNT\\Schneider et al. - 2022 - Neuromodulation Reduces Interindividual Variabilit.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JMWIEHBY\\ENEURO.0166-22.html}
}

@article{schneidmanNetworkInformationConnected2003,
  title = {Network {{Information}} and {{Connected Correlations}}},
  author = {Schneidman, Elad and Still, Susanne and Berry, Michael J. and Bialek, William},
  date = {2003-12-02},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {91},
  number = {23},
  pages = {238701},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevLett.91.238701},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.91.238701},
  urldate = {2022-10-05},
  abstract = {Entropy and information provide natural measures of correlation among elements in a network. We construct here the information theoretic analog of connected correlation functions: irreducible N-point correlation is measured by a decrease in entropy for the joint distribution of N variables relative to the maximum entropy allowed by all the observed N−1 variable distributions. We calculate the “connected information” terms for several examples and show that it also enables the decomposition of the information that is carried by a population of elements about an outside source.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z3KXXWQN\\Schneidman et al. - 2003 - Network Information and Connected Correlations.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IADYYTXC\\PhysRevLett.91.html}
}

@article{schneidmanNetworkInformationConnected2003a,
  title = {Network {{Information}} and {{Connected Correlations}}},
  author = {Schneidman, Elad and Still, Susanne and Ii, Michael J Berry and Bialek, William},
  date = {2003},
  journaltitle = {PHYSICAL REVIEW LETTERS},
  volume = {91},
  number = {23},
  pages = {4},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B62KWLW3\\Schneidman et al. - 2003 - Network Information and Connected Correlations.pdf}
}

@article{semedoCorticalAreasInteract2019,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-23},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FFK9FGES\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CZGNQX33\\S0896627319300534.html}
}

@article{semedoCorticalAreasInteract2019a,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-23},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A64QE4P7\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf}
}

@article{semedoCorticalAreasInteract2019b,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-25},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CA44E9F7\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZVB4WYEX\\S0896627319300534.html}
}

@article{semedoFeedforwardFeedbackInteractions2022,
  title = {Feedforward and Feedback Interactions between Visual Cortical Areas Use Different Population Activity Patterns},
  author = {Semedo, João D. and Jasper, Anna I. and Zandvakili, Amin and Krishna, Aravind and Aschner, Amir and Machens, Christian K. and Kohn, Adam and Yu, Byron M.},
  date = {2022-03-01},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {1099},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28552-w},
  url = {https://www.nature.com/articles/s41467-022-28552-w},
  urldate = {2022-09-23},
  abstract = {Brain function relies on the coordination of activity across multiple, recurrently connected brain areas. For instance, sensory information encoded in early sensory areas is relayed to, and further processed by, higher cortical areas and then fed back. However, the way in which feedforward and feedback signaling interact with one another is incompletely understood. Here we investigate this question by leveraging simultaneous neuronal population recordings in early and midlevel visual areas (V1–V2 and V1–V4). Using a dimensionality reduction approach, we find that population interactions are feedforward-dominated shortly after stimulus onset and feedback-dominated during spontaneous activity. The population activity patterns most correlated across areas were distinct during feedforward- and feedback-dominated periods. These results suggest that feedforward and feedback signaling rely on separate “channels”, which allows feedback signals to not directly affect activity that is fed forward.},
  issue = {1},
  langid = {english},
  keywords = {Computational neuroscience,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DTE3TDXI\\Semedo et al. - 2022 - Feedforward and feedback interactions between visu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BIPSZ6TL\\s41467-022-28552-w.html}
}

@article{shahidiHighorderCoordinationCortical2019,
  title = {High-Order Coordination of Cortical Spiking Activity Modulates Perceptual Accuracy},
  author = {Shahidi, Neda and Andrei, Ariana R. and Hu, Ming and Dragoi, Valentin},
  date = {2019-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {7},
  pages = {1148--1158},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0406-3},
  url = {https://www.nature.com/articles/s41593-019-0406-3},
  urldate = {2023-01-03},
  abstract = {The accurate relay of electrical signals within cortical networks is key to perception and cognitive function. Theoretically, it has long been proposed that temporal coordination of neuronal spiking activity controls signal transmission and behavior. However, whether and how temporally precise neuronal coordination in population activity influences perception are unknown. Here, we recorded populations of neurons in early and mid-level visual cortex (areas V1 and V4) simultaneously to discover that the precise temporal coordination between the spiking activity of three or more cells carries information about visual perception in the absence of firing rate modulation. The accuracy of perceptual responses correlated with high-order spiking coordination within V4, but not V1, and with feedforward coordination between V1 and V4. These results indicate that while visual stimuli are encoded in the discharge rates of neurons, perceptual accuracy is related to temporally precise spiking coordination within and between cortical networks.},
  issue = {7},
  langid = {english},
  keywords = {Neural circuits,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RDIJVQ3B\\Shahidi et al. - 2019 - High-order coordination of cortical spiking activi.pdf}
}

@article{shewAdaptationSensoryInput2015,
  title = {Adaptation to Sensory Input Tunes Visual Cortex to Criticality},
  author = {Shew, Woodrow L. and Clawson, Wesley P. and Pobst, Jeff and Karimipanah, Yahya and Wright, Nathaniel C. and Wessel, Ralf},
  date = {2015-08},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {8},
  pages = {659--663},
  publisher = {{Nature Publishing Group}},
  issn = {1745-2481},
  doi = {10.1038/nphys3370},
  url = {https://www.nature.com/articles/nphys3370},
  urldate = {2022-10-01},
  abstract = {Sensory nervous systems adapt to their environment—a mechanism thought to ensure network dynamics remain critical. Visual cortex experiments show that adaptation maintains criticality even as sensory input drives the system away from this regime.},
  issue = {8},
  langid = {english},
  keywords = {Biological physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XNQK5H2L\\Shew et al. - 2015 - Adaptation to sensory input tunes visual cortex to.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PSRLQPUF\\nphys3370.html}
}

@unpublished{shiComparisonTaskDriven2019,
  title = {Comparison {{Against Task Driven Artificial Neural Networks Reveals Functional Organization}} of {{Mouse Visual Cortex}}},
  author = {Shi, Jianghong and Shea-Brown, Eric and Buice, Michael A.},
  date = {2019-11-18},
  eprint = {1911.07986},
  eprinttype = {arxiv},
  primaryclass = {q-bio},
  url = {http://arxiv.org/abs/1911.07986},
  urldate = {2020-10-08},
  abstract = {Partially inspired by features of computation in visual cortex, deep neural networks compute hierarchical representations of their inputs. While these networks have been highly successful in machine learning, it remains unclear to what extent they can aid our understanding of cortical function. Several groups have developed metrics that provide a quantitative comparison between representations computed by networks and representations measured in cortex. At the same time, neuroscience is well into an unprecedented phase of large-scale data collection, as evidenced by projects such as the Allen Brain Observatory. Despite the magnitude of these efforts, in a given experiment only a fraction of units are recorded, limiting the information available about the cortical representation. Moreover, only a finite number of stimuli can be shown to an animal over the course of a realistic experiment. These limitations raise the question of how and whether metrics that compare representations of deep networks are meaningful on these datasets. Here, we empirically quantify the capabilities and limitations of these metrics due to limited image presentations and neuron samples. We find that the comparison procedure is robust to different choices of stimuli set and the level of subsampling that one might expect in a large-scale brain survey with thousands of neurons. Using these results, we compare the representations measured in the Allen Brain Observatory in response to natural image presentations to deep neural network. We show that the visual cortical areas are relatively high order representations (in that they map to deeper layers of convolutional neural networks). Furthermore, we see evidence of a broad, more parallel organization rather than a sequential hierarchy, with the primary area VISp(V1) being lower order relative to the other areas.},
  archiveprefix = {arXiv},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AKT8V8NC\\Shi et al. - 2019 - Comparison Against Task Driven Artificial Neural N.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYLHR5I9\\1911.html}
}

@article{shiCorticalStateDynamics2022,
  title = {✅ {{Cortical}} State Dynamics and Selective Attention Define the Spatial Pattern of Correlated Variability in Neocortex},
  author = {Shi, Yan-Liang and Steinmetz, Nicholas A. and Moore, Tirin and Boahen, Kwabena and Engel, Tatiana A.},
  date = {2022-01-10},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {44},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-27724-4},
  url = {https://www.nature.com/articles/s41467-021-27724-4},
  urldate = {2022-12-28},
  abstract = {Correlated activity fluctuations in the neocortex influence sensory responses and behavior. Neural correlations reflect anatomical connectivity but also change dynamically with cognitive states such as attention. Yet, the network mechanisms defining the population structure of correlations remain unknown. We measured correlations within columns in the visual cortex. We show that the magnitude of correlations, their attentional modulation, and dependence on lateral distance are explained by columnar On-Off dynamics, which are synchronous activity fluctuations reflecting cortical state. We developed a network model in which the On-Off dynamics propagate across nearby columns generating spatial correlations with the extent controlled by attentional inputs. This mechanism, unlike previous proposals, predicts spatially non-uniform changes in correlations during attention. We confirm this prediction in our columnar recordings by showing that in superficial layers the largest changes in correlations occur at intermediate lateral distances. Our results reveal how spatially structured patterns of correlated variability emerge through interactions of cortical state dynamics, anatomical connectivity, and attention.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Network models,Neural circuits,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EUE4TIV8\\Shi et al. - 2022 - Cortical state dynamics and selective attention de.pdf}
}

@article{shihImprovedStimulusRepresentation2011,
  title = {Improved Stimulus Representation by Short Interspike Intervals in Primary Auditory Cortex},
  author = {Shih, Jonathan Y. and Atencio, Craig A. and Schreiner, Christoph E.},
  date = {2011-04},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J Neurophysiol},
  volume = {105},
  number = {4},
  eprint = {21307320},
  eprinttype = {pmid},
  pages = {1908--1917},
  issn = {0022-3077},
  doi = {10.1152/jn.01055.2010},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3075280/},
  urldate = {2023-01-16},
  abstract = {We analyzed the receptive field information conveyed by interspike intervals (ISIs) in the auditory cortex. In the visual system, different ISIs may both code for different visual features and convey differing amounts of stimulus information. To determine their potential role in auditory signal processing, we obtained extracellular recordings in the primary auditory cortex (AI) of the cat while presenting a dynamic moving ripple stimulus and then used the responses to construct spectrotemporal receptive fields (STRFs). For each neuron, we constructed three STRFs, one for short-ISI events (ISI {$<$} 15 ms); one for isolated, long-ISI events (ISI {$>$} 15 ms); and one including all events. To characterize stimulus encoding, we calculated the feature selectivity and event information for each of the STRFs. Short-ISI spikes were more feature selective and conveyed information more efficiently. The different ISI regimens of AI neurons did not represent different stimulus features, but short-ISI spike events did contribute over-proportionately to the full spike train STRF information. Thus short-ISIs constitute a robust representation of auditory features, and they are particularly effective at driving postsynaptic activity. This suggests that short-ISI events are especially suited to provide noise immunity and high-fidelity information transmission in AI.},
  pmcid = {PMC3075280}
}

@misc{shiSpatialTemporalCorrelations2022,
  title = {Spatial and Temporal Correlations in Neural Networks with Structured Connectivity},
  author = {Shi, Yan-Liang and Zeraati, Roxana and Levina, Anna and Engel, Tatiana A.},
  date = {2022-07-16},
  number = {arXiv:2207.07930},
  eprint = {2207.07930},
  eprinttype = {arxiv},
  primaryclass = {cond-mat, q-bio},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2207.07930},
  url = {http://arxiv.org/abs/2207.07930},
  urldate = {2023-01-03},
  abstract = {Correlated fluctuations in the activity of neural populations reflect the network's dynamics and connectivity. The temporal and spatial dimensions of neural correlations are interdependent. However, prior theoretical work mainly analyzed correlations in either spatial or temporal domains, oblivious to their interplay. We show that the network dynamics and connectivity jointly define the spatiotemporal profile of neural correlations. We derive analytical expressions for pairwise correlations in networks of binary units with spatially arranged connectivity in one and two dimensions. We find that spatial interactions among units generate multiple timescales in auto- and cross-correlations. Each timescale is associated with fluctuations at a particular spatial frequency, making a hierarchical contribution to the correlations. External inputs can modulate the correlation timescales when spatial interactions are nonlinear, and the modulation effect depends on the operating regime of network dynamics. These theoretical results open new ways to relate connectivity and dynamics in cortical networks via measurements of spatiotemporal neural correlations.},
  archiveprefix = {arXiv},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Statistical Mechanics,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8PEHBVBW\\Shi et al. - 2022 - Spatial and temporal correlations in neural networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IV7NGPYR\\2207.html}
}

@article{sinhaActiveDendritesLocal2022,
  title = {Active {{Dendrites}} and {{Local Field Potentials}}: {{Biophysical Mechanisms}} and {{Computational Explorations}}},
  shorttitle = {Active {{Dendrites}} and {{Local Field Potentials}}},
  author = {Sinha, Manisha and Narayanan, Rishikesh},
  date = {2022-05-01},
  journaltitle = {Neuroscience},
  shortjournal = {Neuroscience},
  series = {Dendritic Contributions to Biological and Artificial Computations},
  volume = {489},
  pages = {111--142},
  issn = {0306-4522},
  doi = {10.1016/j.neuroscience.2021.08.035},
  url = {https://www.sciencedirect.com/science/article/pii/S0306452221004504},
  urldate = {2022-09-02},
  abstract = {Neurons and glial cells are endowed with membranes that express a rich repertoire of ion channels, transporters, and receptors. The constant flux of ions across the neuronal and glial membranes results in voltage fluctuations that can be recorded from the extracellular matrix. The high frequency components of this voltage signal contain information about the spiking activity, reflecting the output from the neurons surrounding the recording location. The low frequency components of the signal, referred to as the local field potential (LFP), have been traditionally thought to provide information about the synaptic inputs that impinge on the large dendritic trees of various neurons. In this review, we discuss recent computational and experimental studies pointing to a critical role of several active dendritic mechanisms that can influence the genesis and the location-dependent spectro-temporal dynamics of LFPs, spanning different brain regions. We strongly emphasize the need to account for the several fast and slow dendritic events and associated active mechanisms — including gradients in their expression profiles, inter- and intra-cellular spatio-temporal interactions spanning neurons and glia, heterogeneities and degeneracy across scales, neuromodulatory influences, and activitydependent plasticity — towards gaining important insights about the origins of LFP under different behavioral states in health and disease. We provide simple but essential guidelines on how to model LFPs taking into account these dendritic mechanisms, with detailed methodology on how to account for various heterogeneities and electrophysiological properties of neurons and synapses while studying LFPs.},
  langid = {english},
  keywords = {computational models,degeneracy,heterogeneity,ion channels,neural plasticity,oscillations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CH26RKTL\\Sinha and Narayanan - 2022 - Active Dendrites and Local Field Potentials Bioph.pdf}
}

@article{smithDendriticSpikesEnhance2013,
  title = {Dendritic Spikes Enhance Stimulus Selectivity in Cortical Neurons in Vivo},
  author = {Smith, Spencer L. and Smith, Ikuko T. and Branco, Tiago and Häusser, Michael},
  date = {2013-11},
  journaltitle = {Nature},
  volume = {503},
  number = {7474},
  pages = {115--120},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/nature12600},
  url = {https://www.nature.com/articles/nature12600},
  urldate = {2022-09-30},
  abstract = {Neuronal dendrites are not passive cables, but whether their excitability contributes to computation at the cell’s soma has been uncertain; by observing and interfering with dendritic ‘spikes’ during sensory stimulation, it is now shown that active dendritic processing enhances somatic orientation selectivity, a fundamental brain computation.},
  issue = {7474},
  langid = {english},
  keywords = {Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T2NMJFT4\\Smith et al. - 2013 - Dendritic spikes enhance stimulus selectivity in c.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9IG5YU32\\nature12600.html}
}

@article{smithSpatialTemporalScales2008,
  title = {Spatial and {{Temporal Scales}} of {{Neuronal Correlation}} in {{Primary Visual Cortex}}},
  author = {Smith, Matthew A. and Kohn, Adam},
  date = {2008-11-26},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {28},
  number = {48},
  eprint = {19036953},
  eprinttype = {pmid},
  pages = {12591--12603},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2929-08.2008},
  url = {https://www.jneurosci.org/content/28/48/12591},
  urldate = {2023-01-06},
  abstract = {The spiking activity of cortical neurons is correlated. For instance, trial-to-trial fluctuations in response strength are shared between neurons, and spikes often occur synchronously. Understanding the properties and mechanisms that generate these forms of correlation is critical for determining their role in cortical processing. We therefore investigated the spatial extent and functional specificity of correlated spontaneous and evoked activity. Because feedforward, recurrent, and feedback pathways have distinct extents and specificity, we reasoned that these measurements could elucidate the contribution of each type of input. We recorded single unit activity with microelectrode arrays which allowed us to measure correlation in many hundreds of pairings, across a large range of spatial scales. Our data show that correlated evoked activity is generated by two mechanisms that link neurons with similar orientation preferences on different spatial scales: one with high temporal precision and a limited spatial extent (∼3 mm), and a second that gives rise to correlation on a slow time scale and extends as far as we were able to measure (10 mm). The former is consistent with common input provided by horizontal connections; the latter likely involves feedback from extrastriate cortex. Spontaneous activity was correlated over a similar spatial extent, but approximately twice as strongly as evoked activity. Visual stimuli thus caused a substantial decrease in correlation, particularly at response onset. These properties and the circuit mechanism they imply provide new constraints on the functional role that correlation may play in visual processing.},
  langid = {english},
  keywords = {array,cross-correlogram,multielectrode recordings,noise correlation,population coding,signal correlation,spontaneous activity,synchrony},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P38MLYFV\\Smith and Kohn - 2008 - Spatial and Temporal Scales of Neuronal Correlatio.pdf}
}

@article{snyderDistinctPopulationCodes2018,
  title = {Distinct Population Codes for Attention in the Absence and Presence of Visual Stimulation},
  author = {Snyder, Adam C. and Yu, Byron M. and Smith, Matthew A.},
  date = {2018-10-22},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {4382},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-06754-5},
  url = {https://www.nature.com/articles/s41467-018-06754-5},
  urldate = {2022-12-19},
  abstract = {Visual neurons respond more vigorously to an attended stimulus than an unattended one. How the brain prepares for response gain in anticipation of that stimulus is not well understood. One prominent proposal is that anticipation is characterized by gain-like modulations of spontaneous activity similar to gains in stimulus responses. Here we test an alternative idea: anticipation is characterized by a mixture of both increases and decreases of spontaneous firing rates. Such a strategy would be adaptive as it supports a simple linear scheme for disentangling internal, modulatory signals from external, sensory inputs. We recorded populations of V4 neurons in monkeys performing an attention task, and found that attention states are signaled by different mixtures of neurons across the population in the presence or absence of a stimulus. Our findings support a move from a stimulation-invariant account of anticipation towards a richer view of attentional modulation in a diverse neuronal population.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Neural decoding},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SQBR6DY6\\Snyder et al. - 2018 - Distinct population codes for attention in the abs.pdf}
}

@article{snyderStablePopulationCode2021,
  title = {A {{Stable Population Code}} for {{Attention}} in {{Prefrontal Cortex Leads}} a {{Dynamic Attention Code}} in {{Visual Cortex}}},
  author = {Snyder, Adam C. and Yu, Byron M. and Smith, Matthew A.},
  date = {2021-11-03},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {41},
  number = {44},
  pages = {9163--9176},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0608-21.2021},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0608-21.2021},
  urldate = {2023-01-16},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PKMZPKWD\\Snyder et al. - 2021 - A Stable Population Code for Attention in Prefront.pdf}
}

@article{soleEvolutionBrainsComputers2022,
  title = {Evolution of {{Brains}} and {{Computers}}: {{The Roads Not Taken}}},
  shorttitle = {Evolution of {{Brains}} and {{Computers}}},
  author = {Solé, Ricard and Seoane, Luís F.},
  date = {2022-05},
  journaltitle = {Entropy},
  volume = {24},
  number = {5},
  pages = {665},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e24050665},
  url = {https://www.mdpi.com/1099-4300/24/5/665},
  urldate = {2023-01-11},
  abstract = {When computers started to become a dominant part of technology around the 1950s, fundamental questions about reliable designs and robustness were of great relevance. Their development gave rise to the exploration of new questions, such as what made brains reliable (since neurons can die) and how computers could get inspiration from neural systems. In parallel, the first artificial neural networks came to life. Since then, the comparative view between brains and computers has been developed in new, sometimes unexpected directions. With the rise of deep learning and the development of connectomics, an evolutionary look at how both hardware and neural complexity have evolved or designed is required. In this paper, we argue that important similarities have resulted both from convergent evolution (the inevitable outcome of architectural constraints) and inspiration of hardware and software principles guided by toy pictures of neurobiology. Moreover, dissimilarities and gaps originate from the lack of major innovations that have paved the way to biological computing (including brains) that are completely absent within the artificial domain. As it occurs within synthetic biocomputation, we can also ask whether alternative minds can emerge from A.I. designs. Here, we take an evolutionary view of the problem and discuss the remarkable convergences between living and artificial designs and what are the pre-conditions to achieve artificial intelligence.},
  issue = {5},
  langid = {english},
  keywords = {artificial intelligence,brains,deep learning,embodiment,evolution,neural networks,neurorobotics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MM4FBKA8\\Solé and Seoane - 2022 - Evolution of Brains and Computers The Roads Not T.pdf}
}

@article{speedSpatialAttentionEnhances2020,
  title = {Spatial Attention Enhances Network, Cellular and Subthreshold Responses in Mouse Visual Cortex},
  author = {Speed, Anderson and Del Rosario, Joseph and Mikail, Navid and Haider, Bilal},
  date = {2020-01-24},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {505},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-14355-4},
  url = {https://www.nature.com/articles/s41467-020-14355-4},
  urldate = {2023-01-10},
  abstract = {Internal brain states strongly modulate sensory processing during behaviour. Studies of visual processing in primates show that attention to space selectively improves behavioural and neural responses to stimuli at the attended locations. Here we develop a visual spatial task for mice that elicits behavioural improvements consistent with the effects of spatial attention, and simultaneously measure network, cellular, and subthreshold activity in primary visual cortex. During trial-by-trial behavioural improvements, local field potential (LFP) responses to stimuli detected inside the receptive field (RF) strengthen. Moreover, detection inside the RF selectively enhances excitatory and inhibitory neuron responses to task-irrelevant stimuli and suppresses noise correlations and low frequency LFP fluctuations. Whole-cell patch-clamp recordings reveal that detection inside the RF increases synaptic activity that depolarizes membrane potential responses at the behaviorally relevant location. Our study establishes that mice display fundamental signatures of visual spatial attention spanning behavioral, network, cellular, and synaptic levels, providing new insight into rapid cognitive enhancement of sensory signals in visual cortex.},
  issue = {1},
  langid = {english},
  keywords = {Neural circuits,Sensory processing,Striate cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WMCUFIXA\\Speed et al. - 2020 - Spatial attention enhances network, cellular and s.pdf}
}

@online{SpikingBurstinessWorking,
  title = {Spiking Burstiness and Working Memory in the Human Medial Temporal Lobe | {{Cerebral Cortex Communications}} | {{Oxford Academic}}},
  url = {https://academic.oup.com/cercorcomms/article/3/4/tgac039/6763343?login=false},
  urldate = {2023-01-16},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\64AYNG8B\\6763343.html}
}

@online{SpontaneousRecoveryDynamical,
  title = {Spontaneous Recovery in Dynamical Networks | {{Nature Physics}}},
  url = {https://www.nature.com/articles/nphys2819},
  urldate = {2022-10-03},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2NHPU6AD\\nphys2819.html}
}

@incollection{sprustonDendriticSignalIntegration2009,
  title = {Dendritic {{Signal Integration}}},
  booktitle = {Encyclopedia of {{Neuroscience}}},
  author = {Spruston, N.},
  editor = {Squire, Larry R.},
  date = {2009-01-01},
  pages = {445--452},
  publisher = {{Academic Press}},
  location = {{Oxford}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {http://www.sciencedirect.com/science/article/pii/B978008045046901648X},
  urldate = {2020-10-29},
  abstract = {Neurons integrate inputs from a large number of synapses in a process called synaptic integration. The term ‘dendritic integration’ refers to aspects of synaptic integration that occur in dendrites. To understand dendritic integration, it is necessary to understand basic principles of synaptic integration, as well as the ways in which branching dendrites affect synaptic integration. This article reviews what is known about these processes, beginning with simple examples of interactions between excitatory synapses and progressing to more complex cases, including dendritically localized excitatory and inhibitory synapses and the influence of dendritic voltage-gated channels on dendritic integration.},
  isbn = {978-0-08-045046-9},
  langid = {english},
  keywords = {Action potential,Axon,Dendrite,EPSP,Ion channel,IPSP,Synapse,Synaptic potential},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5LLI3CH2\\B978008045046901648X.html}
}

@article{sprustonPyramidalNeuronsDendritic2008,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {3},
  pages = {206--221},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2286},
  url = {http://www.nature.com/articles/nrn2286},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons are characterized by their distinct apical and basal dendritic trees and the pyramidal shape of their soma. They are found in several regions of the CNS and, although the reasons for their abundance remain unclear, functional studies — especially of CA1 hippocampal and layer V neocortical pyramidal neurons — have offered insights into the functions of their unique cellular architecture. Pyramidal neurons are not all identical, but some shared functional principles can be identified. In particular, the existence of dendritic domains with distinct synaptic inputs, excitability, modulation and plasticity appears to be a common feature that allows synapses throughout the dendritic tree to contribute to actionpotential generation. These properties support a variety of coincidence-detection mechanisms, which are likely to be crucial for synaptic integration and plasticity.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UNRPNYEG\\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf}
}

@article{sprustonPyramidalNeuronsDendritic2008a,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {9},
  number = {3},
  pages = {206--221},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn2286},
  url = {https://www.nature.com/articles/nrn2286},
  urldate = {2020-09-25},
  abstract = {Pyramidal neurons have basal and apical dendrites, including an apical tuft. This preserved core structure suggests that they have conserved core functions, whereas structural variation in other areas suggests additional functional specialization.A number of new methods for studying pyramidal-cell activation and circuitry are available. These include in vivo patch-clamp recording, optical activation and transgenic methods for activating, inactivating or labelling neurons and their connections.Synaptic inputs from distinct sources occur onto separate dendritic domains. Defining the degree to which synapses that carry different kinds of information are segregated onto different dendritic domains remains an important challenge.Most excitatory synapses onto pyramidal neurons occur on dendritic spines, but the structure of the synapses they receive differs between dendritic domains.Dendritic integration of synaptic input depends on the dendritic domain that is targeted. Synapses distant from the soma tend to produce less synaptic depolarization, but this might be countered by increasing the conductance of distal synapses or by activating voltage-gated channels in dendrites. Synapses on small-diameter dendrites cause larger local voltage changes, which reduce the effectiveness of synaptic scaling but increase the activation of voltage-gated conductances.Inhibitory synapses specifically target the axon, soma or different dendritic domains. Integration of inhibitory inputs also differs across cellular domains.The intrinsic firing properties of pyramidal neurons vary considerably. Along with variation in dendritic structure and channel distributions, such variability suggests that different pyramidal neurons might carry out specialized functions.Pyramidal-neuron dendrites contain voltage-gated channels that can influence synaptic integration. These channels can also support backpropagating action potentials and dendritically initiated spikes. Dendritic excitability is a general property of all pyramidal neurons studied so far, but the details differ between different types of pyramidal neurons. Although there is some evidence for dendritic excitability in vivo, much more work is needed in this area.Activation of a small fraction of the tens of thousands of excitatory synapses on a pyramidal neuron can probably evoke dendritic spikes, but these events do not always propagate to the soma and the axon. The coupling of dendritic spikes to axonal action-potential firing probably depends on the pattern of synaptic activation. This results in forms of coincidence detection that are determined by dendritic structure and excitability.Backpropagating action potentials and dendritic spikes are important signals for the induction of synaptic plasticity. Even single dendritic spikes can result in significant long-term potentiation or long-term depression.Neurotransmitters can modulate pyramidal-neuron function. At least some forms of modulation affect various dendritic domains and their synaptic inputs in different ways.Domain-specific properties in excitatory and inhibitory synaptic inputs, voltage-gated channels, dendritic excitability and neuromodulation all point to a multi-compartment model of pyramidal-neuron function. Elaborating simple models of pyramidal-neuron function based on these dendritic-domain-specific properties is a central challenge for the study of cortical function.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LI46IXAV\\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BPSPCV3A\\nrn2286.html}
}

@article{steinmetzEyeMovementPreparation2014,
  title = {Eye {{Movement Preparation Modulates Neuronal Responses}} in {{Area V4 When Dissociated}} from {{Attentional Demands}}},
  author = {Steinmetz, Nicholas A. and Moore, Tirin},
  date = {2014-07-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {83},
  number = {2},
  eprint = {25033188},
  eprinttype = {pmid},
  pages = {496--506},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.06.014},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(14)00536-4},
  urldate = {2023-01-03},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B9ZSX936\\Steinmetz and Moore - 2014 - Eye Movement Preparation Modulates Neuronal Respon.pdf}
}

@article{steinmetzEyeMovementPreparation2014a,
  title = {Eye {{Movement Preparation Modulates Neuronal Responses}} in {{Area V4 When Dissociated}} from {{Attentional Demands}}},
  author = {Steinmetz, Nicholas A. and Moore, Tirin},
  date = {2014-07-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {83},
  number = {2},
  eprint = {25033188},
  eprinttype = {pmid},
  pages = {496--506},
  publisher = {{Elsevier}},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.06.014},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(14)00536-4},
  urldate = {2023-01-05},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\73B3ECYS\\Steinmetz and Moore - 2014 - Eye Movement Preparation Modulates Neuronal Respon.pdf}
}

@article{steinNeuronalVariabilityNoise2005,
  title = {Neuronal Variability: Noise or Part of the Signal?},
  shorttitle = {Neuronal Variability},
  author = {Stein, Richard B. and Gossen, E. Roderich and Jones, Kelvin E.},
  date = {2005-05},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {6},
  number = {5},
  pages = {389--397},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/nrn1668},
  url = {https://www.nature.com/articles/nrn1668},
  urldate = {2022-10-20},
  abstract = {Traditionally, the rate of nerve impulses (spikes) over time was considered to be the main carrier of information in the nervous system. Therefore, any variability in the rate of response to a steady stimulus would reduce the information conveyed by a nerve cell. Many nerve cells fire with considerable variability, which would limit their ability to carry information to 2 or 3 bits in 1 s.With time-varying inputs containing the range of frequencies that the neuron responds to, values of information transmission of approximately 1 bit per spike have been calculated. For a neuron that fires tens or hundreds of spikes per second, much higher bit rates are possible than with steady inputs.Variability might also offer distinct advantages in preventing the entrainment of neurons to high-frequency signals. Enhanced sensitivity to weak signals has been proposed, which is known as 'stochastic resonance', as well as a role of variability in the method of Bayesian inference. Recent work on various sensory systems has emphasized the importance of timing, particularly that of first spikes, rather than the rate of firing over time.Rate coding might be more important in the motor system than precise timing. The variability in rate fluctuates with the mean rate (signal-dependent noise). The variability in the motor output in the presence of this noise can be minimized using optimal control theory.Optimal control theory predicts the form of many movements if a specific rule is assumed that relates the standard deviation in rate to the mean rate. This rule is not observed experimentally for either motor neurons or the motor cortex. However, the relationship between the standard deviation in muscle force and the mean force obeys the rule.The reason for the difference between the neural responses and the force output arises from the Henneman size principle. This states that the first recruited motor units are small and, hence, produce minor variations in force. Later motor units are larger and produce greater variations with the magnitude required by the optimal control theory.In the central nervous system, large excitatory postsynaptic potentials (EPSPs) can cause the near synchronous firing of groups of cells that might be important in attention, as well as learning and memory. Interactions in some areas, such as the hippocampus, between ongoing oscillations and spike activity might be used by 'place neurons' to locate the position of the body in external space. Therefore, variability in the firing rate of individual neurons is not simply noise, but might have a range of functions in neurons throughout the nervous system.},
  issue = {5},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SPPANQV7\\Stein et al. - 2005 - Neuronal variability noise or part of the signal.pdf}
}

@article{stephensBayesianInferenceComputational,
  title = {Bayesian {{Inference}}, {{Computational Methods}} and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  journaltitle = {Monte Carlo},
  pages = {641},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2BIY5RK6\\Stephens - Bayesian Inference, Computational Methods and Mont.pdf}
}

@article{stephensMATH598Bayesian,
  title = {{{MATH}} 598 - {{Bayesian Inference}}, {{Computational Methods}}   and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  pages = {251},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YXUD8S3Z\\Stephens - MATH 598 - Bayesian Inference, Computational Metho.pdf}
}

@article{stringerHighdimensionalGeometryPopulation2019,
  title = {High-Dimensional Geometry of Population Responses in Visual Cortex},
  author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
  date = {2019-07},
  journaltitle = {Nature},
  volume = {571},
  number = {7765},
  pages = {361--365},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1346-5},
  url = {https://www.nature.com/articles/s41586-019-1346-5},
  urldate = {2020-09-22},
  abstract = {A neuronal population encodes information most efficiently when its stimulus responses are high-dimensional and uncorrelated, and most robustly when they are lower-dimensional and correlated. Here we analysed the dimensionality of the encoding of natural images by large populations of neurons in the visual cortex of awake mice. The evoked population activity was high-dimensional, and correlations obeyed an unexpected power law: the nth principal component variance scaled as 1/n. This scaling was not inherited from the power law spectrum of natural images, because it persisted after stimulus whitening. We proved mathematically that if the variance spectrum was to decay more slowly then the population code could not be smooth, allowing small changes in input to dominate population activity. The theory also predicts larger power-law exponents for lower-dimensional stimulus ensembles, which we validated experimentally. These results suggest that coding smoothness may represent a fundamental constraint that determines correlations in neural population codes.},
  issue = {7765},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KZ4KXAA4\\Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B7ZDPWID\\s41586-019-1346-5.html}
}

@article{stuartDendriticIntegration602015,
  title = {Dendritic Integration: 60 Years of Progress},
  shorttitle = {Dendritic Integration},
  author = {Stuart, Greg J and Spruston, Nelson},
  date = {2015-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {12},
  pages = {1713--1721},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4157},
  url = {http://www.nature.com/articles/nn.4157},
  urldate = {2022-09-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LLV9TE6Q\\Stuart and Spruston - 2015 - Dendritic integration 60 years of progress.pdf}
}

@article{takahashiActiveDendriticCurrents2020,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-10},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {10},
  pages = {1277--1285},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2020-09-25},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  issue = {10},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DBTGY9LF\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CI6H8466\\s41593-020-0677-8.html}
}

@article{takahashiActiveDendriticCurrents2020a,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-08-03},
  journaltitle = {Nature Neuroscience},
  pages = {1--9},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2020-09-22},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HZSBVY3S\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RF7LAZU\\s41593-020-0677-8.html}
}

@article{takahashiActiveDendriticCurrents2020b,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {10},
  pages = {1277--1285},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2022-10-02},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  issue = {10},
  langid = {english},
  keywords = {Neuronal physiology,Neuroscience,Sensory processing,Somatosensory system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7MUYBULD\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SIQ82FNB\\s41593-020-0677-8.html}
}

@article{tangIntroductionFocusIssue2020,
  title = {Introduction to {{Focus Issue}}: {{When}} Machine Learning Meets Complex Systems: {{Networks}}, Chaos, and Nonlinear Dynamics},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Tang, Yang and Kurths, Jürgen and Lin, Wei and Ott, Edward and Kocarev, Ljupco},
  date = {2020-06},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {30},
  number = {6},
  pages = {063151},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0016505},
  url = {http://aip.scitation.org/doi/10.1063/5.0016505},
  urldate = {2020-09-30},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7WXCVSQ8\\Tang et al. - 2020 - Introduction to Focus Issue When machine learning.pdf}
}

@article{thieleNeuromodulationAttention2018,
  title = {Neuromodulation of {{Attention}}},
  author = {Thiele, Alexander and Bellgrove, Mark A.},
  date = {2018-02-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {97},
  number = {4},
  pages = {769--785},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.01.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627318300114},
  urldate = {2022-10-17},
  abstract = {Attention is critical to high-level cognition and attention deficits are a hallmark of neurologic and neuropsychiatric disorders. Although years of research indicates that distinct neuromodulators influence attentional control, a mechanistic account that traverses levels of analysis (cells, circuits, behavior) is missing. However, such an account is critical to guide the development of next-generation pharmacotherapies aimed at forestalling or remediating the global burden associated with disorders of attention. Here, we summarize current neuroscientific understanding of how attention affects single neurons and networks of neurons. We then review key results that have informed our understanding of how neuromodulation shapes these neuron and network properties and thereby enables the appropriate allocation of attention to relevant external or internal events. Finally, we highlight areas where we believe hypotheses can be formulated and tackled experimentally in the near future, thereby critically increasing our mechanistic understanding of how attention is implemented at the cellular and network levels.},
  langid = {english},
  keywords = {attention,attractor networks,neuromodulators,pharmacology,population coding,top-down},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LSKXKFB4\\Thiele and Bellgrove - 2018 - Neuromodulation of Attention.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E3L8UDQP\\S0896627318300114.html}
}

@article{toiVivoDirectImaging2022,
  title = {In Vivo Direct Imaging of Neuronal Activity at High Temporospatial Resolution},
  author = {Toi, Phan Tan and Jang, Hyun Jae and Min, Kyeongseon and Kim, Sung-Phil and Lee, Seung-Kyun and Lee, Jongho and Kwag, Jeehyun and Park, Jang-Yeon},
  date = {2022-10-14},
  journaltitle = {Science},
  volume = {378},
  number = {6616},
  pages = {160--168},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.abh4340},
  url = {https://www.science.org/doi/10.1126/science.abh4340},
  urldate = {2022-10-21},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LTCEHWJJ\\Toi et al. - 2022 - In vivo direct imaging of neuronal activity at hig.pdf}
}

@article{tokerConsciousnessSupportedNearcritical2022,
  title = {Consciousness Is Supported by Near-Critical Slow Cortical Electrodynamics},
  author = {Toker, Daniel and Pappas, Ioannis and Lendner, Janna D. and Frohlich, Joel and Mateos, Diego M. and Muthukumaraswamy, Suresh and Carhart-Harris, Robin and Paff, Michelle and Vespa, Paul M. and Monti, Martin M. and Sommer, Friedrich T. and Knight, Robert T. and D’Esposito, Mark},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {7},
  pages = {e2024455119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2024455119},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2024455119},
  urldate = {2022-10-06},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LESIMU5S\\Toker et al. - 2022 - Consciousness is supported by near-critical slow c.pdf}
}

@article{tokerConsciousnessSupportedNearcritical2022a,
  title = {Consciousness Is Supported by Near-Critical Slow Cortical Electrodynamics},
  author = {Toker, Daniel and Pappas, Ioannis and Lendner, Janna D. and Frohlich, Joel and Mateos, Diego M. and Muthukumaraswamy, Suresh and Carhart-Harris, Robin and Paff, Michelle and Vespa, Paul M. and Monti, Martin M. and Sommer, Friedrich T. and Knight, Robert T. and D’Esposito, Mark},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {119},
  number = {7},
  pages = {e2024455119},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2024455119},
  url = {https://pnas.org/doi/full/10.1073/pnas.2024455119},
  urldate = {2022-10-06},
  abstract = {Significance             What changes in the brain when we lose consciousness? One possibility is that the loss of consciousness corresponds to a transition of the brain’s electric activity away from edge-of-chaos criticality, or the knife’s edge in between stability and chaos. Recent mathematical developments have produced tools for testing this hypothesis, which we apply to cortical recordings from diverse brain states. We show that the electric activity of the cortex is indeed poised near the boundary between stability and chaos during conscious states and transitions away from this boundary during unconsciousness and that this transition disrupts cortical information processing.           ,              Mounting evidence suggests that during conscious states, the electrodynamics of the cortex are poised near a critical point or phase transition and that this near-critical behavior supports the vast flow of information through cortical networks during conscious states. Here, we empirically identify a mathematically specific critical point near which waking cortical oscillatory dynamics operate, which is known as the edge-of-chaos critical point, or the boundary between stability and chaos. We do so by applying the recently developed modified 0-1 chaos test to electrocorticography (ECoG) and magnetoencephalography (MEG) recordings from the cortices of humans and macaques across normal waking, generalized seizure, anesthesia, and psychedelic states. Our evidence suggests that cortical information processing is disrupted during unconscious states because of a transition of low-frequency cortical electric oscillations away from this critical point; conversely, we show that psychedelics may increase the information richness of cortical activity by tuning low-frequency cortical oscillations closer to this critical point. Finally, we analyze clinical electroencephalography (EEG) recordings from patients with disorders of consciousness (DOC) and show that assessing the proximity of slow cortical oscillatory electrodynamics to the edge-of-chaos critical point may be useful as an index of consciousness in the clinical setting.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DLUVJ82W\\Toker et al. - 2022 - Consciousness is supported by near-critical slow c.pdf}
}

@article{tomarVariabilityRandomnessInstantaneous2021,
  title = {Variability and {{Randomness}} of the {{Instantaneous Firing Rate}}},
  author = {Tomar, Rimjhim and Kostal, Lubomir},
  date = {2021},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {15},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2021.620410},
  urldate = {2022-10-17},
  abstract = {The apparent stochastic nature of neuronal activity significantly affects the reliability of neuronal coding. To quantify the encountered fluctuations, both in neural data and simulations, the notions of variability and randomness of inter-spike intervals have been proposed and studied. In this article we focus on the concept of the instantaneous firing rate, which is also based on the spike timing. We use several classical statistical models of neuronal activity and we study the corresponding probability distributions of the instantaneous firing rate. To characterize the firing rate variability and randomness under different spiking regimes, we use different indices of statistical dispersion. We find that the relationship between the variability of interspike intervals and the instantaneous firing rate is not straightforward in general. Counter-intuitively, an increase in the randomness (based on entropy) of spike times may either decrease or increase the randomness of instantaneous firing rate, in dependence on the neuronal firing model. Finally, we apply our methods to experimental data, establishing that instantaneous rate analysis can indeed provide additional information about the spiking activity.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7QXQ6WKF\\Tomar and Kostal - 2021 - Variability and Randomness of the Instantaneous Fi.pdf}
}

@article{tremblaySingleTrialDecodingVisual2015,
  title = {Single-{{Trial Decoding}} of {{Visual Attention}} from {{Local Field Potentials}} in the {{Primate Lateral Prefrontal Cortex Is Frequency-Dependent}}},
  author = {Tremblay, S. and Doucet, G. and Pieper, F. and Sachs, A. and Martinez-Trujillo, J.},
  date = {2015-06-17},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {Journal of Neuroscience},
  volume = {35},
  number = {24},
  pages = {9038--9049},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1041-15.2015},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1041-15.2015},
  urldate = {2022-10-03},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NMKZVHYC\\Tremblay et al. - 2015 - Single-Trial Decoding of Visual Attention from Loc.pdf}
}

@article{umakanthaBridgingNeuronalCorrelations2021,
  title = {Bridging Neuronal Correlations and Dimensionality Reduction},
  author = {Umakantha, Akash and Morina, Rudina and Cowley, Benjamin R. and Snyder, Adam C. and Smith, Matthew A. and Yu, Byron M.},
  date = {2021-09-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {17},
  pages = {2740-2754.e12},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.06.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627321004694},
  urldate = {2023-01-13},
  abstract = {Two commonly used approaches to study interactions among neurons are spike count correlation, which describes pairs of neurons, and dimensionality reduction, applied to a population of neurons. Although both approaches have been used to study trial-to-trial neuronal variability correlated among neurons, they are often used in isolation and have not been directly related. We first established concrete mathematical and empirical relationships between pairwise correlation and metrics of population-wide covariability based on dimensionality reduction. Applying these insights to macaque V4 population recordings, we found that the previously reported decrease in mean pairwise correlation associated with attention stemmed from three distinct changes in population-wide covariability. Overall, our work builds the intuition and formalism to bridge between pairwise correlation and population-wide covariability and presents a cautionary tale about the inferences one can make about population activity by using a single statistic, whether it be mean pairwise correlation or dimensionality.},
  langid = {english},
  keywords = {dimensionality reduction,neuronal population,spatial attention,spike count correlation,visual area V4},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J495QWHK\\Umakantha et al. - 2021 - Bridging neuronal correlations and dimensionality .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BHPI4WFQ\\S0896627321004694.html}
}

@online{UniversalExplorationNature,
  title = {Universal Exploration | {{Nature Physics}}},
  url = {https://www.nature.com/articles/nphys3445},
  urldate = {2022-10-05},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z9CZ3C37\\Universal exploration  Nature Physics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T6ESA2L7\\nphys3445.html}
}

@article{vankempenTopdownCoordinationLocal2021,
  title = {Top-down Coordination of Local Cortical State during Selective Attention},
  author = {van Kempen, Jochem and Gieselmann, Marc A. and Boyd, Michael and Steinmetz, Nicholas A. and Moore, Tirin and Engel, Tatiana A. and Thiele, Alexander},
  options = {useprefix=true},
  date = {2021-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {5},
  pages = {894-904.e8},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.12.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320309958},
  urldate = {2021-03-11},
  abstract = {Spontaneous fluctuations in cortical excitability influence sensory processing and behavior. These fluctuations, long thought to reflect global changes in cortical state, were recently found to be modulated locally within a retinotopic map during spatially selective attention. We report that periods of vigorous (On) and faint (Off) spiking activity, the signature of cortical state fluctuations, are coordinated across brain areas with retinotopic precision. Top-down attention enhanced interareal local state coordination, traversing along the reverse cortical hierarchy. The extent of local state coordination between areas was predictive of behavioral performance. Our results show that cortical state dynamics are shared across brain regions, modulated by cognitive demands and relevant for behavior.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M9VZXM8Y\\van Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf}
}

@article{vargaDendriticCodingMultiple2011,
  title = {Dendritic Coding of Multiple Sensory Inputs in Single Cortical Neurons in Vivo},
  author = {Varga, Zsuzsanna and Jia, Hongbo and Sakmann, Bert and Konnerth, Arthur},
  date = {2011-09-13},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {37},
  pages = {15420--15425},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1112355108},
  url = {https://www.pnas.org/doi/10.1073/pnas.1112355108},
  urldate = {2022-09-30},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8ADSB5LC\\Varga et al. - 2011 - Dendritic coding of multiple sensory inputs in sin.pdf}
}

@article{vilelaAreInputParameters2009,
  title = {Are the Input Parameters of White Noise Driven Integrate and Fire Neurons Uniquely Determined by Rate and {{CV}}?},
  author = {Vilela, Rafael D. and Lindner, Benjamin},
  date = {2009-03-07},
  journaltitle = {Journal of Theoretical Biology},
  shortjournal = {Journal of Theoretical Biology},
  volume = {257},
  number = {1},
  pages = {90--99},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2008.11.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0022519308005833},
  urldate = {2022-10-21},
  abstract = {Integrate and fire (IF) neurons have found widespread applications in computational neuroscience. Particularly important are stochastic versions of these models where the driving consists of a synaptic input modeled as white Gaussian noise with mean μ and noise intensity D. Different IF models have been proposed, the firing statistics of which depends nontrivially on the input parameters μ and D. In order to compare these models among each other, one must first specify the correspondence between their parameters. This can be done by determining which set of parameters (μ,D) of each model is associated with a given set of basic firing statistics as, for instance, the firing rate and the coefficient of variation (CV) of the interspike interval (ISI). However, it is not clear a priori whether for a given firing rate and CV there is only one unique choice of input parameters for each model. Here we review the dependence of rate and CV on input parameters for the perfect, leaky, and quadratic IF neuron models and show analytically that indeed in these three models the firing rate and the CV uniquely determine the input parameters.},
  langid = {english},
  keywords = {Neuronal models},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B99MXWT8\\Vilela and Lindner - 2009 - Are the input parameters of white noise driven int.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SGPRNI8P\\S0022519308005833.html}
}

@article{volohCellTypeSpecificBurst2018a,
  title = {Cell-{{Type Specific Burst Firing Interacts}} with {{Theta}} and {{Beta Activity}} in {{Prefrontal Cortex During Attention States}}},
  author = {Voloh, B and Womelsdorf, T},
  date = {2018-12-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {28},
  number = {12},
  pages = {4348--4364},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhx287},
  url = {https://doi.org/10.1093/cercor/bhx287},
  urldate = {2023-01-17},
  abstract = {Population-level theta and beta band activity in anterior cingulate and prefrontal cortices (ACC/PFC) are prominent signatures of self-controlled, adaptive behaviors. But how these rhythmic activities are linked to cell-type specific activity has remained unclear. Here, we suggest such a cell-to-systems level linkage. We found that the rate of burst spiking events is enhanced particularly during attention states and that attention-specific burst spikes have a unique temporal relationship to local theta and beta band population-level activities. For the 5–10 Hz theta frequency range, bursts coincided with transient increases of local theta power relative to nonbursts, particularly for bursts of putative interneurons. For the 16–30 Hz beta frequency, bursts of putative interneurons phase synchronized stronger than nonbursts, and were associated with larger beta power modulation. In contrast, burst of putative pyramidal cells showed similar beta power modulation as nonbursts, but were accompanied by stronger beta power only when they occurred early in the beta cycle. These findings suggest that in the ACC/PFC during attention states, mechanisms underlying burst firing are intimately linked to narrow band population-level activities, providing a cell-type specific window into rhythmic inhibitory gating and the emergence of rhythmically coherent network states during goal directed behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S5P7ITHJ\\Voloh and Womelsdorf - 2018 - Cell-Type Specific Burst Firing Interacts with The.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JG53UWXW\\4608049.html}
}

@article{vuLectureEntropyMutual,
  title = {Lecture 2: {{Entropy}} and Mutual Information},
  author = {Vu, Mai},
  journaltitle = {Electrical and Computer Engineering},
  pages = {8},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IGNQUY2E\\Vu - Lecture 2 Entropy and mutual information.pdf}
}

@article{wangAllenMouseBrain2020,
  title = {The {{Allen Mouse Brain Common Coordinate Framework}}: {{A 3D Reference Atlas}}},
  shorttitle = {The {{Allen Mouse Brain Common Coordinate Framework}}},
  author = {Wang, Quanxin and Ding, Song-Lin and Li, Yang and Royall, Josh and Feng, David and Lesnar, Phil and Graddis, Nile and Naeemi, Maitham and Facer, Benjamin and Ho, Anh and Dolbeare, Tim and Blanchard, Brandon and Dee, Nick and Wakeman, Wayne and Hirokawa, Karla E. and Szafer, Aaron and Sunkin, Susan M. and Oh, Seung Wook and Bernard, Amy and Phillips, John W. and Hawrylycz, Michael and Koch, Christof and Zeng, Hongkui and Harris, Julie A. and Ng, Lydia},
  date = {2020-05-14},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {181},
  number = {4},
  pages = {936-953.e20},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2020.04.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0092867420304025},
  urldate = {2023-01-09},
  abstract = {Recent large-scale collaborations are generating major surveys of cell types and connections in the mouse brain, collecting large amounts of data across modalities, spatial scales, and brain areas. Successful integration of these data requires a standard 3D reference atlas. Here, we present the Allen Mouse Brain Common Coordinate Framework (CCFv3) as such a resource. We constructed an average template brain at 10~μm voxel resolution by interpolating high resolution in-plane serial two-photon tomography images with 100~μm z-sampling from 1,675 young adult C57BL/6J mice. Then, using multimodal reference data, we parcellated the entire brain directly in 3D, labeling every voxel with a brain structure spanning 43 isocortical areas and their layers, 329 subcortical gray matter structures, 81 fiber tracts, and 8 ventricular structures. CCFv3 can be used to analyze, visualize, and integrate multimodal and multiscale datasets in 3D and is openly accessible (https://atlas.brain-map.org/).},
  langid = {english},
  keywords = {3D brain atlas,average mouse brain,brain anatomy,brain parcellation,CCFv3,common coordinate framework,fiber tracts,mouse cortex,reference atlas,transgenic mice},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YMNMSIL6\\Wang et al. - 2020 - The Allen Mouse Brain Common Coordinate Framework.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C733IGKW\\S0092867420304025.html}
}

@article{wangControlFiringMode1993,
  title = {Control of Firing Mode of Corticotectal and Corticopontine Layer {{V}} Burst-Generating Neurons by Norepinephrine, Acetylcholine, and {{1S}},{{3R- ACPD}}},
  author = {Wang, Z. and McCormick, D. A.},
  date = {1993-05-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {13},
  number = {5},
  eprint = {8386756},
  eprinttype = {pmid},
  pages = {2199--2216},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.13-05-02199.1993},
  url = {https://www.jneurosci.org/content/13/5/2199},
  urldate = {2023-01-16},
  abstract = {The ionic mechanisms by which the firing mode of layer V burst- generating neurons is modulated by noradrenergic, cholinergic, and glutamate metabotropic receptors were investigated with intracellular and extracellular recordings obtained in slices of guinea pig sensorimotor and primary visual cortices maintained in vitro. Extracellular and intracellular recordings revealed that a subset of layer V cells spontaneously generated bursts of three to six action potentials with an interburst frequency of 0.2–4 Hz. Depolarization of these cells with the intracellular injection of current inhibited burst firing and switched the cells to the tonic, single-spike mode of action potential generation. Intracellular recording from retrogradely labeled layer V pyramidal cells that project to either the superior colliculus or pontine nuclei revealed that a substantial portion of these are burst-generating cells. Application of norepinephrine (NE), the glutamate metabotropic receptor agonist 1S,3R-aminocyclopentane-1,3- dicarboxylic acid (ACPD), or ACh to layer V burst-generating cells resulted in depolarization and a subsequent shift in firing pattern from spontaneously bursting to single-spike activity. Pharmacological analysis of these responses indicated that they are mediated by the alpha 1-adrenoceptor for NE and the muscarinic subtype for ACh. Thus, the NE response was mimicked by the alpha-agonist phenylephrine but not by the beta-agonist isoprenaline, and was completely blocked by the alpha 1-antagonist prazosin but not by the alpha 2-antagonist yohimbine or the beta-antagonist propranolol. Finally, the ACh effect could be mimicked by the muscarinic agonist acetyl-beta-methylcholine (MCh) and was blocked by the muscarinic antagonist scopolamine. Intracellular recordings revealed that the NE-, MCh-, and ACPD-induced responses in bursting neurons are due to the direct activation of receptors on these cells, since block of synaptic transmission with local application of TTX or bath application of low [Ca2+]o and raised [Mg2+]o did not block the postsynaptic responses. Voltage-clamp analysis of the currents involved in the depolarizing responses of bursting cells revealed that activation of alpha 1-adrenergic, muscarinic, or glutamate metabotropic receptors resulted in a decrease in a potassium conductance that consisted of both a voltage-independent component and a voltage- and Ca(2+)-sensitive component. These results suggest that increased activity in noradrenergic, cholinergic, and glutamatergic pathways may control the firing mode of layer V corticotectal and corticopontine pyramidal cells by determining the resting membrane potential through modulation of both voltage-dependent and voltage-independent K+ conductances.(ABSTRACT TRUNCATED AT 400 WORDS)},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PBXH94RQ\\Wang and McCormick - 1993 - Control of firing mode of corticotectal and cortic.pdf}
}

@article{williamsInformationTheoreticAnalysis,
  title = {An {{Information Theoretic Analysis}} of {{Neural Multiplexing}}},
  author = {Williams, Ezekiel},
  pages = {94},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S6XESADU\\Williams - An Information Theoretic Analysis of Neural Multip.pdf}
}

@article{williamsNeuralBurstCodes2021,
  title = {Neural Burst Codes Disguised as Rate Codes},
  author = {Williams, Ezekiel and Payeur, Alexandre and Gidon, Albert and Naud, Richard},
  date = {2021-08-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {15910},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-95037-z},
  url = {https://doi.org/10.1038/s41598-021-95037-z},
  abstract = {The burst coding hypothesis posits that the occurrence of sudden high-frequency patterns of action potentials constitutes a salient syllable of the neural code. Many neurons, however, do not produce clearly demarcated bursts, an observation invoked to rule out the pervasiveness of this coding scheme across brain areas and cell types. Here we ask how detrimental ambiguous spike patterns, those that are neither clearly bursts nor isolated spikes, are for neuronal information transfer. We addressed this question using information theory and computational simulations. By quantifying how information transmission depends on firing statistics, we found that the information transmitted is not strongly influenced by the presence of clearly demarcated modes in the interspike interval distribution, a feature often used to identify the presence of burst coding. Instead, we found that neurons having unimodal interval distributions were still able to ascribe different meanings to bursts and isolated spikes. In this regime, information transmission depends on dynamical properties of the synapses as well as the length and relative frequency of bursts. Furthermore, we found that common metrics used to quantify burstiness were unable to predict the degree with which bursts could be used to carry information. Our results provide guiding principles for the implementation of coding strategies based on spike-timing patterns, and show that even unimodal firing statistics can be consistent with a bivariate neural code.}
}

@article{womelsdorfDynamicCircuitMotifs2014,
  title = {Dynamic Circuit Motifs Underlying Rhythmic Gain Control, Gating and Integration},
  author = {Womelsdorf, Thilo and Valiante, Taufik A. and Sahin, Ned T. and Miller, Kai J. and Tiesinga, Paul},
  date = {2014-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {8},
  pages = {1031--1039},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/nn.3764},
  url = {https://www.nature.com/articles/nn.3764},
  urldate = {2023-01-03},
  abstract = {In this paper, Womelsdorf and colleagues review the recent advances in our understanding of how rhythmic activity across multiple frequency bands and brain areas affects neural computations. The authors suggest a dynamic tripartite motif framework that links the activity signatures of given circuits with their structural elements and the proposed computational output.},
  issue = {8},
  langid = {english},
  keywords = {Attention,Dynamical systems,Neurophysiology,Psychology},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ITTCIEBL\\Womelsdorf et al. - 2014 - Dynamic circuit motifs underlying rhythmic gain co.pdf}
}

@article{womelsdorfModulationNeuronalInteractions2007,
  title = {Modulation of {{Neuronal Interactions Through Neuronal Synchronization}}},
  author = {Womelsdorf, Thilo and Schoffelen, Jan-Mathijs and Oostenveld, Robert and Singer, Wolf and Desimone, Robert and Engel, Andreas K. and Fries, Pascal},
  date = {2007-06-15},
  journaltitle = {Science},
  volume = {316},
  number = {5831},
  pages = {1609--1612},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1139597},
  url = {https://www.science.org/doi/10.1126/science.1139597},
  urldate = {2023-01-17},
  abstract = {Brain processing depends on the interactions between neuronal groups. Those interactions are governed by the pattern of anatomical connections and by yet unknown mechanisms that modulate the effective strength of a given connection. We found that the mutual influence among neuronal groups depends on the phase relation between rhythmic activities within the groups. Phase relations supporting interactions between the groups preceded those interactions by a few milliseconds, consistent with a mechanistic role. These effects were specific in time, frequency, and space, and we therefore propose that the pattern of synchronization flexibly determines the pattern of neuronal interactions.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\99CYABJF\\Womelsdorf et al. - 2007 - Modulation of Neuronal Interactions Through Neuron.pdf}
}

@article{woodStatisticalInferenceNoisy2010,
  title = {Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems},
  author = {Wood, Simon N.},
  date = {2010-08},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {466},
  number = {7310},
  pages = {1102--1104},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature09319},
  url = {http://www.nature.com/articles/nature09319},
  urldate = {2020-10-26},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\369DUHQK\\Wood - 2010 - Statistical inference for noisy nonlinear ecologic.pdf}
}

@article{xueSpatialAttentionReduces2017,
  title = {Spatial {{Attention Reduces Burstiness}} in {{Macaque Visual Cortical Area MST}}},
  author = {Xue, Cheng and Kaping, Daniel and Ray, Sonia Baloni and Krishna, B. Suresh and Treue, Stefan},
  date = {2017-01-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {27},
  number = {1},
  pages = {83--91},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw326},
  url = {https://doi.org/10.1093/cercor/bhw326},
  urldate = {2023-01-03},
  abstract = {Visual attention modulates the firing rate of neurons in many primate cortical areas. In V4, a cortical area in the ventral visual pathway, spatial attention has also been shown to reduce the tendency of neurons to fire closely separated spikes (burstiness). A recent model proposes that a single mechanism accounts for both the firing rate enhancement and the burstiness reduction in V4, but this has not been empirically tested. It is also unclear if the burstiness reduction by spatial attention is found in other visual areas and for other attentional types. We therefore recorded from single neurons in the medial superior temporal area (MST), a key motion-processing area along the dorsal visual pathway, of two rhesus monkeys while they performed a task engaging both spatial and feature-based attention. We show that in MST, spatial attention is associated with a clear reduction in burstiness that is independent of the concurrent enhancement of firing rate. In contrast, feature-based attention enhances firing rate but is not associated with a significant reduction in burstiness. These results establish burstiness reduction as a widespread effect of spatial attention. They also suggest that in contrast to the recently proposed model, the effects of spatial attention on burstiness and firing rate emerge from different mechanisms.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NDXS42YR\\Xue et al. - 2017 - Spatial Attention Reduces Burstiness in Macaque Vi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6QC6GG36\\2557336.html}
}

@article{yooNeuralInterfaceSystems2021,
  title = {Neural Interface Systems with On-Device Computing: Machine Learning and Neuromorphic Architectures},
  shorttitle = {Neural Interface Systems with On-Device Computing},
  author = {Yoo, Jerald and Shoaran, Mahsa},
  date = {2021-12-01},
  journaltitle = {Current Opinion in Biotechnology},
  shortjournal = {Current Opinion in Biotechnology},
  series = {Tissue, {{Cell}} and {{Pathway Engineering}}},
  volume = {72},
  pages = {95--101},
  issn = {0958-1669},
  doi = {10.1016/j.copbio.2021.10.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0958166921001993},
  urldate = {2022-10-26},
  abstract = {Development of neural interface and brain-machine interface (BMI) systems enables the treatment of neurological disorders including cognitive, sensory, and motor dysfunctions. While neural interfaces have steadily decreased in form factor, recent developments target pervasive implantables. Along with advances in electrodes, neural recording, and neurostimulation circuits, integration of disease biomarkers and machine learning algorithms enables real-time and on-site processing of neural activity with no need for power-demanding telemetry. This recent trend on combining artificial intelligence and machine learning with modern neural interfaces will lead to a new generation of low-power, smart, and miniaturized therapeutic devices for a wide range of neurological and psychiatric disorders. This paper reviews the recent development of the ‘on-chip’ machine learning and neuromorphic architectures, which is one of the key puzzles in devising next-generation clinically viable neural interface systems.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BEDHMESH\\Yoo and Shoaran - 2021 - Neural interface systems with on-device computing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7UFDVLA9\\S0958166921001993.html}
}

@article{yuGaussianProcessFactorAnalysis2009,
  title = {Gaussian-{{Process Factor Analysis}} for {{Low-Dimensional Single-Trial Analysis}} of {{Neural Population Activity}}},
  author = {Yu, Byron M. and Cunningham, John P. and Santhanam, Gopal and Ryu, Stephen I. and Shenoy, Krishna V. and Sahani, Maneesh},
  date = {2009-07},
  journaltitle = {Journal of Neurophysiology},
  volume = {102},
  number = {1},
  pages = {614--635},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.90941.2008},
  url = {https://journals.physiology.org/doi/full/10.1152/jn.90941.2008},
  urldate = {2022-09-23},
  abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SYE4T6G6\\Yu et al. - 2009 - Gaussian-Process Factor Analysis for Low-Dimension.pdf}
}

@article{yuGaussianProcessFactorAnalysis2009a,
  title = {Gaussian-{{Process Factor Analysis}} for {{Low-Dimensional Single-Trial Analysis}} of {{Neural Population Activity}}},
  author = {Yu, Byron M. and Cunningham, John P. and Santhanam, Gopal and Ryu, Stephen I. and Shenoy, Krishna V. and Sahani, Maneesh},
  date = {2009-07},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J Neurophysiol},
  volume = {102},
  number = {1},
  eprint = {19357332},
  eprinttype = {pmid},
  pages = {614--635},
  issn = {0022-3077},
  doi = {10.1152/jn.90941.2008},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2712272/},
  urldate = {2022-09-26},
  abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
  pmcid = {PMC2712272},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SRNKXC5C\\Yu et al. - 2009 - Gaussian-Process Factor Analysis for Low-Dimension.pdf}
}

@article{yuImprovedToolsStudy2020,
  title = {Improved Tools to Study Astrocytes},
  author = {Yu, Xinzhu and Nagai, Jun and Khakh, Baljit S.},
  date = {2020-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {3},
  pages = {121--138},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0264-8},
  url = {https://www.nature.com/articles/s41583-020-0264-8},
  urldate = {2020-11-20},
  abstract = {Astrocytes are a type of glial cell that tile the CNS. They interact with multiple cell types, including neurons, glial cells and blood vessels, and are involved or implicated in brain disorders. Progress has been made in understanding astrocytes, but the field lacks detailed information concerning how they perform their multifarious functions, and how and when they influence the operations of the neural circuits with which they interact. One recognized bottleneck to progress has been the paucity of reliable tools with which to explore astrocytes within the adult vertebrate CNS in vivo. However, improved tools for molecular, genetic, morphological and physiological assessments have been developed recently or have been adapted from their original purposes to study neurons and are now being used to systematically document and interrogate astrocyte biology in vivo. These tools, their uses and limitations, and the insights that they afford are summarized in this Review.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RZ28HLLC\\Yu et al. - 2020 - Improved tools to study astrocytes.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2EWD3J5K\\s41583-020-0264-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8VP7T2B5\\s41583-020-0264-8.html}
}

@article{yusteCommunitybasedTranscriptomicsClassification2020,
  title = {A Community-Based Transcriptomics Classification and Nomenclature of Neocortical Cell Types},
  author = {Yuste, Rafael and Hawrylycz, Michael and Aalling, Nadia and Aguilar-Valles, Argel and Arendt, Detlev and Arnedillo, Ruben Armananzas and Ascoli, Giorgio A. and Bielza, Concha and Bokharaie, Vahid and Bergmann, Tobias Borgtoft and Bystron, Irina and Capogna, Marco and Chang, Yoonjeung and Clemens, Ann and de Kock, Christiaan P. J. and DeFelipe, Javier and Dos Santos, Sandra Esmeralda and Dunville, Keagan and Feldmeyer, Dirk and Fiáth, Richárd and Fishell, Gordon James and Foggetti, Angelica and Gao, Xuefan and Ghaderi, Parviz and Goriounova, Natalia A. and Güntürkün, Onur and Hagihara, Kenta and Hall, Vanessa Jane and Helmstaedter, Moritz and Herculano, Suzana and Hilscher, Markus M. and Hirase, Hajime and Hjerling-Leffler, Jens and Hodge, Rebecca and Huang, Josh and Huda, Rafiq and Khodosevich, Konstantin and Kiehn, Ole and Koch, Henner and Kuebler, Eric S. and Kühnemund, Malte and Larrañaga, Pedro and Lelieveldt, Boudewijn and Louth, Emma Louise and Lui, Jan H. and Mansvelder, Huibert D. and Marin, Oscar and Martinez-Trujillo, Julio and Moradi Chameh, Homeira and Nath, Alok and Nedergaard, Maiken and Němec, Pavel and Ofer, Netanel and Pfisterer, Ulrich Gottfried and Pontes, Samuel and Redmond, William and Rossier, Jean and Sanes, Joshua R. and Scheuermann, Richard and Serrano-Saiz, Esther and Steiger, Jochen F. and Somogyi, Peter and Tamás, Gábor and Tolias, Andreas Savas and Tosches, Maria Antonietta and García, Miguel Turrero and Vieira, Hermany Munguba and Wozny, Christian and Wuttke, Thomas V. and Yong, Liu and Yuan, Juan and Zeng, Hongkui and Lein, Ed},
  options = {useprefix=true},
  date = {2020-08-24},
  journaltitle = {Nature Neuroscience},
  pages = {1--13},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0685-8},
  url = {https://www.nature.com/articles/s41593-020-0685-8},
  urldate = {2020-08-31},
  abstract = {To understand the function of cortical circuits, it is necessary to catalog their cellular diversity. Past attempts to do so using anatomical, physiological or molecular features of cortical cells have not resulted in a unified taxonomy of neuronal or glial cell types, partly due to limited data. Single-cell transcriptomics is enabling, for the first time, systematic high-throughput measurements of cortical cells and generation of datasets that hold the promise of being complete, accurate and permanent. Statistical analyses of these data reveal clusters that often correspond to cell types previously defined by morphological or physiological criteria and that appear conserved across cortical areas and species. To capitalize on these new methods, we propose the adoption of a transcriptome-based taxonomy of cell types for mammalian neocortex. This classification should be hierarchical and use a standardized nomenclature. It should be based on a probabilistic definition of a cell type and incorporate data from different approaches, developmental stages and species. A community-based classification and data aggregation model, such as a knowledge graph, could provide a common foundation for the study of cortical circuits. This community-based classification, nomenclature and data aggregation could serve as an example for cell type atlases in other parts of the body.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZUITQXWX\\Yuste et al. - 2020 - A community-based transcriptomics classification a.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LS9FFTT6\\s41593-020-0685-8.html}
}

@article{zeiselMolecularArchitectureMouse2018,
  title = {Molecular {{Architecture}} of the {{Mouse Nervous System}}},
  author = {Zeisel, Amit and Hochgerner, Hannah and Lönnerberg, Peter and Johnsson, Anna and Memic, Fatima and van der Zwan, Job and Häring, Martin and Braun, Emelie and Borm, Lars E. and La Manno, Gioele and Codeluppi, Simone and Furlan, Alessandro and Lee, Kawai and Skene, Nathan and Harris, Kenneth D. and Hjerling-Leffler, Jens and Arenas, Ernest and Ernfors, Patrik and Marklund, Ulrika and Linnarsson, Sten},
  options = {useprefix=true},
  date = {2018-08},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {174},
  number = {4},
  pages = {999-1014.e22},
  issn = {00928674},
  doi = {10.1016/j.cell.2018.06.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S009286741830789X},
  urldate = {2020-09-02},
  abstract = {The mammalian nervous system executes complex behaviors controlled by specialized, precisely positioned, and interacting cell types. Here, we used RNA sequencing of half a million single cells to create a detailed census of cell types in the mouse nervous system. We mapped cell types spatially and derived a hierarchical, data-driven taxonomy. Neurons were the most diverse and were grouped by developmental anatomical units and by the expression of neurotransmitters and neuropeptides. Neuronal diversity was driven by genes encoding cell identity, synaptic connectivity, neurotransmission, and membrane conductance. We discovered seven distinct, regionally restricted astrocyte types that obeyed developmental boundaries and correlated with the spatial distribution of key glutamate and glycine neurotransmitters. In contrast, oligodendrocytes showed a loss of regional identity followed by a secondary diversification. The resource presented here lays a solid foundation for understanding the molecular architecture of the mammalian nervous system and enables genetic manipulation of specific cell types.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8V6QUQWJ\\Zeisel et al. - 2018 - Molecular Architecture of the Mouse Nervous System.pdf}
}

@article{zenkeDiverseSynapticPlasticity2015,
  title = {Diverse Synaptic Plasticity Mechanisms Orchestrated to Form and Retrieve Memories in Spiking Neural Networks},
  author = {Zenke, Friedemann and Agnes, Everton J. and Gerstner, Wulfram},
  date = {2015-04-21},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {6},
  number = {1},
  pages = {6922},
  publisher = {{Nature Publishing Group}},
  issn = {2041-1723},
  doi = {10.1038/ncomms7922},
  url = {https://www.nature.com/articles/ncomms7922},
  urldate = {2022-10-21},
  abstract = {Synaptic plasticity, the putative basis of learning and memory formation, manifests in various forms and across different timescales. Here we show that the interaction of Hebbian homosynaptic plasticity with rapid non-Hebbian heterosynaptic plasticity is, when complemented with slower homeostatic changes and consolidation, sufficient for assembly formation and memory recall in a spiking recurrent network model of excitatory and inhibitory neurons. In the model, assemblies were formed during repeated sensory stimulation and characterized by strong recurrent excitatory connections. Even days after formation, and despite ongoing network activity and synaptic plasticity, memories could be recalled through selective delay activity following the brief stimulation of a subset of assembly neurons. Blocking any component of plasticity prevented stable functioning as a memory network. Our modelling results suggest that the diversity of plasticity phenomena in the brain is orchestrated towards achieving common functional goals.},
  issue = {1},
  langid = {english},
  keywords = {Learning and memory,Neural circuits,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\352AERJF\\Zenke et al. - 2015 - Diverse synaptic plasticity mechanisms orchestrate.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KBFFA46F\\ncomms7922.html}
}

@article{zeraatiAttentionalModulationIntrinsic2021,
  title = {Attentional Modulation of Intrinsic Timescales in Visual Cortex and Spatial Networks},
  author = {Zeraati, Roxana and Shi, Yan-Liang and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Levina, Anna and Engel, Tatiana A.},
  date = {2021},
  journaltitle = {bioRxiv},
  publisher = {{Cold Spring Harbor Laboratory}}
}

@article{zhangConvolutionalNeuralNetwork2019,
  title = {Convolutional Neural Network Models of {{V1}} Responses to Complex Patterns},
  author = {Zhang, Yimeng and Lee, Tai Sing and Li, Ming and Liu, Fang and Tang, Shiming},
  date = {2019-02-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {46},
  number = {1},
  pages = {33--54},
  issn = {1573-6873},
  doi = {10.1007/s10827-018-0687-7},
  url = {https://doi.org/10.1007/s10827-018-0687-7},
  urldate = {2020-10-08},
  abstract = {In this study, we evaluated the convolutional neural network (CNN) method for modeling V1 neurons of awake macaque monkeys in response to a large set of complex pattern stimuli. CNN models outperformed all the other baseline models, such as Gabor-based standard models for V1 cells and various variants of generalized linear models. We then systematically dissected different components of the CNN and found two key factors that made CNNs outperform other models: thresholding nonlinearity and convolution. In addition, we fitted our data using a pre-trained deep CNN via transfer learning. The deep CNN’s higher layers, which encode more complex patterns, outperformed lower ones, and this result was consistent with our earlier work on the complexity of V1 neural code. Our study systematically evaluates the relative merits of different CNN components in the context of V1 neuron modeling.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RTJIZRDF\\Zhang et al. - 2019 - Convolutional neural network models of V1 response.pdf}
}
