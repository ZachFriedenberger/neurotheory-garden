@online{5f04e48f3e184600cbc92a05,
  title = {5f04e48f3e184600cbc92a05},
  url = {https://mfr.ca-1.osf.io/render?url=https://osf.io/9hkg2/?direct%26mode=render%26action=download%26mode=render},
  urldate = {2020-10-16},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2LUDM9CC\render.html}
}

@article{abbottEffectCorrelatedVariability1999,
  title = {The {{Effect}} of {{Correlated Variability}} on the {{Accuracy}} of a {{Population Code}}},
  author = {Abbott, L. F. and Dayan, Peter},
  date = {1999-01-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {11},
  number = {1},
  pages = {91--101},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/089976699300016827},
  url = {https://direct.mit.edu/neco/article/11/1/91-101/6229},
  urldate = {2023-04-08},
  abstract = {We study the impact of correlated neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a population code.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ESNA86ZR\Abbott and Dayan - 1999 - The Effect of Correlated Variability on the Accura.pdf}
}

@article{abbottEffectCorrelatedVariability1999a,
  title = {The {{Effect}} of {{Correlated Variability}} on the {{Accuracy}} of a {{Population Code}}},
  author = {Abbott, L. F. and Dayan, Peter},
  date = {1999-01-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {11},
  number = {1},
  pages = {91--101},
  issn = {0899-7667},
  doi = {10.1162/089976699300016827},
  url = {https://doi.org/10.1162/089976699300016827},
  urldate = {2023-04-08},
  abstract = {We study the impact of correlated neuronal firing rate variability on the accuracy with which an encoded quantity can be extracted from a population of neurons. Contrary to widespread belief, correlations in the variabilities of neuronal firing rates do not, in general, limit the increase in coding accuracy provided by using large populations of encoding neurons. Furthermore, in some cases, but not all, correlations improve the accuracy of a population code.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7Z86KXRI\\Abbott and Dayan - 1999 - The Effect of Correlated Variability on the Accura.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7BGX2IIJ\\The-Effect-of-Correlated-Variability-on-the.html}
}

@article{abdolrahmaniAttentionSeparatesSensory2021,
  title = {Attention Separates Sensory and Motor Signals in the Mouse Visual Cortex},
  author = {Abdolrahmani, Mohammad and Lyamzin, Dmitry R. and Aoki, Ryo and Benucci, Andrea},
  date = {2021-07-13},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {36},
  number = {2},
  pages = {109377},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2021.109377},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124721007750},
  urldate = {2023-01-03},
  abstract = {Visually guided behaviors depend on the activity of cortical networks receiving visual inputs and transforming these signals to guide appropriate actions. However, non-retinal inputs, carrying motor signals as well as cognitive and attentional modulatory signals, also activate these cortical regions. How these networks integrate coincident signals ensuring reliable visual behaviors is poorly understood. In this study, we observe neural responses in the dorsal-parietal cortex of mice during a visual discrimination task driven by visual stimuli and movements. We find that visual and motor signals interact according to two mechanisms: divisive normalization and separation of responses. Interactions are contextually modulated by the animal’s state of sustained attention, which amplifies visual and motor signals and increases their discriminability in a low-dimensional space of neural activations. These findings reveal computational principles operating in dorsal-parietal networks that enable separation of incoming signals for reliable visually guided behaviors during interactions with the environment.},
  langid = {english},
  keywords = {behavior,decision-making,mouse,movement-related activity,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VMH2H3TK\\Abdolrahmani et al. - 2021 - Attention separates sensory and motor signals in t.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RK8ATIK5\\S2211124721007750.html}
}

@article{abdolrahmaniAttentionSeparatesSensory2021a,
  title = {Attention Separates Sensory and Motor Signals in the Mouse Visual Cortex},
  author = {Abdolrahmani, Mohammad and Lyamzin, Dmitry R. and Aoki, Ryo and Benucci, Andrea},
  date = {2021-07-13},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {36},
  number = {2},
  pages = {109377},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2021.109377},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124721007750},
  urldate = {2023-01-10},
  abstract = {Visually guided behaviors depend on the activity of cortical networks receiving visual inputs and transforming these signals to guide appropriate actions. However, non-retinal inputs, carrying motor signals as well as cognitive and attentional modulatory signals, also activate these cortical regions. How these networks integrate coincident signals ensuring reliable visual behaviors is poorly understood. In this study, we observe neural responses in the dorsal-parietal cortex of mice during a visual discrimination task driven by visual stimuli and movements. We find that visual and motor signals interact according to two mechanisms: divisive normalization and separation of responses. Interactions are contextually modulated by the animal’s state of sustained attention, which amplifies visual and motor signals and increases their discriminability in a low-dimensional space of neural activations. These findings reveal computational principles operating in dorsal-parietal networks that enable separation of incoming signals for reliable visually guided behaviors during interactions with the environment.},
  langid = {english},
  keywords = {behavior,decision-making,mouse,movement-related activity,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FB57TKTA\\Abdolrahmani et al. - 2021 - Attention separates sensory and motor signals in t.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YEJBA6SM\\S2211124721007750.html}
}

@article{abelFunctionalNetworkInference2016,
  title = {✅ {{Functional}} Network Inference of the Suprachiasmatic Nucleus},
  author = {Abel, John H. and Meeker, Kirsten and Granados-Fuentes, Daniel and St. John, Peter C. and Wang, Thomas J. and Bales, Benjamin B. and Doyle, Francis J. and Herzog, Erik D. and Petzold, Linda R.},
  date = {2016-04-19},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {113},
  number = {16},
  pages = {4512--4517},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1521178113},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1521178113},
  urldate = {2023-02-22},
  abstract = {In the mammalian suprachiasmatic nucleus (SCN), noisy cellular oscillators communicate within a neuronal network to generate precise system-wide circadian rhythms. Although the intracellular genetic oscillator and intercellular biochemical coupling mechanisms have been examined previously, the network topology driving synchronization of the SCN has not been elucidated. This network has been particularly challenging to probe, due to its oscillatory components and slow coupling timescale. In this work, we investigated the SCN network at a single-cell resolution through a chemically induced desynchronization. We then inferred functional connections in the SCN by applying the maximal information coefficient statistic to bioluminescence reporter data from individual neurons while they resynchronized their circadian cycling. Our results demonstrate that the functional network of circadian cells associated with resynchronization has small-world characteristics, with a node degree distribution that is exponential. We show that hubs of this small-world network are preferentially located in the central SCN, with sparsely connected shells surrounding these cores. Finally, we used two computational models of circadian neurons to validate our predictions of network structure.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9HRPEQDE\Abel et al. - 2016 - Functional network inference of the suprachiasmati.pdf}
}

@online{aghamohammadiDoublyStochasticRenewal2024,
  title = {A Doubly Stochastic Renewal Framework for Partitioning Spiking Variability},
  author = {Aghamohammadi, Cina and Chandrasekaran, Chandramouli and Engel, Tatiana A.},
  date = {2024-02-23},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.02.21.581457},
  doi = {10.1101/2024.02.21.581457},
  url = {https://www.biorxiv.org/content/10.1101/2024.02.21.581457v1},
  urldate = {2024-03-31},
  abstract = {The firing rate is a prevalent concept used to describe neural computations, but estimating dynamically changing firing rates from irregular spikes is challenging. An inhomogeneous Poisson process, the standard model for partitioning firing rate and spiking irregularity, cannot account for diverse spike statistics observed across neurons. We introduce a doubly stochastic renewal point process, a flexible mathematical framework for partitioning spiking variability, which captures the broad spectrum of spiking irregularity from periodic to super-Poisson. We validate our partitioning framework using intracellular voltage recordings and develop a method for estimating spiking irregularity from data. We find that the spiking irregularity of cortical neurons decreases from sensory to association areas and is nearly constant for each neuron under many conditions but can also change across task epochs. A spiking network model shows that spiking irregularity depends on connectivity and can change with external input. These results help improve the precision of estimating firing rates on single trials and constrain mechanistic models of neural circuits.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DERCCHMI\Aghamohammadi et al. - 2024 - A doubly stochastic renewal framework for partitio.pdf}
}

@article{ahissarAttentionalControlEarly1993,
  title = {Attentional Control of Early Perceptual Learning.},
  author = {Ahissar, M and Hochstein, S},
  date = {1993-06-15},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {90},
  number = {12},
  eprint = {8516322},
  eprinttype = {pmid},
  pages = {5718--5722},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC46793/},
  urldate = {2023-01-19},
  abstract = {The performance of adult humans in simple visual tasks improves dramatically with practice. This improvement is highly specific to basic attributes of the trained stimulus, suggesting that the underlying changes occur at low-level processing stages in the brain, where different orientations and spatial frequencies are handled by separate channels. We asked whether these practice effects are determined solely by activity in stimulus-driven mechanisms or whether high-level attentional mechanisms, which are linked to the perceptual task, might control the learning process. We found that practicing one task did not improve performance in an alternative task, even though both tasks used exactly the same visual stimuli but depended on different stimulus attributes (either orientation of local elements or global shape). Moreover, even when the experiment was designed so that the same responses were associated with the same stimuli (although subjects were instructed to attend to the attribute underlying one task), learning did not transfer from one task to the other. These results suggest that specific high-level attentional mechanisms, controlling changes at early visual processing levels, are essential in perceptual learning.},
  pmcid = {PMC46793},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\N7XLEZW8\Ahissar and Hochstein - 1993 - Attentional control of early perceptual learning..pdf}
}

@article{ahissarAttentionalControlEarly1993a,
  title = {Attentional Control of Early Perceptual Learning.},
  author = {Ahissar, M and Hochstein, S},
  date = {1993-06-15},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {90},
  number = {12},
  eprint = {8516322},
  eprinttype = {pmid},
  pages = {5718--5722},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC46793/},
  urldate = {2023-08-08},
  abstract = {The performance of adult humans in simple visual tasks improves dramatically with practice. This improvement is highly specific to basic attributes of the trained stimulus, suggesting that the underlying changes occur at low-level processing stages in the brain, where different orientations and spatial frequencies are handled by separate channels. We asked whether these practice effects are determined solely by activity in stimulus-driven mechanisms or whether high-level attentional mechanisms, which are linked to the perceptual task, might control the learning process. We found that practicing one task did not improve performance in an alternative task, even though both tasks used exactly the same visual stimuli but depended on different stimulus attributes (either orientation of local elements or global shape). Moreover, even when the experiment was designed so that the same responses were associated with the same stimuli (although subjects were instructed to attend to the attribute underlying one task), learning did not transfer from one task to the other. These results suggest that specific high-level attentional mechanisms, controlling changes at early visual processing levels, are essential in perceptual learning.},
  pmcid = {PMC46793},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RJQE3S7B\Ahissar and Hochstein - 1993 - Attentional control of early perceptual learning..pdf}
}

@article{ahissarMotionChangesIt2008,
  title = {✅ {{And}} Motion Changes It All},
  author = {Ahissar, Ehud},
  date = {2008-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {11},
  number = {12},
  pages = {1369--1370},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn1208-1369},
  url = {https://www.nature.com/articles/nn1208-1369},
  urldate = {2023-04-11},
  abstract = {Demonstrating how specific motor signals modulate sensory processing in the rat vibrissal system, a new study in this issue shows that motor signals first attenuate and then amplify afferent sensory signals.},
  issue = {12},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VNZEI65Y\Ahissar - 2008 - And motion changes it all.pdf}
}

@article{ahissarPerceptionClosedloopConvergence2016,
  title = {✅ {{Perception}} as a Closed-Loop Convergence Process},
  author = {Ahissar, Ehud and Assa, Eldad},
  editor = {Kleinfeld, David},
  date = {2016-05-09},
  journaltitle = {eLife},
  volume = {5},
  pages = {e12830},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.12830},
  url = {https://doi.org/10.7554/eLife.12830},
  urldate = {2023-04-09},
  abstract = {Perception of external objects involves sensory acquisition via the relevant sensory organs. A widely-accepted assumption is that the sensory organ is the first station in a serial chain of processing circuits leading to an internal circuit in which a percept emerges. This open-loop scheme, in which the interaction between the sensory organ and the environment is not affected by its concurrent downstream neuronal processing, is strongly challenged by behavioral and anatomical data. We present here a hypothesis in which the perception of external objects is a closed-loop dynamical process encompassing loops that integrate the organism and its environment and converging towards organism-environment steady-states. We discuss the consistency of closed-loop perception (CLP) with empirical data and show that it can be synthesized in a robotic setup. Testable predictions are proposed for empirical distinction between open and closed loop schemes of perception.},
  keywords = {active sensing,direct perception,dynamic perception,embodied cognition,eye movements,hypothesis,invariant representation,predictions,whisking},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HL8J6V26\Ahissar and Assa - 2016 - Perception as a closed-loop convergence process.pdf}
}

@article{ahissarReverseHierarchyTheory2004,
  title = {The Reverse Hierarchy Theory of Visual Perceptual Learning},
  author = {Ahissar, Merav and Hochstein, Shaul},
  date = {2004-10-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {8},
  number = {10},
  eprint = {15450510},
  eprinttype = {pmid},
  pages = {457--464},
  publisher = {Elsevier},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2004.08.011},
  url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(04)00215-3},
  urldate = {2023-08-08},
  langid = {english}
}

@article{ahissarTaskDifficultySpecificity1997,
  title = {Task Difficulty and the Specificity of Perceptual Learning},
  author = {Ahissar, Merav and Hochstein, Shaul},
  date = {1997-05},
  journaltitle = {Nature},
  volume = {387},
  number = {6631},
  pages = {401--406},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/387401a0},
  url = {https://www.nature.com/articles/387401a0},
  urldate = {2024-02-26},
  abstract = {Practising simple visual tasks leads to a dramatic improvement in performing them. This learning is specific to the stimuli used for training. We show here that the degree of specificity depends on the difficulty of the training conditions. We find that the pattern of specificities maps onto the pattern of receptive field selectivities along the visual pathway. With easy conditions, learning generalizes across orientation and retinal position, matching the spatial generalization of higher visual areas. As task difficulty increases, learning becomes more specific with respect to both orientation and position, matching the fine spatial retinotopy exhibited by lower areas. Consequently, we enjoy the benefits of learning generalization when possible, and of fine grain but specific training when necessary. The dynamics of learning show a corresponding feature. Improvement begins with easy cases (when the subject is allowed long processing times) and only subsequently proceeds to harder cases. This learning cascade implies that easy conditions guide the learning of hard ones. Taken together, the specificity and dynamics suggest that learning proceeds as a countercurrent along the cortical hierarchy. Improvement begins at higher generalizing levels, which, in turn, direct harder-condition learning to the subdomain of their lower-level inputs. As predicted by this reverse hierarchy model, learning can be effective using only difficult trials, but on condition that learning onset has previously been enabled. A single prolonged presentation suffices to initiate learning. We call this single-encounter enabling effect 'eureka'.},
  issue = {6631},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9JUZZGH2\Ahissar and Hochstein - 1997 - Task difficulty and the specificity of perceptual .pdf}
}

@online{akroutDeepLearningWeight2020,
  title = {Deep {{Learning}} without {{Weight Transport}}},
  author = {Akrout, Mohamed and Wilson, Collin and Humphreys, Peter C. and Lillicrap, Timothy and Tweed, Douglas},
  date = {2020-01-09},
  eprint = {1904.05391},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1904.05391},
  urldate = {2024-03-12},
  abstract = {Current algorithms for deep learning probably cannot run in the brain because they rely on weight transport, where forward-path neurons transmit their synaptic weights to a feedback path, in a way that is likely impossible biologically. An algorithm called feedback alignment achieves deep learning without weight transport by using random feedback weights, but it performs poorly on hard visual-recognition tasks. Here we describe two mechanisms - a neural circuit called a weight mirror and a modification of an algorithm proposed by Kolen and Pollack in 1994 - both of which let the feedback path learn appropriate synaptic weights quickly and accurately even in large networks, without weight transport or complex wiring.Tested on the ImageNet visual-recognition task, these mechanisms outperform both feedback alignment and the newer sign-symmetry method, and nearly match backprop, the standard algorithm of deep learning, which uses weight transport.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XU2YLQGJ\\Akrout et al. - 2020 - Deep Learning without Weight Transport.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CH5V2T2M\\1904.html}
}

@article{allenAstrocyteRegulationSynaptic2014,
  title = {Astrocyte {{Regulation}} of {{Synaptic Behavior}}},
  author = {Allen, Nicola J.},
  date = {2014},
  journaltitle = {Annual Review of Cell and Developmental Biology},
  volume = {30},
  number = {1},
  eprint = {25288116},
  eprinttype = {pmid},
  pages = {439--463},
  doi = {10.1146/annurev-cellbio-100913-013053},
  url = {https://doi.org/10.1146/annurev-cellbio-100913-013053},
  urldate = {2020-11-24},
  abstract = {Astrocytes regulate multiple aspects of neuronal and synaptic function from development through to adulthood. Instead of addressing each function independently, this review provides a comprehensive overview of the different ways astrocytes modulate neuronal synaptic function throughout life, with a particular focus on recent findings in each area. It includes the emerging functions of astrocytes, such as a role in synapse formation, as well as more established roles, including the uptake and recycling of neurotransmitters. This broad approach covers the many ways astrocytes and neurons constantly interact to maintain the correct functioning of the brain. It is important to consider all of these diverse functions of astrocytes when investigating how astrocyte-neuron interactions regulate synaptic behavior to appreciate the complexity of these ongoing interactions.},
  file = {C:\Users\Zach Friedenberger\Downloads\annurev-cellbio-100913-013053.pdf}
}

@article{allenStarPowerAstrocytes2019,
  title = {Star {{Power}}: {{Astrocytes Regulate Behavior}}},
  shorttitle = {Star {{Power}}},
  author = {Allen, Nicola J.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31100265},
  eprinttype = {pmid},
  pages = {1091--1093},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.04.042},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30494-5},
  urldate = {2020-11-21},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2C7XMJ66\\Allen - 2019 - Star Power Astrocytes Regulate Behavior.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JF9TY9EP\\S0092-8674(19)30494-5.html}
}

@article{andersonAttentiondependentReductionsBurstiness2013,
  title = {✅ {{Attention-dependent}} Reductions in Burstiness and Action-Potential Height in Macaque Area {{V4}}},
  author = {Anderson, Emily B. and Mitchell, Jude F. and Reynolds, John H.},
  date = {2013-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {16},
  number = {8},
  pages = {1125--1131},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3463},
  url = {https://www.nature.com/articles/nn.3463},
  urldate = {2023-01-03},
  abstract = {This study finds a counterintuitive reduction in neuron bursting during spatial attention. This is explained by a conductance-based model, which also provides a unified explanation for other forms of attentional modulation and correctly predicts the surprising finding that attention decreases action-potential amplitude.},
  issue = {8},
  langid = {english},
  keywords = {Attention},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XAUPFGPA\Anderson et al. - 2013 - Attention-dependent reductions in burstiness and a.pdf}
}

@article{andersonPathwaysAttentionSynaptic2011,
  title = {Pathways of {{Attention}}: {{Synaptic Relationships}} of {{Frontal Eye Field}} to {{V4}}, {{Lateral Intraparietal Cortex}}, and {{Area}} 46 in {{Macaque Monkey}}},
  shorttitle = {Pathways of {{Attention}}},
  author = {Anderson, John C. and Kennedy, Henry and Martin, Kevan A. C.},
  date = {2011-07-27},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {31},
  number = {30},
  eprint = {21795539},
  eprinttype = {pmid},
  pages = {10872--10881},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0622-11.2011},
  url = {https://www.jneurosci.org/content/31/30/10872},
  urldate = {2023-01-04},
  abstract = {The frontal eye field (FEF) of the primate neocortex occupies a pivotal position in the matrix of inter-areal projections. In addition to its role in directing saccadic eye movements, it is the source of an attentional signal that modulates the activity of neurons in extrastriate and parietal cortex. Here, we tested the prediction that FEF preferentially excites inhibitory neurons in target areas during attentional modulation. Using the anterograde tracer biotinylated dextran amine, we found that the projections from FEF terminate in all cortical layers of area 46, lateral intraparietal area (LIP), and visual area V4. Axons in layer 1 spread extensively, those in layer 2/3 were most numerous, individual axons in layer 4 formed sprays of collaterals, and those of the deep layers were the finest caliber and irregular. All labeled synapses were the typical asymmetric morphology of excitatory synapses of pyramidal neurons. Dendritic spines were the most frequent synaptic target in all areas (95\% in area 46, 89\% in V4, 84\% in LIP, 78\% intrinsic local FEF). The remaining targets were one soma and dendritic shafts, most of which showed characteristics of inhibitory neurons with smooth dendrites (5\% of all targets in area 46, 2\% in V4, 9\% in LIP, and 13\% in FEF).},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ME44ZKEI\Anderson et al. - 2011 - Pathways of Attention Synaptic Relationships of F.pdf}
}

@article{andreattaHowNeuronsAdjust2021,
  title = {✅ {{How}} Neurons Adjust to Diurnality},
  author = {Andreatta, Gabriele and Allen, Charles N},
  date = {2021-11-30},
  journaltitle = {eLife},
  volume = {10},
  pages = {e74704},
  issn = {2050-084X},
  doi = {10.7554/eLife.74704},
  url = {https://elifesciences.org/articles/74704},
  urldate = {2023-02-23},
  abstract = {Being active during the day requires a slow-closing ion channel that dampens the activity of neurons in a specific area of the brain.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UTS5DXRP\Andreatta and Allen - 2021 - How neurons adjust to diurnality.pdf}
}

@article{aoiModelbasedTargetedDimensionality2018,
  title = {✅ {{Model-based}} Targeted Dimensionality Reduction for Neuronal Population Data},
  author = {Aoi, Mikio C. and Pillow, Jonathan W.},
  date = {2018-12},
  journaltitle = {Advances in Neural Information Processing Systems},
  shortjournal = {Adv Neural Inf Process Syst},
  volume = {31},
  eprint = {31274967},
  eprinttype = {pmid},
  pages = {6690--6699},
  issn = {1049-5258},
  abstract = {Summarizing high-dimensional data using a small number of parameters is a ubiquitous first step in the analysis of neuronal population activity. Recently developed methods use "targeted" approaches that work by identifying multiple, distinct low-dimensional subspaces of activity that capture the population response to individual experimental task variables, such as the value of a presented stimulus or the behavior of the animal. These methods have gained attention because they decompose total neural activity into what are ostensibly different parts of a neuronal computation. However, existing targeted methods have been developed outside of the confines of probabilistic modeling, making some aspects of the procedures ad hoc, or limited in flexibility or interpretability. Here we propose a new model-based method for targeted dimensionality reduction based on a probabilistic generative model of the population response data. The low-dimensional structure of our model is expressed as a low-rank factorization of a linear regression model. We perform efficient inference using a combination of expectation maximization and direct maximization of the marginal likelihood. We also develop an efficient method for estimating the dimensionality of each subspace. We show that our approach outperforms alternative methods in both mean squared error of the parameter estimates, and in identifying the correct dimensionality of encoding using simulated data. We also show that our method provides more accurate inference of low-dimensional subspaces of activity than a competing algorithm, demixed PCA.},
  langid = {english},
  pmcid = {PMC6605062},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9E25BSC3\Aoi and Pillow - 2018 - Model-based targeted dimensionality reduction for .pdf}
}

@article{aoiPrefrontalCortexExhibits2020,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making},
  author = {Aoi, Mikio C. and Mante, Valerio and Pillow, Jonathan W.},
  date = {2020-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {11},
  pages = {1410--1420},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0696-5},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2022-09-26},
  abstract = {Recent work has suggested that the prefrontal cortex (PFC) plays a key role in context-dependent perceptual decision-making. In this study, we addressed that role using a new method for identifying task-relevant dimensions of neural population activity. Specifically, we show that the PFC has a multidimensional code for context, decisions and both relevant and irrelevant sensory information. Moreover, these representations evolve in time, with an early linear accumulation phase followed by a phase with rotational dynamics. We identify the dimensions of neural activity associated with these phases and show that they do not arise from distinct populations but from a single population with broad tuning characteristics. Finally, we use model-based decoding to show that the transition from linear to rotational dynamics coincides with a plateau in decoding accuracy, revealing that rotational dynamics in the PFC preserve sensory choice information for the duration of the stimulus integration period.},
  issue = {11},
  langid = {english},
  keywords = {Decision,Dimensionality reduction,Neural encoding,Population dynamics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GFASWP5A\\Aoi et al. - 2020 - Prefrontal cortex exhibits multidimensional dynami.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\L5F6WUAF\\s41593-020-0696-5.html}
}

@article{aoiPrefrontalCortexExhibits2020a,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making},
  author = {Aoi, Mikio C. and Mante, Valerio and Pillow, Jonathan W.},
  date = {2020-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {11},
  pages = {1410--1420},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0696-5},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2024-07-16},
  abstract = {Recent work has suggested that the prefrontal cortex (PFC) plays a key role in context-dependent perceptual decision-making. In this study, we addressed that role using a new method for identifying task-relevant dimensions of neural population activity. Specifically, we show that the PFC has a multidimensional code for context, decisions and both relevant and irrelevant sensory information. Moreover, these representations evolve in time, with an early linear accumulation phase followed by a phase with rotational dynamics. We identify the dimensions of neural activity associated with these phases and show that they do not arise from distinct populations but from a single population with broad tuning characteristics. Finally, we use model-based decoding to show that the transition from linear to rotational dynamics coincides with a plateau in decoding accuracy, revealing that rotational dynamics in the PFC preserve sensory choice information for the duration of the stimulus integration period.},
  langid = {english},
  keywords = {Decision,Neural encoding,Population dynamics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\W6T6FCU6\Aoi et al. - 2020 - Prefrontal cortex exhibits multidimensional dynami.pdf}
}

@article{aruCellularMechanismsConscious2020,
  title = {Cellular {{Mechanisms}} of {{Conscious Processing}}},
  author = {Aru, Jaan and Suzuki, Mototaka and Larkum, Matthew E.},
  date = {2020-10-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {10},
  pages = {814--825},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.07.006},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320301753},
  urldate = {2020-10-29},
  abstract = {Recent breakthroughs in neurobiology indicate that the time is ripe to understand how cellular-level mechanisms are related to conscious experience. Here, we highlight the biophysical properties of pyramidal cells, which allow them to act as gates that control the evolution of global activation patterns. In conscious states, this cellular mechanism enables complex sustained dynamics within the thalamocortical system, whereas during unconscious states, such signal propagation is prohibited. We suggest that the hallmark of conscious processing is the flexible integration of bottom-up and top-down data streams at the cellular level. This cellular integration mechanism provides the foundation for Dendritic Information Theory, a novel neurobiological theory of consciousness},
  langid = {english},
  keywords = {anesthesia,dendrites,dendritic integration theory,pyramidal cells},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DZ4DAPD2\\Aru et al. - 2020 - Cellular Mechanisms of Conscious Processing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PM2HSWF9\\S1364661320301753.html}
}

@article{asgari-targhiMathematicalModelingCircadian2019,
  title = {Mathematical Modeling of Circadian Rhythms},
  author = {Asgari-Targhi, Ameneh and Klerman, Elizabeth B.},
  date = {2019},
  journaltitle = {WIREs Systems Biology and Medicine},
  volume = {11},
  number = {2},
  pages = {e1439},
  issn = {1939-005X},
  doi = {10.1002/wsbm.1439},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wsbm.1439},
  urldate = {2023-01-26},
  abstract = {Circadian rhythms are endogenous 24-hr oscillations usually entrained to daily environmental cycles of light/dark. Many biological processes and physiological functions including mammalian body temperature, the cell cycle, sleep/wake cycles, neurobehavioral performance, and a wide range of diseases including metabolic, cardiovascular, and psychiatric disorders are impacted by these rhythms. Circadian clocks are present within individual cells and at tissue and organismal levels as emergent properties from the interaction of cellular oscillators. Mathematical models of circadian rhythms have been proposed to provide a better understanding of and to predict aspects of this complex physiological system. These models can be used to: (a) manipulate the system in silico with specificity that cannot be easily achieved using in vivo and in vitro experimental methods and at lower cost, (b) resolve apparently contradictory empirical results, (c) generate hypotheses, (d) design new experiments, and (e) to design interventions for altering circadian rhythms. Mathematical models differ in structure, the underlying assumptions, the number of parameters and variables, and constraints on variables. Models representing circadian rhythms at different physiologic scales and in different species are reviewed to promote understanding of these models and facilitate their use. This article is categorized under: Physiology {$>$} Mammalian Physiology in Health and Disease Models of Systems Properties and Processes {$>$} Organ, Tissue, and Physiological Models},
  langid = {english},
  keywords = {biological oscillators,circadian clock,circadian rhythms,dynamic systems,mathematical modeling,statistical modeling},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GGH8CL9V\\Asgari-Targhi and Klerman - 2019 - Mathematical modeling of circadian rhythms.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M5JSXUAX\\c96f844cd46bdd7bed35fedc77232ece.pdf}
}

@online{AttentionalModulationNeuronal,
  title = {Attentional Modulation of Neuronal Variability in Circuit Models of Cortex | {{eLife}}},
  url = {https://elifesciences.org/articles/23978},
  urldate = {2023-08-28}
}

@online{AttentionalModulationNeuronala,
  title = {Attentional Modulation of Neuronal Variability in Circuit Models of Cortex | {{eLife}}},
  url = {https://elifesciences.org/articles/23978},
  urldate = {2023-08-28},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3NGA8Y3H\23978.html}
}

@article{audettePOmThalamocorticalInput2018,
  title = {{{POm Thalamocortical Input Drives Layer-Specific Microcircuits}} in {{Somatosensory Cortex}}},
  author = {Audette, Nicholas J. and Urban-Ciecko, Joanna and Matsushita, Megumi and Barth, Alison L.},
  date = {2018-04-01},
  journaltitle = {Cerebral Cortex (New York, N.Y.: 1991)},
  shortjournal = {Cereb Cortex},
  volume = {28},
  number = {4},
  eprint = {28334225},
  eprinttype = {pmid},
  pages = {1312--1328},
  issn = {1460-2199},
  doi = {10.1093/cercor/bhx044},
  abstract = {Higher-order thalamic nuclei, such as the posterior medial nucleus (POm) in the somatosensory system or the pulvinar in the visual system, densely innervate the cortex and can influence perception and plasticity. To systematically evaluate how higher-order thalamic nuclei can drive cortical circuits, we investigated cell-type selective responses to POm stimulation in mouse primary somatosensory (barrel) cortex, using genetically targeted whole-cell recordings in acute brain slices. We find that ChR2-evoked thalamic input selectively targets specific cell types in the neocortex, revealing layer-specific modules for the summation and processing of POm input. Evoked activity in pyramidal neurons from deep layers is fast and synchronized by rapid feedforward inhibition from GABAergic parvalbumin-expressing neurons, and activity in superficial layers is weaker and prolonged, facilitated by slow inhibition from GABAergic neurons expressing the 5HT3a receptor. Somatostatin-expressing GABAergic neurons do not receive direct input in either layer and their spontaneous activity is suppressed during POm stimulation. This novel pattern of weak, delayed, thalamus-evoked inhibition in layer 2 suggests a longer integration window for incoming sensory information and may facilitate stimulus detection and plasticity in superficial pyramidal neurons.},
  langid = {english},
  pmcid = {PMC6093433},
  keywords = {Animals,Channelrhodopsins,Excitatory Amino Acid Antagonists,Inhibitory Postsynaptic Potentials,Mice,Mice Inbred C57BL,Nerve Net,Neural Pathways,Parvalbumins,Piperidines,Potassium Channel Blockers,Pyramidal Cells,Quinoxalines,Receptors Serotonin 5-HT3,Sodium Channel Blockers,Somatosensory Cortex,Somatostatin,Tetrodotoxin,Thalamic Nuclei,Vasoactive Intestinal Peptide},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3N8SG7ZI\Audette et al. - 2018 - POm Thalamocortical Input Drives Layer-Specific Mi.pdf}
}

@article{audetteRapidPlasticityHigherOrder2019,
  title = {Rapid {{Plasticity}} of {{Higher-Order Thalamocortical Inputs}} during {{Sensory Learning}}},
  author = {Audette, Nicholas J. and Bernhard, Sarah M. and Ray, Ajit and Stewart, Luke T. and Barth, Alison L.},
  date = {2019-07-17},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {103},
  number = {2},
  eprint = {31151774},
  eprinttype = {pmid},
  pages = {277-291.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.04.037},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(19)30394-0},
  urldate = {2023-08-03},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\B7QELWDE\Audette et al. - 2019 - Rapid Plasticity of Higher-Order Thalamocortical I.pdf}
}

@article{averbeckEffectsNoiseCorrelations2006,
  title = {Effects of {{Noise Correlations}} on {{Information Encoding}} and {{Decoding}}},
  author = {Averbeck, Bruno B. and Lee, Daeyeol},
  date = {2006-06},
  journaltitle = {Journal of Neurophysiology},
  volume = {95},
  number = {6},
  pages = {3633--3644},
  publisher = {American Physiological Society},
  issn = {0022-3077},
  doi = {10.1152/jn.00919.2005},
  url = {https://journals.physiology.org/doi/full/10.1152/jn.00919.2005},
  urldate = {2023-03-31},
  abstract = {Response variability is often correlated across populations of neurons, and these noise correlations may play a role in information coding. In previous studies, this possibility has been examined from the encoding and decoding perspectives. Here we used d prime and related information measures to examine how studies of noise correlations from these two perspectives are related. We found that for a pair of neurons, the effect of noise correlations on information decoding can be zero when the effect of noise correlations on the information encoded obtains its largest positive or negative values. Furthermore, there can be no effect of noise correlations on the information encoded when it has an effect on information decoding. We also measured the effect of noise correlations on information encoding and decoding in simultaneously recorded neurons in the supplementary motor area to see how well d prime accounted for the information actually present in the neural responses and to see how noise correlations affected encoding and decoding in real data. These analyses showed that d prime provides an accurate measure of information encoding and decoding in our population of neurons. We also found that the effect of noise correlations on information encoding was somewhat larger than the effect of noise correlations on information decoding, but both were relatively small. Finally, as predicted theoretically, the effects of correlations were slightly greater for larger ensembles (3–8 neurons) than for pairs of neurons.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TB9IBBVF\Averbeck and Lee - 2006 - Effects of Noise Correlations on Information Encod.pdf}
}

@article{averbeckNeuralCorrelationsPopulation2006,
  title = {✅  {{Neural}} Correlations, Population Coding and Computation},
  author = {Averbeck, Bruno B. and Latham, Peter E. and Pouget, Alexandre},
  date = {2006-05},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {7},
  number = {5},
  pages = {358--366},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn1888},
  url = {https://www.nature.com/articles/nrn1888},
  urldate = {2023-03-22},
  abstract = {Correlations among neurons can affect both the amount of information encoded in a population and strategies for decoding the population. These two issues — encoding and decoding — lead to complementary perspectives about the role of correlations.In the encoding perspective, the information encoded in a population of correlated neurons is compared with the information that would be encoded if the population were uncorrelated.In the decoding perspective, the amount of information lost if correlations are ignored when decoding is measured. Note that the decoding perspective is much more subtle than the encoding perspective — it asks whether a potentially suboptimal strategy, ignoring correlations, really is suboptimal, and, if so, just how bad it is.If we knew only that neural responses were correlated, we would not know whether or not those correlations affected information encoding, nor would we know whether or not they affected decoding strategies. Furthermore, correlations can increase, decrease or not affect the amount of information encoded, just as they can affect or not affect the amount of information extracted using a decoder that ignores correlations.As a corollary to the previous point, the information present in neural responses, as well as the change in information due to attentional or learning-related factors, cannot be estimated by single neuron recordings.At the level of pairs of neurons, the measured effects of correlations on encoding and decoding have been small (in all but one study less than ∼10\%) across many brain areas and species.Correlations can have a large effect at the population level even when they have a small effect at the level of pairs. Consequently, results obtained for pairs of neurons cannot be directly extrapolated to populations, a fact that is true for both encoding and decoding.},
  issue = {5},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3MVZT9TR\Averbeck et al. - 2006 - Neural correlations, population coding and computa.pdf}
}

@article{bairPowerSpectrumAnalysis1994,
  title = {Power Spectrum Analysis of Bursting Cells in Area {{MT}} in the Behaving Monkey},
  author = {Bair, W and Koch, C and Newsome, W and Britten, K},
  date = {1994-05-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {14},
  number = {5},
  pages = {2870--2892},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.14-05-02870.1994},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.14-05-02870.1994},
  urldate = {2023-01-16},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\S8VBZBEN\Bair et al. - 1994 - Power spectrum analysis of bursting cells in area .pdf}
}

@article{bairPowerSpectrumAnalysis1994a,
  title = {Power Spectrum Analysis of Bursting Cells in Area {{MT}} in the Behaving Monkey},
  author = {Bair, W. and Koch, C. and Newsome, W. and Britten, K.},
  date = {1994-05-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {14},
  number = {5},
  eprint = {8182445},
  eprinttype = {pmid},
  pages = {2870--2892},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.14-05-02870.1994},
  url = {https://www.jneurosci.org/content/14/5/2870},
  urldate = {2023-01-16},
  abstract = {It is widely held that visual cortical neurons encode information primarily in their mean firing rates. Some proposals, however, emphasize the information potentially available in the temporal structure of spike trains (Optican and Richmond, 1987; Bialek et al., 1991), in particular with respect to stimulus-related synchronized oscillations in the 30–70 Hz range (Eckhorn et al., 1988; Gray et al., 1989; Kreiter and Singer, 1992) as well as via bursting cells (Cattaneo et al., 1981a; Bonds, 1992). We investigate the temporal fine structure of spike trains recorded in extrastriate area MT of the trained macaque monkey, a region that plays a major role in processing motion information. The data were recorded while the monkey performed a near- threshold direction discrimination task so that both physiological and psychophysical data could be obtained on the same set of trials (Britten et al., 1992). We identify bursting cells and quantify their properties, in particular in relation to the behavior of the animal. We compute the power spectrum and the distribution of interspike intervals (ISIs) associated with individual spike trains from 212 cells, averaging these quantities across similar trials. (1) About 33\% of the cells have a relatively flat power spectrum with a dip at low temporal frequencies. We analytically derive the power spectrum of a Poisson process with refractory period and show that it matches the observed spectrum of these cells. (2) About 62\% of the cells have a peak in the 20–60 Hz frequency band. In about 10\% of all cells, this peak is at least twice the height of its base. The presence of such a peak strongly correlates with a tendency of the cell to respond in bursts, that is, two to four spikes within 2–8 msec. For 93\% of cells, the shape of the power spectrum did not change dramatically with stimulus conditions. (3) Both the ISI distribution and the power spectrum of the vast majority of bursting cells are compatible with the notion that these cells fire Poisson-distributed bursts, with a burst-related refractory period. Thus, for our stimulus conditions, no explicitly oscillating neuronal process is required to yield a peak in the power spectrum. (4) We found no statistically significant relationship between the peak in the power spectrum and psychophysical measures of the monkeys' performance on the direction discrimination task.(ABSTRACT TRUNCATED AT 400 WORDS)},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3F2N54TV\Bair et al. - 1994 - Power spectrum analysis of bursting cells in area .pdf}
}

@inproceedings{baltieriModularityActionPerception2018,
  title = {The Modularity of Action and Perception Revisited Using Control Theory and Active Inference},
  booktitle = {The 2018 {{Conference}} on {{Artificial Life}}},
  author = {Baltieri, Manuel and Buckley, Christopher L.},
  date = {2018},
  pages = {121--128},
  publisher = {MIT Press},
  location = {Tokyo, Japan},
  doi = {10.1162/isal_a_00031},
  url = {https://www.mitpressjournals.org/doi/abs/10.1162/isal_a_00031},
  urldate = {2023-08-10},
  abstract = {The assumption that action and perception can be investigated independently is entrenched in theories, models and experimental approaches across the brain and mind sciences. In cognitive science, this has been a central point of contention between computationalist and 4Es (enactive, embodied, extended and embedded) theories of cognition, with the former embracing the “classical sandwich”, modular, architecture of the mind and the latter actively denying this separation can be made. In this work we suggest that the modular independence of action and perception strongly resonates with the separation principle of control theory and furthermore that this principle provides formal criteria within which to evaluate the implications of the modularity of action and perception. We will also see that real-time feedback with the environment, often considered necessary for the definition of 4Es ideas, is not however a sufficient condition to avoid the “classical sandwich”. Finally, we argue that an emerging framework in the cognitive and brain sciences, active inference, extends ideas derived from control theory to the study of biological systems while disposing of the separation principle, describing non-modular models of behaviour strongly aligned with 4Es theories of cognition.},
  eventtitle = {The 2018 {{Conference}} on {{Artificial Life}}},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2YSVPSLV\Baltieri and Buckley - 2018 - The modularity of action and perception revisited .pdf}
}

@article{barbieriCanAttractorNetwork2008,
  title = {Can {{Attractor Network Models Account}} for the {{Statistics}} of {{Firing During Persistent Activity}} in {{Prefrontal Cortex}}?},
  author = {Barbieri, Francesca and Brunel, Nicolas},
  date = {2008},
  journaltitle = {Frontiers in Neuroscience},
  volume = {2},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/articles/10.3389/neuro.01.003.2008},
  urldate = {2022-10-21},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\F2WS9WWD\Barbieri and Brunel - 2008 - Can Attractor Network Models Account for the Stati.pdf}
}

@article{barzegaranFourConcurrentFeedforward2022,
  title = {Four Concurrent Feedforward and Feedback Networks with Different Roles in the Visual Cortical Hierarchy},
  author = {Barzegaran, Elham and Plomp, Gijs},
  date = {2022-02-10},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {20},
  number = {2},
  pages = {e3001534},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001534},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001534},
  urldate = {2023-01-10},
  abstract = {Visual stimuli evoke fast-evolving activity patterns that are distributed across multiple cortical areas. These areas are hierarchically structured, as indicated by their anatomical projections, but how large-scale feedforward and feedback streams are functionally organized in this system remains an important missing clue to understanding cortical processing. By analyzing visual evoked responses in laminar recordings from 6 cortical areas in awake mice, we uncovered a dominant feedforward network with scale-free interactions in the time domain. In addition, we established the simultaneous presence of a gamma band feedforward and 2 low frequency feedback networks, each with a distinct laminar functional connectivity profile, frequency spectrum, temporal dynamics, and functional hierarchy. We could identify distinct roles for each of these 4 processing streams, by leveraging stimulus contrast effects, analyzing receptive field (RF) convergency along functional interactions, and determining relationships to spiking activity. Our results support a dynamic dual counterstream view of hierarchical processing and provide new insight into how separate functional streams can simultaneously and dynamically support visual processes.},
  langid = {english},
  keywords = {Cognitive science,Mice,Neural networks,Primates,Scale-free networks,Sensory perception,Vision,Visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RBTBHDIY\Barzegaran and Plomp - 2022 - Four concurrent feedforward and feedback networks .pdf}
}

@article{bassCircadianIntegrationMetabolism2010,
  title = {Circadian {{Integration}} of {{Metabolism}} and {{Energetics}}},
  author = {Bass, Joseph and Takahashi, Joseph S.},
  date = {2010-12-03},
  journaltitle = {Science},
  volume = {330},
  number = {6009},
  pages = {1349--1354},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1195027},
  url = {https://www.science.org/doi/abs/10.1126/science.1195027},
  urldate = {2023-02-16},
  abstract = {Circadian clocks align behavioral and biochemical processes with the day/night cycle. Nearly all vertebrate cells possess self-sustained clocks that couple endogenous rhythms with changes in cellular environment. Genetic disruption of clock genes in mice perturbs metabolic functions of specific tissues at distinct phases of the sleep/wake cycle. Circadian desynchrony, a characteristic of shift work and sleep disruption in humans, also leads to metabolic pathologies. Here, we review advances in understanding the interrelationship among circadian disruption, sleep deprivation, obesity, and diabetes and implications for rational therapeutics for these conditions.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2BQZCKUR\\Bass and Takahashi - 2010 - Circadian Integration of Metabolism and Energetics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VMKXYLMY\\bass2010.pdf}
}

@article{bastosCanonicalMicrocircuitsPredictive2012,
  title = {Canonical Microcircuits for Predictive Coding},
  author = {Bastos, Andre M. and Usrey, W. Martin and Adams, Rick A. and Mangun, George R. and Fries, Pascal and Friston, Karl J.},
  date = {2012-11-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {76},
  number = {4},
  eprint = {23177956},
  eprinttype = {pmid},
  pages = {695--711},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2012.10.038},
  abstract = {This Perspective considers the influential notion of a canonical (cortical) microcircuit in light of recent theories about neuronal processing. Specifically, we conciliate quantitative studies of microcircuitry and the functional logic of neuronal computations. We revisit the established idea that message passing among hierarchical cortical areas implements a form of Bayesian inference-paying careful attention to the implications for intrinsic connections among neuronal populations. By deriving canonical forms for these computations, one can associate specific neuronal populations with specific computational roles. This analysis discloses a remarkable correspondence between the microcircuitry of the cortical column and the connectivity implied by predictive coding. Furthermore, it provides some intuitive insights into the functional asymmetries between feedforward and feedback connections and the characteristic frequencies over which they operate.},
  langid = {english},
  pmcid = {PMC3777738},
  keywords = {Animals,Cerebral Cortex,Computer Simulation,Feedback Physiological,Functional Laterality,Humans,Models Neurological,Nerve Net,Neural Pathways},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UY94TSFL\Bastos et al. - 2012 - Canonical microcircuits for predictive coding.pdf}
}

@article{battistonPhysicsHigherorderInteractions2021,
  title = {The Physics of Higher-Order Interactions in Complex Systems},
  author = {Battiston, Federico and Amico, Enrico and Barrat, Alain and Bianconi, Ginestra and Ferraz de Arruda, Guilherme and Franceschiello, Benedetta and Iacopini, Iacopo and Kéfi, Sonia and Latora, Vito and Moreno, Yamir and Murray, Micah M. and Peixoto, Tiago P. and Vaccarino, Francesco and Petri, Giovanni},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1093--1098},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01371-4},
  url = {https://www.nature.com/articles/s41567-021-01371-4},
  urldate = {2022-10-01},
  abstract = {Complex networks have become the main paradigm for modelling the dynamics of interacting systems. However, networks are intrinsically limited to describing pairwise interactions, whereas real-world systems are often characterized by higher-order interactions involving groups of three or more units. Higher-order structures, such as hypergraphs and simplicial complexes, are therefore a better tool to map the real organization of many social, biological and man-made systems. Here, we highlight recent evidence of collective behaviours induced by higher-order interactions, and we outline three key challenges for the physics of higher-order systems.},
  issue = {10},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Information theory and computation},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BKIZNWBF\\Battiston et al. - 2021 - The physics of higher-order interactions in comple.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\39U85876\\s41567-021-01371-4.html}
}

@article{battistonPhysicsHigherorderInteractions2021a,
  title = {✅ {{The}} Physics of Higher-Order Interactions in Complex Systems},
  author = {Battiston, Federico and Amico, Enrico and Barrat, Alain and Bianconi, Ginestra and Ferraz de Arruda, Guilherme and Franceschiello, Benedetta and Iacopini, Iacopo and Kéfi, Sonia and Latora, Vito and Moreno, Yamir and Murray, Micah M. and Peixoto, Tiago P. and Vaccarino, Francesco and Petri, Giovanni},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1093--1098},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01371-4},
  url = {https://www.nature.com/articles/s41567-021-01371-4},
  urldate = {2022-10-02},
  abstract = {Complex networks have become the main paradigm for modelling the dynamics of interacting systems. However, networks are intrinsically limited to describing pairwise interactions, whereas real-world systems are often characterized by higher-order interactions involving groups of three or more units. Higher-order structures, such as hypergraphs and simplicial complexes, are therefore a better tool to map the real organization of many social, biological and man-made systems. Here, we highlight recent evidence of collective behaviours induced by higher-order interactions, and we outline three key challenges for the physics of higher-order systems.},
  issue = {10},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Information theory and computation},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FYCINRUZ\\Battiston et al. - 2021 - The physics of higher-order interactions in comple.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X2E3E3TP\\s41567-021-01371-4.html}
}

@article{beaulieu-larocheEnhancedDendriticCompartmentalization2018,
  title = {Enhanced {{Dendritic Compartmentalization}} in {{Human Cortical Neurons}}},
  author = {Beaulieu-Laroche, Lou and Toloza, Enrique H. S. and van der Goes, Marie-Sophie and Lafourcade, Mathieu and Barnagian, Derrick and Williams, Ziv M. and Eskandar, Emad N. and Frosch, Matthew P. and Cash, Sydney S. and Harnett, Mark T.},
  date = {2018-10-18},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {175},
  number = {3},
  eprint = {30340039},
  eprinttype = {pmid},
  pages = {643-651.e14},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2018.08.045},
  url = {https://www.cell.com/cell/abstract/S0092-8674(18)31106-1},
  urldate = {2020-10-29},
  langid = {english},
  keywords = {biophysics,compartmentalization,computation,cortex,dendrite,human,ion channels,neuron,patch-clamp},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M8YNL7TK\\Beaulieu-Laroche et al. - 2018 - Enhanced Dendritic Compartmentalization in Human C.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\49985XDW\\S0092-8674(18)31106-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RTATAXEM\\S0092-8674(18)31106-1.html}
}

@article{bellarditaPhenotypicCharacterizationSpeedAssociated2015,
  title = {Phenotypic {{Characterization}} of {{Speed-Associated Gait Changes}} in {{Mice Reveals Modular Organization}} of {{Locomotor Networks}}},
  author = {Bellardita, Carmelo and Kiehn, Ole},
  date = {2015-06-01},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {25},
  number = {11},
  eprint = {25959968},
  eprinttype = {pmid},
  pages = {1426--1436},
  publisher = {Elsevier},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2015.04.005},
  url = {https://www.cell.com/current-biology/abstract/S0960-9822(15)00418-2},
  urldate = {2023-03-22},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MUV6TXYN\Bellardita and Kiehn - 2015 - Phenotypic Characterization of Speed-Associated Ga.pdf}
}

@article{bellInformationMaximizationApproachBlind,
  title = {An {{Information-Maximization Approach}} to {{Blind Separation}} and {{Blind Deconvolution}}},
  author = {Bell, A J and Sejnowski, T J},
  pages = {31},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8EAQ9LIA\Bell and Sejnowski - An Information-Maximization Approach to Blind Sepa.pdf}
}

@article{benchenaneOscillationsPrefrontalCortex2011,
  title = {Oscillations in the Prefrontal Cortex: A Gateway to Memory and Attention},
  shorttitle = {Oscillations in the Prefrontal Cortex},
  author = {Benchenane, Karim and Tiesinga, Paul H and Battaglia, Francesco P},
  date = {2011-06-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Behavioural and Cognitive Neuroscience},
  volume = {21},
  number = {3},
  pages = {475--485},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2011.01.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438811000080},
  urldate = {2023-03-27},
  abstract = {We consider the potential role of oscillations in the prefrontal cortex (PFC) in mediating attention, working memory and memory consolidation. Activity in the theta, beta, and gamma bands is related to communication between PFC and different brain areas. While gamma/beta oscillations mediate bottom-up and top-down interactions between PFC and visual cortices, related to attention, theta rhythms are engaged by hippocampal/PFC interplay. These interactions are dynamic, depending on the nature and relevance of the information currently being processed. The profound modifications of the PFC neuronal network associated with changes in oscillatory coherence are controlled by neuromodulators such as dopamine, which thereby allow or prevent the formation of cell assemblies for information encoding and storage.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5PED4PIH\\Benchenane et al. - 2011 - Oscillations in the prefrontal cortex a gateway t.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3M47JTRA\\S0959438811000080.html}
}

@article{beniaguevSingleCorticalNeurons2021,
  title = {Single Cortical Neurons as Deep Artificial Neural Networks},
  author = {Beniaguev, David and Segev, Idan and London, Michael},
  date = {2021-09-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {17},
  eprint = {34380016},
  eprinttype = {pmid},
  pages = {2727-2739.e3},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.07.002},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(21)00501-8},
  urldate = {2023-05-02},
  langid = {english},
  keywords = {calcium spike,compartmental model,cortical pyramidal neuron,deep learning,dendritic computation,dendritic nonlinearities,machine learning,neural coding,NMDA spike,synaptic integration},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TEC59QCC\Beniaguev et al. - 2021 - Single cortical neurons as deep artificial neural .pdf}
}

@article{beuthMechanisticCorticalMicrocircuit2015,
  title = {A Mechanistic Cortical Microcircuit of Attention for Amplification, Normalization and Suppression},
  author = {Beuth, Frederik and Hamker, Fred H.},
  date = {2015-11-01},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  series = {Computational {{Models}} of {{Visual Attention}}},
  volume = {116},
  pages = {241--257},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2015.04.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0042698915001273},
  urldate = {2023-01-20},
  abstract = {Computational models of visual attention have replicated a large number of data from visual attention experiments. However, typically each computational model has been shown to account for only a few data sets. We developed a novel model of attention, particularly focused on explaining single cell recordings in multiple brain areas, to better understand the underlying computational circuits of attention involved in spatial- and feature-based biased competition, modulation of the contrast response function, modulation of the neuronal tuning curve, and modulation of surround suppression. In contrast to previous models, we use a two layer structure inspired by the layered cortical architecture which implements amplification, divisive normalization and suppression as well as spatial pooling.},
  langid = {english},
  keywords = {Attention models,Biased competition,Contrast vs. response gain,Scaling vs. sharpening of tuning curves,Surround suppression},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8XRMYZVJ\\Beuth and Hamker - 2015 - A mechanistic cortical microcircuit of attention f.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UCE6H8GT\\S0042698915001273.html}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  date = {2006},
  series = {Information Science and Statistics},
  publisher = {Springer},
  location = {New York},
  isbn = {978-0-387-31073-2},
  langid = {english},
  pagetotal = {738},
  keywords = {Machine learning,Pattern perception},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4PGXM8TC\Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@article{bogaczTutorialFreeenergyFramework2017,
  title = {✅ {{A}} Tutorial on the Free-Energy Framework for Modelling Perception and Learning},
  author = {Bogacz, Rafal},
  date = {2017-02-01},
  journaltitle = {Journal of Mathematical Psychology},
  shortjournal = {Journal of Mathematical Psychology},
  series = {Model-Based {{Cognitive Neuroscience}}},
  volume = {76},
  pages = {198--211},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2015.11.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0022249615000759},
  urldate = {2023-03-24},
  abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2MWSRQ6J\\Bogacz - 2017 - A tutorial on the free-energy framework for modell.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GP6A8V68\\S0022249615000759.html}
}

@article{botvinickDeepReinforcementLearning2020,
  title = {Deep {{Reinforcement Learning}} and {{Its Neuroscientific Implications}}},
  author = {Botvinick, Matthew and Wang, Jane X. and Dabney, Will and Miller, Kevin J. and Kurth-Nelson, Zeb},
  date = {2020-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {4},
  pages = {603--616},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.06.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320304682},
  urldate = {2020-08-29},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NJIYYGYT\Botvinick et al. - 2020 - Deep Reinforcement Learning and Its Neuroscientifi.pdf}
}

@article{bovenCerebrocerebellarNetworksFacilitate2023,
  title = {Cerebro-Cerebellar Networks Facilitate Learning through Feedback Decoupling},
  author = {Boven, Ellen and Pemberton, Joseph and Chadderton, Paul and Apps, Richard and Costa, Rui Ponte},
  date = {2023-01-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {51},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-35658-8},
  url = {https://www.nature.com/articles/s41467-022-35658-8},
  urldate = {2024-03-14},
  abstract = {Behavioural feedback is critical for learning in the cerebral cortex. However, such feedback is often not readily available. How the cerebral cortex learns efficiently despite the sparse nature of feedback remains unclear. Inspired by recent deep learning algorithms, we introduce a systems-level computational model of cerebro-cerebellar interactions. In this model a cerebral recurrent network receives feedback predictions from a cerebellar network, thereby decoupling learning in cerebral networks from future feedback. When trained in a simple sensorimotor task the model shows faster learning and reduced dysmetria-like behaviours, in line with the widely observed functional impact of the cerebellum. Next, we demonstrate that these results generalise to more complex motor and cognitive tasks. Finally, the model makes several experimentally testable predictions regarding cerebro-cerebellar task-specific representations over learning, task-specific benefits of cerebellar predictions and the differential impact of cerebellar and inferior olive lesions. Overall, our work offers a theoretical framework of cerebro-cerebellar networks as feedback decoupling machines.},
  langid = {english},
  keywords = {Cerebellum,Cortex,Dyslexia,Learning algorithms},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MXUBPUXP\Boven et al. - 2023 - Cerebro-cerebellar networks facilitate learning th.pdf}
}

@article{bradberryMolecularBasisSynaptotagmin1Associated2020,
  title = {Molecular {{Basis}} for {{Synaptotagmin-1-Associated Neurodevelopmental Disorder}}},
  author = {Bradberry, Mazdak M. and Courtney, Nicholas A. and Dominguez, Matthew J. and Lofquist, Sydney M. and Knox, Andrew T. and Sutton, R. Bryan and Chapman, Edwin R.},
  date = {2020-07-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {1},
  eprint = {32362337},
  eprinttype = {pmid},
  pages = {52-64.e7},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.04.003},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30272-5},
  urldate = {2020-10-06},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GXHC8MCT\\Bradberry et al. - 2020 - Molecular Basis for Synaptotagmin-1-Associated Neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QGVIXQCH\\S0896-6273(20)30272-5.html}
}

@article{brancaccioNetworkMediatedEncodingCircadian2014,
  title = {Network-{{Mediated Encoding}} of {{Circadian Time}}: {{The Suprachiasmatic Nucleus}} ({{SCN}}) from {{Genes}} to {{Neurons}} to {{Circuits}}, and {{Back}}},
  shorttitle = {Network-{{Mediated Encoding}} of {{Circadian Time}}},
  author = {Brancaccio, Marco and Enoki, Ryosuke and Mazuski, Cristina N. and Jones, Jeff and Evans, Jennifer A. and Azzi, Abdelhalim},
  date = {2014-11-12},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {34},
  number = {46},
  eprint = {25392488},
  eprinttype = {pmid},
  pages = {15192--15199},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3233-14.2014},
  url = {https://www.jneurosci.org/content/34/46/15192},
  urldate = {2023-02-22},
  abstract = {The transcriptional architecture of intracellular circadian clocks is similar across phyla, but in mammals interneuronal mechanisms confer a higher level of circadian integration. The suprachiasmatic nucleus (SCN) is a unique model to study these mechanisms, as it operates as a ∼24 h clock not only in the living animal, but also when isolated in culture. This “clock in a dish” can be used to address fundamental questions, such as how intraneuronal mechanisms are translated by SCN neurons into circuit-level emergent properties and how the circuit decodes, and responds to, light input. This review addresses recent developments in understanding the relationship between electrical activity, [Ca2+]i, and intracellular clocks. Furthermore, optogenetic and chemogenetic approaches to investigate the distinct roles of neurons and glial cells in circuit encoding of circadian time will be discussed, as well as the epigenetic and circuit-level mechanisms that enable the SCN to translate light input into coherent daily rhythms.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VL6AI2FG\Brancaccio et al. - 2014 - Network-Mediated Encoding of Circadian Time The S.pdf}
}

@inproceedings{braunExactLearningDynamics2022,
  title = {Exact Learning Dynamics of Deep Linear Networks with Prior Knowledge},
  author = {Braun, Lukas and Dominé, Clémentine Carla Juliette and Fitzgerald, James E. and Saxe, Andrew M.},
  date = {2022-05-16},
  url = {https://openreview.net/forum?id=lJx2vng-KiC},
  urldate = {2024-01-08},
  abstract = {Learning in deep neural networks is known to depend critically on the knowledge embedded in the initial network weights. However, few theoretical results have precisely linked prior knowledge to learning dynamics. Here we derive exact solutions to the dynamics of learning with rich prior knowledge in deep linear networks by generalising Fukumizu's matrix Riccati solution \textbackslash citep\{fukumizu1998effect\}. We obtain explicit expressions for the evolving network function, hidden representational similarity, and neural tangent kernel over training for a broad class of initialisations and tasks. The expressions reveal a class of task-independent initialisations that radically alter learning dynamics from slow non-linear dynamics to fast exponential trajectories while converging to a global optimum with identical representational similarity, dissociating learning trajectories from the structure of initial internal representations. We characterise how network weights dynamically align with task structure, rigorously justifying why previous solutions successfully described learning from small initial weights without incorporating their fine-scale structure. Finally, we discuss the implications of these findings for continual learning, reversal learning and learning of structured knowledge. Taken together, our results provide a mathematical toolkit for understanding the impact of prior knowledge on deep learning.},
  eventtitle = {Advances in {{Neural Information Processing Systems}}},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JL72DKYJ\Braun et al. - 2022 - Exact learning dynamics of deep linear networks wi.pdf}
}

@article{breakspearGenerativeModelsCortical2010,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-11-10},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\A5HJA3WT\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{breakspearGenerativeModelsCortical2010a,
  title = {Generative {{Models}} of {{Cortical Oscillations}}: {{Neurobiological Implications}} of the {{Kuramoto Model}}},
  shorttitle = {Generative {{Models}} of {{Cortical Oscillations}}},
  author = {Breakspear, Michael and Heitmann, Stewart and Daffertshofer, Andreas},
  date = {2010-11-11},
  journaltitle = {Frontiers in Human Neuroscience},
  shortjournal = {Front Hum Neurosci},
  volume = {4},
  eprint = {21151358},
  eprinttype = {pmid},
  issn = {1662-5161},
  doi = {10.3389/fnhum.2010.00190},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2995481/},
  urldate = {2020-10-05},
  abstract = {Understanding the fundamental mechanisms governing fluctuating oscillations in large-scale cortical circuits is a crucial prelude to a proper knowledge of their role in both adaptive and pathological cortical processes. Neuroscience research in this area has much to gain from understanding the Kuramoto model, a mathematical model that speaks to the very nature of coupled oscillating processes, and which has elucidated the core mechanisms of a range of biological and physical phenomena. In this paper, we provide a brief introduction to the Kuramoto model in its original, rather abstract, form and then focus on modifications that increase its neurobiological plausibility by incorporating topological properties of local cortical connectivity. The extended model elicits elaborate spatial patterns of synchronous oscillations that exhibit persistent dynamical instabilities reminiscent of cortical activity. We review how the Kuramoto model may be recast from an ordinary differential equation to a population level description using the nonlinear Fokker–Planck equation. We argue that such formulations are able to provide a mechanistic and unifying explanation of oscillatory phenomena in the human cortex, such as fluctuating beta oscillations, and their relationship to basic computational processes including multistability, criticality, and information capacity.},
  pmcid = {PMC2995481},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X5BBY6BW\Breakspear et al. - 2010 - Generative Models of Cortical Oscillations Neurob.pdf}
}

@article{breitenbachEffectiveModelEndogenous2021,
  title = {An Effective Model of Endogenous Clocks and External Stimuli Determining Circadian Rhythms},
  author = {Breitenbach, Tim and Helfrich-Förster, Charlotte and Dandekar, Thomas},
  date = {2021-08-09},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {11},
  number = {1},
  pages = {16165},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-95391-y},
  url = {https://www.nature.com/articles/s41598-021-95391-y},
  urldate = {2023-01-26},
  abstract = {Circadian endogenous clocks of eukaryotic organisms are an established and rapidly developing research field. To investigate and simulate in an effective model the effect of external stimuli on such clocks and their components we developed a software framework for download and simulation. The application is useful to understand the different involved effects in a mathematical simple and effective model. This concerns the effects of Zeitgebers, feedback loops and further modifying components. We start from a known mathematical oscillator model, which is based on experimental molecular findings. This is extended with an effective framework that includes the impact of external stimuli on the circadian oscillations including high dose pharmacological treatment. In particular, the external stimuli framework defines a systematic procedure by input-output-interfaces to couple different oscillators. The framework is validated by providing phase response curves and ranges of entrainment. Furthermore, Aschoffs rule is computationally investigated. It is shown how the external stimuli framework can be used to study biological effects like points of singularity or oscillators integrating different signals at once. The mathematical framework and formalism is generic and allows to study in general the effect of external stimuli on oscillators and other biological processes. For an easy replication of each numerical experiment presented in this work and an easy implementation of the framework the corresponding Mathematica files are fully made available. They can be downloaded at the following link: https://www.biozentrum.uni-wuerzburg.de/bioinfo/computing/circadian/.},
  issue = {1},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Systems biology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BE2J4DBI\Breitenbach et al. - 2021 - An effective model of endogenous clocks and extern.pdf}
}

@inproceedings{brendelDemixedPrincipalComponent2011,
  title = {Demixed {{Principal Component Analysis}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brendel, Wieland and Romo, Ranulfo and Machens, Christian K},
  date = {2011},
  volume = {24},
  publisher = {Curran Associates, Inc.},
  url = {https://papers.nips.cc/paper_files/paper/2011/hash/f4a331b7a22d1b237565d8813a34d8ac-Abstract.html},
  urldate = {2024-07-16},
  abstract = {In many experiments, the data points collected live in high-dimensional observation spaces, yet can be assigned a set of labels or parameters. In electrophysiological recordings, for instance, the responses of populations of neurons generally depend on mixtures of experimentally controlled parameters. The heterogeneity and diversity of these parameter dependencies can make visualization and interpretation of such data extremely difficult. Standard dimensionality reduction techniques such as principal component analysis (PCA) can provide a succinct and complete description of the data, but the description is constructed independent of the relevant task variables and is often hard to interpret. Here, we start with the assumption that a particularly informative description is one that reveals the dependency of the high-dimensional data on the individual parameters. We show how to modify the loss function of PCA so that the principal components seek to capture both the maximum amount of variance about the data, while also depending on a minimum number of parameters. We call this method demixed principal component analysis (dPCA) as the principal components here segregate the parameter dependencies. We phrase the problem as a probabilistic graphical model, and present a fast Expectation-Maximization (EM) algorithm. We demonstrate the use of this algorithm for electrophysiological data and show that it serves to demix the parameter-dependence of a neural population response.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CN8JSZCL\Brendel et al. - 2011 - Demixed Principal Component Analysis.pdf}
}

@article{bretteComputingNeuralSynchrony2012,
  title = {Computing with {{Neural Synchrony}}},
  author = {Brette, Romain},
  date = {2012-06-14},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {8},
  number = {6},
  pages = {e1002561},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002561},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002561},
  urldate = {2023-03-22},
  abstract = {Neurons communicate primarily with spikes, but most theories of neural computation are based on firing rates. Yet, many experimental observations suggest that the temporal coordination of spikes plays a role in sensory processing. Among potential spike-based codes, synchrony appears as a good candidate because neural firing and plasticity are sensitive to fine input correlations. However, it is unclear what role synchrony may play in neural computation, and what functional advantage it may provide. With a theoretical approach, I show that the computational interest of neural synchrony appears when neurons have heterogeneous properties. In this context, the relationship between stimuli and neural synchrony is captured by the concept of synchrony receptive field, the set of stimuli which induce synchronous responses in a group of neurons. In a heterogeneous neural population, it appears that synchrony patterns represent structure or sensory invariants in stimuli, which can then be detected by postsynaptic neurons. The required neural circuitry can spontaneously emerge with spike-timing-dependent plasticity. Using examples in different sensory modalities, I show that this allows simple neural circuits to extract relevant information from realistic sensory stimuli, for example to identify a fluctuating odor in the presence of distractors. This theory of synchrony-based computation shows that relative spike timing may indeed have computational relevance, and suggests new types of neural network models for sensory processing with appealing computational properties.},
  langid = {english},
  keywords = {Acoustic signals,Action potentials,Membrane potential,Neuronal tuning,Neurons,Olfactory receptor neurons,Sensory perception,Synapses},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DI5QN76Q\Brette - 2012 - Computing with Neural Synchrony.pdf}
}

@article{bretteComputingNeuralSynchrony2012a,
  title = {Computing with {{Neural Synchrony}}},
  author = {Brette, Romain},
  date = {2012-06-14},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {8},
  number = {6},
  pages = {e1002561},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1002561},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002561},
  urldate = {2023-03-22},
  abstract = {Neurons communicate primarily with spikes, but most theories of neural computation are based on firing rates. Yet, many experimental observations suggest that the temporal coordination of spikes plays a role in sensory processing. Among potential spike-based codes, synchrony appears as a good candidate because neural firing and plasticity are sensitive to fine input correlations. However, it is unclear what role synchrony may play in neural computation, and what functional advantage it may provide. With a theoretical approach, I show that the computational interest of neural synchrony appears when neurons have heterogeneous properties. In this context, the relationship between stimuli and neural synchrony is captured by the concept of synchrony receptive field, the set of stimuli which induce synchronous responses in a group of neurons. In a heterogeneous neural population, it appears that synchrony patterns represent structure or sensory invariants in stimuli, which can then be detected by postsynaptic neurons. The required neural circuitry can spontaneously emerge with spike-timing-dependent plasticity. Using examples in different sensory modalities, I show that this allows simple neural circuits to extract relevant information from realistic sensory stimuli, for example to identify a fluctuating odor in the presence of distractors. This theory of synchrony-based computation shows that relative spike timing may indeed have computational relevance, and suggests new types of neural network models for sensory processing with appealing computational properties.},
  langid = {english},
  keywords = {Acoustic signals,Action potentials,Membrane potential,Neuronal tuning,Neurons,Olfactory receptor neurons,Sensory perception,Synapses},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BQE9NH6Z\Brette - 2012 - Computing with Neural Synchrony.pdf}
}

@article{broidoScalefreeNetworksAre2019,
  title = {Scale-Free Networks Are Rare},
  author = {Broido, Anna D. and Clauset, Aaron},
  date = {2019-03-04},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {10},
  eprint = {30833554},
  eprinttype = {pmid},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-08746-5},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6399239/},
  urldate = {2020-09-01},
  abstract = {Real-world networks are often claimed to be scale free,~meaning that the fraction of nodes with degree k follows a power law k−α, a pattern with broad implications for the structure and dynamics of complex systems. However, the universality of scale-free networks remains controversial. Here, we organize different definitions of scale-free networks and construct a severe test of their empirical prevalence using state-of-the-art statistical tools applied to nearly 1000 social, biological, technological, transportation, and information networks. Across these networks, we find robust evidence that strongly scale-free structure is empirically rare, while for most networks, log-normal distributions fit the data as well or better than power laws. Furthermore, social networks are at best weakly scale free, while a handful of technological and biological networks appear strongly scale free. These findings highlight the structural diversity of real-world networks and the need for new theoretical explanations of these non-scale-free patterns., Real-world networks are often said to be ”scale free”, meaning their degree distribution follows a power law. Broido and Clauset perform statistical tests of this claim using a large and diverse corpus of real-world networks, showing that scale-free structure is far from universal.},
  pmcid = {PMC6399239},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\R7HRJLJX\Broido and Clauset - 2019 - Scale-free networks are rare.pdf}
}

@article{buiceFieldtheoreticApproachFluctuation2007,
  title = {Field-Theoretic Approach to Fluctuation Effects in Neural Networks},
  author = {Buice, Michael A. and Cowan, Jack D.},
  date = {2007-05-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {75},
  number = {5},
  pages = {051919},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.75.051919},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.75.051919},
  urldate = {2024-01-08},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9U3ZCNQW\Buice and Cowan - 2007 - Field-theoretic approach to fluctuation effects in.pdf}
}

@article{buschmanTopDownBottomUpControl2007,
  title = {Top-{{Down Versus Bottom-Up Control}} of {{Attention}} in the {{Prefrontal}} and {{Posterior Parietal Cortices}}},
  author = {Buschman, Timothy J. and Miller, Earl K.},
  date = {2007-03-30},
  journaltitle = {Science},
  volume = {315},
  number = {5820},
  pages = {1860--1862},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1138071},
  url = {https://www.science.org/doi/10.1126/science.1138071},
  urldate = {2023-03-26},
  abstract = {Attention can be focused volitionally by “top-down” signals derived from task demands and automatically by “bottom-up” signals from salient stimuli. The frontal and parietal cortices are involved, but their neural activity has not been directly compared. Therefore, we recorded from them simultaneously in monkeys. Prefrontal neurons reflected the target location first during top-down attention, whereas parietal neurons signaled it earlier during bottom-up attention. Synchrony between frontal and parietal areas was stronger in lower frequencies during top-down attention and in higher frequencies during bottom-up attention. This result indicates that top-down and bottom-up signals arise from the frontal and sensory cortex, respectively, and different modes of attention may emphasize synchrony at different frequencies.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QDNCXTYL\Buschman and Miller - 2007 - Top-Down Versus Bottom-Up Control of Attention in .pdf}
}

@article{buschmanTopDownBottomUpControl2007a,
  title = {Top-{{Down Versus Bottom-Up Control}} of {{Attention}} in the {{Prefrontal}} and {{Posterior Parietal Cortices}}},
  author = {Buschman, Timothy J. and Miller, Earl K.},
  date = {2007-03-30},
  journaltitle = {Science},
  volume = {315},
  number = {5820},
  pages = {1860--1862},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1138071},
  url = {https://www.science.org/doi/full/10.1126/science.1138071},
  urldate = {2023-03-31},
  abstract = {Attention can be focused volitionally by “top-down” signals derived from task demands and automatically by “bottom-up” signals from salient stimuli. The frontal and parietal cortices are involved, but their neural activity has not been directly compared. Therefore, we recorded from them simultaneously in monkeys. Prefrontal neurons reflected the target location first during top-down attention, whereas parietal neurons signaled it earlier during bottom-up attention. Synchrony between frontal and parietal areas was stronger in lower frequencies during top-down attention and in higher frequencies during bottom-up attention. This result indicates that top-down and bottom-up signals arise from the frontal and sensory cortex, respectively, and different modes of attention may emphasize synchrony at different frequencies.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\25GBJPXN\Buschman and Miller - 2007 - Top-Down Versus Bottom-Up Control of Attention in .pdf}
}

@article{buttsTuningCurvesNeuronal2006,
  title = {Tuning {{Curves}}, {{Neuronal Variability}}, and {{Sensory Coding}}},
  author = {Butts, Daniel A. and Goldman, Mark S.},
  date = {2006-03-21},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {4},
  number = {4},
  pages = {e92},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.0040092},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0040092},
  urldate = {2023-04-05},
  abstract = {Tuning curves are widely used to characterize the responses of sensory neurons to external stimuli, but there is an ongoing debate as to their role in sensory processing. Commonly, it is assumed that a neuron's role is to encode the stimulus at the tuning curve peak, because high firing rates are the neuron's most distinct responses. In contrast, many theoretical and empirical studies have noted that nearby stimuli are most easily discriminated in high-slope regions of the tuning curve. Here, we demonstrate that both intuitions are correct, but that their relative importance depends on the experimental context and the level of variability in the neuronal response. Using three different information-based measures of encoding applied to experimentally measured sensory neurons, we show how the best-encoded stimulus can transition from high-slope to high-firing-rate regions of the tuning curve with increasing noise level. We further show that our results are consistent with recent experimental findings that correlate neuronal sensitivities with perception and behavior. This study illustrates the importance of the noise level in determining the encoding properties of sensory neurons and provides a unified framework for interpreting how the tuning curve and neuronal variability relate to the overall role of the neuron in sensory encoding.},
  langid = {english},
  keywords = {Behavior,Crickets,Information entropy,Neuronal tuning,Neurons,Sensory neurons,Sensory perception,Single neuron function},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TBEZZQHD\Butts and Goldman - 2006 - Tuning Curves, Neuronal Variability, and Sensory C.pdf}
}

@article{buzsakiNeuronalOscillationsCortical2004,
  title = {Neuronal {{Oscillations}} in {{Cortical Networks}}},
  author = {Buzsáki, György and Draguhn, Andreas},
  date = {2004-06-25},
  journaltitle = {Science},
  volume = {304},
  number = {5679},
  eprint = {15218136},
  eprinttype = {pmid},
  pages = {1926--1929},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1099745},
  url = {https://science.sciencemag.org/content/304/5679/1926},
  urldate = {2020-11-10},
  abstract = {Clocks tick, bridges and skyscrapers vibrate, neuronal networks oscillate. Are neuronal oscillations an inevitable by-product, similar to bridge vibrations, or an essential part of the brain's design? Mammalian cortical neurons form behavior-dependent oscillating networks of various sizes, which span five orders of magnitude in frequency. These oscillations are phylogenetically preserved, suggesting that they are functionally relevant. Recent findings indicate that network oscillations bias input selection, temporally link neurons into assemblies, and facilitate synaptic plasticity, mechanisms that cooperatively support temporal representation and long-term consolidation of information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FF7ZAZVB\\Buzsáki and Draguhn - 2004 - Neuronal Oscillations in Cortical Networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U2HLRDY\\1926.html}
}

@article{buzsakiThetaOscillationsHippocampus2002,
  title = {Theta {{Oscillations}} in the {{Hippocampus}}},
  author = {Buzsáki, György},
  date = {2002-01-31},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {33},
  number = {3},
  pages = {325--340},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(02)00586-X},
  url = {https://www.sciencedirect.com/science/article/pii/S089662730200586X},
  urldate = {2023-03-24},
  abstract = {Theta oscillations represent the “on-line” state of the hippocampus. The extracellular currents underlying theta waves are generated mainly by the entorhinal input, CA3 (Schaffer) collaterals, and voltage-dependent Ca2+ currents in pyramidal cell dendrites. The rhythm is believed to be critical for temporal coding/decoding of active neuronal ensembles and the modification of synaptic weights. Nevertheless, numerous critical issues regarding both the generation of theta oscillations and their functional significance remain challenges for future research.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5C7AE8LM\Buzsáki - 2002 - Theta Oscillations in the Hippocampus.pdf}
}

@article{cadenaDeepConvolutionalModels2019,
  title = {Deep Convolutional Models Improve Predictions of Macaque {{V1}} Responses to Natural Images},
  author = {Cadena, Santiago A. and Denfield, George H. and Walker, Edgar Y. and Gatys, Leon A. and Tolias, Andreas S. and Bethge, Matthias and Ecker, Alexander S.},
  editor = {Einhäuser, Wolfgang},
  date = {2019-04-23},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLoS Comput Biol},
  volume = {15},
  number = {4},
  pages = {e1006897},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006897},
  url = {https://dx.plos.org/10.1371/journal.pcbi.1006897},
  urldate = {2020-10-08},
  abstract = {Despite great efforts over several decades, our best models of primary visual cortex (V1) still predict spiking activity quite poorly when probed with natural stimuli, highlighting our limited understanding of the nonlinear computations in V1. Recently, two approaches based on deep learning have emerged for modeling these nonlinear computations: transfer learning from artificial neural networks trained on object recognition and data-driven convolutional neural network models trained end-to-end on large populations of neurons. Here, we test the ability of both approaches to predict spiking activity in response to natural images in V1 of awake monkeys. We found that the transfer learning approach performed similarly well to the data-driven approach and both outperformed classical linear-nonlinear and waveletbased feature representations that build on existing theories of V1. Notably, transfer learning using a pre-trained feature space required substantially less experimental time to achieve the same performance. In conclusion, multi-layer convolutional neural networks (CNNs) set the new state of the art for predicting neural responses to natural images in primate V1 and deep features learned for object recognition are better explanations for V1 computation than all previous filter bank theories. This finding strengthens the necessity of V1 models that are multiple nonlinearities away from the image domain and it supports the idea of explaining early visual cortex based on high-level functional goals.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8VWFCWPK\Cadena et al. - 2019 - Deep convolutional models improve predictions of m.pdf}
}

@inproceedings{cadenaHowWellDeep2019,
  title = {✅ {{How}} Well Do Deep Neural Networks Trained on Object Recognition Characterize the Mouse Visual System?},
  author = {Cadena, Santiago A. and Sinz, Fabian H. and Muhammad, Taliah and Froudarakis, Emmanouil and Cobos, Erick and Walker, Edgar Y. and Reimer, Jake and Bethge, Matthias and Tolias, Andreas and Ecker, Alexander S.},
  date = {2019-10-02},
  url = {https://openreview.net/forum?id=rkxcXmtUUS},
  urldate = {2024-06-17},
  abstract = {Recent work on modeling neural responses in the primate visual system has benefited from deep neural networks trained on large-scale object recognition, and found a hierarchical correspondence between layers of the artificial neural network and brain areas along the ventral visual stream. However, we neither know whether such task-optimized networks enable equally good models of the rodent visual system, nor if a similar hierarchical correspondence exists. Here, we address these questions in the mouse visual system by extracting features at several layers of a convolutional neural network (CNN) trained on ImageNet to predict the responses of thousands of neurons in four visual areas (V1, LM, AL, RL) to natural images. We found that the CNN features outperform classical subunit energy models, but found no evidence for an order of the areas we recorded via a correspondence to the hierarchy of CNN layers. Moreover, the same CNN but with random weights provided an equivalently useful feature space for predicting neural responses. Our results suggest that object recognition as a high-level task does not provide more discriminative features to characterize the mouse visual system than a random network. Unlike in the primate, training on ethologically relevant visually guided behaviors -- beyond static object recognition -- may be needed to unveil the functional organization of the mouse visual cortex.},
  eventtitle = {Real {{Neurons}} \{\textbackslash\&\} {{Hidden Units}}: {{Future}} Directions at the Intersection of Neuroscience and Artificial Intelligence @ {{NeurIPS}} 2019},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T49GYGGW\Cadena et al. - 2019 - How well do deep neural networks trained on object.pdf}
}

@article{calhounUnsupervisedIdentificationInternal2019,
  title = {Unsupervised Identification of the Internal States That Shape Natural Behavior},
  author = {Calhoun, Adam J. and Pillow, Jonathan W. and Murthy, Mala},
  date = {2019-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {12},
  pages = {2040--2049},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0533-x},
  url = {http://www.nature.com/articles/s41593-019-0533-x},
  urldate = {2020-09-05},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\I2GZC5RB\Calhoun et al. - 2019 - Unsupervised identification of the internal states.pdf}
}

@article{campagnolaLocalConnectivitySynaptic2022,
  title = {Local Connectivity and Synaptic Dynamics in Mouse and Human Neocortex},
  author = {Campagnola, Luke and Seeman, Stephanie C. and Chartrand, Thomas and Kim, Lisa and Hoggarth, Alex and Gamlin, Clare and Ito, Shinya and Trinh, Jessica and Davoudian, Pasha and Radaelli, Cristina and Kim, Mean-Hwan and Hage, Travis and Braun, Thomas and Alfiler, Lauren and Andrade, Julia and Bohn, Phillip and Dalley, Rachel and Henry, Alex and Kebede, Sara and Mukora, Alice and Sandman, David and Williams, Grace and Larsen, Rachael and Teeter, Corinne and Daigle, Tanya L. and Berry, Kyla and Dotson, Nadia and Enstrom, Rachel and Gorham, Melissa and Hupp, Madie and Dingman Lee, Samuel and Ngo, Kiet and Nicovich, Philip R. and Potekhina, Lydia and Ransford, Shea and Gary, Amanda and Goldy, Jeff and McMillen, Delissa and Pham, Trangthanh and Tieu, Michael and Siverts, La’Akea and Walker, Miranda and Farrell, Colin and Schroedter, Martin and Slaughterbeck, Cliff and Cobb, Charles and Ellenbogen, Richard and Gwinn, Ryder P. and Keene, C. Dirk and Ko, Andrew L. and Ojemann, Jeffrey G. and Silbergeld, Daniel L. and Carey, Daniel and Casper, Tamara and Crichton, Kirsten and Clark, Michael and Dee, Nick and Ellingwood, Lauren and Gloe, Jessica and Kroll, Matthew and Sulc, Josef and Tung, Herman and Wadhwani, Katherine and Brouner, Krissy and Egdorf, Tom and Maxwell, Michelle and McGraw, Medea and Pom, Christina Alice and Ruiz, Augustin and Bomben, Jasmine and Feng, David and Hejazinia, Nika and Shi, Shu and Szafer, Aaron and Wakeman, Wayne and Phillips, John and Bernard, Amy and Esposito, Luke and D’Orazi, Florence D. and Sunkin, Susan and Smith, Kimberly and Tasic, Bosiljka and Arkhipov, Anton and Sorensen, Staci and Lein, Ed and Koch, Christof and Murphy, Gabe and Zeng, Hongkui and Jarsky, Tim},
  date = {2022-03-11},
  journaltitle = {Science},
  volume = {375},
  number = {6585},
  pages = {eabj5861},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abj5861},
  url = {https://www.science.org/doi/10.1126/science.abj5861},
  urldate = {2023-01-23},
  abstract = {We present a unique, extensive, and open synaptic physiology analysis platform and dataset. Through its application, we reveal principles that relate cell type to synaptic properties and intralaminar circuit organization in the mouse and human cortex. The dynamics of excitatory synapses align with the postsynaptic cell subclass, whereas inhibitory synapse dynamics partly align with presynaptic cell subclass but with considerable overlap. Synaptic properties are heterogeneous in most subclass-to-subclass connections. The two main axes of heterogeneity are strength and variability. Cell subclasses divide along the variability axis, whereas the strength axis accounts for substantial heterogeneity within the subclass. In the human cortex, excitatory-to-excitatory synaptic dynamics are distinct from those in the mouse cortex and vary with depth across layers 2 and 3.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CRUT8WJ3\Campagnola et al. - 2022 - Local connectivity and synaptic dynamics in mouse .pdf}
}

@article{careyEmbarrassedNotDepressed2002,
  title = {Embarrassed, but {{Not Depressed}}: {{Eye Opening Lessons}} for {{Cerebellar Learning}}},
  shorttitle = {Embarrassed, but {{Not Depressed}}},
  author = {Carey, Megan R. and Lisberger, Stephen G.},
  date = {2002-07-18},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {35},
  number = {2},
  eprint = {12160741},
  eprinttype = {pmid},
  pages = {223--226},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(02)00771-7},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(02)00771-7},
  urldate = {2023-04-23},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7C6AFXIJ\Carey and Lisberger - 2002 - Embarrassed, but Not Depressed Eye Opening Lesson.pdf}
}

@article{careySynapticMechanismsSensorimotor2011,
  title = {✅ {{Synaptic}} Mechanisms of Sensorimotor Learning in the Cerebellum},
  author = {Carey, Megan R},
  date = {2011-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Sensory and Motor Systems},
  volume = {21},
  number = {4},
  pages = {609--615},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2011.06.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438811001206},
  urldate = {2023-04-23},
  abstract = {The cerebellum plays an essential role in motor learning. The ability to identify specific sensory and motor signals carried by neurons with known connectivity makes the cerebellum an attractive system for investigating how synaptic plasticity relates to learning. Early studies focused primarily on a single form of plasticity, long-term depression at parallel fiber–Purkinje cell synapses. Recent work has highlighted both the diversity of synaptic plasticity that exists within the cerebellum and the fact that individual plasticity mechanisms can have unexpected consequences when they act within neural circuits.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BDCEYN62\\Carey - 2011 - Synaptic mechanisms of sensorimotor learning in th.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NV2Z9WXJ\\S0959438811001206.html}
}

@article{ceiReversedThetaSequences2014,
  title = {Reversed Theta Sequences of Hippocampal Cell Assemblies during Backward Travel},
  author = {Cei, Anne and Girardeau, Gabrielle and Drieu, Céline and Kanbi, Karim El and Zugaro, Michaël},
  date = {2014-05},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {5},
  pages = {719--724},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3698},
  url = {https://www.nature.com/articles/nn.3698},
  urldate = {2023-03-27},
  abstract = {Cei and colleagues used a model train to transport rats forward or backward on a circular track while the animals walked on a miniature treadmill. The authors found that the firing fields of hippocampal place cells remained stable across travel directions and that, when the train transported the rat backward, theta sequences of hippocampal cell assemblies and theta phase precession still represented the trajectory and the distance traveled through place fields.},
  issue = {5},
  langid = {english},
  keywords = {Hippocampus,Neuronal physiology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X76B7WW9\Cei et al. - 2014 - Reversed theta sequences of hippocampal cell assem.pdf}
}

@article{chakrabartiCuspApple2021,
  title = {The Cusp of an Apple},
  author = {Chakrabarti, Aditi and Michaels, Thomas C. T. and Yin, Sifan and Sun, Eric and Mahadevan, L.},
  date = {2021-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {10},
  pages = {1125--1129},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01335-8},
  url = {https://www.nature.com/articles/s41567-021-01335-8},
  urldate = {2022-10-03},
  abstract = {Singularities are common in diverse physical systems1 and lead to universal structures2,3. This universality suggests that they should also naturally arise in biological systems, where active growth, autonomous motion, kinesis and taxis focus deformations in spacetime, as exemplified in the morphogenetic processes determining biological size and shape4. A familiar example of a morphogenetic singularity is seen in the humble apple, which forms in the neighbourhood of the stalk as the apple grows. Here we study the geometry and morphogenesis of the cusp of an apple by combining observations of fruit growth with a simple theory, finite element simulations and controlled swelling experiments using a physical gel simulacrum. Our observations show that the axisymmetric cusp develops into a self-similar form, which can be understood in terms of a mechanical theory for the inhomogeneous growth of a soft sphere. Physical experiments using local inhibition in swelling gels corroborate our theoretical predictions. These experiments further show that axisymmetric cusps can lose stability and become lobed. We use simulations to show that the number of cuspidal lobes depends on the ratio of the size of the stalk to the size of the sphere, as well as the amplitude and periodicity of perturbations that mimic the role of fruit anatomy, consistent with observations of multi-cusped fruits.},
  issue = {10},
  langid = {english},
  keywords = {Gels and hydrogels,Nonlinear phenomena},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\452PPD5E\Chakrabarti et al. - 2021 - The cusp of an apple.pdf}
}

@article{challetMinireviewEntrainmentSuprachiasmatic2007,
  title = {✅ {{Minireview}}: {{Entrainment}} of the {{Suprachiasmatic Clockwork}} in {{Diurnal}} and {{Nocturnal Mammals}}},
  shorttitle = {Minireview},
  author = {Challet, Etienne},
  date = {2007-12-01},
  journaltitle = {Endocrinology},
  shortjournal = {Endocrinology},
  volume = {148},
  number = {12},
  pages = {5648--5655},
  issn = {0013-7227},
  doi = {10.1210/en.2007-0804},
  url = {https://doi.org/10.1210/en.2007-0804},
  urldate = {2023-02-26},
  abstract = {Daily rhythmicity, including timing of wakefulness and hormone secretion, is mainly controlled by a master clock located in the suprachiasmatic nucleus (SCN) of the hypothalamus. The SCN clockwork involves various clock genes, with specific temporal patterns of expression that are similar in nocturnal and diurnal species (e.g. the clock gene Per1 in the SCN peaks at midday in both categories). Timing of sensitivity to light is roughly similar, during nighttime, in diurnal and nocturnal species. Molecular mechanisms of photic resetting are also comparable in both species categories. By contrast, in animals housed in constant light, exposure to darkness can reset the SCN clock, mostly during the resting period, i.e. at opposite circadian times between diurnal and nocturnal species. Nonphotic stimuli, such as scheduled voluntary exercise, food shortage, exogenous melatonin, or serotonergic receptor activation, are also capable of shifting the master clock and/or modulating photic synchronization. Comparison between day- and night-active species allows classifications of nonphotic cues in two, arousal-independent and arousal-dependent, families of factors. Arousal-independent factors, such as melatonin (always secreted during nighttime, independently of daily activity pattern) or γ-aminobutyric acid (GABA), have shifting effects at the same circadian times in both nocturnal and diurnal rodents. By contrast, arousal-dependent factors, such as serotonin (its cerebral levels follow activity pattern), induce phase shifts only during resting and have opposite modulating effects on photic resetting between diurnal and nocturnal species. Contrary to light and arousal-independent nonphotic cues, arousal-dependent nonphotic stimuli provide synchronizing feedback signals to the SCN clock in circadian antiphase between nocturnal and diurnal animals.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TUSTKDWN\\Challet - 2007 - Minireview Entrainment of the Suprachiasmatic Clo.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\H3E4P9S5\\2501331.html}
}

@article{chaudhuriIntrinsicAttractorManifold2019,
  title = {The Intrinsic Attractor Manifold and Population Dynamics of a Canonical Cognitive Circuit across Waking and Sleep},
  author = {Chaudhuri, Rishidev and Gerçek, Berk and Pandey, Biraj and Peyrache, Adrien and Fiete, Ila},
  date = {2019-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {9},
  pages = {1512--1520},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-019-0460-x},
  url = {http://www.nature.com/articles/s41593-019-0460-x},
  urldate = {2020-09-06},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3D6BIVRS\s41593-019-0460-x.pdf}
}

@article{chazalIntroductionTopologicalData2021,
  title = {An {{Introduction}} to {{Topological Data Analysis}}: {{Fundamental}} and {{Practical Aspects}} for {{Data Scientists}}},
  shorttitle = {An {{Introduction}} to {{Topological Data Analysis}}},
  author = {Chazal, Frédéric and Michel, Bertrand},
  date = {2021-09-29},
  journaltitle = {Frontiers in Artificial Intelligence},
  shortjournal = {Front. Artif. Intell.},
  volume = {4},
  publisher = {Frontiers},
  issn = {2624-8212},
  doi = {10.3389/frai.2021.667963},
  url = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2021.667963/full},
  urldate = {2024-07-03},
  abstract = {{$<$}p{$>$}With the recent explosion in the amount, the variety, and the dimensionality of available data, identifying, extracting, and exploiting their underlying structure has become a problem of fundamental importance for data analysis and statistical learning. Topological data analysis (\textsc{tda}) is a recent and fast-growing field providing a set of new topological and geometric tools to infer relevant features for possibly complex data. It proposes new well-founded mathematical theories and computational tools that can be used independently or in combination with other data analysis and statistical learning techniques. This article is a brief introduction, through a few selected topics, to basic fundamental and practical aspects of \textsc{tda} for nonexperts.{$<$}/p{$>$}},
  langid = {english},
  keywords = {Geometric inference,Machine Learing,statistic,topological data analysis,Topological inference},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X859Y7GK\Chazal and Michel - 2021 - An Introduction to Topological Data Analysis Fund.pdf}
}

@article{chenSpatiotemporalMechanismVisual2022,
  title = {A Spatiotemporal Mechanism of Visual Attention: {{Superdiffusive}} Motion and Theta Oscillations of Neural Population Activity Patterns},
  shorttitle = {A Spatiotemporal Mechanism of Visual Attention},
  author = {Chen, Guozhang and Gong, Pulin},
  date = {2022-04-22},
  journaltitle = {Science Advances},
  volume = {8},
  number = {16},
  pages = {eabl4995},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abl4995},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abl4995},
  urldate = {2023-01-21},
  abstract = {Recent evidence has demonstrated that during visual spatial attention sampling, neural activity and behavioral performance exhibit large fluctuations. To understand the origin of these fluctuations and their functional role, here, we introduce a mechanism based on the dynamical activity pattern (attention spotlight) emerging from neural circuit models in the transition regime between different dynamical states. This attention activity pattern with rich spatiotemporal dynamics flexibly samples from different stimulus locations, explaining many key aspects of temporal fluctuations such as variable theta oscillations of visual spatial attention. Moreover, the mechanism expands our understanding of how visual attention exploits spatially complex fluctuations characterized by superdiffusive motion in space and makes experimentally testable predictions. We further illustrate that attention sampling based on such spatiotemporal fluctuations provides profound functional advantages such as adaptive switching between exploitation and exploration activities and is particularly efficient at sampling natural scenes with multiple salient objects.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\96Y4HUV3\Chen and Gong - 2022 - A spatiotemporal mechanism of visual attention Su.pdf}
}

@article{chenSpatiotemporalMechanismVisual2022a,
  title = {A Spatiotemporal Mechanism of Visual Attention: {{Superdiffusive}} Motion and Theta Oscillations of Neural Population Activity Patterns},
  shorttitle = {A Spatiotemporal Mechanism of Visual Attention},
  author = {Chen, Guozhang and Gong, Pulin},
  date = {2022-04-22},
  journaltitle = {Science Advances},
  volume = {8},
  number = {16},
  pages = {eabl4995},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abl4995},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abl4995},
  urldate = {2023-04-03},
  abstract = {Recent evidence has demonstrated that during visual spatial attention sampling, neural activity and behavioral performance exhibit large fluctuations. To understand the origin of these fluctuations and their functional role, here, we introduce a mechanism based on the dynamical activity pattern (attention spotlight) emerging from neural circuit models in the transition regime between different dynamical states. This attention activity pattern with rich spatiotemporal dynamics flexibly samples from different stimulus locations, explaining many key aspects of temporal fluctuations such as variable theta oscillations of visual spatial attention. Moreover, the mechanism expands our understanding of how visual attention exploits spatially complex fluctuations characterized by superdiffusive motion in space and makes experimentally testable predictions. We further illustrate that attention sampling based on such spatiotemporal fluctuations provides profound functional advantages such as adaptive switching between exploitation and exploration activities and is particularly efficient at sampling natural scenes with multiple salient objects.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SF94PS9F\Chen and Gong - 2022 - A spatiotemporal mechanism of visual attention Su.pdf}
}

@article{chialvoEmergentComplexNeural2010,
  title = {✅ {{Emergent}} Complex Neural Dynamics},
  author = {Chialvo, Dante R.},
  date = {2010-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {6},
  number = {10},
  pages = {744--750},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys1803},
  url = {https://www.nature.com/articles/nphys1803},
  urldate = {2022-10-01},
  abstract = {A large repertoire of spatiotemporal activity patterns in the brain is the basis for adaptive behaviour. Understanding the mechanism by which the brain’s hundred billion neurons and hundred trillion synapses manage to produce such a range of cortical configurations in a flexible manner remains a fundamental problem in neuroscience. One plausible solution is the involvement of universal mechanisms of emergent complex phenomena evident in dynamical systems poised near a critical point of a second-order phase transition. We review recent theoretical and empirical results supporting the notion that the brain is naturally poised near criticality, as well as its implications for better understanding of the brain.},
  issue = {10},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7I75I5QH\\Chialvo - 2010 - Emergent complex neural dynamics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3HGGL3KA\\nphys1803.html}
}

@article{chikkerurWhatWhereBayesian2010,
  title = {What and Where: {{A Bayesian}} Inference Theory of Attention},
  shorttitle = {What and Where},
  author = {Chikkerur, Sharat and Serre, Thomas and Tan, Cheston and Poggio, Tomaso},
  date = {2010-10-28},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  series = {Mathematical {{Models}} of {{Visual Coding}}},
  volume = {50},
  number = {22},
  pages = {2233--2247},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2010.05.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0042698910002348},
  urldate = {2023-01-19},
  abstract = {In the theoretical framework of this paper, attention is part of the inference process that solves the visual recognition problem of what is where. The theory proposes a computational role for attention and leads to a model that predicts some of its main properties at the level of psychophysics and physiology. In our approach, the main goal of the visual system is to infer the identity and the position of objects in visual scenes: spatial attention emerges as a strategy to reduce the uncertainty in shape information while feature-based attention reduces the uncertainty in spatial information. Featural and spatial attention represent two distinct modes of a computational process solving the problem of recognizing and localizing objects, especially in difficult recognition tasks such as in cluttered natural scenes. We describe a specific computational model and relate it to the known functional anatomy of attention. We show that several well-known attentional phenomena – including bottom-up pop-out effects, multiplicative modulation of neuronal tuning curves and shift in contrast responses – all emerge naturally as predictions of the model. We also show that the Bayesian model predicts well human eye fixations (considered as a proxy for shifts of attention) in natural scenes.},
  langid = {english},
  keywords = {Attention,Bayesian inference,Computational model,Object recognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TE8LQKJN\\Chikkerur et al. - 2010 - What and where A Bayesian inference theory of att.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KVKUR7Y7\\S0042698910002348.html}
}

@article{chikkerurWhatWhereBayesian2010a,
  title = {What and Where: {{A Bayesian}} Inference Theory of Attention},
  shorttitle = {What and Where},
  author = {Chikkerur, Sharat and Serre, Thomas and Tan, Cheston and Poggio, Tomaso},
  date = {2010-10-28},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  series = {Mathematical {{Models}} of {{Visual Coding}}},
  volume = {50},
  number = {22},
  pages = {2233--2247},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2010.05.013},
  url = {https://www.sciencedirect.com/science/article/pii/S0042698910002348},
  urldate = {2023-01-31},
  abstract = {In the theoretical framework of this paper, attention is part of the inference process that solves the visual recognition problem of what is where. The theory proposes a computational role for attention and leads to a model that predicts some of its main properties at the level of psychophysics and physiology. In our approach, the main goal of the visual system is to infer the identity and the position of objects in visual scenes: spatial attention emerges as a strategy to reduce the uncertainty in shape information while feature-based attention reduces the uncertainty in spatial information. Featural and spatial attention represent two distinct modes of a computational process solving the problem of recognizing and localizing objects, especially in difficult recognition tasks such as in cluttered natural scenes. We describe a specific computational model and relate it to the known functional anatomy of attention. We show that several well-known attentional phenomena – including bottom-up pop-out effects, multiplicative modulation of neuronal tuning curves and shift in contrast responses – all emerge naturally as predictions of the model. We also show that the Bayesian model predicts well human eye fixations (considered as a proxy for shifts of attention) in natural scenes.},
  langid = {english},
  keywords = {Attention,Bayesian inference,Computational model,Object recognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MWVNWN56\\Chikkerur et al. - 2010 - What and where A Bayesian inference theory of att.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IFK3GV94\\S0042698910002348.html}
}

@article{chrobokFastOscillationsCircadian2021,
  title = {From {{Fast Oscillations}} to {{Circadian Rhythms}}: {{Coupling}} at {{Multiscale Frequency Bands}} in the {{Rodent Subcortical Visual System}}},
  shorttitle = {From {{Fast Oscillations}} to {{Circadian Rhythms}}},
  author = {Chrobok, Lukasz and Belle, Mino D. C. and Myung, Jihwan},
  date = {2021},
  journaltitle = {Frontiers in Physiology},
  volume = {12},
  eprint = {34899375},
  eprinttype = {pmid},
  publisher = {Frontiers Media SA},
  doi = {10.3389/fphys.2021.738229},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8662821/},
  urldate = {2023-02-22},
  abstract = {The subcortical visual system (SVS) is a unique collection of brain structures localised in the thalamus, hypothalamus and midbrain. The SVS receives ambient light inputs from retinal ganglion cells and integrates this signal with internal homeostatic ...},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I7IVF6Y3\\Chrobok et al. - 2021 - From Fast Oscillations to Circadian Rhythms Coupl.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S8QUGD77\\PMC8662821.html}
}

@article{chungNeuralPopulationGeometry2021,
  title = {Neural Population Geometry: {{An}} Approach for Understanding Biological and Artificial Neural Networks},
  shorttitle = {Neural Population Geometry},
  author = {Chung, SueYeon and Abbott, L. F.},
  date = {2021-10-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Computational {{Neuroscience}}},
  volume = {70},
  pages = {137--144},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2021.10.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438821001227},
  urldate = {2024-07-03},
  abstract = {Advances in experimental neuroscience have transformed our ability to explore the structure and function of neural circuits. At the same time, advances in machine learning have unleashed the remarkable computational power of artificial neural networks (ANNs). While these two fields have different tools and applications, they present a similar challenge: namely, understanding how information is embedded and processed through high-dimensional representations to solve complex tasks. One approach to addressing this challenge is to utilize mathematical and computational tools to analyze the geometry of these high-dimensional representations, i.e., neural population geometry. We review examples of geometrical approaches providing insight into the function of biological and artificial neural networks: representation untangling in perception, a geometric theory of classification capacity, disentanglement, and abstraction in cognitive systems, topological representations underlying cognitive maps, dynamic untangling in motor systems, and a dynamical approach to cognition. Together, these findings illustrate an exciting trend at the intersection of machine learning, neuroscience, and geometry, in which neural population geometry provides a useful population-level mechanistic descriptor underlying task implementation. Importantly, geometric descriptions are applicable across sensory modalities, brain regions, network architectures, and timescales. Thus, neural population geometry has the potential to unify our understanding of structure and function in biological and artificial neural networks, bridging the gap between single neurons, population activities, and behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZWVVY786\\Chung and Abbott - 2021 - Neural population geometry An approach for unders.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YQREEELS\\S0959438821001227.html}
}

@article{chupeauCoverTimesRandom2015,
  title = {Cover Times of Random Searches},
  author = {Chupeau, Marie and Bénichou, Olivier and Voituriez, Raphaël},
  date = {2015-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {10},
  pages = {844--847},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys3413},
  url = {https://www.nature.com/articles/nphys3413},
  urldate = {2022-10-05},
  abstract = {The first-passage time relates the efficiency of a search process, but fails to do so for searches in which several targets are sought. Now, the distribution of times required for a random search to visit all sites has been determined analytically.},
  issue = {10},
  langid = {english},
  keywords = {Biological physics,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6KYBGX2A\\Chupeau et al. - 2015 - Cover times of random searches.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GT6HR2VD\\nphys3413.html}
}

@article{churchlandNeuralPopulationDynamics2012,
  title = {Neural Population Dynamics during Reaching},
  author = {Churchland, Mark M. and Cunningham, John P. and Kaufman, Matthew T. and Foster, Justin D. and Nuyujukian, Paul and Ryu, Stephen I. and Shenoy, Krishna V.},
  date = {2012-07},
  journaltitle = {Nature},
  volume = {487},
  number = {7405},
  pages = {51--56},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature11129},
  url = {https://www.nature.com/articles/nature11129},
  urldate = {2022-09-26},
  abstract = {Most theories of motor cortex have assumed that neural activity represents movement parameters. This view derives from what is known about primary visual cortex, where neural activity represents patterns of light. Yet it is unclear how well the analogy between motor and visual cortex holds. Single-neuron responses in motor cortex are complex, and there is marked disagreement regarding which movement parameters are represented. A better analogy might be with other motor systems, where a common principle is rhythmic neural activity. Here we find that motor cortex responses during reaching contain a brief but strong oscillatory component, something quite unexpected for a non-periodic behaviour. Oscillation amplitude and phase followed naturally from the preparatory state, suggesting a mechanistic role for preparatory neural activity. These results demonstrate an unexpected yet surprisingly simple structure in the population response. This underlying structure explains many of the confusing features of individual neural responses.},
  issue = {7405},
  langid = {english},
  keywords = {Motor cortex,Neuronal physiology,Population dynamics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X99ZZQW3\\Churchland et al. - 2012 - Neural population dynamics during reaching.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5HBFYAGB\\nature11129.html}
}

@article{cocinaSpikingBurstinessWorking2022,
  title = {Spiking Burstiness and Working Memory in the Human Medial Temporal Lobe},
  author = {Cocina, Francesco and Vitalis, Andreas and Caflisch, Amedeo},
  date = {2022-10-01},
  journaltitle = {Cerebral Cortex Communications},
  volume = {3},
  number = {4},
  pages = {tgac039},
  issn = {2632-7376},
  doi = {10.1093/texcom/tgac039},
  url = {https://academic.oup.com/cercorcomms/article/doi/10.1093/texcom/tgac039/6763343},
  urldate = {2023-01-16},
  abstract = {P-value for the combined LvR is given by the median of the 100 extracted ones.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QPUF7N32\Cocina et al. - 2022 - Spiking burstiness and working memory in the human.pdf}
}

@article{cohenAttentionImprovesPerformance2009,
  title = {✅ {{Attention}} Improves Performance Primarily by Reducing Interneuronal Correlations},
  author = {Cohen, Marlene R. and Maunsell, John H. R.},
  date = {2009-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {12},
  number = {12},
  pages = {1594--1600},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.2439},
  url = {https://www.nature.com/articles/nn.2439},
  urldate = {2022-12-19},
  abstract = {Previous work has suggested that visual attention improves behavioral performance by increasing the firing rates of individual sensory neurons. Recording from populations of neurons in monkey visual area V4, this study finds that most of the attentional improvement in the population signal results from decreases in interneuronal correlations.},
  issue = {12},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XELVT9NU\Cohen and Maunsell - 2009 - Attention improves performance primarily by reduci.pdf}
}

@article{cohenMeasuringInterpretingNeuronal2011,
  title = {Measuring and Interpreting Neuronal Correlations},
  author = {Cohen, Marlene R. and Kohn, Adam},
  date = {2011-06-27},
  journaltitle = {Nature neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {14},
  number = {7},
  eprint = {21709677},
  eprinttype = {pmid},
  pages = {811--819},
  issn = {1097-6256},
  doi = {10.1038/nn.2842},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3586814/},
  urldate = {2023-03-22},
  abstract = {Mounting evidence suggests that understanding how the brain encodes information and performs computations will require studying correlations between neurons. The recent advent of recording techniques such as multielectrode arrays and two-photon imaging has made it easier to measure correlations, opening the door to detailed exploration of their properties and contributions to cortical processing. Studies to date, however, have reported discrepant findings, providing a confusing picture. Here, we briefly review these studies and conduct simulations to explore the influence of several experimental and physiological factors on correlation measurements. Differences in response strength, the time window over which spikes are counted, spike sorting conventions, and internal states can all dramatically affect measured correlations and systematically bias estimates. Given these complicating factors, we offer guidelines for interpreting correlation data and a discussion of how best to evaluate the impact of correlations on cortical processing.},
  pmcid = {PMC3586814},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5TQ723ZR\\nn.2842.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PHKT6VKM\\Cohen and Kohn - 2011 - Measuring and interpreting neuronal correlations.pdf}
}

@article{cohenSerotonergicNeuronsSignal2015,
  title = {✅ {{Serotonergic}} Neurons Signal Reward and Punishment on Multiple Timescales},
  author = {Cohen, Jeremiah Y and Amoroso, Mackenzie W and Uchida, Naoshige},
  editor = {Behrens, Timothy},
  date = {2015-02-25},
  journaltitle = {eLife},
  volume = {4},
  pages = {e06346},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.06346},
  url = {https://doi.org/10.7554/eLife.06346},
  urldate = {2023-04-18},
  abstract = {Serotonin's function in the brain is unclear. One challenge in testing the numerous hypotheses about serotonin's function has been observing the activity of identified serotonergic neurons in animals engaged in behavioral tasks. We recorded the activity of dorsal raphe neurons while mice experienced a task in which rewards and punishments varied across blocks of trials. We ‘tagged’ serotonergic neurons with the light-sensitive protein channelrhodopsin-2 and identified them based on their responses to light. We found three main features of serotonergic neuron activity: (1) a large fraction of serotonergic neurons modulated their tonic firing rates over the course of minutes during reward vs punishment blocks; (2) most were phasically excited by punishments; and (3) a subset was phasically excited by reward-predicting cues. By contrast, dopaminergic neurons did not show firing rate changes across blocks of trials. These results suggest that serotonergic neurons signal information about reward and punishment on multiple timescales.},
  keywords = {behavior,dorsal raphe,neurophysiology,punishment,reward,serotonin},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NPG27UHT\Cohen et al. - 2015 - Serotonergic neurons signal reward and punishment .pdf}
}

@article{colginMechanismsFunctionsTheta2013,
  title = {✅ {{Mechanisms}} and {{Functions}} of {{Theta Rhythms}}},
  author = {Colgin, Laura Lee},
  date = {2013},
  journaltitle = {Annual Review of Neuroscience},
  volume = {36},
  number = {1},
  eprint = {23724998},
  eprinttype = {pmid},
  pages = {295--312},
  doi = {10.1146/annurev-neuro-062012-170330},
  url = {https://doi.org/10.1146/annurev-neuro-062012-170330},
  urldate = {2023-03-23},
  abstract = {The theta rhythm is one of the largest and most sinusoidal activity patterns in the brain. Here I survey progress in the field of theta rhythms research. I present arguments supporting the hypothesis that theta rhythms emerge owing to intrinsic cellular properties yet can be entrained by several theta oscillators throughout the brain. I review behavioral correlates of theta rhythms and consider how these correlates inform our understanding of theta rhythms' functions. I discuss recent work suggesting that one function of theta is to package related information within individual theta cycles for more efficient spatial memory processing. Studies examining the role of theta phase precession in spatial memory, particularly sequence retrieval, are also summarized. Additionally, I discuss how interregional coupling of theta rhythms facilitates communication across brain regions. Finally, I conclude by summarizing how theta rhythms may support cognitive operations in the brain, including learning.},
  keywords = {CA1,hippocampus,memory,oscillations,phase precession,place cells},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\66MKP9EP\Colgin - 2013 - Mechanisms and Functions of Theta Rhythms.pdf}
}

@article{colginRhythmsHippocampalNetwork2016,
  title = {Rhythms of the Hippocampal Network},
  author = {Colgin, Laura Lee},
  date = {2016-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {17},
  number = {4},
  pages = {239--249},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.21},
  url = {https://www.nature.com/articles/nrn.2016.21},
  urldate = {2023-03-24},
  abstract = {The hippocampus shows three main classes of rhythms: theta (∼4–12 Hz), sharp wave–ripples (∼150–200 Hz ripples superimposed on ∼0.01–3 Hz sharp waves) and gamma (∼25–100 Hz).Theta rhythm generation involves a variety of mechanisms, including theta rhythmic firing in septal and hippocampal interneurons, excitatory inputs to hippocampus and intrinsic properties of hippocampal neurons.Theta rhythms are likely to be important for the formation of memories of sequences of events.Sharp wave–ripple complexes are composed of two distinct network patterns: sharp waves (excitatory events that propagate from CA3 to CA1) and ripples (which reflect high frequency firing in hippocampal interneurons).Accumulating evidence suggests that sharp wave–ripples are important for intrinsic hippocampal operations, including offline memory processing, retrieval of previously stored memories and planning of future behaviours.The class of brain rhythms traditionally defined as gamma probably contains at least two different variants of oscillatory activity.Recent findings suggest that slow (∼25–55 Hz) and fast (∼60–100 Hz) variants of gamma have different origins and may have different functions.},
  issue = {4},
  langid = {english},
  keywords = {Hippocampus,Learning and memory,Navigation},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\S4IGQJ6I\Colgin - 2016 - Rhythms of the hippocampal network.pdf}
}

@article{colwellLinkingNeuralActivity2011,
  title = {Linking Neural Activity and Molecular Oscillations in the {{SCN}}},
  author = {Colwell, Christopher S.},
  date = {2011-10},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {12},
  number = {10},
  pages = {553--569},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3086},
  url = {http://www.nature.com/articles/nrn3086},
  urldate = {2023-02-22},
  abstract = {Neurons in the suprachiasmatic nucleus (SCN) function as part of a central timing circuit that drives daily changes in our behaviour and underlying physiology. A hallmark feature of SCN neuronal populations is that they are mostly electrically silent during the night, start to fire action potentials near dawn and then continue to generate action potentials with a slow and steady pace all day long. Sets of currents are responsible for this daily rhythm, with the strongest evidence for persistent Na+ currents, L‑type Ca2+ currents, hyperpolarizationactivated currents (IH), large-conductance Ca2+ activated K+ (BK) currents and fast delayed rectifier (FDR) K+ currents. These rhythms in electrical activity are crucial for the function of the circadian timing system, including the expression of clock genes, and decline with ageing and disease. This article reviews our current understanding of the ionic and molecular mechanisms that drive the rhythmic firing patterns in the SCN.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KG3MD6NQ\Colwell - 2011 - Linking neural activity and molecular oscillations.pdf}
}

@report{confavreuxMetalearningApproachRe2020,
  type = {preprint},
  title = {A Meta-Learning Approach to (Re)Discover Plasticity Rules That Carve a Desired Function into a Neural Network},
  author = {Confavreux, Basile and Agnes, Everton J. and Zenke, Friedemann and Lillicrap, Timothy and Vogels, Tim P.},
  date = {2020-10-25},
  institution = {Neuroscience},
  doi = {10.1101/2020.10.24.353409},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.10.24.353409},
  urldate = {2023-12-17},
  abstract = {The search for biologically faithful synaptic plasticity rules has resulted in a large body of models. They are usually inspired by – and fitted to – experimental data, but they rarely produce neural dynamics that serve complex functions. These failures suggest that current plasticity models are still under-constrained by existing data. Here, we present an alternative approach that uses meta-learning to discover plausible synaptic plasticity rules. Instead of experimental data, the rules are constrained by the functions they implement and the structure they are meant to produce. Briefly, we parameterize synaptic plasticity rules by a Volterra expansion and then use supervised learning methods (gradient descent or evolutionary strategies) to minimize a problem-dependent loss function that quantifies how effectively a candidate plasticity rule transforms an initially random network into one with the desired function. We first validate our approach by re-discovering previously described plasticity rules, starting at the single-neuron level and “Oja’s rule”, a simple Hebbian plasticity rule that captures the direction of most variability of inputs to a neuron (i.e., the first principal component). We expand the problem to the network level and ask the framework to find Oja’s rule together with an anti-Hebbian rule such that an initially random two-layer firing-rate network will recover several principal components of the input space after learning. Next, we move to networks of integrate-and-fire neurons with plastic inhibitory afferents. We train for rules that achieve a target firing rate by countering tuned excitation. Our algorithm discovers a specific subset of the manifold of rules that can solve this task. Our work is a proof of principle of an automated and unbiased approach to unveil synaptic plasticity rules that obey biological constraints and can solve complex functions.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KD78GQIG\Confavreux et al. - 2020 - A meta-learning approach to (re)discover plasticit.pdf}
}

@online{ConnectingLevelsAnalysis,
  title = {‪{{Connecting}} Levels of Analysis in the Computational Era‬},
  url = {https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2HXsblgAAAAJ&sortby=pubdate&citation_for_view=2HXsblgAAAAJ:3x-KLxxGyuUC},
  urldate = {2023-05-17},
  abstract = {‪R Naud, A Longtin‬, ‪arXiv preprint arXiv:2305.06037, 2023‬}
}

@article{constantinouCrackingBrainCode,
  title = {Cracking the {{Brain}}'s {{Code}}: {{How}} Do {{Brain Rhythms Support Information Processing}}?},
  author = {Constantinou, Maria},
  pages = {159},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KTE5WG73\Constantinou - Cracking the Brain's Code How do Brain Rhythms Su.pdf}
}

@article{corriganDistinctNeuralCodes2022,
  title = {Distinct Neural Codes in Primate Hippocampus and Lateral Prefrontal Cortex during Associative Learning in Virtual Environments},
  author = {Corrigan, Benjamin W. and Gulli, Roberto A. and Doucet, Guillaume and Roussy, Megan and Luna, Rogelio and Pradeepan, Kartik S. and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
  date = {2022-07-06},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {13},
  pages = {2155-2169.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.04.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322003610},
  urldate = {2023-01-12},
  abstract = {The hippocampus (HPC) and the lateral prefrontal cortex (LPFC) are two cortical areas of the primate brain deemed essential to cognition. Here, we hypothesized that the codes mediating neuronal communication in the HPC and LPFC microcircuits have distinctively evolved to serve plasticity and memory function at different spatiotemporal scales. We used a virtual reality task in which animals selected one of the two targets in the arms of the maze, according to a learned context-color rule. Our results show that during associative learning, HPC principal cells concentrate spikes in bursts, enabling temporal summation and fast synaptic plasticity in small populations of neurons and ultimately facilitating rapid encoding of associative memories. On the other hand, layer II/III LPFC pyramidal cells fire spikes more sparsely distributed over time. The latter would facilitate broadcasting of signals loaded in short-term memory across neuronal populations without necessarily triggering fast synaptic plasticity.},
  langid = {english},
  keywords = {burst firing,hippocampus,long-term memory,neural code,prefrontal cortex,primate,short-term memory,working memory},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I8M3UEJV\\Corrigan et al. - 2022 - Distinct neural codes in primate hippocampus and l.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7JPT4A9W\\S0896627322003610.html}
}

@article{corriganDistinctNeuralCodes2022a,
  title = {Distinct Neural Codes in Primate Hippocampus and Lateral Prefrontal Cortex during Associative Learning in Virtual Environments},
  author = {Corrigan, Benjamin W. and Gulli, Roberto A. and Doucet, Guillaume and Roussy, Megan and Luna, Rogelio and Pradeepan, Kartik S. and Sachs, Adam J. and Martinez-Trujillo, Julio C.},
  date = {2022-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {13},
  pages = {2155-2169.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2022.04.016},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627322003610},
  urldate = {2023-01-12},
  abstract = {The hippocampus (HPC) and the lateral prefrontal cortex (LPFC) are two cortical areas of the primate brain deemed essential to cognition. Here, we hypothesized that the codes mediating neuronal communication in the HPC and LPFC microcircuits have distinctively evolved to serve plasticity and memory function at different spatiotemporal scales. We used a virtual reality task in which animals selected one of the two targets in the arms of the maze, according to a learned context-color rule. Our results show that during associative learning, HPC principal cells concentrate spikes in bursts, enabling temporal summation and fast synaptic plasticity in small populations of neurons and ultimately facilitating rapid encoding of associative memories. On the other hand, layer II/III LPFC pyramidal cells fire spikes more sparsely distributed over time. The latter would facilitate broadcasting of signals loaded in short-term memory across neuronal populations without necessarily triggering fast synaptic plasticity.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\54T6SXXZ\Corrigan et al. - 2022 - Distinct neural codes in primate hippocampus and l.pdf}
}

@article{costaFluctuatingLandscapesHeavy2024,
  title = {Fluctuating {{Landscapes}} and {{Heavy Tails}} in {{Animal Behavior}}},
  author = {Costa, Antonio Carlos and Sridhar, Gautam and Wyart, Claire and Vergassola, Massimo},
  date = {2024-04-02},
  journaltitle = {PRX Life},
  shortjournal = {PRX Life},
  volume = {2},
  number = {2},
  pages = {023001},
  publisher = {American Physical Society},
  doi = {10.1103/PRXLife.2.023001},
  url = {https://link.aps.org/doi/10.1103/PRXLife.2.023001},
  urldate = {2024-04-20},
  abstract = {Animal behavior is shaped by a myriad of mechanisms acting on a wide range of scales, which hampers quantitative reasoning and the identification of general principles. Here, we combine data analysis and theory to investigate the relationship between behavioral plasticity and heavy-tailed statistics often observed in animal behavior. Specifically, we first leverage high-resolution recordings of Caenorhabditis elegans locomotion to show that stochastic transitions among long-lived behaviors exhibit heavy-tailed first-passage-time distributions and correlation functions. Such heavy tails can be explained by slow adaptation of behavior over time. This particular result motivates our second step of introducing a general model where we separate fast dynamics on a quasistationary multiwell potential, from nonergodic, slowly varying modes. We then show that heavy tails generically emerge in such a model, and we provide a theoretical derivation of the resulting functional form, which can become a power law with exponents that depend on the strength of the fluctuations. Finally, we provide direct support for the generality of our findings by testing them in a C. elegans mutant where adaptation is suppressed and heavy tails thus disappear, and recordings of larval zebrafish swimming behavior where heavy tails are again prevalent.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SZMQRCDC\\Costa et al. - 2024 - Fluctuating Landscapes and Heavy Tails in Animal B.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\U9DPS5EZ\\PRXLife.2.html}
}

@article{costaModelingEffectSleep2016,
  title = {Modeling the Effect of Sleep Regulation on a Neural Mass Model},
  author = {Costa, Michael Schellenberger and Born, Jan and Claussen, Jens Christian and Martinetz, Thomas},
  date = {2016-08-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {41},
  number = {1},
  pages = {15--28},
  issn = {1573-6873},
  doi = {10.1007/s10827-016-0602-z},
  url = {https://doi.org/10.1007/s10827-016-0602-z},
  urldate = {2020-11-20},
  abstract = {In mammals, sleep is categorized by two main sleep stages, rapid eye movement (REM) and non-REM (NREM) sleep that are known to fulfill different functional roles, the most notable being the consolidation of memory. While REM sleep is characterized by brain activity similar to wakefulness, the EEG activity changes drastically with the emergence of K-complexes, sleep spindles and slow oscillations during NREM sleep. These changes are regulated by circadian and ultradian rhythms, which emerge from an intricate interplay between multiple neuronal populations in the brainstem, forebrain and hypothalamus and the resulting varying levels of neuromodulators. Recently, there has been progress in the understanding of those rhythms both from a physiological as well as theoretical perspective. However, how these neuromodulators affect the generation of the different EEG patterns and their temporal dynamics is poorly understood. Here, we build upon previous work on a neural mass model of the sleeping cortex and investigate the effect of those neuromodulators on the dynamics of the cortex and the corresponding transition between wakefulness and the different sleep stages. We show that our simplified model is sufficient to generate the essential features of human EEG over a full day. This approach builds a bridge between sleep regulatory networks and EEG generating neural mass models and provides a valuable tool for model validation.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TRDNCRCM\Costa et al. - 2016 - Modeling the effect of sleep regulation on a neura.pdf}
}

@article{crutchfieldOrderChaos2012,
  title = {Between Order and Chaos},
  author = {Crutchfield, James P.},
  date = {2012-01},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {8},
  number = {1},
  pages = {17--24},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys2190},
  url = {https://www.nature.com/articles/nphys2190},
  urldate = {2022-10-01},
  abstract = {What is a pattern? How do we come to recognize patterns never seen before? Quantifying the notion of pattern and formalizing the process of pattern discovery go right to the heart of physical science. Over the past few decades physics’ view of nature’s lack of structure—its unpredictability—underwent a major renovation with the discovery of deterministic chaos, overthrowing two centuries of Laplace’s strict determinism in classical physics. Behind the veil of apparent randomness, though, many processes are highly ordered, following simple rules. Tools adapted from the theories of information and computation have brought physical science to the brink of automatically discovering hidden patterns and quantifying their structural complexity.},
  issue = {1},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QIEHIFSL\\Crutchfield - 2012 - Between order and chaos.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\F58V7STZ\\nphys2190.html}
}

@article{cunninghamDimensionalityReductionLargescale2014,
  title = {✅ {{Dimensionality}} Reduction for Large-Scale Neural Recordings},
  author = {Cunningham, John P. and Yu, Byron M.},
  date = {2014-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {11},
  pages = {1500--1509},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3776},
  url = {https://www.nature.com/articles/nn.3776},
  urldate = {2024-07-11},
  abstract = {Many recent studies have adopted dimensionality reduction to analyze neural population activity and to find features that are not apparent at the level of individual neurons. The authors describe the scientific motivation for population analyses and the dimensionality reduction methods commonly applied to population activity. They also offer practical advice about selecting methods and interpreting their outputs.},
  langid = {english},
  keywords = {Learning algorithms},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZXAN9JZG\Cunningham and Yu - 2014 - Dimensionality reduction for large-scale neural re.pdf}
}

@article{czeislerMeasuringPassageBrain2016,
  title = {Measuring the Passage of Brain Time},
  author = {Czeisler, Charles A.},
  date = {2016-08-12},
  journaltitle = {Science},
  volume = {353},
  number = {6300},
  pages = {648--649},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aah5402},
  url = {https://www.science.org/doi/abs/10.1126/science.aah5402},
  urldate = {2023-02-16},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\A7E337T8\Czeisler - 2016 - Measuring the passage of brain time.pdf}
}

@article{dacostaExplosivePercolationTransition2010,
  title = {Explosive {{Percolation Transition}} Is {{Actually Continuous}}},
  author = {da Costa, R. A. and Dorogovtsev, S. N. and Goltsev, A. V. and Mendes, J. F. F.},
  options = {useprefix=true},
  date = {2010-12-14},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {105},
  number = {25},
  pages = {255701},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.105.255701},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.105.255701},
  urldate = {2022-10-05},
  abstract = {Recently a discontinuous percolation transition was reported in a new “explosive percolation” problem for irreversible systems [D. Achlioptas, R. M. D’Souza, and J. Spencer, Science 323, 1453 (2009)] in striking contrast to ordinary percolation. We consider a representative model which shows that the explosive percolation transition is actually a continuous, second order phase transition though with a uniquely small critical exponent of the percolation cluster size. We describe the unusual scaling properties of this transition and find its critical exponents and dimensions.},
  keywords = {networks,percolation,phase transitions},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\677AC7BN\\da Costa et al. - 2010 - Explosive Percolation Transition is Actually Conti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WENV6L8P\\PhysRevLett.105.html}
}

@article{dallaportaFeedforwardFeedbackInfluences2021,
  title = {Feedforward and Feedback Influences through Distinct Frequency Bands between Two Spiking-Neuron Networks},
  author = {Dalla Porta, Leonardo and Castro, Daniel M. and Copelli, Mauro and Carelli, Pedro V. and Matias, Fernanda S.},
  date = {2021-11-11},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {5},
  pages = {054404},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.104.054404},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.054404},
  urldate = {2022-10-02},
  abstract = {Several studies on brain signals suggested that bottom-up and top-down influences are exerted through distinct frequency bands among visual cortical areas. It was recently shown that theta and gamma rhythms subserve feedforward, whereas the feedback influence is dominated by the alpha-beta rhythm in primates. A few theoretical models for reproducing these effects have been proposed so far. Here we show that a simple but biophysically plausible two-network motif composed of spiking-neuron models and chemical synapses can exhibit feedforward and feedback influences through distinct frequency bands. Different from previous studies, this kind of model allows us to study directed influences not only at the population level, by using a proxy for the local field potential, but also at the cellular level, by using the neuronal spiking series.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AQTVKU5U\\Dalla Porta et al. - 2021 - Feedforward and feedback influences through distin.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z9Q4L6KG\\PhysRevE.104.html}
}

@article{dangeloSeekingUnifiedFramework2013,
  title = {Seeking a Unified Framework for Cerebellar Function and Dysfunction: From Circuit Operations to Cognition},
  shorttitle = {Seeking a Unified Framework for Cerebellar Function and Dysfunction},
  author = {D‘Angelo, Egidio and Casali, Stefano},
  date = {2013},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {6},
  issn = {1662-5110},
  url = {https://www.frontiersin.org/articles/10.3389/fncir.2012.00116},
  urldate = {2023-04-23},
  abstract = {Following the fundamental recognition of its involvement in sensory-motor coordination and learning, the cerebellum is now also believed to take part in the processing of cognition and emotion. This hypothesis is recurrent in numerous papers reporting anatomical and functional observations, and it requires an explanation. We argue that a similar circuit structure in all cerebellar areas may carry out various operations using a common computational scheme. On the basis of a broad review of anatomical data, it is conceivable that the different roles of the cerebellum lie in the specific connectivity of the cerebellar modules, with motor, cognitive, and emotional functions (at least partially) segregated into different cerebro-cerebellar loops. We here develop a conceptual and operational framework based on multiple interconnected levels (a meta-levels hypothesis): from cellular/molecular to network mechanisms leading to generation of computational primitives, thence to high-level cognitive/emotional processing, and finally to the sphere of mental function and dysfunction. The main concept explored is that of intimate interplay between timing and learning (reminiscent of the “timing and learning machine” capabilities long attributed to the cerebellum), which reverberates from cellular to circuit mechanisms. Subsequently, integration within large-scale brain loops could generate the disparate cognitive/emotional and mental functions in which the cerebellum has been implicated. We propose, therefore, that the cerebellum operates as a general-purpose co-processor, whose effects depend on the specific brain centers to which individual modules are connected. Abnormal functioning in these loops could eventually contribute to the pathogenesis of major brain pathologies including not just ataxia but also dyslexia, autism, schizophrenia, and depression.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YICCTFYR\D‘Angelo and Casali - 2013 - Seeking a unified framework for cerebellar functio.pdf}
}

@article{dangeloTimingPlasticityCerebellum2009,
  title = {Timing and Plasticity in the Cerebellum: Focus on the Granular Layer},
  shorttitle = {Timing and Plasticity in the Cerebellum},
  author = {D’Angelo, Egidio and Zeeuw, Chris I. De},
  date = {2009-01-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {32},
  number = {1},
  eprint = {18977038},
  eprinttype = {pmid},
  pages = {30--40},
  publisher = {Elsevier},
  issn = {0166-2236, 1878-108X},
  doi = {10.1016/j.tins.2008.09.007},
  url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(08)00245-2},
  urldate = {2023-04-23},
  langid = {english}
}

@article{davisPhaseTransitionsInformation2020,
  title = {Phase Transitions in Information Spreading on Structured Populations},
  author = {Davis, Jessica T. and Perra, Nicola and Zhang, Qian and Moreno, Yamir and Vespignani, Alessandro},
  date = {2020-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {16},
  number = {5},
  pages = {590--596},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-020-0810-3},
  url = {https://www.nature.com/articles/s41567-020-0810-3},
  urldate = {2022-10-02},
  abstract = {Mathematical models of social contagion that incorporate networks of human interactions have become increasingly popular, however, very few approaches have tackled the challenges of including complex and realistic properties of socio-technical systems. Here, we define a framework to characterize the dynamics of the Maki–Thompson rumour spreading model in structured populations, and analytically find a previously uncharacterized dynamical phase transition that separates the local and global contagion regimes. We validate our threshold prediction through extensive Monte Carlo simulations. Furthermore, we apply this framework in two real-world systems, the European commuting and transportation network and the Digital Bibliography and Library Project collaboration network. Our findings highlight the importance of the underlying population structure in understanding social contagion phenomena and have the potential to define new intervention strategies aimed at hindering or facilitating the diffusion of information in socio-technical systems.},
  issue = {5},
  langid = {english},
  keywords = {Complex networks,Phase transitions and critical phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NSLJ53VL\\Davis et al. - 2020 - Phase transitions in information spreading on stru.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MMAGCJ6S\\s41567-020-0810-3.html}
}

@article{deboerSleepHomeostasisCircadian2018,
  title = {Sleep Homeostasis and the Circadian Clock: {{Do}} the Circadian Pacemaker and the Sleep Homeostat Influence Each Other’s Functioning?},
  shorttitle = {Sleep Homeostasis and the Circadian Clock},
  author = {Deboer, Tom},
  date = {2018-03-01},
  journaltitle = {Neurobiology of Sleep and Circadian Rhythms},
  shortjournal = {Neurobiol Sleep Circadian Rhythms},
  volume = {5},
  eprint = {31236513},
  eprinttype = {pmid},
  pages = {68--77},
  issn = {2451-9944},
  doi = {10.1016/j.nbscr.2018.02.003},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6584681/},
  urldate = {2023-02-26},
  abstract = {Sleep is regulated by a homeostatic and a circadian process. Together these two processes determine most aspects of sleep and related variables like sleepiness and alertness. The two processes are known to be able to work independently, but also to both influence sleep and sleep related variables in an additive or more complex manner. The question remains whether the two processes are directly influencing each other., The present review summarizes evidence from behavioural and electroencephalographic determined sleep, electrophysiology, gene knock out mouse models, and mathematical modelling to explore whether sleep homeostasis can influence circadian clock functioning and vice versa., There is a multitude of data available showing parallel action or influence of sleep homeostatic mechanisms and the circadian clock on several objective and subjective variables related to sleep and alertness. However, the evidence of a direct influence of the circadian clock on sleep homeostatic mechanisms is sparse and more research is needed, particularly applying longer sleep deprivations that include a second night., The strongest evidence of an influence of sleep homeostatic mechanisms on clock functioning comes from sleep deprivation experiments, demonstrating an attenuation of phase shifts of the circadian rhythm to light pulses when sleep homeostatic pressure is increased. The data suggest that the circadian clock is less susceptible to light when sleep pressure is high., The available data indicate that a strong central clock will induce periods of deep sleep, which in turn will strengthen clock function. Both are therefore important for health and wellbeing. Weakening of one will also hamper functioning of the other. Shift work and jet lag are situations where one tries to adapt to zeitgebers in a condition where sleep is compromised. Adaptation to zeitgebers may be improved by introducing nap schedules to reduce sleep pressure, and through that increasing clock susceptibility to light.,                                        •               Sleep is regulated by homeostatic and circadian processes.                                         •               Both are acting downstream on physiology and behaviour.                                         •               This review addresses the question whether they also influence each other directly.                                         •               There is limited evidence that the central circadian pacemaker is influencing sleep homeostasis.                                         •               There is more evidence of sleep homeostatic mechanisms influencing functioning of the circadian clock.                                         •               The latter can be applied to optimize shift work protocols and recovery from jetlag.},
  pmcid = {PMC6584681},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CTT3LYMB\Deboer - 2018 - Sleep homeostasis and the circadian clock Do the .pdf}
}

@article{dedomenicoPhysicsSpreadingProcesses2016,
  title = {The Physics of Spreading Processes in Multilayer Networks},
  author = {De Domenico, Manlio and Granell, Clara and Porter, Mason A. and Arenas, Alex},
  date = {2016-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {12},
  number = {10},
  pages = {901--906},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys3865},
  url = {https://www.nature.com/articles/nphys3865},
  urldate = {2022-10-01},
  abstract = {Despite the success of traditional network analysis, standard networks provide a limited representation of complex systems, which often include different types of relationships (or ‘multiplexity’) between their components. Such structural complexity has a significant effect on both dynamics and function. Throwing away or aggregating available structural information can generate misleading results and be a major obstacle towards attempts to understand complex systems. The recent multilayer approach for modelling networked systems explicitly allows the incorporation of multiplexity and other features of realistic systems. It allows one to couple different structural relationships by encoding them in a convenient mathematical object. It also allows one to couple different dynamical processes on top of such interconnected structures. The resulting framework plays a crucial role in helping to achieve a thorough, accurate understanding of complex systems. The study of multilayer networks has also revealed new physical phenomena that remain hidden when using ordinary graphs, the traditional network representation. Here we survey progress towards attaining a deeper understanding of spreading processes on multilayer networks, and we highlight some of the physical phenomena related to spreading processes that emerge from multilayer structure.},
  issue = {10},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RT6PDM9I\\De Domenico et al. - 2016 - The physics of spreading processes in multilayer n.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZNEIYACP\\nphys3865.html}
}

@article{dedomenicoPhysicsSpreadingProcesses2016a,
  title = {The Physics of Spreading Processes in Multilayer Networks},
  author = {De Domenico, Manlio and Granell, Clara and Porter, Mason A. and Arenas, Alex},
  date = {2016-10},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {12},
  number = {10},
  pages = {901--906},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys3865},
  url = {https://www.nature.com/articles/nphys3865},
  urldate = {2022-10-03},
  abstract = {Despite the success of traditional network analysis, standard networks provide a limited representation of complex systems, which often include different types of relationships (or ‘multiplexity’) between their components. Such structural complexity has a significant effect on both dynamics and function. Throwing away or aggregating available structural information can generate misleading results and be a major obstacle towards attempts to understand complex systems. The recent multilayer approach for modelling networked systems explicitly allows the incorporation of multiplexity and other features of realistic systems. It allows one to couple different structural relationships by encoding them in a convenient mathematical object. It also allows one to couple different dynamical processes on top of such interconnected structures. The resulting framework plays a crucial role in helping to achieve a thorough, accurate understanding of complex systems. The study of multilayer networks has also revealed new physical phenomena that remain hidden when using ordinary graphs, the traditional network representation. Here we survey progress towards attaining a deeper understanding of spreading processes on multilayer networks, and we highlight some of the physical phenomena related to spreading processes that emerge from multilayer structure.},
  issue = {10},
  langid = {english},
  keywords = {Complex networks,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KEQ5BWVY\\De Domenico et al. - 2016 - The physics of spreading processes in multilayer n.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FZYHTLX7\\nphys3865.html}
}

@article{degerFluctuationsInformationFiltering2014,
  title = {Fluctuations and Information Filtering in Coupled Populations of Spiking Neurons with Adaptation},
  author = {Deger, Moritz and Schwalger, Tilo and Naud, Richard and Gerstner, Wulfram},
  date = {2014-12-01},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {90},
  number = {6},
  eprint = {1311.4206},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  pages = {062704},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.90.062704},
  url = {http://arxiv.org/abs/1311.4206},
  urldate = {2022-09-02},
  abstract = {Finite-sized populations of spiking elements are fundamental to brain function, but also used in many areas of physics. Here we present a theory of the dynamics of finite-sized populations of spiking units, based on a quasi-renewal description of neurons with adaptation. We derive an integral equation with colored noise that governs the stochastic dynamics of the population activity in response to time-dependent stimulation and calculate the spectral density in the asynchronous state. We show that systems of coupled populations with adaptation can generate a frequency band in which sensory information is preferentially encoded. The theory is applicable to fully as well as randomly connected networks, and to leaky integrate-and-fire as well as to generalized spiking neurons with adaptation on multiple time scales.},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\54MR2BB8\\Deger et al. - 2014 - Fluctuations and information filtering in coupled .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YVZ863KA\\1311.html}
}

@article{delaAntiphaseOscillationLeft2000,
  title = {Antiphase {{Oscillation}} of the {{Left}} and {{Right Suprachiasmatic Nuclei}}},
  author = {de {la}, Horacio O. and Iglesia and Meyer, Jennifer and Carpino, Alan and Schwartz, William J.},
  options = {useprefix=true},
  date = {2000-10-27},
  journaltitle = {Science},
  volume = {290},
  number = {5492},
  pages = {799--801},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.290.5492.799},
  url = {https://www.science.org/doi/10.1126/science.290.5492.799},
  urldate = {2023-02-28},
  abstract = {An unusual property of the circadian timekeeping systems of animals is rhythm “splitting,” in which a single daily period of physical activity (usually measured as wheel running) dissociates into two stably coupled components about 12 hours apart; this behavior has been ascribed to a clock composed of two circadian oscillators cycling in antiphase. We analyzed gene expression in the hypothalamic circadian clock, the suprachiasmatic nucleus (SCN), of behaviorally “split” hamsters housed in constant light. The results show that the two oscillators underlying the split condition correspond to the left and right sides of the bilaterally paired SCN.}
}

@article{delarochaCorrelationNeuralSpike2007,
  title = {Correlation between Neural Spike Trains Increases with Firing Rate},
  author = {de la Rocha, Jaime and Doiron, Brent and Shea-Brown, Eric and Josić, Krešimir and Reyes, Alex},
  options = {useprefix=true},
  date = {2007-08},
  journaltitle = {Nature},
  volume = {448},
  number = {7155},
  pages = {802--806},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature06028},
  url = {https://www.nature.com/articles/nature06028},
  urldate = {2022-10-28},
  abstract = {Deciphering a 'neural code' usually requires measurement of either the rate of spike (electrical impulses) production or the spike synchrony. However, these two measures are not independent, as higher rates are associated with higher synchrony. It is further shown that the connection between rate and synchrony enhances information coding.},
  issue = {7155},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DM9THWWD\\de la Rocha et al. - 2007 - Correlation between neural spike trains increases .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VFM7AXJP\\nature06028.html}
}

@article{demartinoIntroductionMaximumEntropy2018,
  title = {An Introduction to the Maximum Entropy Approach and Its Application to Inference Problems in Biology},
  author = {De Martino, Andrea and De Martino, Daniele},
  date = {2018-04-01},
  journaltitle = {Heliyon},
  shortjournal = {Heliyon},
  volume = {4},
  number = {4},
  pages = {e00596},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2018.e00596},
  url = {https://www.sciencedirect.com/science/article/pii/S2405844018301695},
  urldate = {2023-04-14},
  abstract = {A cornerstone of statistical inference, the maximum entropy framework is being increasingly applied to construct descriptive and predictive models of biological systems, especially complex biological networks, from large experimental data sets. Both its broad applicability and the success it obtained in different contexts hinge upon its conceptual simplicity and mathematical soundness. Here we try to concisely review the basic elements of the maximum entropy principle, starting from the notion of ‘entropy’, and describe its usefulness for the analysis of biological systems. As examples, we focus specifically on the problem of reconstructing gene interaction networks from expression data and on recent work attempting to expand our system-level understanding of bacterial metabolism. Finally, we highlight some extensions and potential limitations of the maximum entropy approach, and point to more recent developments that are likely to play a key role in the upcoming challenges of extracting structures and information from increasingly rich, high-throughput biological data.},
  langid = {english},
  keywords = {Bioinformatics,Computational biology,Mathematical bioscience,Molecular biology,Systems biology},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S824APFF\\De Martino and De Martino - 2018 - An introduction to the maximum entropy approach an.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7G784HQA\\S2405844018301695.html}
}

@online{DendriticComputationsCaptured,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model},
  doi = {10.1073/pnas.1904463116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GMFEWWRS\\Dendritic computations captured by an effective po.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6S27Q8Y\\pnas.html}
}

@online{DendriticComputationsCaptureda,
  title = {Dendritic Computations Captured by an Effective Point Neuron Model | {{PNAS}}},
  url = {https://www.pnas.org/doi/10.1073/pnas.1904463116},
  urldate = {2022-09-08}
}

@article{denfieldAttentionalFluctuationsInduce2018,
  title = {Attentional Fluctuations Induce Shared Variability in Macaque Primary Visual Cortex},
  author = {Denfield, George H. and Ecker, Alexander S. and Shinn, Tori J. and Bethge, Matthias and Tolias, Andreas S.},
  date = {2018-07-09},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {2654},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-05123-6},
  url = {https://www.nature.com/articles/s41467-018-05123-6},
  urldate = {2023-01-05},
  abstract = {Variability in neuronal responses to identical stimuli is frequently correlated across a population. Attention is thought to reduce these correlations by suppressing noisy inputs shared by the population. However, even with precise control of the visual stimulus, the subject’s attentional state varies across trials. While these state fluctuations are bound to induce some degree of correlated variability, it is currently unknown how strong their effect is, as previous studies generally do not dissociate changes in attentional strength from changes in attentional state variability. We designed a novel paradigm that does so and find both a pronounced effect of attentional fluctuations on correlated variability at long timescales and attention-dependent reductions in correlations at short timescales. These effects predominate in layers 2/3, as expected from a feedback signal such as attention. Thus, significant portions of correlated variability can be attributed to fluctuations in internally generated signals, like attention, rather than noise.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3WR8R348\Denfield et al. - 2018 - Attentional fluctuations induce shared variability.pdf}
}

@article{denoudenHowPredictionErrors2012,
  title = {How {{Prediction Errors Shape Perception}}, {{Attention}}, and {{Motivation}}},
  author = {Den Ouden, Hanneke and Kok, Peter and De Lange, Floris},
  date = {2012},
  journaltitle = {Frontiers in Psychology},
  volume = {3},
  issn = {1664-1078},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00548},
  urldate = {2023-03-30},
  abstract = {Prediction errors (PE) are a central notion in theoretical models of reinforcement learning, perceptual inference, decision-making and cognition, and prediction error signals have been reported across a wide range of brain regions and experimental paradigms. Here, we will make an attempt to see the forest for the trees and consider the commonalities and differences of reported PE signals in light of recent suggestions that the computation of PE forms a fundamental mode of brain function. We discuss where different types of PE are encoded, how they are generated, and the different functional roles they fulfill. We suggest that while encoding of PE is a common computation across brain regions, the content and function of these error signals can be very different and are determined by the afferent and efferent connections within the neural circuitry in which they arise.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EVXFWFEY\Den Ouden et al. - 2012 - How Prediction Errors Shape Perception, Attention,.pdf}
}

@article{desimoneNeuralMechanismsSelective1995a,
  title = {Neural Mechanisms of Selective Visual Attention},
  author = {Desimone, R. and Duncan, J.},
  date = {1995},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu Rev Neurosci},
  volume = {18},
  eprint = {7605061},
  eprinttype = {pmid},
  pages = {193--222},
  issn = {0147-006X},
  doi = {10.1146/annurev.ne.18.030195.001205},
  langid = {english},
  keywords = {Animals,Attention,Humans,Mental Processes,Models Neurological,Photic Stimulation,Visual Pathways},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QTC2GWID\Desimone and Duncan - 1995 - Neural mechanisms of selective visual attention.pdf}
}

@article{desimoneNeuralSynchronySelective2009,
  title = {Neural Synchrony and Selective Attention},
  author = {Desimone, Robert},
  date = {2009-07},
  journaltitle = {IEEE},
  publisher = {{Institute of Electrical and Electronics Engineers}},
  issn = {1098-7576},
  url = {https://dspace.mit.edu/handle/1721.1/58973},
  urldate = {2023-03-31},
  abstract = {A complex visual scene will typically contain many different objects, few of which are currently relevant to behavior. Thus, attentional mechanisms are needed to select the relevant objects from the scene and to reject the irrelevant ones. Neurophysiological studies in monkeys have identified some of the neural mechanisms of attentional selection within the ventral, ldquoobject recognitionrdquo, stream of the cortex, which begins with area V1 and continues through areas V2, V4, and IT cortex. At each stage along this stream, attended, or behaviorally relevant, stimuli are processed preferentially compared to irrelevant distracters. The source of the attentional feedback to visual cortex seems to originate in parietal and prefrontal cortex. We proposed some years ago that this attentional feedback biased competitive interactions among neurons in visual cortex, in favor of neuronal responses to the most behaviorally relevant stimulus. More recent work indicates that these competitive interactions are one aspect of a more general visual mechanism for contrast normalization, which is present in most or all visual areas. By providing the appropriate input to this normalization mechanism, feedback from parietal and prefrontal cortex appears to shift the balance of visual cortical responses towards the attended stimulus.},
  isbn = {9781424435487},
  langid = {american},
  annotation = {Accepted: 2010-10-08T16:30:18Z},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JTYARXCW\Desimone - 2009 - Neural synchrony and selective attention.pdf}
}

@article{destexheWilsonCowanModel2009,
  title = {The {{Wilson}}–{{Cowan}} Model, 36 Years Later},
  author = {Destexhe, Alain and Sejnowski, Terrence J.},
  date = {2009-07},
  journaltitle = {Biological cybernetics},
  shortjournal = {Biol Cybern},
  volume = {101},
  number = {1},
  eprint = {19662434},
  eprinttype = {pmid},
  pages = {1--2},
  issn = {0340-1200},
  doi = {10.1007/s00422-009-0328-3},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2866289/},
  urldate = {2020-09-29},
  abstract = {The Wilson–Cowan model of interacting neurons (1973) is one of the most influential papers published in Biological Cybernetics (Kybernetik). This paper and a companion paper published in 1972 have been cited over 1000 times. Rather than focus on the microscopic properties of neurons, Wilson and Cowan analyzed the collective properties of large numbers of neurons using methods from statistical mechanics, based on the mean-field approach. New experimental techniques to measure neuronal activity at the level of large populations are now available to test these models, including optical recording of brain activity with intrinsic signals and voltage sensitive dyes, and new methods for analyzing EEG and MEG. These measurement techniques have revealed patterns of coherent activity that span centimetres of tissue in the cerebral cortex. Here the underlying ideas are reviewed in a historic context.},
  pmcid = {PMC2866289},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\P5FE2M44\Destexhe and Sejnowski - 2009 - The Wilson–Cowan model, 36 years later.pdf}
}

@article{devriesLargescaleStandardizedPhysiological2020,
  title = {A Large-Scale Standardized Physiological Survey Reveals Functional Organization of the Mouse Visual Cortex},
  author = {de Vries, Saskia E. J. and Lecoq, Jerome A. and Buice, Michael A. and Groblewski, Peter A. and Ocker, Gabriel K. and Oliver, Michael and Feng, David and Cain, Nicholas and Ledochowitsch, Peter and Millman, Daniel and Roll, Kate and Garrett, Marina and Keenan, Tom and Kuan, Leonard and Mihalas, Stefan and Olsen, Shawn and Thompson, Carol and Wakeman, Wayne and Waters, Jack and Williams, Derric and Barber, Chris and Berbesque, Nathan and Blanchard, Brandon and Bowles, Nicholas and Caldejon, Shiella D. and Casal, Linzy and Cho, Andrew and Cross, Sissy and Dang, Chinh and Dolbeare, Tim and Edwards, Melise and Galbraith, John and Gaudreault, Nathalie and Gilbert, Terri L. and Griffin, Fiona and Hargrave, Perry and Howard, Robert and Huang, Lawrence and Jewell, Sean and Keller, Nika and Knoblich, Ulf and Larkin, Josh D. and Larsen, Rachael and Lau, Chris and Lee, Eric and Lee, Felix and Leon, Arielle and Li, Lu and Long, Fuhui and Luviano, Jennifer and Mace, Kyla and Nguyen, Thuyanh and Perkins, Jed and Robertson, Miranda and Seid, Sam and Shea-Brown, Eric and Shi, Jianghong and Sjoquist, Nathan and Slaughterbeck, Cliff and Sullivan, David and Valenza, Ryan and White, Casey and Williford, Ali and Witten, Daniela M. and Zhuang, Jun and Zeng, Hongkui and Farrell, Colin and Ng, Lydia and Bernard, Amy and Phillips, John W. and Reid, R. Clay and Koch, Christof},
  options = {useprefix=true},
  date = {2020-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {1},
  pages = {138--151},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0550-9},
  url = {https://www.nature.com/articles/s41593-019-0550-9},
  urldate = {2024-06-17},
  abstract = {To understand how the brain processes sensory information to guide behavior, we must know how stimulus representations are transformed throughout the visual cortex. Here we report an open, large-scale physiological survey of activity in the awake mouse visual cortex: the Allen Brain Observatory Visual Coding dataset. This publicly available dataset includes the cortical activity of nearly 60,000 neurons from six visual areas, four layers, and 12 transgenic mouse lines in a total of 243 adult mice, in response to a systematic set of visual stimuli. We classify neurons on the basis of joint reliabilities to multiple stimuli and validate this functional classification with models of visual responses. While most classes are characterized by responses to specific subsets of the stimuli, the largest class is not reliably responsive to any of the stimuli and becomes progressively larger in higher visual areas. These classes reveal a functional organization wherein putative dorsal areas show specialization for visual motion signals.},
  langid = {english},
  keywords = {Sensory processing,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UEKYILBT\de Vries et al. - 2020 - A large-scale standardized physiological survey re.pdf}
}

@article{diamondWhereWhatWhisker2008,
  title = {'{{Where}}' and 'what' in the Whisker Sensorimotor System},
  author = {Diamond, Mathew E. and von Heimendahl, Moritz and Knutsen, Per Magne and Kleinfeld, David and Ahissar, Ehud},
  options = {useprefix=true},
  date = {2008-08},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {8},
  pages = {601--612},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn2411},
  url = {https://www.nature.com/articles/nrn2411},
  urldate = {2023-04-11},
  abstract = {The first study of whisker function, from 1912, showed that rats lose the capacity to navigate in a complex labyrinth if their whiskers are clipped. The tactile modality is crucial to the behavioural repertoire of most rodent species.Rats and mice generate their sense of touch through active movement of their whiskers. From signals that originate in sensory receptors at the base of the whisker, the brain builds up representations of the location and identity of contacted objects.The modern era of research into whisker function began in 1970 with the discovery of cortical barrels, which are clusters of densely-packed cells that anchor a columnar module dedicated to one whisker. Barrels are organized as a map that conserves the spatial relationships between whiskers.Since the discovery of cortical barrels, further investigations have unravelled the functional circuitry of the sensory pathways from whiskers to the cortex. Most work has come from anaesthetized animals.Researchers are now trying to learn how animals use their whiskers under natural conditions, and how the surrounding world is represented in their brains. Objects can be considered according to their location ('where') and their identity ('what').As examples of localization tasks, we consider rats' capacities to sense the size of an opening between two walls and the forward–backward position of vertical poles. Sensorimotor strategy — that is, how the animal whisks and how it uses signals from multiple whiskers — differs according to the task.The neuronal representation of object location involves the integration of the response to object contact with a reference signal that reports the position of the whisker at the instant of contact. Reference signals originate from sensory receptors, but the motor system could also provide information about whisker position.As examples of object identification tasks, we consider rats' capacities to sense shape and texture; in both of these, rats are highly proficient. The Etruscan shrew uses its whiskers to identify insect prey by shape.In rats, the texture of a contacted surface is encoded by neuronal firing rate; rougher surfaces evoke higher firing rates. On single trials, firing rate correlates with the animal's judgment of texture.Because the strength of the animal's own motor output will affect the strength of the sensory response, we hypothesize that the animal uses knowledge of motor output to interpret the firing rate on individual contacts. A numerical model illustrates how knowledge of motor output makes sensory judgments more accurate.Three problems are particularly fascinating for future research. How are whisker dynamics reported by neuronal activity in behaving animals? Where in the sensory system are the 'where' and 'what' signals separated? How are neuronal representations transformed from stages at which they encode physical signals to stages at which they encode things that are meaningful to the animal?},
  issue = {8},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZAZJDEIX\Diamond et al. - 2008 - 'Where' and 'what' in the whisker sensorimotor sys.pdf}
}

@article{diazSimilarLocalNeuronal2021,
  title = {Similar Local Neuronal Dynamics May Lead to Different Collective Behavior},
  author = {Diaz, Margarita M. Sánchez and Trejo, Eyisto J. Aguilar and Martin, Daniel A. and Cannas, Sergio A. and Grigera, Tomás S. and Chialvo, Dante R.},
  date = {2021-12-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {6},
  pages = {064309},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.104.064309},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.064309},
  urldate = {2022-10-01},
  abstract = {This report is concerned with the relevance of the microscopic rules that implement individual neuronal activation, in determining the collective dynamics, under variations of the network topology. To fix ideas we study the dynamics of two cellular automaton models, commonly used, rather in-distinctively, as the building blocks of large-scale neuronal networks. One model, due to Greenberg and Hastings (GH), can be described by evolution equations mimicking an integrate-and-fire process, while the other model, due to Kinouchi and Copelli (KC), represents an abstract branching process, where a single active neuron activates a given number of postsynaptic neurons according to a prescribed “activity” branching ratio. Despite the apparent similarity between the local neuronal dynamics of the two models, it is shown that they exhibit very different collective dynamics as a function of the network topology. The GH model shows qualitatively different dynamical regimes as the network topology is varied, including transients to a ground (inactive) state, continuous and discontinuous dynamical phase transitions. In contrast, the KC model only exhibits a continuous phase transition, independently of the network topology. These results highlight the importance of paying attention to the microscopic rules chosen to model the interneuronal interactions in large-scale numerical simulations, in particular when the network topology is far from a mean-field description. One such case is the extensive work being done in the context of the Human Connectome, where a wide variety of types of models are being used to understand the brain collective dynamics.}
}

@article{dixonAlgorithmsSelectiveAttention1981,
  title = {Algorithms and Selective Attention},
  author = {Dixon, Peter},
  date = {1981-03},
  journaltitle = {Memory \& Cognition},
  shortjournal = {Mem Cogn},
  volume = {9},
  number = {2},
  pages = {177--184},
  issn = {0090-502X, 1532-5946},
  doi = {10.3758/BF03202333},
  url = {http://link.springer.com/10.3758/BF03202333},
  urldate = {2023-01-18},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5NF3GDEA\Dixon - 1981 - Algorithms and selective attention.pdf}
}

@article{doironMechanicsStatedependentNeural2016,
  title = {The Mechanics of State-Dependent Neural Correlations},
  author = {Doiron, Brent and Litwin-Kumar, Ashok and Rosenbaum, Robert and Ocker, Gabriel K. and Josić, Krešimir},
  date = {2016-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {19},
  number = {3},
  pages = {383--393},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4242},
  url = {https://www.nature.com/articles/nn.4242},
  urldate = {2023-08-28},
  abstract = {The state of the nervous system shifts constantly. Most studies focus on how state determines the average neural response, with little attention to the trial-to-trial fluctuations of brain activity. We review recent theoretical advances in modeling the physiological mechanisms responsible for state-dependent modulations in the correlated fluctuations of neuronal populations.},
  issue = {3},
  langid = {english},
  keywords = {Biophysical models,Computational neuroscience,Neural circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\58DF49YZ\Doiron et al. - 2016 - The mechanics of state-dependent neural correlatio.pdf}
}

@article{doraDeepGatedHebbian2021,
  title = {Deep {{Gated Hebbian Predictive Coding Accounts}} for {{Emergence}} of {{Complex Neural Response Properties Along}} the {{Visual Cortical Hierarchy}}},
  author = {Dora, Shirin and Bohte, Sander M. and Pennartz, Cyriel M. A.},
  date = {2021},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {15},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2021.666131},
  urldate = {2023-01-20},
  abstract = {Predictive coding provides a computational paradigm for modeling perceptual processing as the construction of representations accounting for causes of sensory inputs. Here, we developed a scalable, deep network architecture for predictive coding that is trained using a gated Hebbian learning rule and mimics the feedforward and feedback connectivity of the cortex. After training on image datasets, the models formed latent representations in higher areas that allowed reconstruction of the original images. We analyzed low- and high-level properties such as orientation selectivity, object selectivity and sparseness of neuronal populations in the model. As reported experimentally, image selectivity increased systematically across ascending areas in the model hierarchy. Depending on the strength of regularization factors, sparseness also increased from lower to higher areas. The results suggest a rationale as to why experimental results on sparseness across the cortical hierarchy have been inconsistent. Finally, representations for different object classes became more distinguishable from lower to higher areas. Thus, deep neural networks trained using a gated Hebbian formulation of predictive coding can reproduce several properties associated with neuronal responses along the visual cortical hierarchy.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WX972DRE\Dora et al. - 2021 - Deep Gated Hebbian Predictive Coding Accounts for .pdf}
}

@article{dorflerSynchronizationComplexNetworks2014,
  title = {Synchronization in Complex Networks of Phase Oscillators: {{A}} Survey},
  shorttitle = {Synchronization in Complex Networks of Phase Oscillators},
  author = {Dörfler, Florian and Bullo, Francesco},
  date = {2014-06-01},
  journaltitle = {Automatica},
  shortjournal = {Automatica},
  volume = {50},
  number = {6},
  pages = {1539--1564},
  issn = {0005-1098},
  doi = {10.1016/j.automatica.2014.04.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0005109814001423},
  urldate = {2023-02-17},
  abstract = {The emergence of synchronization in a network of coupled oscillators is a fascinating subject of multidisciplinary research. This survey reviews the vast literature on the theory and the applications of complex oscillator networks. We focus on phase oscillator models that are widespread in real-world synchronization phenomena, that generalize the celebrated Kuramoto model, and that feature a rich phenomenology. We review the history and the countless applications of this model throughout science and engineering. We justify the importance of the widespread coupled oscillator model as a locally canonical model and describe some selected applications relevant to control scientists, including vehicle coordination, electric power networks, and clock synchronization. We introduce the reader to several synchronization notions and performance estimates. We propose analysis approaches to phase and frequency synchronization, phase balancing, pattern formation, and partial synchronization. We present the sharpest known results about synchronization in networks of homogeneous and heterogeneous oscillators, with complete or sparse interconnection topologies, and in finite-dimensional and infinite-dimensional settings. We conclude by summarizing the limitations of existing analysis methods and by highlighting some directions for future research.},
  langid = {english},
  keywords = {Complex networks,Coupled oscillators,Kuramoto model,Nonlinear analysis,Synchronization},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DFUKNMNC\\Dörfler and Bullo - 2014 - Synchronization in complex networks of phase oscil.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2DIGXPVE\\S0005109814001423.html}
}

@article{doronSpikingIrregularityFrequency2014,
  title = {Spiking {{Irregularity}} and {{Frequency Modulate}} the {{Behavioral Report}} of {{Single-Neuron Stimulation}}},
  author = {Doron, Guy and {von~Heimendahl}, Moritz and Schlattmann, Peter and Houweling, Arthur R. and Brecht, Michael},
  date = {2014-02-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {81},
  number = {3},
  eprint = {24507196},
  eprinttype = {pmid},
  pages = {653--663},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.11.032},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(13)01129-X},
  urldate = {2023-01-23},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5IXHU3HI\Doron et al. - 2014 - Spiking Irregularity and Frequency Modulate the Be.pdf}
}

@article{douglasRecurrentExcitationNeocortical1995,
  title = {Recurrent {{Excitation}} in {{Neocortical Circuits}}},
  author = {Douglas, Rodney J. and Koch, Christof and Mahowald, Misha and Martin, Kevan A. C. and Suarez, Humbert H.},
  date = {1995},
  journaltitle = {Science},
  volume = {269},
  number = {5226},
  eprint = {2887714},
  eprinttype = {jstor},
  pages = {981--985},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  url = {https://www.jstor.org/stable/2887714},
  urldate = {2022-09-02},
  abstract = {The majority of synapses in the mammalian cortex originate from cortical neurons. Indeed, the largest input to cortical cells comes from neighboring excitatory cells. However, most models of cortical development and processing do not reflect the anatomy and physiology of feedback excitation and are restricted to serial feedforward excitation. This report describes how populations of neurons in cat visual cortex can use excitatory feedback, characterized as an effective "network conductance," to amplify their feedforward input signals and demonstrates how neuronal discharge can be kept proportional to stimulus strength despite strong, recurrent connections that threaten to cause runaway excitation. These principles are incorporated into models of cortical direction and orientation selectivity that emphasize the basic design principles of cortical architectures.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4HUSPB72\Douglas et al. - 1995 - Recurrent Excitation in Neocortical Circuits.pdf}
}

@article{drieuHippocampalSequencesExploration2019,
  title = {✅ {{Hippocampal Sequences During Exploration}}: {{Mechanisms}} and {{Functions}}},
  shorttitle = {Hippocampal {{Sequences During Exploration}}},
  author = {Drieu, Céline and Zugaro, Michaël},
  date = {2019},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {13},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2019.00232},
  urldate = {2023-03-25},
  abstract = {Although the hippocampus plays a critical role in spatial and episodic memories, the mechanisms underlying memory formation, stabilization, and recall for adaptive behavior remain relatively unknown. During exploration, within single cycles of the ongoing theta rhythm that dominates hippocampal local field potentials, place cells form precisely ordered sequences of activity. These neural sequences result from the integration of both external inputs conveying sensory-motor information, and intrinsic network dynamics possibly related to memory processes. Their endogenous replay during subsequent sleep is critical for memory consolidation. The present review discusses possible mechanisms and functions of hippocampal theta sequences during exploration. We present several lines of evidence suggesting that these neural sequences play a key role in information processing and support the formation of initial memory traces, and discuss potential functional distinctions between neural sequences emerging during theta vs. awake sharp-wave ripples.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YMYETMT2\Drieu and Zugaro - 2019 - Hippocampal Sequences During Exploration Mechanis.pdf}
}

@article{drieuNestedSequencesHippocampal2018,
  title = {Nested Sequences of Hippocampal Assemblies during Behavior Support Subsequent Sleep Replay},
  author = {Drieu, Céline and Todorova, Ralitsa and Zugaro, Michaël},
  date = {2018-11-09},
  journaltitle = {Science},
  volume = {362},
  number = {6415},
  pages = {675--679},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aat2952},
  url = {https://www.science.org/doi/10.1126/science.aat2952},
  urldate = {2023-03-26},
  abstract = {Consolidation of spatial and episodic memories is thought to rely on replay of neuronal activity sequences during sleep. However, the network dynamics underlying the initial storage of memories during wakefulness have never been tested. Although slow, behavioral time scale sequences have been claimed to sustain sequential memory formation, fast (“theta”) time scale sequences, nested within slow sequences, could be instrumental. We found that in rats traveling passively on a model train, place cells formed behavioral time scale sequences but theta sequences were degraded, resulting in impaired subsequent sleep replay. In contrast, when the rats actively ran on a treadmill while being transported on the train, place cells generated clear theta sequences and accurate trajectory replay during sleep. Our results support the view that nested sequences underlie the initial formation of memory traces subsequently consolidated during sleep.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\989V4R7L\Drieu et al. - 2018 - Nested sequences of hippocampal assemblies during .pdf}
}

@article{dsouzaHierarchicalNonhierarchicalFeatures2022,
  title = {Hierarchical and Nonhierarchical Features of the Mouse Visual Cortical Network},
  author = {D’Souza, Rinaldo D. and Wang, Quanxin and Ji, Weiqing and Meier, Andrew M. and Kennedy, Henry and Knoblauch, Kenneth and Burkhalter, Andreas},
  date = {2022-01-26},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {503},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28035-y},
  url = {https://www.nature.com/articles/s41467-022-28035-y},
  urldate = {2024-06-12},
  abstract = {Neocortical computations underlying vision are performed by a distributed network of functionally specialized areas. Mouse visual cortex, a dense interareal network that exhibits hierarchical properties, comprises subnetworks interconnecting distinct processing streams. To determine the layout of the mouse visual hierarchy, we have evaluated the laminar patterns formed by interareal axonal projections originating in each of ten areas. Reciprocally connected pairs of areas exhibit feedforward/feedback relationships consistent with a hierarchical organization. Beta regression analyses, which estimate a continuous hierarchical distance measure, indicate that the network comprises multiple nonhierarchical circuits embedded in a hierarchical organization of overlapping levels. Single-unit recordings in anaesthetized mice show that receptive field sizes are generally consistent with the hierarchy, with the ventral stream exhibiting a stricter hierarchy than the dorsal stream. Together, the results provide an anatomical metric for hierarchical distance, and reveal both hierarchical and nonhierarchical motifs in mouse visual cortex.},
  langid = {english},
  keywords = {Computational neuroscience,Neural circuits,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VNSTTXU7\D’Souza et al. - 2022 - Hierarchical and nonhierarchical features of the m.pdf}
}

@article{dumoulinLayersNeuroscience2017,
  title = {Layers of {{Neuroscience}}},
  author = {Dumoulin, Serge O.},
  date = {2017-12-20},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {96},
  number = {6},
  pages = {1205--1206},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.12.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627317311273},
  urldate = {2023-01-05},
  abstract = {In a patch of cortex, laminae connect to different parts of the brain. Huber et~al. (2017) demonstrate the ability of human neuroimaging to derive laminar information flow between brain regions, paving the way for human neuroscience applications.},
  langid = {english},
  keywords = {connectivity,cortex,fMRI,lamina,layers,neuroimaging},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5R8L36T8\\Dumoulin - 2017 - Layers of Neuroscience.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3GZKTNXB\\S0896627317311273.html}
}

@online{DynamicalRegimeSensory,
  title = {The {{Dynamical Regime}} of {{Sensory Cortex}}: {{Stable Dynamics}} around a {{Single Stimulus-Tuned Attractor Account}} for {{Patterns}} of {{Noise Variability}}: {{Neuron}}},
  url = {https://www.cell.com/neuron/fulltext/S0896-6273(18)30325-8?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627318303258%3Fshowall%3Dtrue},
  urldate = {2023-01-03},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8QJ7MBYT\S0896-6273(18)30325-8.html}
}

@article{eban-rothschildNeuronalMechanismsSleep2018,
  title = {Neuronal {{Mechanisms}} for {{Sleep}}/{{Wake Regulation}} and {{Modulatory Drive}}},
  author = {Eban-Rothschild, Ada and Appelbaum, Lior and de Lecea, Luis},
  options = {useprefix=true},
  date = {2018-04},
  journaltitle = {Neuropsychopharmacology},
  shortjournal = {Neuropsychopharmacol.},
  volume = {43},
  number = {5},
  pages = {937--952},
  publisher = {Nature Publishing Group},
  issn = {1740-634X},
  doi = {10.1038/npp.2017.294},
  url = {https://www.nature.com/articles/npp2017294},
  urldate = {2023-02-24},
  abstract = {Humans have been fascinated by sleep for millennia. After almost a century of scientific interrogation, significant progress has been made in understanding the neuronal regulation and functions of sleep. The application of new methods in neuroscience that enable the analysis of genetically defined neuronal circuits with unprecedented specificity and precision has been paramount in this endeavor. In this review, we first discuss electrophysiological and behavioral features of sleep/wake states and the principal neuronal populations involved in their regulation. Next, we describe the main modulatory drives of sleep and wakefulness, including homeostatic, circadian, and motivational processes. Finally, we describe a revised integrative model for sleep/wake regulation.},
  issue = {5},
  langid = {english},
  keywords = {Hypocretin,Inhibition–excitation balance,Molecular neuroscience,Neural circuits,Optogenetics,Sleep,Wakefulness},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8JIZYMUD\Eban-Rothschild et al. - 2018 - Neuronal Mechanisms for SleepWake Regulation and .pdf}
}

@article{ebrahimiEmergentReliabilitySensory2022,
  title = {Emergent Reliability in Sensory Cortical Coding and Inter-Area Communication},
  author = {Ebrahimi, Sadegh and Lecoq, Jérôme and Rumyantsev, Oleg and Tasci, Tugce and Zhang, Yanping and Irimia, Cristina and Li, Jane and Ganguli, Surya and Schnitzer, Mark J.},
  date = {2022-05},
  journaltitle = {Nature},
  volume = {605},
  number = {7911},
  pages = {713--721},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-04724-y},
  url = {https://www.nature.com/articles/s41586-022-04724-y},
  urldate = {2023-11-21},
  abstract = {Reliable sensory discrimination must arise from high-fidelity neural representations and communication between brain areas. However, how neocortical sensory processing overcomes the substantial~variability of neuronal sensory responses remains undetermined1–6. Here we imaged neuronal~activity in eight neocortical areas concurrently and over five days in mice performing a visual discrimination task, yielding longitudinal recordings of more than 21,000 neurons. Analyses revealed a sequence of events across the neocortex starting from a resting state, to early stages of perception, and through the formation of a task response. At rest, the neocortex had one pattern of functional connections, identified through sets of areas that shared activity cofluctuations7,8. Within about 200\,ms after the onset of the sensory stimulus, such connections rearranged, with different areas sharing cofluctuations and task-related information. During this short-lived state~(approximately 300 ms duration), both~inter-area sensory data transmission and the redundancy of sensory encoding peaked, reflecting a transient increase in correlated fluctuations among task-related neurons. By around 0.5\,s after stimulus onset, the~visual representation reached a more stable form, the structure of which was robust to the prominent, day-to-day variations in the responses of individual cells. About 1\,s into stimulus presentation, a global fluctuation mode conveyed the upcoming response of the mouse to every area examined and was orthogonal to modes carrying sensory data. Overall, the neocortex supports sensory performance through brief elevations in sensory coding redundancy~near the start of perception, neural population~codes that are robust to cellular variability, and widespread~inter-area fluctuation modes that transmit sensory data and task responses in non-interfering channels.},
  issue = {7911},
  langid = {english},
  keywords = {Network models,Neural decoding,Striate cortex,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\K5WUWXWB\Ebrahimi et al. - 2022 - Emergent reliability in sensory cortical coding an.pdf}
}

@article{echevesteCorticallikeDynamicsRecurrent2020,
  title = {Cortical-like Dynamics in Recurrent Circuits Optimized for Sampling-Based Probabilistic Inference},
  author = {Echeveste, Rodrigo and Aitchison, Laurence and Hennequin, Guillaume and Lengyel, Máté},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1138--1149},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0671-1},
  url = {https://www.nature.com/articles/s41593-020-0671-1},
  urldate = {2020-11-16},
  abstract = {Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory–inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function—fast sampling-based inference—and predict further properties of these motifs that can be tested in future experiments.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RNMV49VD\\Echeveste et al. - 2020 - Cortical-like dynamics in recurrent circuits optim.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MFG7WH3U\\s41593-020-0671-1.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V9D3A8RM\\s41593-020-0671-1.html}
}

@online{eckmannSynapsetypespecificCompetitiveHebbian2022,
  title = {Synapse-Type-Specific Competitive {{Hebbian}} Learning Forms Functional Recurrent Networks},
  author = {Eckmann, Samuel and Gjorgjieva, Julijana},
  date = {2022-03-14},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.03.11.483899},
  doi = {10.1101/2022.03.11.483899},
  url = {https://www.biorxiv.org/content/10.1101/2022.03.11.483899v1},
  urldate = {2022-09-30},
  abstract = {Cortical networks exhibit complex stimulus-response patterns. Previous work has identified the balance between excitatory and inhibitory currents as a central component of cortical computations, but has not considered how the required synaptic connectivity emerges from biologically plausible plasticity rules. Using theory and modeling, we demonstrate how a wide range of cortical response properties can arise from Hebbian learning that is stabilized by the synapse-type-specific competition for synaptic resources. In fully plastic recurrent circuits, this competition enables the development and decorrelation of inhibition-balanced receptive fields. Networks develop an assembly structure with stronger connections between similarly tuned neurons and exhibit response normalization and surround suppression. These results demonstrate how neurons can self-organize into functional circuits and provide a foundational understanding of plasticity in recurrent networks.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5SVHD698\\Eckmann and Gjorgjieva - 2022 - Synapse-type-specific competitive Hebbian learning.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NES5VQN8\\2022.03.11.html}
}

@article{efronComputerAgeStatistical,
  title = {Computer {{Age Statistical Inference}}},
  author = {Efron, Bradley and Hastie, Trevor},
  pages = {493},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\466BVHQG\Efron and Hastie - Computer Age Statistical Inference.pdf}
}

@incollection{ekenChapter21Possible1989,
  title = {Chapter 21 {{Possible}} Functions of Transmitter-Controlled Plateau Potentials in α Motoneurones},
  booktitle = {Progress in {{Brain Research}}},
  author = {Eken, T. and Hultborn, H. and Kiehn, O.},
  editor = {Allum, J. H. J. and Hulliger, M.},
  date = {1989-01-01},
  series = {Afferent {{Control}} of {{Posture}} and {{Locomotion}}},
  volume = {80},
  pages = {257--267},
  publisher = {Elsevier},
  doi = {10.1016/S0079-6123(08)62219-0},
  url = {https://www.sciencedirect.com/science/article/pii/S0079612308622190},
  urldate = {2023-03-21},
  abstract = {An increasing number of vertebrate central neurones has been shown to possess complex membrane properties. However, the functional significance of such properties is unclear. The aim of the present paper is to review some old and new findings in this field from this laboratory. First, a bistability in α motoneurones in reduced preparations is described. Thereafter we present some new data on a bistable behaviour in motor units in unrestrained intact animals during posture. Finally, the possible role of motoneuronal bistability in locomotion and in spasticity is discussed. Recently a bistable firing behaviour in motoneurones was described in the unanaesthetized decerebrate cat. This behaviour is generated by a plateau potential, which causes long-lasting excitability increase and can be initiated and terminated by short-lasting synaptic excitation and inhibition respectively, and is contingent upon activity in descending noradrenergic and serotonergic systems. In an in vitro preparation of the turtle spinal cord the plateau potential was shown to be serotonin dependent and generated by a voltage-dependent non-inactivating calcium conductance. In order to elucidate possible functional consequences of a bistable firing behaviour in the intact animal, the firing pattern of individual soleus motor units was studied by means of chronic EMG registration in awake unrestrained rats during quiet standing. Implanted electrodes allowed the delivery of excitatory and inhibitory stimulus trains to the motoneurones. It was found that short-lasting synaptic stimulation could induce maintained shifts between two stable levels of motoneurone firing frequencies, as in the decerebrate cat. Spontaneous shifts between the same two levels were also present. It seems most likely that plateau potentials are responsible for this bistable firing property in intact animals. The role of plateau potentials in locomotion is difficult to study. At present there are no clear indications of the utilization of plateau potentials in locomotion in intact animals. However, “clamped frequency” bursts which are observed in fictive locomotion in spinal cats might be explained by plateaus. The existence of plateau potentials in motoneurones may also be of importance in spasticity. Therefore, the development of spasticity in two spinalized cats was followed for 3 weeks. Acute experiments demonstrated plateau potentials in some motoneurones in this preparation.},
  langid = {english},
  keywords = {5-Hydroxytryptamine,Calcium conductance,Electrophysiology,Locomotion,Motoneurone,Motor unit,Noradrenaline,Posture,Spasticity,Spinal cord},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\48UV58EZ\\Eken et al. - 1989 - Chapter 21 Possible functions of transmitter-contr.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZNQI7BR6\\S0079612308622190.html}
}

@article{el-boustaniAnatomicallyFunctionallyDistinct2020,
  title = {Anatomically and Functionally Distinct Thalamocortical Inputs to Primary and Secondary Mouse Whisker Somatosensory Cortices},
  author = {El-Boustani, Sami and Sermet, B. Semihcan and Foustoukos, Georgios and Oram, Tess B. and Yizhar, Ofer and Petersen, Carl C. H.},
  date = {2020-07-03},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {3342},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-17087-7},
  url = {https://www.nature.com/articles/s41467-020-17087-7},
  urldate = {2023-08-01},
  abstract = {Subdivisions of mouse whisker somatosensory thalamus project to cortex in a region-specific and layer-specific manner. However, a clear anatomical dissection of these pathways and their functional properties during whisker sensation is lacking. Here, we use anterograde trans-synaptic viral vectors to identify three specific thalamic subpopulations based on their connectivity with brainstem. The principal trigeminal nucleus innervates ventral posterior medial thalamus, which conveys whisker-selective tactile information to layer 4 primary somatosensory cortex that is highly sensitive to self-initiated movements. The spinal trigeminal nucleus innervates a rostral part of the posterior medial (POm) thalamus, signaling whisker-selective sensory information, as well as decision-related information during a goal-directed behavior, to layer 4 secondary somatosensory cortex. A caudal part of the~POm, which apparently does not receive brainstem input, innervates layer 1 and 5A, responding with little whisker selectivity, but showing decision-related modulation. Our results suggest the existence of complementary segregated information streams to somatosensory cortices.},
  issue = {1},
  langid = {english},
  keywords = {Barrel cortex,Decision,Neural circuits,Sensorimotor processing,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AF7F53NV\El-Boustani et al. - 2020 - Anatomically and functionally distinct thalamocort.pdf}
}

@article{engelDynamicPredictionsOscillations2001,
  title = {Dynamic Predictions: Oscillations and Synchrony in Top-down Processing},
  shorttitle = {Dynamic Predictions},
  author = {Engel, A. K. and Fries, P. and Singer, W.},
  date = {2001-10},
  journaltitle = {Nature Reviews. Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {2},
  number = {10},
  eprint = {11584308},
  eprinttype = {pmid},
  pages = {704--716},
  issn = {1471-003X},
  doi = {10.1038/35094565},
  abstract = {Classical theories of sensory processing view the brain as a passive, stimulus-driven device. By contrast, more recent approaches emphasize the constructive nature of perception, viewing it as an active and highly selective process. Indeed, there is ample evidence that the processing of stimuli is controlled by top-down influences that strongly shape the intrinsic dynamics of thalamocortical networks and constantly create predictions about forthcoming sensory events. We discuss recent experiments indicating that such predictions might be embodied in the temporal structure of both stimulus-evoked and ongoing activity, and that synchronous oscillations are particularly important in this process. Coherence among subthreshold membrane potential fluctuations could be exploited to express selective functional relationships during states of expectancy or attention, and these dynamic patterns could allow the grouping and selection of distributed neuronal responses for further processing.},
  langid = {english},
  keywords = {Animals,Brain,Haplorhini,Humans,Mental Processes,Models Neurological,Motor Activity,Neurons,Oscillometry,Pattern Recognition Visual,Time Factors,Visual Cortex}
}

@article{engelSelectiveModulationCortical2016,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-03},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6DCJMHHR\Engel et al. - 2016 - Selective modulation of cortical state during spat.pdf}
}

@article{engelSelectiveModulationCortical2016a,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-09},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S88T9JZR\\Engel et al. - 2016 - Selective modulation of cortical state during spat.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VCFYAGL3\\science.aag1420.pdf}
}

@article{engelSelectiveModulationCortical2016b,
  title = {Selective Modulation of Cortical State during Spatial Attention},
  author = {Engel, Tatiana A. and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Boahen, Kwabena},
  date = {2016-12-02},
  journaltitle = {Science},
  volume = {354},
  number = {6316},
  pages = {1140--1144},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aag1420},
  url = {https://www.science.org/doi/10.1126/science.aag1420},
  urldate = {2023-01-03},
  abstract = {Neocortical activity is permeated with endogenously generated fluctuations, but how these dynamics affect goal-directed behavior remains a mystery. We found that ensemble neural activity in primate visual cortex spontaneously fluctuated between phases of vigorous (On) and faint (Off) spiking synchronously across cortical layers. These On-Off dynamics, reflecting global changes in cortical state, were also modulated at a local scale during selective attention. Moreover, the momentary phase of local ensemble activity predicted behavioral performance. Our results show that cortical state is controlled locally within a cortical map according to cognitive demands and reveal the impact of these local changes in cortical state on goal-directed behavior.}
}

@article{erdiHippocampalThetaRhythms2005,
  title = {Hippocampal Theta Rhythms from a Computational Perspective: {{Code}} Generation, Mood Regulation and Navigation},
  shorttitle = {Hippocampal Theta Rhythms from a Computational Perspective},
  author = {Érdi, Péter and Huhn, Zsófia and Kiss, Tamás},
  date = {2005-11-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  series = {Computational {{Theories}} of the {{Functions}} of the {{Hippocampus}}},
  volume = {18},
  number = {9},
  pages = {1202--1211},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2005.08.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608005001942},
  urldate = {2023-03-24},
  abstract = {In this paper three computer models are summarized discussing different functions of the cortico-hippocampal system. Mood regulation, rhythm and code generation and navigation are integrated into a coherent conceptual framework around the concepts of structural hierarchy and circular causality. First, a model of spatio-temporal code generation is reviewed in which the hippocampal population theta rhythm plays an important role. Next, generation and pharmcological modulation of this rhythm is examined using a computer model of multiple cell populations forming a feed-back loop within the hippocampus and between the septum and the hippocampus. Last, an abstract, but biologically motivated model of navigation is described which achieves a near optimal mode of navigation by composing hierarchical levels of the cortico-hippocampal system. The connections among the different hierarchical structures of the cortico-hippocampal organization and their functional roles are discussed.},
  langid = {english},
  keywords = {Circular causality,Computational neuropharmacology,Conductance based modeling,Cortico-hippocampal loop,Hierarchical organization,Phase precession,Septo-hippocampal system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M7IWJV9E\\Érdi et al. - 2005 - Hippocampal theta rhythms from a computational per.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GU67K2RF\\S0893608005001942.html}
}

@article{ermentroutComplexDynamicsWinnertakeall1992,
  title = {Complex Dynamics in Winner-Take-All Neural Nets with Slow Inhibition},
  author = {Ermentrout, Bard},
  date = {1992-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {5},
  number = {3},
  pages = {415--431},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(92)90004-3},
  url = {https://www.sciencedirect.com/science/article/pii/0893608092900043},
  urldate = {2023-06-15},
  abstract = {We consider a layer of excitatory neurons with small asymmetric excitatory connections and strong coupling to a single inhibitory interneuron. If the inhibition is fast, the network behaves as a winner-take-all network in which one cell fires at the expense of all others. As the inhibition slows down, oscillatory behavior begins. This is followed by a symmetric rotating solution in which neurons share the activity in a round-robin fashion. Finally, if the inhibition is sufficiently slower than excitation the neurons completely synchronize to a global periodic solution. Conditions guaranteeing stable synchrony are given.},
  langid = {english},
  keywords = {Oscillatory neurons,Rhythmogenesis,Synchrony},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AQLY492I\\Ermentrout - 1992 - Complex dynamics in winner-take-all neural nets wi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UF9BBLB7\\0893608092900043.html}
}

@article{esghaeiDynamicCouplingOscillatory2022,
  title = {✅ {{Dynamic}} Coupling of Oscillatory Neural Activity and Its Roles in Visual Attention},
  author = {Esghaei, Moein and Treue, Stefan and Vidyasagar, Trichur R.},
  date = {2022-04-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {45},
  number = {4},
  pages = {323--335},
  issn = {0166-2236},
  doi = {10.1016/j.tins.2022.01.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0166223622000157},
  urldate = {2023-04-06},
  abstract = {Oscillatory neural activity is believed to have a central role in information processing in the mammalian brain. While early studies often focussed on the function of individual frequency bands, there is emerging appreciation for the role of simultaneous activity in many distinct frequency bands and the interactions between them in high-level cognitive functions. Here, we focus on the role of cross-frequency coupling (CFC) in visual attention. First, we propose a framework that reconciles previous contrasting findings, showing how CFC could have a functional role on both intra- and interareal scales. Second, we outline how CFC between distinct frequency bands could label different submodalities of sensory information. Overall, our scheme provides a novel perspective of how interfrequency interaction contributes to efficient and dynamic processing of information across the brain.},
  langid = {english},
  keywords = {cross-frequency coupling (CFC),information transmission,neural oscillations,neural synchrony,phase amplitude coupling (PAC),visual attention},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C2PHY26I\\Esghaei et al. - 2022 - Dynamic coupling of oscillatory neural activity an.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4ZLGPX32\\S0166223622000157.html}
}

@article{esmaeiliCorticalCircuitsTransforming2020,
  title = {Cortical Circuits for Transforming Whisker Sensation into Goal-Directed Licking},
  author = {Esmaeili, Vahid and Tamura, Keita and Foustoukos, Georgios and Oryshchuk, Anastasiia and Crochet, Sylvain and Petersen, Carl CH},
  date = {2020-12-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Whole-Brain Interactions between Neural Circuits},
  volume = {65},
  pages = {38--48},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2020.08.003},
  url = {https://www.sciencedirect.com/science/article/pii/S095943882030115X},
  urldate = {2023-04-12},
  abstract = {Animals can learn to use sensory stimuli to generate motor actions in order to obtain rewards. However, the precise neuronal circuits driving learning and execution of a specific goal-directed sensory-to-motor transformation remain to be elucidated. Here, we review progress in understanding the contribution of cortical neuronal circuits to a task in which head-restrained water-restricted mice learn to lick a reward spout in response to whisker deflection. We first examine ‘innate’ pathways for whisker sensory processing and licking motor control, and then discuss how these might become linked through reward-based learning, perhaps enabled by cholinergic-gated and dopaminergic-gated plasticity. The aim is to uncover the synaptically connected neuronal pathways that mediate reward-based learning and execution of a well-defined sensory-to-motor transformation.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TGHKMA87\\Esmaeili et al. - 2020 - Cortical circuits for transforming whisker sensati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JV8NPNTC\\S095943882030115X.html}
}

@article{faisalNoiseNervousSystem2008,
  title = {Noise in the Nervous System},
  author = {Faisal, A. Aldo and Selen, Luc P. J. and Wolpert, Daniel M.},
  date = {2008-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {4},
  pages = {292--303},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn2258},
  url = {https://www.nature.com/articles/nrn2258},
  urldate = {2023-03-30},
  abstract = {Trial-to-trial variability can result from both deterministic sources, such as complex dynamics or internal states, and randomness — that is, noise. This Review focuses on noise and its impact along the behavioural loop.Sensory noise is noise in sensory signals and sensory receptors. It limits the amount of information that is available to other areas of the CNS.Cellular noise is an underestimated contributor to neuronal variability. The stochastic nature of neuronal mechanisms becomes critical in the many small structures of the CNS.Electrical noise in neurons, especially channel noise from voltage-gated ion channels, limits neuronal reliability and cell size, producing millisecond variability in action-potential initiation and propagation.Synaptic noise results from the noisy biochemical processes that underlie synaptic transmission. Adding up these noise sources can account for the observed postsynaptic-response variability.Noise build-up in neural networks can be contained by appropriate network layouts, homeostatic mechanisms and the threshold-like nature of neurons.Motor noise results when neural signals are converted into forces. The architecture of motor neurons and their muscle fibres makes the conversion noisy. The brain organizes movements to minimize the effects of motor noise on movement variability.Beneficial effects of noise include stochastic resonance in specific cases of sensory processing and forcing neural networks to be more robust and explore more states.Behavioural variability, as observed in sensory estimation and movement tasks, appears to be mainly produced by noise.The principle of averaging is one of two fundamental principles applied by the CNS to compensate for noise by summing over sources of redundant information.The principle of prior knowledge is the other fundamental principle: it exploits the expected nature of signals and noise. The CNS often applies it in combination with averaging, such as in Bayesian cue combination in sensory processing.},
  issue = {4},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VX9VH253\Faisal et al. - 2008 - Noise in the nervous system.pdf}
}

@unpublished{fangExploitingNeuronSynapse2020,
  title = {Exploiting {{Neuron}} and {{Synapse Filter Dynamics}} in {{Spatial Temporal Learning}} of {{Deep Spiking Neural Network}}},
  author = {Fang, Haowen and Shrestha, Amar and Zhao, Ziyi and Qiu, Qinru},
  date = {2020-07-25},
  eprint = {2003.02944},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2003.02944},
  urldate = {2020-10-16},
  abstract = {The recent discovered spatial-temporal information processing capability of bio-inspired Spiking neural networks (SNN) has enabled some interesting models and applications. However designing large-scale and high-performance model is yet a challenge due to the lack of robust training algorithms. A bio-plausible SNN model with spatial-temporal property is a complex dynamic system. Each synapse and neuron behave as filters capable of preserving temporal information. As such neuron dynamics and filter effects are ignored in existing training algorithms, the SNN downgrades into a memoryless system and loses the ability of temporal signal processing. Furthermore, spike timing plays an important role in information representation, but conventional rate-based spike coding models only consider spike trains statistically, and discard information carried by its temporal structures. To address the above issues, and exploit the temporal dynamics of SNNs, we formulate SNN as a network of infinite impulse response (IIR) filters with neuron nonlinearity. We proposed a training algorithm that is capable to learn spatial-temporal patterns by searching for the optimal synapse filter kernels and weights. The proposed model and training algorithm are applied to construct associative memories and classifiers for synthetic and public datasets including MNIST, NMNIST, DVS 128 etc.; and their accuracy outperforms state-of-art approaches.},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KHQFPTIR\\Fang et al. - 2020 - Exploiting Neuron and Synapse Filter Dynamics in S.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NDX6FBLK\\2003.html}
}

@article{feldmanAttentionUncertaintyFreeEnergy2010,
  title = {Attention, {{Uncertainty}}, and {{Free-Energy}}},
  author = {Feldman, Harriet and Friston, Karl},
  date = {2010},
  journaltitle = {Frontiers in Human Neuroscience},
  volume = {4},
  issn = {1662-5161},
  url = {https://www.frontiersin.org/articles/10.3389/fnhum.2010.00215},
  urldate = {2023-03-30},
  abstract = {We suggested recently that attention can be understood as inferring the level of uncertainty or precision during hierarchical perception. In this paper, we try to substantiate this claim using neuronal simulations of directed spatial attention and biased competition. These simulations assume that neuronal activity encodes a probabilistic representation of the world that optimizes free-energy in a Bayesian fashion. Because free-energy bounds surprise or the (negative) log-evidence for internal models of the world, this optimization can be regarded as evidence accumulation or (generalized) predictive coding. Crucially, both predictions about the state of the world generating sensory data and the precision of those data have to be optimized. Here, we show that if the precision depends on the states, one can explain many aspects of attention. We illustrate this in the context of the Posner paradigm, using the simulations to generate both psychophysical and electrophysiological responses. These simulated responses are consistent with attentional bias or gating, competition for attentional resources, attentional capture and associated speed-accuracy trade-offs. Furthermore, if we present both attended and non-attended stimuli simultaneously, biased competition for neuronal representation emerges as a principled and straightforward property of Bayes-optimal perception.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PH4EE9S7\Feldman and Friston - 2010 - Attention, Uncertainty, and Free-Energy.pdf}
}

@article{feldmanNeuralBindingProblem2013,
  title = {The Neural Binding Problem(s)},
  author = {Feldman, Jerome},
  date = {2013-02},
  journaltitle = {Cognitive Neurodynamics},
  shortjournal = {Cogn Neurodyn},
  volume = {7},
  number = {1},
  eprint = {24427186},
  eprinttype = {pmid},
  pages = {1--11},
  issn = {1871-4080},
  doi = {10.1007/s11571-012-9219-8},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3538094/},
  urldate = {2023-01-23},
  abstract = {The famous Neural Binding Problem (NBP) comprises at least four distinct problems with different computational and neural requirements. This review discusses the current state of work on General Coordination, Visual Feature-Binding, Variable Binding, and the SubjectiveUnity of Perception. There is significant continuing progress, partially masked by confusing the different versions of the NBP.},
  pmcid = {PMC3538094},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3CMNWH55\Feldman - 2013 - The neural binding problem(s).pdf}
}

@article{feldmanNeuralBindingProblem2013a,
  title = {The Neural Binding Problem(s)},
  author = {Feldman, Jerome},
  date = {2013-02},
  journaltitle = {Cognitive Neurodynamics},
  shortjournal = {Cogn Neurodyn},
  volume = {7},
  number = {1},
  eprint = {24427186},
  eprinttype = {pmid},
  pages = {1--11},
  issn = {1871-4080},
  doi = {10.1007/s11571-012-9219-8},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3538094/},
  urldate = {2023-04-04},
  abstract = {The famous Neural Binding Problem (NBP) comprises at least four distinct problems with different computational and neural requirements. This review discusses the current state of work on General Coordination, Visual Feature-Binding, Variable Binding, and the SubjectiveUnity of Perception. There is significant continuing progress, partially masked by confusing the different versions of the NBP.},
  pmcid = {PMC3538094},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BHQD9SX4\Feldman - 2013 - The neural binding problem(s).pdf}
}

@article{feldmeyerS1Microcircuits2015,
  title = {S1 Microcircuits},
  author = {Feldmeyer, Dirk},
  date = {2015-05-10},
  journaltitle = {Scholarpedia},
  volume = {10},
  number = {5},
  pages = {7458},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.7458},
  url = {http://www.scholarpedia.org/article/S1_microcircuits},
  urldate = {2023-08-01},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4IGYYK3B\S1_microcircuits.html}
}

@article{fergusonCombiningTheoryModel2017,
  title = {Combining {{Theory}}, {{Model}}, and {{Experiment}} to {{Explain How Intrinsic Theta Rhythms Are Generated}} in an {{In Vitro Whole Hippocampus Preparation}} without {{Oscillatory Inputs}}},
  author = {Ferguson, Katie A. and Chatzikalymniou, Alexandra P. and Skinner, Frances K.},
  date = {2017-08-07},
  journaltitle = {eNeuro},
  shortjournal = {eNeuro},
  volume = {4},
  number = {4},
  eprint = {28791333},
  eprinttype = {pmid},
  pages = {ENEURO.0131-17.2017},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0131-17.2017},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5547196/},
  urldate = {2023-03-25},
  abstract = {Scientists have observed local field potential theta rhythms (3–12 Hz) in the hippocampus for decades, but understanding the mechanisms underlying their generation is complicated by their diversity in pharmacological and frequency profiles. In addition, interactions with other brain structures and oscillatory drives to the hippocampus during distinct brain states has made it difficult to identify hippocampus-specific properties directly involved in theta generation. To overcome this, we develop cellular-based network models using a whole hippocampus in vitro preparation that spontaneously generates theta rhythms. Building on theoretical and computational analyses, we find that spike frequency adaptation and postinhibitory rebound constitute a basis for theta generation in large, minimally connected CA1 pyramidal (PYR) cell network models with fast-firing parvalbumin-positive (PV+) inhibitory cells. Sparse firing of PYR cells and large excitatory currents onto PV+ cells are present as in experiments. The particular theta frequency is more controlled by PYR-to-PV+ cell interactions rather than PV+-to-PYR cell interactions. We identify two scenarios by which theta rhythms can emerge, and they can be differentiated by the ratio of excitatory to inhibitory currents to PV+ cells, but not to PYR cells. Only one of the scenarios is consistent with data from the whole hippocampus preparation, which leads to the prediction that the connection probability from PV+ to PYR cells needs to be larger than from PYR to PV+ cells. Our models can serve as a platform on which to build and develop an understanding of in vivo theta generation.},
  pmcid = {PMC5547196},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XC4RH74D\Ferguson et al. - 2017 - Combining Theory, Model, and Experiment to Explain.pdf}
}

@article{fergusonMechanismsUnderlyingGain2020,
  title = {Mechanisms Underlying Gain Modulation in the Cortex},
  author = {Ferguson, Katie A. and Cardin, Jessica A.},
  date = {2020-02},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {21},
  number = {2},
  pages = {80--92},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-019-0253-y},
  url = {https://www.nature.com/articles/s41583-019-0253-y},
  urldate = {2023-01-03},
  abstract = {Cortical gain regulation allows neurons to respond adaptively to changing inputs. Neural gain is modulated by internal and external influences, including attentional and arousal states, motor activity and neuromodulatory input. These influences converge to a common set of mechanisms for gain modulation, including GABAergic inhibition, synaptically driven fluctuations in membrane potential, changes in cellular conductance and changes in other biophysical neural properties. Recent work has identified GABAergic interneurons as targets of neuromodulatory input and mediators of state-dependent gain modulation. Here, we review the engagement and effects of gain modulation in the cortex. We highlight key recent findings that link phenomenological observations of gain modulation to underlying cellular and circuit-level mechanisms. Finally, we place these cellular and circuit interactions in the larger context of their impact on perception and cognition.},
  issue = {2},
  langid = {english},
  keywords = {Computational neuroscience,Neural circuits,Neuronal physiology,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8BGZB9HM\Ferguson and Cardin - 2020 - Mechanisms underlying gain modulation in the corte.pdf}
}

@article{fernandezMolecularAtlasAdult2020,
  title = {Molecular Atlas of\hspace{0.166em}the\hspace{0.166em}Adult Mouse Brain},
  author = {Fernandez, Jose},
  date = {2020},
  journaltitle = {SCIENCE ADVANCES},
  pages = {14},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KMUMT29G\Fernandez - 2020 - Molecular atlas of the adult mouse brain.pdf}
}

@article{festaNeuronalVariabilityReflects2021,
  title = {Neuronal Variability Reflects Probabilistic Inference Tuned to Natural Image Statistics},
  author = {Festa, Dylan and Aschner, Amir and Davila, Aida and Kohn, Adam and Coen-Cagli, Ruben},
  date = {2021-06-15},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {3635},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-23838-x},
  url = {https://www.nature.com/articles/s41467-021-23838-x},
  urldate = {2022-10-17},
  abstract = {Neuronal activity in sensory cortex fluctuates over time and across repetitions of the same input. This variability is often considered detrimental to neural coding. The theory of neural sampling proposes instead that variability encodes the uncertainty of perceptual inferences. In primary visual cortex (V1), modulation of variability by sensory and non-sensory factors supports this view. However, it is unknown whether V1 variability reflects the statistical structure of visual inputs, as would be required for inferences correctly tuned to the statistics of the natural environment. Here we combine analysis of image statistics and recordings in macaque V1 to show that probabilistic inference tuned to natural image statistics explains the widely observed dependence between spike~count variance and mean, and the modulation of V1 activity and variability by spatial context in images. Our results show that the properties of a basic aspect of cortical responses—their variability—can be explained by a probabilistic representation tuned to naturalistic inputs.},
  issue = {1},
  langid = {english},
  keywords = {Computational neuroscience,Neural encoding,Neuroscience,Striate cortex,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3U6PECBL\Festa et al. - 2021 - Neuronal variability reflects probabilistic infere.pdf}
}

@article{fiebelkornRhythmicTheoryAttention2019,
  title = {A Rhythmic Theory of Attention},
  author = {Fiebelkorn, Ian C. and Kastner, Sabine},
  date = {2019-02},
  journaltitle = {Trends in cognitive sciences},
  shortjournal = {Trends Cogn Sci},
  volume = {23},
  number = {2},
  eprint = {30591373},
  eprinttype = {pmid},
  pages = {87--101},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2018.11.009},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6343831/},
  urldate = {2023-03-24},
  abstract = {Recent evidence has demonstrated that environmental sampling is a fundamentally rhythmic process. Both perceptual sensitivity during covert spatial attention and the probability of overt exploratory movements are tethered to theta-band activity (3–8 Hz) in the attention network. The fronto-parietal part of this network is positioned at the nexus of sensory and motor functions, directing two tightly coupled processes related to environmental exploration: preferential routing of sensory input and saccadic eye movements. We propose that intrinsic theta rhythms temporally resolve potential functional conflicts by periodically re-weighting functional connections between higher-order brain regions and either sensory or motor regions. This rhythmic re-weighting alternately promotes either sampling at a behaviorally relevant location (i.e., sensory functions) or shifting to another location (i.e., motor functions).},
  pmcid = {PMC6343831},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CE25LZEZ\\j.tics.2018.11.009.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NAUSJ6X9\\Fiebelkorn and Kastner - 2019 - A rhythmic theory of attention.pdf}
}

@article{fiebelkornRhythmicTheoryAttention2019a,
  title = {A {{Rhythmic Theory}} of {{Attention}}},
  author = {Fiebelkorn, Ian C. and Kastner, Sabine},
  date = {2019-02-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {2},
  eprint = {30591373},
  eprinttype = {pmid},
  pages = {87--101},
  publisher = {Elsevier},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2018.11.009},
  url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(18)30281-X},
  urldate = {2023-04-07},
  langid = {english},
  keywords = {attention,motor,oscillations,saccades,theta,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4UVYFGAE\\Fiebelkorn and Kastner - 2019 - A Rhythmic Theory of Attention.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR8IHLE9\\j.tics.2018.11.009 (1).pdf}
}

@article{filipchukAwakePerceptionAssociated2022,
  title = {Awake Perception Is Associated with Dedicated Neuronal Assemblies in the Cerebral Cortex},
  author = {Filipchuk, Anton and Schwenkgrub, Joanna and Destexhe, Alain and Bathellier, Brice},
  date = {2022-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {25},
  number = {10},
  pages = {1327--1338},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01168-5},
  url = {https://www.nature.com/articles/s41593-022-01168-5},
  urldate = {2022-12-23},
  abstract = {Neural activity in the sensory cortex combines stimulus responses and ongoing activity, but it remains unclear whether these reflect the same underlying dynamics or separate processes. In the present study, we show in mice that, during wakefulness, the neuronal assemblies evoked by sounds in the auditory cortex and thalamus are specific to the stimulus and distinct from the assemblies observed in ongoing activity. By contrast, under three different anesthetics, evoked assemblies are indistinguishable from ongoing assemblies in the cortex. However, they remain distinct in the thalamus. A strong remapping of sensory responses accompanies this dynamic state change produced by anesthesia. Together, these results show that the awake cortex engages dedicated neuronal assemblies in response to sensory inputs, which we suggest is a network correlate of sensory perception.},
  issue = {10},
  langid = {english},
  keywords = {Cortex,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\IICG7LZV\Filipchuk et al. - 2022 - Awake perception is associated with dedicated neur.pdf}
}

@article{fischerDendriticMechanismsVivo2022,
  title = {Dendritic {{Mechanisms}} for {{{\emph{In Vivo}}}} {{Neural Computations}} and {{Behavior}}},
  author = {Fischer, Lukas and Mojica Soto-Albors, Raul and Tang, Vincent D. and Bicknell, Brendan and Grienberger, Christine and Francioni, Valerio and Naud, Richard and Palmer, Lucy M. and Takahashi, Naoya},
  date = {2022-11-09},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {42},
  number = {45},
  pages = {8460--8467},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1132-22.2022},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1132-22.2022},
  urldate = {2023-08-08},
  abstract = {Dendrites receive the vast majority of a single neuron's inputs, and coordinate the transformation of these signals into neuronal output.               Ex vivo               and theoretical evidence has shown that dendrites possess powerful processing capabilities, yet little is known about how these mechanisms are engaged in the intact brain or how they influence circuit dynamics. New experimental and computational technologies have led to a surge in interest to unravel and harness their computational potential. This review highlights recent and emerging work that combines established and cutting-edge technologies to identify the role of dendrites in brain function. We discuss active dendritic mediation of sensory perception and learning in neocortical and hippocampal pyramidal neurons. Complementing these physiological findings, we present theoretical work that provides new insights into the underlying computations of single neurons and networks by using biologically plausible implementations of dendritic processes. Finally, we present a novel brain–computer interface task, which assays somatodendritic coupling to study the mechanisms of biological credit assignment. Together, these findings present exciting progress in understanding how dendrites are critical for               in vivo               learning and behavior, and highlight how subcellular processes can contribute to our understanding of both biological and artificial neural computation.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\U9EUZZ8L\Fischer et al. - 2022 - Dendritic Mechanisms for In Vivo Neural Com.pdf}
}

@article{fisekAreHumanDendrites2020,
  title = {Are {{Human Dendrites Different}}?},
  author = {Fişek, Mehmet and Häusser, Michael},
  date = {2020-06-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {24},
  number = {6},
  pages = {411--412},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2020.03.002},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661320300693},
  urldate = {2020-10-29},
  abstract = {The first patch-clamp recordings from the dendrites of human neocortical neurons have recently been reported by Beaulieu-Laroche et al. and Gidon et al. These studies have shown that human dendrites are electrically excitable, exhibiting backpropagating action potentials and fast dendritic calcium spikes. This new frontier highlights the potential for interspecies differences in the biophysics of dendritic computation.},
  langid = {english},
  keywords = {cortex,dendrite,human,neural computation,patch clamp,pyramidal cell,rodent,synaptic integration},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YKVESYHP\\Fişek and Häusser - 2020 - Are Human Dendrites Different.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DA79YYSI\\S1364661320300693.html}
}

@article{fisekCorticocorticalFeedbackEngages2023,
  title = {Cortico-Cortical Feedback Engages Active Dendrites in Visual Cortex},
  author = {Fişek, Mehmet and Herrmann, Dustin and Egea-Weiss, Alexander and Cloves, Matilda and Bauer, Lisa and Lee, Tai-Ying and Russell, Lloyd E. and Häusser, Michael},
  date = {2023-05-03},
  journaltitle = {Nature},
  pages = {1--8},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06007-6},
  url = {https://www.nature.com/articles/s41586-023-06007-6},
  urldate = {2023-05-04},
  abstract = {Sensory processing in the neocortex requires both feedforward and feedback information flow between cortical areas1. In feedback processing, higher-level representations provide contextual information to lower levels, and facilitate perceptual functions such as contour integration and figure–ground segmentation2,3. However, we have limited understanding of the circuit and cellular mechanisms that mediate feedback influence. Here we use long-range all-optical connectivity mapping in mice to show that feedback influence from the lateromedial higher visual area (LM) to the primary visual cortex (V1) is spatially organized. When the source and target of feedback represent the same area of visual space, feedback is relatively suppressive. By contrast, when the source is offset from the target in visual space, feedback is relatively facilitating. Two-photon calcium imaging data show that this facilitating feedback is nonlinearly integrated in the apical tuft dendrites of V1 pyramidal neurons: retinotopically offset (surround) visual stimuli drive local dendritic calcium signals indicative of regenerative events, and two-photon optogenetic activation of LM neurons projecting to identified feedback-recipient spines in~V1 can drive similar branch-specific local calcium signals. Our results show how neocortical feedback connectivity and nonlinear dendritic integration can together form a substrate to support both predictive and cooperative contextual interactions.},
  langid = {english},
  keywords = {Neuroscience,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LJ3TMA7K\Fişek et al. - 2023 - Cortico-cortical feedback engages active dendrites.pdf}
}

@article{fisekCorticocorticalFeedbackEngages2023a,
  title = {Cortico-Cortical Feedback Engages Active Dendrites in Visual Cortex},
  author = {Fişek, Mehmet and Herrmann, Dustin and Egea-Weiss, Alexander and Cloves, Matilda and Bauer, Lisa and Lee, Tai-Ying and Russell, Lloyd E. and Häusser, Michael},
  date = {2023-05},
  journaltitle = {Nature},
  volume = {617},
  number = {7962},
  pages = {769--776},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06007-6},
  url = {https://www.nature.com/articles/s41586-023-06007-6},
  urldate = {2023-08-08},
  abstract = {Sensory processing in the neocortex requires both feedforward and feedback information flow between cortical areas1. In feedback processing, higher-level representations provide contextual information to lower levels, and facilitate perceptual functions such as contour integration and figure–ground segmentation2,3. However, we have limited understanding of the circuit and cellular mechanisms that mediate feedback influence. Here we use long-range all-optical connectivity mapping in mice to show that feedback influence from the lateromedial higher visual area (LM) to the primary visual cortex (V1) is spatially organized. When the source and target of feedback represent the same area of visual space, feedback is relatively suppressive. By contrast, when the source is offset from the target in visual space, feedback is relatively facilitating. Two-photon calcium imaging data show that this facilitating feedback is nonlinearly integrated in the apical tuft dendrites of V1 pyramidal neurons: retinotopically offset (surround) visual stimuli drive local dendritic calcium signals indicative of regenerative events, and two-photon optogenetic activation of LM neurons projecting to identified feedback-recipient spines in~V1 can drive similar branch-specific local calcium signals. Our results show how neocortical feedback connectivity and nonlinear dendritic integration can together form a substrate to support both predictive and cooperative contextual interactions.},
  issue = {7962},
  langid = {english},
  keywords = {Neuroscience,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QXWI6L2X\Fişek et al. - 2023 - Cortico-cortical feedback engages active dendrites.pdf}
}

@article{fisekCorticocorticalFeedbackEngages2023b,
  title = {Cortico-Cortical Feedback Engages Active Dendrites in Visual Cortex},
  author = {Fişek, Mehmet and Herrmann, Dustin and Egea-Weiss, Alexander and Cloves, Matilda and Bauer, Lisa and Lee, Tai-Ying and Russell, Lloyd E. and Häusser, Michael},
  date = {2023-05},
  journaltitle = {Nature},
  volume = {617},
  number = {7962},
  pages = {769--776},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06007-6},
  url = {https://www.nature.com/articles/s41586-023-06007-6},
  urldate = {2024-03-16},
  abstract = {Sensory processing in the neocortex requires both feedforward and feedback information flow between cortical areas1. In feedback processing, higher-level representations provide contextual information to lower levels, and facilitate perceptual functions such as contour integration and figure–ground segmentation2,3. However, we have limited understanding of the circuit and cellular mechanisms that mediate feedback influence. Here we use long-range all-optical connectivity mapping in mice to show that feedback influence from the lateromedial higher visual area (LM) to the primary visual cortex (V1) is spatially organized. When the source and target of feedback represent the same area of visual space, feedback is relatively suppressive. By contrast, when the source is offset from the target in visual space, feedback is relatively facilitating. Two-photon calcium imaging data show that this facilitating feedback is nonlinearly integrated in the apical tuft dendrites of V1 pyramidal neurons: retinotopically offset (surround) visual stimuli drive local dendritic calcium signals indicative of regenerative events, and two-photon optogenetic activation of LM neurons projecting to identified feedback-recipient spines in~V1 can drive similar branch-specific local calcium signals. Our results show how neocortical feedback connectivity and nonlinear dendritic integration can together form a substrate to support both predictive and cooperative contextual interactions.},
  langid = {english},
  keywords = {Neuroscience,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BESM7N5J\Fişek et al. - 2023 - Cortico-cortical feedback engages active dendrites.pdf}
}

@article{fiserStatisticalLearningVision2022,
  title = {Statistical {{Learning}} in {{Vision}}},
  author = {Fiser, József and Lengyel, Gábor},
  date = {2022},
  journaltitle = {Annual Review of Vision Science},
  volume = {8},
  number = {1},
  eprint = {35727961},
  eprinttype = {pmid},
  pages = {265--290},
  doi = {10.1146/annurev-vision-100720-103343},
  url = {https://doi.org/10.1146/annurev-vision-100720-103343},
  urldate = {2024-03-13},
  abstract = {Vision and learning have long been considered to be two areas of research linked only distantly. However, recent developments in vision research have changed the conceptual definition of vision from a signal-evaluating process to a goal-oriented interpreting process, and this shift binds learning, together with the resulting internal representations, intimately to vision. In this review, we consider various types of learning (perceptual, statistical, and rule/abstract) associated with vision in the past decades and argue that they represent differently specialized versions of the fundamental learning process, which must be captured in its entirety when applied to complex visual processes. We show why the generalized version of statistical learning can provide the appropriate setup for such a unified treatment of learning in vision, what computational framework best accommodates this kind of statistical learning, and what plausible neural scheme could feasibly implement this framework. Finally, we list the challenges that the field of statistical learning faces in fulfilling the promise of being the right vehicle for advancing our understanding of vision in its entirety.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VN9PQR7P\Fiser and Lengyel - 2022 - Statistical Learning in Vision.pdf}
}

@article{flackCoarsegrainingDownwardCausation2017,
  title = {Coarse-Graining as a Downward Causation Mechanism},
  author = {Flack, Jessica C.},
  date = {2017-12-28},
  journaltitle = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {375},
  number = {2109},
  pages = {20160338},
  publisher = {Royal Society},
  doi = {10.1098/rsta.2016.0338},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsta.2016.0338},
  urldate = {2022-10-01},
  abstract = {Downward causation is the controversial idea that ‘higher’ levels of organization can causally influence behaviour at ‘lower’ levels of organization. Here I propose that we can gain traction on downward causation by being operational and examining how adaptive systems identify regularities in evolutionary or learning time and use these regularities to guide behaviour. I suggest that in many adaptive systems components collectively compute their macroscopic worlds through coarse-graining. I further suggest we move from simple feedback to downward causation when components tune behaviour in response to estimates of collectively computed macroscopic properties. I introduce a weak and strong notion of downward causation and discuss the role the strong form plays in the origins of new organizational levels. I illustrate these points with examples from the study of biological and social systems and deep neural networks. This article is part of the themed issue ‘Reconceptualizing the origins of life’.},
  keywords = {biological effective theories,collective computation,endogenous coarse-graining,organizational levels,regularity estimation},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AA4AXGNL\Flack - 2017 - Coarse-graining as a downward causation mechanism.pdf}
}

@article{fonteneleCriticalityCorticalStates2019,
  title = {Criticality between {{Cortical States}}},
  author = {Fontenele, Antonio J. and de Vasconcelos, Nivaldo A. P. and Feliciano, Thaís and Aguiar, Leandro A. A. and Soares-Cunha, Carina and Coimbra, Bárbara and Dalla Porta, Leonardo and Ribeiro, Sidarta and Rodrigues, Ana João and Sousa, Nuno and Carelli, Pedro V. and Copelli, Mauro},
  options = {useprefix=true},
  date = {2019-05-21},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {122},
  number = {20},
  pages = {208101},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.122.208101},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.122.208101},
  urldate = {2022-10-02},
  abstract = {Since the first measurements of neuronal avalanches, the critical brain hypothesis has gained traction. However, if the brain is critical, what is the phase transition? For several decades, it has been known that the cerebral cortex operates in a diversity of regimes, ranging from highly synchronous states (with higher spiking variability) to desynchronized states (with lower spiking variability). Here, using both new and publicly available data, we test independent signatures of criticality and show that a phase transition occurs in an intermediate value of spiking variability, in both anesthetized and freely moving animals. The critical exponents point to a universality class different from mean-field directed percolation. Importantly, as the cortex hovers around this critical point, the avalanche exponents follow a linear relation that encompasses previous experimental results from different setups and is reproduced by a model.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EBQABDL4\Fontenele et al. - 2019 - Criticality between Cortical States.pdf}
}

@article{forgerDetailedPredictiveModel2003,
  title = {A Detailed Predictive Model of the Mammalian Circadian Clock},
  author = {Forger, Daniel B. and Peskin, Charles S.},
  date = {2003-12-09},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {100},
  number = {25},
  pages = {14806--14811},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2036281100},
  url = {https://www.pnas.org/doi/10.1073/pnas.2036281100},
  urldate = {2023-02-23},
  abstract = {Experimental data on the circadian (≈24-h) clock in mammalian cells are vast, diverse, and detailed. Mathematical models are therefore needed to piece these data together and to study overall clock behavior. Previous models have focused on Neurospora or Drosophila or can be converted to a Drosophila model simply by renaming variables. Those models used Hill-type terms for transcription regulation and Michaelis–Menten type or delay terms for posttranslation regulation. Recent mammalian experimental data call into question some of the assumptions in these approaches. Moreover, gene duplication has led to more proteins in the mammalian system than in lower organisms. Here we develop a detailed distinctly mammalian model by using mass action kinetics. Parameters for our model are found from experimental data by using a coordinate search method. The model accurately predicts the phase of entrainment, amplitude of oscillation, and shape of time profiles of clock mRNAs and proteins and is also robust to parameter changes and mutations.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6RCS2QGE\Forger and Peskin - 2003 - A detailed predictive model of the mammalian circa.pdf}
}

@report{francioniVectorizedInstructiveSignals2023,
  type = {preprint},
  title = {Vectorized Instructive Signals in Cortical Dendrites during a Brain-Computer Interface Task},
  author = {Francioni, Valerio and Tang, Vincent D and Brown, Norma J. and Toloza, Enrique H.S. and Harnett, Mark},
  date = {2023-11-05},
  institution = {Neuroscience},
  doi = {10.1101/2023.11.03.565534},
  url = {http://biorxiv.org/lookup/doi/10.1101/2023.11.03.565534},
  urldate = {2024-01-11},
  abstract = {Abstract                        Backpropagation of error is the most widely used learning algorithm in artificial neural networks, forming the backbone of modern machine learning and artificial intelligence             1,2             . Backpropagation provides a solution to the credit assignment problem by vectorizing an error signal tailored to individual neurons. Recent theoretical models have suggested that neural circuits could implement backpropagation-like learning by semi-independently processing feedforward and feedback information streams in separate dendritic compartments             3–7             . This presents a compelling, but untested, hypothesis for how cortical circuits could solve credit assignment in the brain. We designed a neurofeedback brain-computer interface (BCI) task with an experimenter-defined reward function to evaluate the key requirements for dendrites to implement backpropagation-like learning. We trained mice to modulate the activity of two spatially intermingled populations (4 or 5 neurons each) of layer 5 pyramidal neurons in the retrosplenial cortex to rotate a visual grating towards a target orientation while we recorded GCaMP activity from somas and corresponding distal apical dendrites. We observed that the relative magnitudes of somatic versus dendritic signals could be predicted using the activity of the surrounding network and contained information about task-related variables that could serve as instructive signals, including reward and error. The signs of these putative teaching signals both depended on the causal role of individual neurons in the task and predicted changes in overall activity over the course of learning. These results provide the first biological evidence of a backpropagation-like solution to the credit assignment problem in the brain.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\M8E3CJPG\Francioni et al. - 2023 - Vectorized instructive signals in cortical dendrit.pdf}
}

@online{francioniVectorizedInstructiveSignals2023a,
  title = {Vectorized Instructive Signals in Cortical Dendrites during a Brain-Computer Interface Task},
  author = {Francioni, Valerio and Tang, Vincent D. and Brown, Norma J. and Toloza, Enrique H. S. and Harnett, Mark},
  date = {2023-11-05},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.11.03.565534},
  doi = {10.1101/2023.11.03.565534},
  url = {https://www.biorxiv.org/content/10.1101/2023.11.03.565534v1},
  urldate = {2024-01-11},
  abstract = {Backpropagation of error is the most widely used learning algorithm in artificial neural networks, forming the backbone of modern machine learning and artificial intelligence1,2. Backpropagation provides a solution to the credit assignment problem by vectorizing an error signal tailored to individual neurons. Recent theoretical models have suggested that neural circuits could implement backpropagation-like learning by semi-independently processing feedforward and feedback information streams in separate dendritic compartments3–7. This presents a compelling, but untested, hypothesis for how cortical circuits could solve credit assignment in the brain. We designed a neurofeedback brain-computer interface (BCI) task with an experimenter-defined reward function to evaluate the key requirements for dendrites to implement backpropagation-like learning. We trained mice to modulate the activity of two spatially intermingled populations (4 or 5 neurons each) of layer 5 pyramidal neurons in the retrosplenial cortex to rotate a visual grating towards a target orientation while we recorded GCaMP activity from somas and corresponding distal apical dendrites. We observed that the relative magnitudes of somatic versus dendritic signals could be predicted using the activity of the surrounding network and contained information about task-related variables that could serve as instructive signals, including reward and error. The signs of these putative teaching signals both depended on the causal role of individual neurons in the task and predicted changes in overall activity over the course of learning. These results provide the first biological evidence of a backpropagation-like solution to the credit assignment problem in the brain.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\P89XEVEN\Francioni et al. - 2023 - Vectorized instructive signals in cortical dendrit.pdf}
}

@article{friedenbergerSilencesSpikesBursts2023,
  title = {Silences, Spikes and Bursts: {{Three-part}} Knot of the Neural Code},
  shorttitle = {Silences, Spikes and Bursts},
  author = {Friedenberger, Zachary and Harkin, Emerson and Tóth, Katalin and Naud, Richard},
  date = {2023},
  journaltitle = {The Journal of Physiology},
  volume = {601},
  number = {23},
  pages = {5165--5193},
  issn = {1469-7793},
  doi = {10.1113/JP281510},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/JP281510},
  urldate = {2024-07-08},
  abstract = {When a neuron breaks silence, it can emit action potentials in a number of patterns. Some responses are so sudden and intense that electrophysiologists felt the need to single them out, labelling action potentials emitted at a particularly high frequency with a metonym – bursts. Is there more to bursts than a figure of speech? After all, sudden bouts of high-frequency firing are expected to occur whenever inputs surge. The burst coding hypothesis advances that the neural code has three syllables: silences, spikes and bursts. We review evidence supporting this ternary code in terms of devoted mechanisms for burst generation, synaptic transmission and synaptic plasticity. We also review the learning and attention theories for which such a triad is beneficial.},
  langid = {english},
  keywords = {attention,learning,long-term plasticity,neural coding,short-term plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LDTHIG5Z\\Friedenberger et al. - 2023 - Silences, spikes and bursts Three-part knot of th.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\29JGIBZN\\JP281510.html}
}

@article{fristonDoesPredictiveCoding2018,
  title = {Does Predictive Coding Have a Future?},
  author = {Friston, Karl},
  date = {2018-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {8},
  pages = {1019--1021},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0200-7},
  url = {https://www.nature.com/articles/s41593-018-0200-7},
  urldate = {2023-03-30},
  abstract = {In the 20th century we thought the brain extracted knowledge from sensations. The 21st century witnessed a ‘strange inversion’, in which the brain became an organ of inference, actively constructing explanations for what’s going on ‘out there’, beyond its sensory epithelia. One paper played a key role in this paradigm shift.},
  issue = {8},
  langid = {english},
  keywords = {Computational neuroscience,Neural circuits,Neuronal physiology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PRW6YGL5\Friston - 2018 - Does predictive coding have a future.pdf}
}

@article{fristonFreeenergyPrincipleUnified2010,
  title = {The Free-Energy Principle: A Unified Brain Theory?},
  shorttitle = {The Free-Energy Principle},
  author = {Friston, Karl},
  date = {2010-02},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {11},
  number = {2},
  pages = {127--138},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2787},
  url = {http://www.nature.com/articles/nrn2787},
  urldate = {2020-09-07},
  abstract = {A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7PEKABBM\Friston - 2010 - The free-energy principle a unified brain theory.pdf}
}

@online{FrontiersAttentionUncertainty,
  title = {Frontiers | {{Attention}}, {{Uncertainty}}, and {{Free-Energy}}},
  url = {https://www.frontiersin.org/articles/10.3389/fnhum.2010.00215/full},
  urldate = {2022-12-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6ECFXZ6T\\Frontiers  Attention, Uncertainty, and Free-Energ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QE9EJLJI\\full.html}
}

@online{FrontiersDualCoding,
  title = {Frontiers | {{Dual Coding Theory Explains Biphasic Collective Computation}} in {{Neural Decision-Making}}},
  url = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00313/full},
  urldate = {2022-12-06},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WSZ6Q5DG\full.html}
}

@article{fujisawaBehaviordependentShorttermAssembly2008,
  title = {Behavior-Dependent Short-Term Assembly Dynamics in the Medial Prefrontal Cortex},
  author = {Fujisawa, Shigeyoshi and Amarasingham, Asohan and Harrison, Matthew T. and Buzsáki, György},
  date = {2008-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {11},
  number = {7},
  pages = {823--833},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.2134},
  url = {https://www.nature.com/articles/nn.2134},
  urldate = {2022-11-04},
  abstract = {Fujisawa and colleagues report that during a working memory task, firing patterns in ensembles of rat medial prefrontal cortex neurons reflect behavioral outcomes on coarser time scales and short-term synaptic plasticity on finer time scales. These results suggest that short-term plasticity plays a role in the neural computations guiding behavior.},
  issue = {7},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\I7RQQB9V\Fujisawa et al. - 2008 - Behavior-dependent short-term assembly dynamics in.pdf}
}

@online{GABAmediatedRepulsiveCoupling,
  title = {{{GABA-mediated}} Repulsive Coupling between Circadian Clock Neurons in the {{SCN}} Encodes Seasonal Time | {{PNAS}}},
  url = {https://www.pnas.org/doi/10.1073/pnas.1421200112},
  urldate = {2023-02-17},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Y9QF5XGA\pnas.html}
}

@article{gallegoLongtermStabilityCortical2020,
  title = {Long-Term Stability of Cortical Population Dynamics Underlying Consistent Behavior},
  author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
  date = {2020-02},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {2},
  pages = {260--270},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0555-4},
  url = {https://www.nature.com/articles/s41593-019-0555-4},
  urldate = {2020-10-06},
  abstract = {Animals readily execute learned behaviors in a consistent manner over long periods of time, and yet no equally stable neural correlate has been demonstrated. How does the cortex achieve this stable control? Using the sensorimotor system as a model of cortical processing, we investigated the hypothesis that the dynamics of neural latent activity, which captures the dominant co-variation patterns within the neural population, must be preserved across time. We recorded from populations of neurons in premotor, primary motor and somatosensory cortices as monkeys performed a reaching task, for up to 2 years. Intriguingly, despite a steady turnover in the recorded neurons, the low-dimensional latent dynamics remained stable. The stability allowed reliable decoding of behavioral features for the entire timespan, while fixed decoders based directly on the recorded neural activity degraded substantially. We posit that stable latent cortical dynamics within the manifold are the fundamental building blocks underlying consistent behavioral execution.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YXAL3Y7N\\Gallego et al. - 2020 - Long-term stability of cortical population dynamic.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KDCJ5ERA\\s41593-019-0555-4.html}
}

@article{galuskeRelationGammaOscillations2019,
  title = {Relation between Gamma Oscillations and Neuronal Plasticity in the Visual Cortex},
  author = {Galuske, Ralf A. W. and Munk, Matthias H. J. and Singer, Wolf},
  date = {2019-11-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {46},
  pages = {23317--23325},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1901277116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1901277116},
  urldate = {2022-10-03},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\K3PIX3B2\Galuske et al. - 2019 - Relation between gamma oscillations and neuronal p.pdf}
}

@article{ganselNeuralSynchronyCortical2022,
  title = {Neural Synchrony in Cortical Networks: Mechanisms and Implications for Neural Information Processing and Coding},
  shorttitle = {Neural Synchrony in Cortical Networks},
  author = {Gansel, Kai S.},
  date = {2022},
  journaltitle = {Frontiers in Integrative Neuroscience},
  volume = {16},
  issn = {1662-5145},
  url = {https://www.frontiersin.org/articles/10.3389/fnint.2022.900715},
  urldate = {2023-03-22},
  abstract = {Synchronization of neuronal discharges on the millisecond scale has long been recognized as a prevalent and functionally important attribute of neural activity. In this article, I review classical concepts and corresponding evidence of the mechanisms that govern the synchronization of distributed discharges in cortical networks and relate those mechanisms to their possible roles in coding and cognitive functions. To accommodate the need for a selective, directed synchronization of cells, I propose that synchronous firing of distributed neurons is a natural consequence of spike-timing-dependent plasticity (STDP) that associates cells repetitively receiving temporally coherent input: the “synchrony through synaptic plasticity” hypothesis. Neurons that are excited by a repeated sequence of synaptic inputs may learn to selectively respond to the onset of this sequence through synaptic plasticity. Multiple neurons receiving coherent input could thus actively synchronize their firing by learning to selectively respond at corresponding temporal positions. The hypothesis makes several predictions: first, the position of the cells in the network, as well as the source of their input signals, would be irrelevant as long as their input signals arrive simultaneously; second, repeating discharge patterns should get compressed until all or some part of the signals are synchronized; and third, this compression should be accompanied by a sparsening of signals. In this way, selective groups of cells could emerge that would respond to some recurring event with synchronous firing. Such a learned response pattern could further be modulated by synchronous network oscillations that provide a dynamic, flexible context for the synaptic integration of distributed signals. I conclude by suggesting experimental approaches to further test this new hypothesis.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HA68SBQP\Gansel - 2022 - Neural synchrony in cortical networks mechanisms .pdf}
}

@article{gaoDistributedSynergisticPlasticity2012,
  title = {Distributed Synergistic Plasticity and Cerebellar Learning},
  author = {Gao, Zhenyu and van Beugen, Boeke J. and De Zeeuw, Chris I.},
  options = {useprefix=true},
  date = {2012-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {13},
  number = {9},
  pages = {619--635},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn3312},
  url = {https://www.nature.com/articles/nrn3312},
  urldate = {2023-04-23},
  abstract = {The cerebellum is involved in motor learning, yet the precise forms of plasticity that may underlie this form of memory formation are still under debate.Recent advances in mouse transgenics and phenomics have provided new pieces of evidence as to how different forms of plasticity at synaptic and extrasynaptic sites in the cerebellar cortex may act together to mediate particular aspects of motor learning.By systematically reviewing all forms of plasticity in the granule cell network and Purkinje cell network and integrating the behavioural phenotypes that can be observed following manipulation of these forms of plasticity, we propose that plasticity in the cerebellar cortex operates in a distributed and synergistic manner.Mediated mainly by input from the mossy fibres, plasticity in the granular layer may serve to spread diversity of coding, while climbing fibre-guided plasticity in the molecular layer may serve to select the appropriate coding required for the specific spatiotemporal demands of the motor learning paradigm involved.Owing to the distributed and synergistic character of cerebellar cortical plasticity guided by common afferent inputs, there is ample room for compensatory mechanisms so as to warrant the consecutive processes of motor performance, motor learning and motor consolidation.},
  issue = {9},
  langid = {english},
  keywords = {Learning and memory,Synaptic plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\GME62GJG\Gao et al. - 2012 - Distributed synergistic plasticity and cerebellar .pdf}
}

@article{garrettExperienceShapesActivity2020,
  title = {Experience Shapes Activity Dynamics and Stimulus Coding of {{VIP}} Inhibitory Cells},
  author = {Garrett, Marina and Manavi, Sahar and Roll, Kate and Ollerenshaw, Douglas R and Groblewski, Peter A and Ponvert, Nicholas D and Kiggins, Justin T and Casal, Linzy and Mace, Kyla and Williford, Ali and Leon, Arielle and Jia, Xiaoxuan and Ledochowitsch, Peter and Buice, Michael A and Wakeman, Wayne and Mihalas, Stefan and Olsen, Shawn R},
  editor = {Bathellier, Brice and Gold, Joshua I and Bathellier, Brice and Keller, Georg B},
  date = {2020-02-26},
  journaltitle = {eLife},
  volume = {9},
  pages = {e50340},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.50340},
  url = {https://doi.org/10.7554/eLife.50340},
  urldate = {2020-09-24},
  abstract = {Cortical circuits can flexibly change with experience and learning, but the effects on specific cell types, including distinct inhibitory types, are not well understood. Here we investigated how excitatory and VIP inhibitory cells in layer 2/3 of mouse visual cortex were impacted by visual experience in the context of a behavioral task. Mice learned a visual change detection task with a set of eight natural scene images. Subsequently, during 2-photon imaging experiments, mice performed the task with these familiar images and three sets of novel images. Strikingly, the temporal dynamics of VIP activity differed markedly between novel and familiar images: VIP cells were stimulus-driven by novel images but were suppressed by familiar stimuli and showed ramping activity when expected stimuli were omitted from a temporally predictable sequence. This prominent change in VIP activity suggests that these cells may adopt different modes of processing under novel versus familiar conditions.},
  keywords = {behavior,learning,visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XZQNTX29\Garrett et al. - 2020 - Experience shapes activity dynamics and stimulus c.pdf}
}

@online{garrettStimulusNoveltyUncovers2023,
  title = {Stimulus Novelty Uncovers Coding Diversity in Visual Cortical Circuits},
  author = {Garrett, Marina and Groblewski, Peter and Piet, Alex and Ollerenshaw, Doug and Najafi, Farzaneh and Yavorska, Iryna and Amster, Adam and Bennett, Corbett and Buice, Michael and Caldejon, Shiella and Casal, Linzy and D’Orazi, Florence and Daniel, Scott and De Vries, Saskia Ej and Kapner, Daniel and Kiggins, Justin and Lecoq, Jerome and Ledochowitsch, Peter and Manavi, Sahar and Mei, Nicholas and Morrison, Christopher B. and Naylor, Sarah and Orlova, Natalia and Perkins, Jed and Ponvert, Nick and Roll, Clark and Seid, Sam and Williams, Derric and Williford, Allison and Ahmed, Ruweida and Amine, Daniel and Billeh, Yazan and Bowman, Chris and Cain, Nicholas and Cho, Andrew and Dawe, Tim and Departee, Max and Desoto, Marie and Feng, David and Gale, Sam and Gelfand, Emily and Gradis, Nile and Grasso, Conor and Hancock, Nicole and Hu, Brian and Hytnen, Ross and Jia, Xiaoxuan and Johnson, Tye and Kato, India and Kivikas, Sara and Kuan, Leonard and L’Heureux, Quinn and Lambert, Sophie and Leon, Arielle and Liang, Elizabeth and Long, Fuhui and Mace, Kyla and Magrans De Abril, Ildefons and Mochizuki, Chris and Nayan, Chelsea and North, Katherine and Ng, Lydia and Ocker, Gabriel Koch and Oliver, Michael and Rhoads, Paul and Ronellenfitch, Kara and Schelonka, Kathryn and Sevigny, Josh and Sullivan, David and Sutton, Ben and Swapp, Jackie and Nguyen, Thuyanh K and Waughman, Xana and Wilkes, Joshua and Wang, Michael and Farrell, Colin and Wakeman, Wayne and Zeng, Hongkui and Phillips, John and Mihalas, Stefan and Arkhipov, Anton and Koch, Christof and Olsen, Shawn R},
  date = {2023-02-15},
  doi = {10.1101/2023.02.14.528085},
  url = {http://biorxiv.org/lookup/doi/10.1101/2023.02.14.528085},
  urldate = {2024-04-12},
  abstract = {The detection of novel stimuli is critical to learn and survive in a dynamic environment. Though novel stimuli powerfully affect brain activity, their impact on specific cell types and circuits is not well understood. Disinhibition is one candidate mechanism for novelty-induced enhancements in activity. Here we characterize the impact of stimulus novelty on disinhibitory circuit components using longitudinal 2-photon calcium imaging of Vip, Sst, and excitatory populations in the mouse visual cortex. Mice learn a behavioral task with stimuli that become highly familiar, then are tested on both familiar and novel stimuli. Mice consistently perform the task with novel stimuli, yet responses to stimulus presentations and stimulus omissions are dramatically altered. Further, we find that novelty modifies coding of visual as well as behavioral and task information. At the population level, the direction of these changes is consistent with engagement of the Vip-Sst disinhibitory circuit. At the single cell level, we identify separate clusters of Vip, Sst, and excitatory cells with unique patterns of novelty-induced coding changes. This study and the accompanying open-access dataset reveals the impact of novelty on sensory and behavioral representations in visual cortical circuits and establishes novelty as a key driver of cellular functional diversity.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\I5M77DTK\Garrett et al. - 2023 - Stimulus novelty uncovers coding diversity in visu.pdf}
}

@online{garrettStimulusNoveltyUncovers2023a,
  title = {Stimulus Novelty Uncovers Coding Diversity in Visual Cortical Circuits},
  author = {Garrett, Marina and Groblewski, Peter and Piet, Alex and Ollerenshaw, Doug and Najafi, Farzaneh and Yavorska, Iryna and Amster, Adam and Bennett, Corbett and Buice, Michael and Caldejon, Shiella and Casal, Linzy and D’Orazi, Florence and Daniel, Scott and de Vries, Saskia EJ and Kapner, Daniel and Kiggins, Justin and Lecoq, Jerome and Ledochowitsch, Peter and Manavi, Sahar and Mei, Nicholas and Morrison, Christopher B. and Naylor, Sarah and Orlova, Natalia and Perkins, Jed and Ponvert, Nick and Roll, Clark and Seid, Sam and Williams, Derric and Williford, Allison and Ahmed, Ruweida and Amine, Daniel and Billeh, Yazan and Bowman, Chris and Cain, Nicholas and Cho, Andrew and Dawe, Tim and Departee, Max and Desoto, Marie and Feng, David and Gale, Sam and Gelfand, Emily and Gradis, Nile and Grasso, Conor and Hancock, Nicole and Hu, Brian and Hytnen, Ross and Jia, Xiaoxuan and Johnson, Tye and Kato, India and Kivikas, Sara and Kuan, Leonard and L’Heureux, Quinn and Lambert, Sophie and Leon, Arielle and Liang, Elizabeth and Long, Fuhui and Mace, Kyla and de Abril, Ildefons Magrans and Mochizuki, Chris and Nayan, Chelsea and North, Katherine and Ng, Lydia and Ocker, Gabriel Koch and Oliver, Michael and Rhoads, Paul and Ronellenfitch, Kara and Schelonka, Kathryn and Sevigny, Josh and Sullivan, David and Sutton, Ben and Swapp, Jackie and Nguyen, Thuyanh K. and Waughman, Xana and Wilkes, Joshua and Wang, Michael and Farrell, Colin and Wakeman, Wayne and Zeng, Hongkui and Phillips, John and Mihalas, Stefan and Arkhipov, Anton and Koch, Christof and Olsen, Shawn R.},
  date = {2023-02-17},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.02.14.528085},
  doi = {10.1101/2023.02.14.528085},
  url = {https://www.biorxiv.org/content/10.1101/2023.02.14.528085v2},
  urldate = {2024-04-12},
  abstract = {The detection of novel stimuli is critical to learn and survive in a dynamic environment. Though novel stimuli powerfully affect brain activity, their impact on specific cell types and circuits is not well understood. Disinhibition is one candidate mechanism for novelty-induced enhancements in activity. Here we characterize the impact of stimulus novelty on disinhibitory circuit components using longitudinal 2-photon calcium imaging of Vip, Sst, and excitatory populations in the mouse visual cortex. Mice learn a behavioral task with stimuli that become highly familiar, then are tested on both familiar and novel stimuli. Mice consistently perform the task with novel stimuli, yet responses to stimulus presentations and stimulus omissions are dramatically altered. Further, we find that novelty modifies coding of visual as well as behavioral and task information. At the population level, the direction of these changes is consistent with engagement of the Vip-Sst disinhibitory circuit. At the single cell level, we identify separate clusters of Vip, Sst, and excitatory cells with unique patterns of novelty-induced coding changes. This study and the accompanying open-access dataset reveals the impact of novelty on sensory and behavioral representations in visual cortical circuits and establishes novelty as a key driver of cellular functional diversity.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RFNFNVHY\Garrett et al. - 2023 - Stimulus novelty uncovers coding diversity in visu.pdf}
}

@online{GaussianProcessesMachine,
  title = {Gaussian {{Processes}} for {{Machine Learning}}: {{Contents}}},
  url = {http://gaussianprocess.org/gpml/chapters/},
  urldate = {2022-09-26},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SF5ES5AD\chapters.html}
}

@article{geislerHippocampalPlaceCell2007,
  title = {Hippocampal Place Cell Assemblies Are Speed-Controlled Oscillators},
  author = {Geisler, Caroline and Robbe, David and Zugaro, Michaël and Sirota, Anton and Buzsáki, György},
  date = {2007-05-08},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {104},
  number = {19},
  pages = {8149--8154},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0610121104},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.0610121104},
  urldate = {2023-03-26},
  abstract = {The phase of spikes of hippocampal pyramidal cells relative to the local field θ oscillation shifts forward (“phase precession”) over a full θ cycle as the animal crosses the cell's receptive field (“place field”). The linear relationship between the phase of the spikes and the travel distance within the place field is independent of the animal's running speed. This invariance of the phase–distance relationship is likely to be important for coordinated activity of hippocampal cells and space coding, yet the mechanism responsible for it is not known. Here we show that at faster running speeds place cells are active for fewer θ cycles but oscillate at a higher frequency and emit more spikes per cycle. As a result, the phase shift of spikes from cycle to cycle (i.e., temporal precession slope) is faster, yet spatial-phase precession stays unchanged. Interneurons can also show transient-phase precession and contribute to the formation of coherently precessing assemblies. We hypothesize that the speed-correlated acceleration of place cell assembly oscillation is responsible for the phase–distance invariance of hippocampal place cells.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\78XVJZHP\Geisler et al. - 2007 - Hippocampal place cell assemblies are speed-contro.pdf}
}

@article{ghavasiehStatisticalPhysicsComplex2020,
  title = {Statistical Physics of Complex Information Dynamics},
  author = {Ghavasieh, Arsham and Nicolini, Carlo and De Domenico, Manlio},
  date = {2020-11-10},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {102},
  number = {5},
  pages = {052304},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.102.052304},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.102.052304},
  urldate = {2022-10-02},
  abstract = {The constituents of a complex system exchange information to function properly. Their signaling dynamics often leads to the appearance of emergent phenomena, such as phase transitions and collective behaviors. While information exchange has been widely modeled by means of distinct spreading processes—such as continuous-time diffusion, random walks, synchronization and consensus—on top of complex networks, a unified and physically grounded framework to study information dynamics and gain insights about the macroscopic effects of microscopic interactions is still eluding us. In this paper, we present this framework in terms of a statistical field theory of information dynamics, unifying a range of dynamical processes governing the evolution of information on top of static or time-varying structures. We show that information operators form a meaningful statistical ensemble and their superposition defines a density matrix that can be used for the analysis of complex dynamics. As a direct application, we show that the von Neumann entropy of the ensemble can be a measure of the functional diversity of complex systems, defined in terms of the functional differentiation of higher-order interactions among their components. Our results suggest that modularity and hierarchy, two key features of empirical complex systems—from the human brain to social and urban networks—play a key role to guarantee functional diversity and, consequently, are favored.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5CWJQFZB\\Ghavasieh et al. - 2020 - Statistical physics of complex information dynamic.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\88XY535E\\PhysRevE.102.html}
}

@article{ghoshNeuronalCorrelatesSelective2022,
  title = {Neuronal Correlates of Selective Attention and Effort in Visual Area {{V4}} Are Invariant of Motivational Context},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2022-06-10},
  journaltitle = {Science Advances},
  volume = {8},
  number = {23},
  pages = {eabc8812},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abc8812},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abc8812},
  urldate = {2022-12-28},
  abstract = {Task demands can differentially engage two fundamental attention components: selectivity (spatial bias) and effort (total nonselective attentional intensity). The relative contributions and interactions of these components in modulating neuronal signals remain unknown. We recorded V4 neurons while monkeys’ spatially selective attention and effort were independently controlled by adjusting either task difficulty or reward size at two locations. Neurons were robustly modulated by either selective attention or effort. Notably, increasing overall effort to improve performance at a distant site reduced neuronal responses even when performance was unchanged for receptive field stimuli. This interaction between attentional selectivity and effort was evident in single-trial spiking and can be explained by divisive normalization of spatially distributed behavioral performance at the single-neuron level. Changing motivation using task difficulty or reward produced indistinguishable effects. These results provide a cellular-level mechanism of how attention components integrate to modulate sensory processing in different motivational contexts.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3ANIUNZ6\Ghosh and Maunsell - 2022 - Neuronal correlates of selective attention and eff.pdf}
}

@article{ghoshNeuronalCorrelatesSelective2022a,
  title = {Neuronal Correlates of Selective Attention and Effort in Visual Area {{V4}} Are Invariant of Motivational Context},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2022-06-10},
  journaltitle = {Science Advances},
  volume = {8},
  number = {23},
  pages = {eabc8812},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abc8812},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abc8812},
  urldate = {2023-01-03},
  abstract = {Task demands can differentially engage two fundamental attention components: selectivity (spatial bias) and effort (total nonselective attentional intensity). The relative contributions and interactions of these components in modulating neuronal signals remain unknown. We recorded V4 neurons while monkeys’ spatially selective attention and effort were independently controlled by adjusting either task difficulty or reward size at two locations. Neurons were robustly modulated by either selective attention or effort. Notably, increasing overall effort to improve performance at a distant site reduced neuronal responses even when performance was unchanged for receptive field stimuli. This interaction between attentional selectivity and effort was evident in single-trial spiking and can be explained by divisive normalization of spatially distributed behavioral performance at the single-neuron level. Changing motivation using task difficulty or reward produced indistinguishable effects. These results provide a cellular-level mechanism of how attention components integrate to modulate sensory processing in different motivational contexts.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XUBGK2CD\Ghosh and Maunsell - 2022 - Neuronal correlates of selective attention and eff.pdf}
}

@article{ghoshSingleTrialNeuronal2021,
  title = {Single Trial Neuronal Activity Dynamics of Attentional Intensity in Monkey Visual Area {{V4}}},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2021-03-31},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2003},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22281-2},
  url = {https://www.nature.com/articles/s41467-021-22281-2},
  urldate = {2022-12-19},
  abstract = {Understanding how activity of visual neurons represents distinct components of attention and their dynamics that account for improved visual performance remains elusive because single-unit experiments have not isolated the intensive aspect of attention from attentional selectivity. We isolated attentional intensity and its single trial dynamics as determined by spatially non-selective attentional performance in an orientation discrimination task while recording from neurons in monkey visual area V4. We found that attentional intensity is a distinct cognitive signal that can be distinguished from spatial selectivity, reward expectations and motor actions. V4 spiking on single trials encodes a combination of sensory and cognitive signals on different time scales. Attentional intensity and the detection of behaviorally relevant sensory signals are well represented, but immediate reward expectation and behavioral choices are poorly represented in V4 spiking. These results provide a detailed representation of perceptual and cognitive signals in V4 that are crucial for attentional performance.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Extrastriate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AGFB3YS8\Ghosh and Maunsell - 2021 - Single trial neuronal activity dynamics of attenti.pdf}
}

@article{ghoshSingleTrialNeuronal2021a,
  title = {Single Trial Neuronal Activity Dynamics of Attentional Intensity in Monkey Visual Area {{V4}}},
  author = {Ghosh, Supriya and Maunsell, John H. R.},
  date = {2021-03-31},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {12},
  number = {1},
  pages = {2003},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-22281-2},
  url = {https://www.nature.com/articles/s41467-021-22281-2},
  urldate = {2023-01-03},
  abstract = {Understanding how activity of visual neurons represents distinct components of attention and their dynamics that account for improved visual performance remains elusive because single-unit experiments have not isolated the intensive aspect of attention from attentional selectivity. We isolated attentional intensity and its single trial dynamics as determined by spatially non-selective attentional performance in an orientation discrimination task while recording from neurons in monkey visual area V4. We found that attentional intensity is a distinct cognitive signal that can be distinguished from spatial selectivity, reward expectations and motor actions. V4 spiking on single trials encodes a combination of sensory and cognitive signals on different time scales. Attentional intensity and the detection of behaviorally relevant sensory signals are well represented, but immediate reward expectation and behavioral choices are poorly represented in V4 spiking. These results provide a detailed representation of perceptual and cognitive signals in V4 that are crucial for attentional performance.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Extrastriate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TWFEXKZF\Ghosh and Maunsell - 2021 - Single trial neuronal activity dynamics of attenti.pdf}
}

@article{gibsonHumanSemiSupervisedLearning2013,
  title = {Human {{Semi-Supervised Learning}}},
  author = {Gibson, Bryan R. and Rogers, Timothy T. and Zhu, Xiaojin},
  date = {2013},
  journaltitle = {Topics in Cognitive Science},
  volume = {5},
  number = {1},
  pages = {132--172},
  issn = {1756-8765},
  doi = {10.1111/tops.12010},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12010},
  urldate = {2024-06-12},
  abstract = {Most empirical work in human categorization has studied learning in either fully supervised or fully unsupervised scenarios. Most real-world learning scenarios, however, are semi-supervised: Learners receive a great deal of unlabeled information from the world, coupled with occasional experiences in which items are directly labeled by a knowledgeable source. A large body of work in machine learning has investigated how learning can exploit both labeled and unlabeled data provided to a learner. Using equivalences between models found in human categorization and machine learning research, we explain how these semi-supervised techniques can be applied to human learning. A series of experiments are described which show that semi-supervised learning models prove useful for explaining human behavior when exposed to both labeled and unlabeled data. We then discuss some machine learning models that do not have familiar human categorization counterparts. Finally, we discuss some challenges yet to be addressed in the use of semi-supervised models for modeling human categorization.},
  langid = {english},
  keywords = {Category learning,Machine learning,Semi-supervised learning},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\95URF3W6\tops.html}
}

@article{gidonDendriticActionPotentials2020,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  date = {2020-01-03},
  journaltitle = {Science},
  volume = {367},
  number = {6473},
  eprint = {31896716},
  eprinttype = {pmid},
  pages = {83--87},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aax6239},
  url = {https://science.sciencemag.org/content/367/6473/83},
  urldate = {2020-09-24},
  abstract = {Human dendrites are special A special developmental program in the human brain drives the disproportionate thickening of cortical layer 2/3. This suggests that the expansion of layer 2/3, along with its numerous neurons and their large dendrites, may contribute to what makes us human. Gidon et al. thus investigated the dendritic physiology of layer 2/3 pyramidal neurons in slices taken from surgically resected brain tissue in epilepsy patients. Dual somatodendritic recordings revealed previously unknown classes of action potentials in the dendrites of these neurons, which make their activity far more complex than has been previously thought. These action potentials allow single neurons to solve two long-standing computational problems in neuroscience that were considered to require multilayer neural networks. Science, this issue p. 83 The active electrical properties of dendrites shape neuronal input and output and are fundamental to brain function. However, our knowledge of active dendrites has been almost entirely acquired from studies of rodents. In this work, we investigated the dendrites of layer 2 and 3 (L2/3) pyramidal neurons of the human cerebral cortex ex vivo. In these neurons, we discovered a class of calcium-mediated dendritic action potentials (dCaAPs) whose waveform and effects on neuronal output have not been previously described. In contrast to typical all-or-none action potentials, dCaAPs were graded; their amplitudes were maximal for threshold-level stimuli but dampened for stronger stimuli. These dCaAPs enabled the dendrites of individual human neocortical pyramidal neurons to classify linearly nonseparable inputs—a computation conventionally thought to require multilayered networks. Dendritic action potentials extend the repertoire of computations available to human neurons. Dendritic action potentials extend the repertoire of computations available to human neurons.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCXZX7BN\\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HNZXZGEN\\83.html}
}

@article{gidonDendriticActionPotentials2020a,
  title = {Dendritic Action Potentials and Computation in Human Layer 2/3 Cortical Neurons},
  author = {Gidon, Albert and Zolnik, Timothy Adam and Fidzinski, Pawel and Bolduan, Felix and Papoutsi, Athanasia and Poirazi, Panayiota and Holtkamp, Martin and Vida, Imre and Larkum, Matthew Evan},
  date = {2020-01-03},
  journaltitle = {Science},
  volume = {367},
  number = {6473},
  pages = {83--87},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aax6239},
  url = {https://www.science.org/doi/abs/10.1126/science.aax6239},
  urldate = {2022-10-01},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JIUYSHJX\Gidon et al. - 2020 - Dendritic action potentials and computation in hum.pdf}
}

@article{gillonResponsesPatternViolatingVisual2024,
  title = {Responses to {{Pattern-Violating Visual Stimuli Evolve Differently Over Days}} in {{Somata}} and {{Distal Apical Dendrites}}},
  author = {Gillon, Colleen J. and Pina, Jason E. and Lecoq, Jérôme A. and Ahmed, Ruweida and Billeh, Yazan N. and Caldejon, Shiella and Groblewski, Peter and Henley, Timothy M. and Kato, India and Lee, Eric and Luviano, Jennifer and Mace, Kyla and Nayan, Chelsea and Nguyen, Thuyanh V. and North, Kat and Perkins, Jed and Seid, Sam and Valley, Matthew T. and Williford, Ali and Bengio, Yoshua and Lillicrap, Timothy P. and Richards, Blake A. and Zylberberg, Joel},
  date = {2024-01-31},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {44},
  number = {5},
  eprint = {37989593},
  eprinttype = {pmid},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1009-23.2023},
  url = {https://www.jneurosci.org/content/44/5/e1009232023},
  urldate = {2024-03-19},
  abstract = {Scientists have long conjectured that the neocortex learns patterns in sensory data to generate top-down predictions of upcoming stimuli. In line with this conjecture, different responses to pattern-matching vs pattern-violating visual stimuli have been observed in both spiking and somatic calcium imaging data. However, it remains unknown whether these pattern-violation signals are different between the distal apical dendrites, which are heavily targeted by top-down signals, and the somata, where bottom-up information is primarily integrated. Furthermore, it is unknown how responses to pattern-violating stimuli evolve over time as an animal gains more experience with them. Here, we address these unanswered questions by analyzing responses of individual somata and dendritic branches of layer 2/3 and layer 5 pyramidal neurons tracked over multiple days in primary visual cortex of awake, behaving female and male mice. We use sequences of Gabor patches with patterns in their orientations to create pattern-matching and pattern-violating stimuli, and two-photon calcium imaging to record neuronal responses. Many neurons in both layers show large differences between their responses to pattern-matching and pattern-violating stimuli. Interestingly, these responses evolve in opposite directions in the somata and distal apical dendrites, with somata becoming less sensitive to pattern-violating stimuli and distal apical dendrites more sensitive. These differences between the somata and distal apical dendrites may be important for hierarchical computation of sensory predictions and learning, since these two compartments tend to receive bottom-up and top-down information, respectively.},
  langid = {english},
  keywords = {distal apical dendrites,hierarchy,neocortex,pyramidal neurons,sensory prediction,unsupervised learning},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VZYHN2LV\Gillon et al. - 2024 - Responses to Pattern-Violating Visual Stimuli Evol.pdf}
}

@article{girardi-schappoUnifiedTheorySynaptic2021,
  title = {A Unified Theory of {{E}}/{{I}} Synaptic Balance, Quasicritical Neuronal Avalanches and Asynchronous Irregular Spiking},
  author = {Girardi-Schappo, Mauricio and Galera, Emilio F. and Carvalho, Tawan T. A. and Brochini, Ludmila and Kamiji, Nilton L. and Roque, Antonio C. and Kinouchi, Osame},
  date = {2021-10},
  journaltitle = {Journal of Physics: Complexity},
  shortjournal = {J. Phys. Complex.},
  volume = {2},
  number = {4},
  pages = {045001},
  publisher = {IOP Publishing},
  issn = {2632-072X},
  doi = {10.1088/2632-072X/ac2792},
  url = {https://doi.org/10.1088/2632-072x/ac2792},
  urldate = {2022-10-01},
  abstract = {Neuronal avalanches and asynchronous irregular (AI) firing patterns have been thought to represent distinct frameworks to understand the brain spontaneous activity. The former is typically present in systems where there is a balance between the slow accumulation of tension and its fast dissipation, whereas the latter is accompanied by the balance between synaptic excitation and inhibition (E/I). Here, we develop a new theory of E/I balance that relies on two homeostatic adaptation mechanisms: the short-term depression of inhibition and the spike-dependent threshold increase. First, we turn off the adaptation and show that the so-called static system has a typical critical point commonly attributed to self-organized critical models. Then, we turn on the adaptation and show that the network evolves to a dynamic regime in which: (I) E/I synapses balance for large recovery time scales; (II) an AI firing pattern emerges; and (III) neuronal avalanches display power laws. This is the first time that these three phenomena appear simultaneously in the same network activity. Thus, we show that AI activity and PL avalanches may coexist into a single dynamics, provided that adaptation mechanisms are in place. In our model, the AI firing pattern is a direct consequence of the hovering close to the critical line where external inputs are compensated by threshold growth, creating synaptic balance for any E/I weight ratio.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TLB9E879\Girardi-Schappo et al. - 2021 - A unified theory of EI synaptic balance, quasicri.pdf}
}

@article{glickfeldHigherOrderAreasMouse2017,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017-09-15},
  journaltitle = {Annual Review of Vision Science},
  shortjournal = {Annu Rev Vis Sci},
  volume = {3},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  issn = {2374-4650},
  doi = {10.1146/annurev-vision-102016-061331},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  langid = {english},
  keywords = {Animals,Behavior Animal,Brain Mapping,connectivity,Connectome,functional specialization,hierarchical and parallel processing,higher visual area,Mice,mouse,visual cortex,Visual Cortex,Visual Pathways,Visual Perception}
}

@article{glickfeldHigherOrderAreasMouse2017a,
  title = {Higher-{{Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017},
  journaltitle = {Annual Review of Vision Science},
  volume = {3},
  number = {1},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  doi = {10.1146/annurev-vision-102016-061331},
  url = {https://doi.org/10.1146/annurev-vision-102016-061331},
  urldate = {2020-11-10},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.}
}

@article{glickfeldHigherOrderAreasMouse2017b,
  title = {✅ {{Higher-Order Areas}} of the {{Mouse Visual Cortex}}},
  author = {Glickfeld, Lindsey L. and Olsen, Shawn R.},
  date = {2017-09-15},
  journaltitle = {Annual Review of Vision Science},
  shortjournal = {Annu Rev Vis Sci},
  volume = {3},
  eprint = {28746815},
  eprinttype = {pmid},
  pages = {251--273},
  issn = {2374-4650},
  doi = {10.1146/annurev-vision-102016-061331},
  abstract = {The brain has evolved to transform sensory information in the environment into neural representations that can be used for perception and action. Higher-order sensory cortical areas, with their increasingly complex receptive fields and integrative properties, are thought to be critical nodes for this function. This is especially true in the primate visual cortex, in which functionally specialized areas are engaged in parallel streams to support diverse computations. Recent anatomical and physiological studies of the mouse visual cortex have revealed a similarly complex network of specialized higher-order areas. This structure provides a useful model for determining the synaptic and circuit mechanisms through which information is transformed across distinct processing stages. In this review, we summarize the current knowledge on the layout, connectivity, and functional properties of the higher visual areas in the mouse. In addition, we speculate on the contribution of these areas to perception and action, and how knowledge of the mouse visual system can inform us about the principles that govern information processing in integrated networks.},
  langid = {english},
  keywords = {Animals,Behavior Animal,Brain Mapping,connectivity,Connectome,functional specialization,hierarchical and parallel processing,higher visual area,Mice,mouse,visual cortex,Visual Cortex,Visual Pathways,Visual Perception},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4DM65D5C\Glickfeld and Olsen - 2017 - Higher-Order Areas of the Mouse Visual Cortex.pdf}
}

@article{goetzActiveDendritesEnable2021,
  title = {Active Dendrites Enable Strong but Sparse Inputs to Determine Orientation Selectivity},
  author = {Goetz, Lea and Roth, Arnd and Häusser, Michael},
  date = {2021-07-27},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {118},
  number = {30},
  pages = {e2017339118},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2017339118},
  url = {https://pnas.org/doi/full/10.1073/pnas.2017339118},
  urldate = {2022-09-02},
  abstract = {Significance                            An active pyramidal cell model, constrained by physiological and anatomical data, was used to simulate dendritic integration in vivo. The model shows that small numbers of strong excitatory synapses can trigger dendritic Na               +               and NMDA spikes. Moreover, only a few dendritic spikes are sufficient to drive a single output action potential. As a consequence, as few as 1\% of the synaptic inputs to a neuron can determine the tuning of somatic output in vivo. These results suggest that dendritic spikes can help to make sensory representations more efficient and flexible: they require fewer connections to sustain them, and only a small number of connections need to be changed to encode a different stimulus and alter the response properties of a neuron.                        ,                             The dendrites of neocortical pyramidal neurons are excitable. However, it is unknown how synaptic inputs engage nonlinear dendritic mechanisms during sensory processing in vivo, and how they in turn influence action potential output. Here, we provide a quantitative account of the relationship between synaptic inputs, nonlinear dendritic events, and action potential output. We developed a detailed pyramidal neuron model constrained by in vivo dendritic recordings. We drive this model with realistic input patterns constrained by sensory responses measured in vivo and connectivity measured in vitro. We show mechanistically that under realistic conditions, dendritic Na               +               and NMDA spikes are the major determinants of neuronal output in vivo. We demonstrate that these dendritic spikes can be triggered by a surprisingly small number of strong synaptic inputs, in some cases even by single synapses. We predict that dendritic excitability allows the 1\% strongest synaptic inputs of a neuron to control the tuning of its output. Active dendrites therefore allow smaller subcircuits consisting of only a few strongly connected neurons to achieve selectivity for specific sensory features.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XQ6LMJPM\Goetz et al. - 2021 - Active dendrites enable strong but sparse inputs t.pdf}
}

@article{gokcenDisentanglingFlowSignals2022,
  title = {✅ {{Disentangling}} the Flow of Signals between Populations of Neurons},
  author = {Gokcen, Evren and Jasper, Anna I. and Semedo, João D. and Zandvakili, Amin and Kohn, Adam and Machens, Christian K. and Yu, Byron M.},
  date = {2022-08},
  journaltitle = {Nature Computational Science},
  shortjournal = {Nat Comput Sci},
  volume = {2},
  number = {8},
  pages = {512--525},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00282-5},
  url = {https://www.nature.com/articles/s43588-022-00282-5},
  urldate = {2022-09-23},
  abstract = {Technological advances now allow us to record from large populations of neurons across multiple brain areas. These recordings may illuminate how communication between areas contributes to brain function, yet a substantial barrier remains: how do we disentangle the concurrent, bidirectional flow of signals between populations of neurons? We propose here a dimensionality reduction framework, delayed latents across groups (DLAG), that disentangles signals relayed in each direction, identifies how these signals are represented by each population and characterizes how they evolve within and across trials. We demonstrate that DLAG performs well on synthetic datasets similar in scale to current neurophysiological recordings. Then we study simultaneously recorded populations in primate visual areas V1 and V2, where DLAG reveals signatures of bidirectional yet selective communication. Our framework lays a foundation for dissecting the intricate flow of signals across populations of neurons, and how this signalling contributes to cortical computation.},
  issue = {8},
  langid = {english},
  keywords = {Computational models,Computational neuroscience,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E65ZMZ2K\\43588_2022_282_MOESM1_ESM.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RLZHRGAW\\GokcenNatCompSci2022.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYST8HXS\\Gokcen et al. - 2022 - Disentangling the flow of signals between populati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\63S4J46D\\s43588-022-00282-5.html}
}

@article{goldbachPerformanceEvenSimple2021,
  title = {Performance in Even a Simple Perceptual Task Depends on Mouse Secondary Visual Areas},
  author = {Goldbach, Hannah C and Akitake, Bradley and Leedy, Caitlin E and Histed, Mark H},
  editor = {Gold, Joshua I and Pasternak, Tatiana and Steinmetz, Nicholas},
  date = {2021-02-01},
  journaltitle = {eLife},
  volume = {10},
  pages = {e62156},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.62156},
  url = {https://doi.org/10.7554/eLife.62156},
  urldate = {2024-06-12},
  abstract = {Primary visual cortex (V1) in the mouse projects to numerous brain areas, including several secondary visual areas, frontal cortex, and basal ganglia. While it has been demonstrated that optogenetic silencing of V1 strongly impairs visually guided behavior, it is not known which downstream areas are required for visual behaviors. Here we trained mice to perform a contrast-increment change detection task, for which substantial stimulus information is present in V1. Optogenetic silencing of visual responses in secondary visual areas revealed that their activity is required for even this simple visual task. In vivo electrophysiology showed that, although inhibiting secondary visual areas could produce some feedback effects in V1, the principal effect was profound suppression at the location of the optogenetic light. The results show that pathways through secondary visual areas are necessary for even simple visual behaviors.},
  keywords = {cerebral cortex,neural circuits,optogenetics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DKT89QBS\Goldbach et al. - 2021 - Performance in even a simple perceptual task depen.pdf}
}

@inproceedings{goldtDynamicsStochasticGradient2019,
  title = {Dynamics of Stochastic Gradient Descent for Two-Layer Neural Networks in the Teacher-Student Setup},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Goldt, Sebastian and Advani, Madhu and Saxe, Andrew M and Krzakala, Florent and Zdeborová, Lenka},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/cab070d53bd0d200746fb852a922064a-Abstract.html},
  urldate = {2024-01-08},
  abstract = {Deep neural networks achieve stellar generalisation even when they have enough parameters to easily fit all their training data. We study this phenomenon by analysing the dynamics and the performance of over-parameterised two-layer neural networks in the teacher-student setup, where one network, the student, is trained on data generated by another network, called the teacher. We show how the dynamics of stochastic gradient descent (SGD) is captured by a set of differential equations and prove that this description is asymptotically exact in the limit of large inputs. Using this framework, we calculate the final generalisation error of student networks that have more parameters than their teachers. We find that the final generalisation error of the student increases with network size when training only the first layer, but stays constant or even decreases with size when training both layers. We show that these different behaviours have their root in the different solutions SGD finds for different activation functions. Our results indicate that achieving good generalisation in neural networks goes beyond the properties of SGD alone and depends on the interplay of at least the algorithm, the model architecture, and the data set.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UFVH9ZJI\Goldt et al. - 2019 - Dynamics of stochastic gradient descent for two-la.pdf}
}

@article{goldtStochasticThermodynamicsLearning2017,
  title = {Stochastic {{Thermodynamics}} of {{Learning}}},
  author = {Goldt, Sebastian and Seifert, Udo},
  date = {2017-01-06},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {118},
  number = {1},
  pages = {010601},
  issn = {0031-9007, 1079-7114},
  doi = {10.1103/PhysRevLett.118.010601},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.118.010601},
  urldate = {2024-01-08},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LY6TNJBS\Goldt and Seifert - 2017 - Stochastic Thermodynamics of Learning.pdf}
}

@article{golloActiveDendritesEnhance2009,
  title = {Active {{Dendrites Enhance Neuronal Dynamic Range}}},
  author = {Gollo, Leonardo L. and Kinouchi, Osame and Copelli, Mauro},
  date = {2009-06-12},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {6},
  pages = {e1000402},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000402},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000402},
  urldate = {2022-09-02},
  abstract = {Since the first experimental evidences of active conductances in dendrites, most neurons have been shown to exhibit dendritic excitability through the expression of a variety of voltage-gated ion channels. However, despite experimental and theoretical efforts undertaken in the past decades, the role of this excitability for some kind of dendritic computation has remained elusive. Here we show that, owing to very general properties of excitable media, the average output of a model of an active dendritic tree is a highly non-linear function of its afferent rate, attaining extremely large dynamic ranges (above 50 dB). Moreover, the model yields double-sigmoid response functions as experimentally observed in retinal ganglion cells. We claim that enhancement of dynamic range is the primary functional role of active dendritic conductances. We predict that neurons with larger dendritic trees should have larger dynamic range and that blocking of active conductances should lead to a decrease in dynamic range.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Neuronal dendrites,Neurons,Nonlinear dynamics,Psychophysics,Signal amplification,Synapses},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RP9KYMK6\Gollo et al. - 2009 - Active Dendrites Enhance Neuronal Dynamic Range.pdf}
}

@article{golloActiveDendritesEnhance2009a,
  title = {Active {{Dendrites Enhance Neuronal Dynamic Range}}},
  author = {Gollo, Leonardo L. and Kinouchi, Osame and Copelli, Mauro},
  date = {2009-06-12},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {6},
  pages = {e1000402},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000402},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000402},
  urldate = {2022-10-02},
  abstract = {Since the first experimental evidences of active conductances in dendrites, most neurons have been shown to exhibit dendritic excitability through the expression of a variety of voltage-gated ion channels. However, despite experimental and theoretical efforts undertaken in the past decades, the role of this excitability for some kind of dendritic computation has remained elusive. Here we show that, owing to very general properties of excitable media, the average output of a model of an active dendritic tree is a highly non-linear function of its afferent rate, attaining extremely large dynamic ranges (above 50 dB). Moreover, the model yields double-sigmoid response functions as experimentally observed in retinal ganglion cells. We claim that enhancement of dynamic range is the primary functional role of active dendritic conductances. We predict that neurons with larger dendritic trees should have larger dynamic range and that blocking of active conductances should lead to a decrease in dynamic range.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Neuronal dendrites,Neurons,Nonlinear dynamics,Psychophysics,Signal amplification,Synapses},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G869MBJS\\Gollo et al. - 2009 - Active Dendrites Enhance Neuronal Dynamic Range.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\69TYQ2D6\\article.html}
}

@article{golloCoexistenceCriticalSensitivity2017,
  title = {Coexistence of Critical Sensitivity and Subcritical Specificity Can Yield Optimal Population Coding},
  author = {Gollo, Leonardo L.},
  date = {2017-09-30},
  journaltitle = {Journal of The Royal Society Interface},
  volume = {14},
  number = {134},
  pages = {20170207},
  publisher = {Royal Society},
  doi = {10.1098/rsif.2017.0207},
  url = {https://royalsocietypublishing.org/doi/full/10.1098/rsif.2017.0207},
  urldate = {2022-10-03},
  abstract = {The vicinity of phase transitions selectively amplifies weak stimuli, yielding optimal sensitivity to distinguish external input. Along with this enhanced sensitivity, enhanced levels of fluctuations at criticality reduce the specificity of the response. Given that the specificity of the response is largely compromised when the sensitivity is maximal, the overall benefit of criticality for signal processing remains questionable. Here, it is shown that this impasse can be solved by heterogeneous systems incorporating functional diversity, in which critical and subcritical components coexist. The subnetwork of critical elements has optimal sensitivity, and the subnetwork of subcritical elements has enhanced specificity. Combining segregated features extracted from the different subgroups, the resulting collective response can maximize the trade-off between sensitivity and specificity measured by the dynamic-range-to-noise ratio. Although numerous benefits can be observed when the entire system is critical, our results highlight that optimal performance is obtained when only a small subset of the system is at criticality.},
  keywords = {complex systems,criticality,diversity,heterogeneity,subcriticality,systems neuroscience},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NSNYCRBD\Gollo - 2017 - Coexistence of critical sensitivity and subcritica.pdf}
}

@article{goltsteinMouseVisualCortex2021,
  title = {Mouse Visual Cortex Areas Represent Perceptual and Semantic Features of Learned Visual Categories},
  author = {Goltstein, Pieter M. and Reinert, Sandra and Bonhoeffer, Tobias and Hübener, Mark},
  date = {2021-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {24},
  number = {10},
  pages = {1441--1451},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00914-5},
  url = {https://www.nature.com/articles/s41593-021-00914-5},
  urldate = {2024-07-08},
  abstract = {Associative memories are stored in distributed networks extending across multiple brain regions. However, it is unclear to what extent sensory cortical areas are part of these networks. Using a paradigm for visual category learning in mice, we investigated whether perceptual and semantic features of learned category associations are already represented at the first stages of visual information processing in the neocortex. Mice learned categorizing visual stimuli, discriminating between categories and generalizing within categories. Inactivation experiments showed that categorization performance was contingent on neuronal activity in the visual cortex. Long-term calcium imaging in nine areas of the visual cortex identified changes in feature tuning and category tuning that occurred during this learning process, most prominently in the postrhinal area (POR). These results provide evidence for the view that associative memories form a brain-wide distributed network, with learning in early stages shaping perceptual representations and supporting semantic content downstream.},
  langid = {english},
  keywords = {Cortex,Learning and memory,Sensory processing,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HB95RLLY\Goltstein et al. - 2021 - Mouse visual cortex areas represent perceptual and.pdf}
}

@article{gomez-navaIntermittentCollectiveMotion2022,
  title = {Intermittent Collective Motion in Sheep Results from Alternating the Role of Leader and Follower},
  author = {Gómez-Nava, Luis and Bon, Richard and Peruani, Fernando},
  date = {2022-10-20},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  pages = {1--8},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-022-01769-8},
  url = {https://www.nature.com/articles/s41567-022-01769-8},
  urldate = {2022-10-25},
  abstract = {Flocking behaviour is often presented as an example of a self-organized process, where individuals continuously negotiate on the direction of travel and compromise by moving along a local average velocity until the group reaches a consensus. Such a collective behaviour does not take advantage of the benefits of hierarchical organizational strategies that confer the leader of the group full control over it with a reduced information flow overhead. Here we study the spontaneous behaviour of small sheep flocks and find that sheep exhibit a collective behaviour that consists of a series of collective motion episodes interrupted by grazing phases. Each motion episode has a temporal leader that guides the group in line formation. Combining experiments and a data-driven model, we provide evidence that group coordination in these episodes results from the propagation of positional information of the temporal leader to all group members through a strongly hierarchical, directed interaction network. Furthermore, we show that group members alternate the role of leader and follower by a random process, which is independent of the navigation mechanism that regulates collective motion episodes. Our analysis suggests that it is possible to conceive intermittent collective strategies that take advantage of both hierarchical and democratic organizational schemes.},
  langid = {english},
  keywords = {Biological physics,Computational biophysics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JNQZHWT4\\Gómez-Nava et al. - 2022 - Intermittent collective motion in sheep results fr.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BZXKT952\\s41567-022-01769-8.html}
}

@article{gonzeModelingCircadianClocks2011,
  title = {Modeling Circadian Clocks: {{From}} Equations to Oscillations},
  shorttitle = {Modeling Circadian Clocks},
  author = {Gonze, Didier},
  date = {2011-10-01},
  journaltitle = {Open Life Sciences},
  volume = {6},
  number = {5},
  pages = {699--711},
  publisher = {De Gruyter Open Access},
  issn = {2391-5412},
  doi = {10.2478/s11535-011-0061-5},
  url = {https://www.degruyter.com/document/doi/10.2478/s11535-011-0061-5/html?lang=en},
  urldate = {2023-01-26},
  abstract = {Circadian rhythms are generated at the cellular level by a small but tightly regulated genetic network. In higher eukaryotes, interlocked transcriptional-translational feedback loops form the core of this network, which ensures the activation of the right genes (proteins) at the right time of the day. Understanding how such a complex molecular network can generate robust, self-sustained oscillations and accurately responds to signals from the environment (such as light and temperature) is greatly helped by mathematical modeling. In the present paper we review some mathematical models for circadian clocks, ranging from abstract, phenomenological models to the most detailed molecular models. We explain how the equations are derived, highlighting the challenges for the modelers, and how the models are analyzed. We show how to compute bifurcation diagrams, entrainment, and phase response curves. In the subsequent paper, we discuss, through a selection of examples, how modeling efforts have contributed to a better understanding of the dynamics of the circadian regulatory network.},
  langid = {english},
  keywords = {Bifurcation diagram,Circadian rhythms,Differential equations,Limit-cycle oscillations,Mathematical models},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AFHLLIAH\Gonze - 2011 - Modeling circadian clocks From equations to oscil.pdf}
}

@article{goodwinOscillatoryBehaviorEnzymatic1965,
  title = {Oscillatory Behavior in Enzymatic Control Processes},
  author = {Goodwin, Brian C.},
  date = {1965-01},
  journaltitle = {Advances in Enzyme Regulation},
  shortjournal = {Advances in Enzyme Regulation},
  volume = {3},
  pages = {425--437},
  issn = {00652571},
  doi = {10.1016/0065-2571(65)90067-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0065257165900671},
  urldate = {2023-02-17},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\M2JDE629\Goodwin - 1965 - Oscillatory behavior in enzymatic control processe.pdf}
}

@article{grangerModelsThalamocorticalSystem2007,
  title = {Models of Thalamocortical System},
  author = {Granger, Richard H. and Hearn, Robert A.},
  date = {2007-11-26},
  journaltitle = {Scholarpedia},
  volume = {2},
  number = {11},
  pages = {1796},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.1796},
  url = {http://www.scholarpedia.org/article/Models_of_thalamocortical_system},
  urldate = {2023-08-03},
  langid = {english}
}

@online{granierConfidenceSecondorderErrors2024,
  title = {Confidence and Second-Order Errors in Cortical Circuits},
  author = {Granier, Arno and Petrovici, Mihai A. and Senn, Walter and Wilmes, Katharina A.},
  date = {2024-03-26},
  eprint = {2309.16046},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2309.16046},
  url = {http://arxiv.org/abs/2309.16046},
  urldate = {2024-04-22},
  abstract = {Minimization of cortical prediction errors has been considered a key computational goal of the cerebral cortex underlying perception, action and learning. However, it is still unclear how the cortex should form and use information about uncertainty in this process. Here, we formally derive neural dynamics that minimize prediction errors under the assumption that cortical areas must not only predict the activity in other areas and sensory streams but also jointly project their confidence (inverse expected uncertainty) in their predictions. In the resulting neuronal dynamics, the integration of bottom-up and top-down cortical streams is dynamically modulated based on confidence in accordance with the Bayesian principle. Moreover, the theory predicts the existence of cortical second-order errors, comparing confidence and actual performance. These errors are propagated through the cortical hierarchy alongside classical prediction errors and are used to learn the weights of synapses responsible for formulating confidence. We propose a detailed mapping of the theory to cortical circuitry, discuss entailed functional interpretations and provide potential directions for experimental work.},
  pubstate = {prepublished},
  keywords = {Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I6U3FAYC\\Granier et al. - 2024 - Confidence and second-order errors in cortical cir.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YCV2DN7A\\2309.html}
}

@article{grazianoAttentionSchemaTheory2015,
  title = {The Attention Schema Theory: A Mechanistic Account of Subjective Awareness},
  shorttitle = {The Attention Schema Theory},
  author = {Graziano, Michael S. A. and Webb, Taylor W.},
  date = {2015},
  journaltitle = {Frontiers in Psychology},
  volume = {6},
  issn = {1664-1078},
  url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00500},
  urldate = {2023-01-18},
  abstract = {We recently proposed the attention schema theory, a novel way to explain the brain basis of subjective awareness in a mechanistic and scientifically testable manner. The theory begins with attention, the process by which signals compete for the brain’s limited computing resources. This internal signal competition is partly under a bottom–up influence and partly under top–down control. We propose that the top–down control of attention is improved when the brain has access to a simplified model of attention itself. The brain therefore constructs a schematic model of the process of attention, the ‘attention schema,’ in much the same way that it constructs a schematic model of the body, the ‘body schema.’ The content of this internal model leads a brain to conclude that it has a subjective experience. One advantage of this theory is that it explains how awareness and attention can sometimes become dissociated; the brain’s internal models are never perfect, and sometimes a model becomes dissociated from the object being modeled. A second advantage of this theory is that it explains how we can be aware of both internal and external events. The brain can apply attention to many types of information including external sensory information and internal information about emotions and cognitive states. If awareness is a model of attention, then this model should pertain to the same domains of information to which attention pertains. A third advantage of this theory is that it provides testable predictions. If awareness is the internal model of attention, used to help control attention, then without awareness, attention should still be possible but should suffer deficits in control. In this article, we review the existing literature on the relationship between attention and awareness, and suggest that at least some of the predictions of the theory are borne out by the evidence.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KJGPV53R\Graziano and Webb - 2015 - The attention schema theory a mechanistic account.pdf}
}

@online{greedySinglephaseDeepLearning2022,
  title = {Single-Phase Deep Learning in Cortico-Cortical Networks},
  author = {Greedy, Will and Zhu, Heng Wei and Pemberton, Joseph and Mellor, Jack and Costa, Rui Ponte},
  date = {2022-10-24},
  eprint = {2206.11769},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2206.11769},
  url = {http://arxiv.org/abs/2206.11769},
  urldate = {2023-03-23},
  abstract = {The error-backpropagation (backprop) algorithm remains the most common solution to the credit assignment problem in artificial neural networks. In neuroscience, it is unclear whether the brain could adopt a similar strategy to correctly modify its synapses. Recent models have attempted to bridge this gap while being consistent with a range of experimental observations. However, these models are either unable to effectively backpropagate error signals across multiple layers or require a multi-phase learning process, neither of which are reminiscent of learning in the brain. Here, we introduce a new model, Bursting Cortico-Cortical Networks (BurstCCN), which solves these issues by integrating known properties of cortical networks namely bursting activity, short-term plasticity (STP) and dendrite-targeting interneurons. BurstCCN relies on burst multiplexing via connection-type-specific STP to propagate backprop-like error signals within deep cortical networks. These error signals are encoded at distal dendrites and induce burst-dependent plasticity as a result of excitatory-inhibitory top-down inputs. First, we demonstrate that our model can effectively backpropagate errors through multiple layers using a single-phase learning process. Next, we show both empirically and analytically that learning in our model approximates backprop-derived gradients. Finally, we demonstrate that our model is capable of learning complex image classification tasks (MNIST and CIFAR-10). Overall, our results suggest that cortical features across sub-cellular, cellular, microcircuit and systems levels jointly underlie single-phase efficient deep learning in the brain.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HEVFXY25\\Greedy et al. - 2022 - Single-phase deep learning in cortico-cortical net.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MJYU3U55\\2206.html}
}

@online{greedySinglephaseDeepLearning2022a,
  title = {Single-Phase Deep Learning in Cortico-Cortical Networks},
  author = {Greedy, Will and Zhu, Heng Wei and Pemberton, Joseph and Mellor, Jack and Costa, Rui Ponte},
  date = {2022-10-24},
  eprint = {2206.11769},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2206.11769},
  url = {http://arxiv.org/abs/2206.11769},
  urldate = {2023-04-25},
  abstract = {The error-backpropagation (backprop) algorithm remains the most common solution to the credit assignment problem in artificial neural networks. In neuroscience, it is unclear whether the brain could adopt a similar strategy to correctly modify its synapses. Recent models have attempted to bridge this gap while being consistent with a range of experimental observations. However, these models are either unable to effectively backpropagate error signals across multiple layers or require a multi-phase learning process, neither of which are reminiscent of learning in the brain. Here, we introduce a new model, Bursting Cortico-Cortical Networks (BurstCCN), which solves these issues by integrating known properties of cortical networks namely bursting activity, short-term plasticity (STP) and dendrite-targeting interneurons. BurstCCN relies on burst multiplexing via connection-type-specific STP to propagate backprop-like error signals within deep cortical networks. These error signals are encoded at distal dendrites and induce burst-dependent plasticity as a result of excitatory-inhibitory top-down inputs. First, we demonstrate that our model can effectively backpropagate errors through multiple layers using a single-phase learning process. Next, we show both empirically and analytically that learning in our model approximates backprop-derived gradients. Finally, we demonstrate that our model is capable of learning complex image classification tasks (MNIST and CIFAR-10). Overall, our results suggest that cortical features across sub-cellular, cellular, microcircuit and systems levels jointly underlie single-phase efficient deep learning in the brain.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4ZJJXNQZ\\Greedy et al. - 2022 - Single-phase deep learning in cortico-cortical net.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WLHNUAU8\\2206.html}
}

@article{greedySinglephaseDeepLearning2022b,
  title = {Single-Phase Deep Learning in Cortico-Cortical Networks},
  author = {Greedy, Will and Zhu, Heng Wei and Pemberton, Joseph and Mellor, Jack and Ponte Costa, Rui},
  date = {2022-12-06},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {24213--24225},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/99088dffd5eab0babebcda4bc58bbcea-Abstract-Conference.html},
  urldate = {2024-04-18},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PV4XDQZZ\\Greedy et al. - 2022 - Single-phase deep learning in cortico-cortical net.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YCEXXYU4\\NeurIPS-2022-single-phase-deep-learning-in-cortico-cortical-networks-Supplemental-Conference.pdf}
}

@article{grienbergerEntorhinalCortexDirects2022,
  title = {✅ {{Entorhinal}} Cortex Directs Learning-Related Changes in {{CA1}} Representations},
  author = {Grienberger, Christine and Magee, Jeffrey C.},
  date = {2022-11},
  journaltitle = {Nature},
  volume = {611},
  number = {7936},
  pages = {554--562},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-05378-6},
  url = {https://www.nature.com/articles/s41586-022-05378-6},
  urldate = {2023-04-17},
  abstract = {Learning-related changes in brain activity are thought to underlie adaptive behaviours1,2. For instance, the learning of a reward site by rodents requires the development of an over-representation of that location in the hippocampus3–6. How this learning-related change occurs remains unknown. Here we recorded hippocampal CA1 population activity as mice learned a reward location on a linear treadmill. Physiological and pharmacological evidence suggests that the adaptive over-representation required behavioural timescale synaptic plasticity (BTSP)7. BTSP is known to be driven by dendritic voltage signals that we proposed were initiated by input from entorhinal cortex layer 3 (EC3). Accordingly, the CA1 over-representation was largely removed by optogenetic inhibition of EC3 activity. Recordings from EC3 neurons revealed an activity pattern that could provide an instructive signal directing BTSP to generate the over-representation. Consistent with this function, our observations show that exposure to a second environment possessing a prominent reward-predictive cue resulted in both EC3 activity and CA1 place field density that were more elevated at the cue than at the reward. These data indicate that learning-related changes in the hippocampus are produced by synaptic plasticity directed by an instructive signal from the EC3 that seems to be specifically adapted to the behaviourally relevant features of the environment.},
  issue = {7936},
  langid = {english},
  keywords = {Hippocampus,Synaptic plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LVCS4MYL\Grienberger and Magee - 2022 - Entorhinal cortex directs learning-related changes.pdf}
}

@article{grienbergerEntorhinalCortexDirects2022a,
  title = {Entorhinal Cortex Directs Learning-Related Changes in {{CA1}} Representations},
  author = {Grienberger, Christine and Magee, Jeffrey C.},
  date = {2022-11},
  journaltitle = {Nature},
  volume = {611},
  number = {7936},
  pages = {554--562},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-022-05378-6},
  url = {https://www.nature.com/articles/s41586-022-05378-6},
  urldate = {2023-04-21},
  abstract = {Learning-related changes in brain activity are thought to underlie adaptive behaviours1,2. For instance, the learning of a reward site by rodents requires the development of an over-representation of that location in the hippocampus3–6. How this learning-related change occurs remains unknown. Here we recorded hippocampal CA1 population activity as mice learned a reward location on a linear treadmill. Physiological and pharmacological evidence suggests that the adaptive over-representation required behavioural timescale synaptic plasticity (BTSP)7. BTSP is known to be driven by dendritic voltage signals that we proposed were initiated by input from entorhinal cortex layer 3 (EC3). Accordingly, the CA1 over-representation was largely removed by optogenetic inhibition of EC3 activity. Recordings from EC3 neurons revealed an activity pattern that could provide an instructive signal directing BTSP to generate the over-representation. Consistent with this function, our observations show that exposure to a second environment possessing a prominent reward-predictive cue resulted in both EC3 activity and CA1 place field density that were more elevated at the cue than at the reward. These data indicate that learning-related changes in the hippocampus are produced by synaptic plasticity directed by an instructive signal from the EC3 that seems to be specifically adapted to the behaviourally relevant features of the environment.},
  issue = {7936},
  langid = {english},
  keywords = {Hippocampus,Synaptic plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\GJNWHR6Q\Grienberger and Magee - 2022 - Entorhinal cortex directs learning-related changes.pdf}
}

@article{grienbergerNMDAReceptorDependentMultidendrite2014,
  title = {{{NMDA Receptor-Dependent Multidendrite Ca2}}+ {{Spikes Required}} for {{Hippocampal Burst Firing In~Vivo}}},
  author = {Grienberger, Christine and Chen, Xiaowei and Konnerth, Arthur},
  date = {2014-03-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {81},
  number = {6},
  pages = {1274--1281},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.01.014},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627314000191},
  urldate = {2023-06-08},
  abstract = {High-frequency bursts of action potentials (APs) are a distinctive form of signaling in various types of mammalian central neurons. In CA1 hippocampal pyramidal neurons in~vivo, such complex spike bursts (CSs) are detected during various behaviors and are considered to be particularly important for learning- and memory-related synaptic plasticity. Here, we combined whole-cell recordings and two-photon imaging in mouse CA1 pyramidal neurons to investigate the cellular mechanisms underlying CSs in~vivo. Our results demonstrate that CSs are of synaptic origin, as they require N-methyl-D-aspartate (NMDA) receptor activation. We identify voltage-gated Ca2+ channel-dependent, spike-like depolarizations as integral components of the CSs. These Ca2+ spikes were invariably associated with widespread large-amplitude Ca2+ transients in basal and apical dendrites. Together, our results reveal a type of NMDA receptor-dependent multidendrite Ca2+ spike required for high-frequency bursting in~vivo.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V7K6MTV6\\Grienberger et al. - 2014 - NMDA Receptor-Dependent Multidendrite Ca2+ Spikes .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3QGCSUSV\\S0896627314000191.html}
}

@article{groblewskiCharacterizationLearningMotivation2020,
  title = {Characterization of {{Learning}}, {{Motivation}}, and {{Visual Perception}} in {{Five Transgenic Mouse Lines Expressing GCaMP}} in {{Distinct Cell Populations}}},
  author = {Groblewski, Peter A. and Ollerenshaw, Douglas R. and Kiggins, Justin T. and Garrett, Marina E. and Mochizuki, Chris and Casal, Linzy and Cross, Sissy and Mace, Kyla and Swapp, Jackie and Manavi, Sahar and Williams, Derric and Mihalas, Stefan and Olsen, Shawn R.},
  date = {2020},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  volume = {14},
  issn = {1662-5153},
  url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2020.00104},
  urldate = {2023-01-09},
  abstract = {To study the mechanisms of perception and cognition, neural measurements must be made during behavior. A goal of the Allen Brain Observatory is to map the activity of distinct cortical cell classes underlying visual and behavioral processing. Here we describe standardized methodology for training head-fixed mice on a visual change detection task, and we use our paradigm to characterize learning and behavior of five GCaMP6-expressing transgenic lines. We used automated training procedures to facilitate comparisons across mice. Training times varied, but most transgenic mice learned the behavioral task. Motivation levels also varied across mice. To compare mice in similar motivational states we subdivided sessions into over-, under-, and optimally motivated periods. When motivated, the pattern of perceptual decisions were highly correlated across transgenic lines, although overall performance (d-prime) was lower in one line labeling somatostatin inhibitory cells. These results provide important context for using these mice to map neural activity underlying perception and behavior.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NJ5L3ZRX\Groblewski et al. - 2020 - Characterization of Learning, Motivation, and Visu.pdf}
}

@incollection{grohCorticothalamicPathwaysSomatosensory2022,
  title = {Corticothalamic {{Pathways}} in the {{Somatosensory System}}},
  booktitle = {The {{Thalamus}}},
  author = {Groh, Alexander and Mease, Rebecca},
  editor = {Halassa, Michael M.},
  date = {2022},
  pages = {221--236},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  doi = {10.1017/9781108674287.013},
  url = {https://www.cambridge.org/core/books/thalamus/corticothalamic-pathways-in-the-somatosensory-system/9566D0A4D5DC10576017214C45B0B33F},
  urldate = {2023-08-01},
  abstract = {The somatosensory thalamocortical system has proven a tractable model for dissecting how different neuronal populations sculpt bidirectional information exchange between the thalamus and the cortex. This chapter reviews corticothalamic (CT) pathways from layers 5 (L5) and 6 (L6) of the primary somatosensory (S1) cortex to first-order ventroposterior (VP) and higher-order posterior medial (POm) somatosensory thalamic nuclei. With a focus on insights gained from recent cell-type–specific approaches in rodent models, we contrast L5 and L6 CT pathways at the scales of network architecture, anatomical connectivity, and physiological characteristics. We further compare the distinct feedforward inhibitory circuits engaged by L6 and L5 CT pathways, which involve the thalamic reticular nucleus and extrathalamic inhibitory nuclei, respectively. Where data exist, we discuss short- and long-term synaptic dynamics of the specific CT circuits. We close with a discussion of the proposed functions of these distinct pathways in conveying “top-down” cortical signals for both the modulation of thalamic processing of sensory information and the transmission of information between cortical regions.},
  isbn = {978-1-108-48156-4},
  keywords = {barrel cortex,corticothalamic,gain control,layer 5,layer 6,pyramidal tract,short-term plasticity,somatosensory,thalamic firing modes,whisker}
}

@article{grohDriverCoincidenceDetector2008,
  title = {Driver or {{Coincidence Detector}}: {{Modal Switch}} of a {{Corticothalamic Giant Synapse Controlled}} by {{Spontaneous Activity}} and {{Short-Term Depression}}},
  shorttitle = {Driver or {{Coincidence Detector}}},
  author = {Groh, Alexander and de Kock, Christiaan P. J. and Wimmer, Verena C. and Sakmann, Bert and Kuner, Thomas},
  date = {2008-09-24},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {28},
  number = {39},
  eprint = {18815251},
  eprinttype = {pmid},
  pages = {9652--9663},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1554-08.2008},
  url = {https://www.jneurosci.org/content/28/39/9652},
  urldate = {2023-08-28},
  abstract = {Giant synapses between layer 5B (L5B) neurons of somatosensory (barrel) cortex and neurons of the posteromedial nucleus (POm) of thalamus reside in a key position of the cortico-thalamo-cortical (CTC) loop, yet their synaptic properties and contribution to CTC information processing remain poorly understood. Fluorescence-guided local stimulation of terminals were combined with postsynaptic whole-cell recordings in thalamus to study synaptic transmission at an identified giant synapse. We found large EPSCs mediated by Ca2+-permeable AMPA and NMDA receptors. A single presynaptic electrical stimulus evoked a train of postsynaptic action potentials, indicating that a single L5B input can effectively drive the thalamic neuron. Repetitive stimulation caused strong short-term depression (STD) with fast recovery. To examine how these synaptic properties affect information transfer, spontaneous and evoked activity of L5B neurons was recorded in vivo and played back to giant terminals in vitro. We found that suprathreshold synaptic transmission was suppressed because of spontaneous activity causing strong STD of the L5B–POm giant synapse. Thalamic neurons only spiked after intervals of presynaptic silence or when costimulating two giant terminals. Therefore, STD caused by spontaneous activity of L5B neurons can switch the synapse from a “driver mode” to a “coincidence mode.” Mechanisms decreasing spontaneous activity in L5B neurons and inputs synchronized by a sensory stimulus may thus gate the cortico-thalamo-cortical loop.},
  langid = {english},
  keywords = {corticothalamic,giant synapse,low-pass filtering,posteromedial nucleus of thalamus,short-term depression,virus-mediated gene expression},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\496L8GQY\Groh et al. - 2008 - Driver or Coincidence Detector Modal Switch of a .pdf}
}

@article{grossmanNeuromodulationNeurophysiologyTimescale2022,
  title = {Neuromodulation and {{Neurophysiology}} on the {{Timescale}} of {{Learning}} and {{Decision-Making}}},
  author = {Grossman, Cooper D. and Cohen, Jeremiah Y.},
  date = {2022-07-08},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu Rev Neurosci},
  volume = {45},
  eprint = {35363533},
  eprinttype = {pmid},
  pages = {317--337},
  issn = {1545-4126},
  doi = {10.1146/annurev-neuro-092021-125059},
  abstract = {Nervous systems evolved to effectively navigate the dynamics of the environment to achieve their goals. One framework used to study this fundamental problem arose in the study of learning and decision-making. In this framework, the demands of effective behavior require slow dynamics-on the scale of seconds to minutes-of networks of neurons. Here, we review the phenomena and mechanisms involved. Using vignettes from a few species and areas of the nervous system, we view neuromodulators as key substrates for temporal scaling of neuronal dynamics.},
  langid = {english},
  keywords = {Decision Making,dopamine,Learning,Neurons,Neurophysiology,Neurotransmitter Agents,norepinephrine,reinforcement learning,serotonin},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CVFI67R5\Grossman and Cohen - 2022 - Neuromodulation and Neurophysiology on the Timesca.pdf}
}

@article{guDifferencesIntrinsicAmplitudes2017,
  title = {Differences in Intrinsic Amplitudes of Neuronal Oscillators Improve Synchronization in the Suprachiasmatic Nucleus},
  author = {Gu, Changgui and Yang, Huijie},
  date = {2017-09},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {27},
  number = {9},
  pages = {093108},
  publisher = {American Institute of Physics},
  issn = {1054-1500},
  doi = {10.1063/1.5000039},
  url = {https://aip.scitation.org/doi/10.1063/1.5000039},
  urldate = {2023-02-16}
}

@article{guNoiseInducesOscillation2015,
  title = {Noise {{Induces Oscillation}} and {{Synchronization}} of the {{Circadian Neurons}}},
  author = {Gu, Changgui and Xu, Jinshan and Rohling, Jos and Yang, Huijie and Liu, Zonghua},
  date = {2015-12-21},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {10},
  number = {12},
  pages = {e0145360},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0145360},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0145360},
  urldate = {2023-02-22},
  abstract = {The principle clock of mammals, named suprachiasmatic nucleus (SCN), coordinates the circadian rhythms of behavioral and physiological activity to the external 24 h light-dark cycle. In the absence of the daily cycle, the SCN acts as an endogenous clock that regulates the \textasciitilde 24h rhythm of activity. Experimental and theoretical studies usually take the light-dark cycle as a main external influence, and often ignore light pollution as an external influence. However, in modern society, the light pollution such as induced by electrical lighting influences the circadian clock. In the present study, we examined the effect of external noise (light pollution) on the collective behavior of coupled circadian oscillators under constant darkness using a Goodwin model. We found that the external noise plays distinct roles in the network behavior of neurons for weak or strong coupling between the neurons. In the case of strong coupling, the noise reduces the synchronization and the period of the SCN network. Interestingly, in the case of weak coupling, the noise induces a circadian rhythm in the SCN network which is absent in noise-free condition. In addition, the noise increases the synchronization and decreases the period of the SCN network. Our findings may shed new light on the impact of the external noise on the collective behavior of SCN neurons.},
  langid = {english},
  keywords = {Circadian oscillators,Circadian rhythms,Eigenvalues,Light pollution,Neural networks,Neurons,Schematic diagrams,White noise},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7HB58AHP\Gu et al. - 2015 - Noise Induces Oscillation and Synchronization of t.pdf}
}

@article{haimFunctionalDiversityAstrocytes2017,
  title = {Functional Diversity of Astrocytes in Neural Circuit Regulation},
  author = {Haim, Lucile Ben and Rowitch, David H.},
  date = {2017-01},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {18},
  number = {1},
  pages = {31--41},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.159},
  url = {https://www.nature.com/articles/nrn.2016.159},
  urldate = {2020-11-22},
  abstract = {Astrocytes display numerous inter- and intra-regional distinctions, ranging from differences in their morphology to differential dynamics of calcium signalling.Astrocytes in specific neural circuits modulate neuronal activity, which affects a range of brain functions.Regionally encoded astrocyte functions are required for neuronal homeostasis and survival.Astrocyte heterogeneity is determined by the developmental patterning of the CNS and is refined in adulthood to produce highly specialized neuron–glia units.Under pathological conditions, reactive astrocytes display several molecular and functional changes that have a differential influence on disease outcome.New techniques will help to uncover the molecular and functional heterogeneity of astrocytes both in health and disease.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VX47A8UK\\Haim and Rowitch - 2017 - Functional diversity of astrocytes in neural circu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SHUCTZYZ\\nrn.2016.html}
}

@article{hanBehaviorrelevantTopdownCrossmodal2024,
  title = {Behavior-Relevant Top-down Cross-Modal Predictions in Mouse Neocortex},
  author = {Han, Shuting and Helmchen, Fritjof},
  date = {2024-02},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {27},
  number = {2},
  pages = {298--308},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01534-x},
  url = {https://www.nature.com/articles/s41593-023-01534-x},
  urldate = {2024-07-03},
  abstract = {Animals adapt to a constantly changing world by predicting their environment and the consequences of their actions. The predictive coding hypothesis proposes that the brain generates predictions and continuously compares them with sensory inputs to guide behavior. However, how the brain reconciles conflicting top-down predictions and bottom-up sensory information remains unclear. To address this question, we simultaneously imaged neuronal populations in the mouse somatosensory barrel cortex and posterior parietal cortex during an auditory-cued texture discrimination task. In mice that had learned the task with fixed tone–texture matching, the presentation of mismatched pairing induced conflicts between tone-based texture predictions and actual texture inputs. When decisions were based on the predicted rather than the actual texture, top-down information flow was dominant and texture representations in both areas were modified, whereas dominant bottom-up information flow led to correct representations and behavioral choice. Our findings provide evidence for hierarchical predictive coding in the mouse neocortex.},
  langid = {english},
  keywords = {Neural circuits,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\E9CCD3KD\Han and Helmchen - 2024 - Behavior-relevant top-down cross-modal predictions.pdf}
}

@article{hanLogicSinglecellProjections2018,
  title = {The Logic of Single-Cell Projections from Visual Cortex},
  author = {Han, Yunyun and Kebschull, Justus M. and Campbell, Robert A. A. and Cowan, Devon and Imhof, Fabia and Zador, Anthony M. and Mrsic-Flogel, Thomas D.},
  date = {2018-04},
  journaltitle = {Nature},
  volume = {556},
  number = {7699},
  pages = {51--56},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature26159},
  url = {https://www.nature.com/articles/nature26159},
  urldate = {2024-06-12},
  abstract = {Neocortical areas communicate through extensive axonal projections, but the logic of information transfer remains poorly understood, because the projections of individual neurons have not been systematically characterized. It is not known whether individual neurons send projections only to single cortical areas or distribute signals across multiple targets. Here we determine the projection patterns of 591 individual neurons in the mouse primary visual cortex using whole-brain fluorescence-based axonal tracing and high-throughput DNA sequencing of genetically barcoded neurons (MAPseq). Projections were highly diverse and divergent, collectively targeting at least 18 cortical and subcortical areas. Most neurons targeted multiple cortical areas, often in non-random combinations, suggesting that sub-classes of intracortical projection neurons exist. Our results indicate that the dominant mode of intracortical information transfer is not based on ‘one neuron–one target area’ mapping. Instead, signals carried by individual cortical neurons are shared across subsets of target areas, and thus concurrently contribute to multiple functional pathways.},
  langid = {english},
  keywords = {Extrastriate cortex,Neural circuits,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DZQN5W8F\Han et al. - 2018 - The logic of single-cell projections from visual c.pdf}
}

@article{hanselParallelFiberLTD2001,
  title = {Beyond Parallel Fiber {{LTD}}: The Diversity of Synaptic and Non-Synaptic Plasticity in the Cerebellum},
  shorttitle = {Beyond Parallel Fiber {{LTD}}},
  author = {Hansel, Christian and Linden, David J. and D'Angelo, Egidio},
  date = {2001-05},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {4},
  number = {5},
  pages = {467--475},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/87419},
  url = {https://www.nature.com/articles/nn0501_467},
  urldate = {2023-04-24},
  abstract = {In recent years, it has become clear that motor learning, as revealed by associative eyelid conditioning and adaptation of the vestibulo-ocular reflex, contributes to the well-established cerebellar functions of sensorimotor integration and control. Long-term depression of the parallel fiber–Purkinje cell synapse (which is often called 'cerebellar LTD') is a cellular phenomenon that has been suggested to underlie these forms of learning. However, it is clear that parallel fiber LTD, by itself, cannot account for all the properties of cerebellar motor learning. Here we review recent electrophysiological experiments that have described a rich variety of use-dependent plasticity in cerebellum, including long-term potentiation (LTP) and LTD of excitatory and inhibitory synapses, and persistent modulation of intrinsic neuronal excitability. Finally, using associative eyelid conditioning as an example, we propose some ideas about how these cellular phenomena might function and interact to endow the cerebellar circuit with particular computational and mnemonic properties.},
  issue = {5},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5YK3WQIT\Hansel et al. - 2001 - Beyond parallel fiber LTD the diversity of synapt.pdf}
}

@article{harrisCorticalStateAttention2011,
  title = {Cortical State and Attention},
  author = {Harris, Kenneth D. and Thiele, Alexander},
  date = {2011-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {12},
  number = {9},
  pages = {509--523},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn3084},
  url = {https://www.nature.com/articles/nrn3084},
  urldate = {2023-01-03},
  abstract = {Cortex operates in multiple states, which are characterized by varying amounts of fluctuation in spontaneous population activity.The classical desynchronized and synchronized states that are associated with waking and slow-wave sleep, respectively, are two points on a continuum of states; the continuum is probably multidimensional.More-desynchronized states exhibit decreases in low-frequency local field potential (LFP) power and lower pairwise spiking correlations than synchronized states.Selective attention seems to involve desynchronization operating locally in a patch of cortex that represents the attended stimulus.Local desynchronization may result from a combination of widespread neuromodulatory input, and tonic glutamatergic feedback focused on the patch representing the attended stimulus.},
  issue = {9},
  langid = {english},
  keywords = {Attention,Computational neuroscience,Neuronal physiology,Sensory systems,Sleep,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ABZYDESX\Harris and Thiele - 2011 - Cortical state and attention.pdf}
}

@article{harrisLongRangeNeuralSynchrony2015,
  title = {✅ {{Long-Range Neural Synchrony}} in {{Behavior}}},
  author = {Harris, Alexander Z. and Gordon, Joshua A.},
  date = {2015},
  journaltitle = {Annual Review of Neuroscience},
  volume = {38},
  number = {1},
  eprint = {25897876},
  eprinttype = {pmid},
  pages = {171--194},
  doi = {10.1146/annurev-neuro-071714-034111},
  url = {https://doi.org/10.1146/annurev-neuro-071714-034111},
  urldate = {2023-03-31},
  abstract = {Long-range synchrony between distant brain regions accompanies multiple forms of behavior. This review compares and contrasts the methods by which long-range synchrony is evaluated in both humans and model animals. Three examples of behaviorally relevant long-range synchrony are discussed in detail: gamma-frequency synchrony during visual perception, hippocampal-prefrontal synchrony during working memory, and prefrontal-amygdala synchrony during anxiety. Implications for circuit mechanism, translation, and clinical relevance are discussed.},
  keywords = {coherence,gamma,hippocampus,oscillations,prefrontal cortex,theta},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JE782VEG\Harris and Gordon - 2015 - Long-Range Neural Synchrony in Behavior.pdf}
}

@article{harrisNeuralSignaturesCell2005,
  title = {Neural Signatures of Cell Assembly Organization},
  author = {Harris, Kenneth D.},
  date = {2005-05},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {6},
  number = {5},
  pages = {399--407},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn1669},
  url = {https://www.nature.com/articles/nrn1669},
  urldate = {2023-03-27},
  abstract = {Cortical neurons show irregular but structured spike trains. This has been interpreted as evidence for 'temporal coding', whereby stimuli are represented by precise spike-timing patterns. Here, we suggest an alternative interpretation based on the older concept of the cell assembly. The dynamic evolution of assembly sequences, which are steered but not deterministically controlled by sensory input, is the proposed substrate of psychological processes beyond simple stimulus–response associations. Accordingly, spike trains show a temporal structure that is stimulus-dependent and more variable than would be predicted by strict sensory control. We propose four signatures of assembly organization that can be experimentally tested. We argue that many observations that have been interpreted as evidence for temporal coding might instead reflect an underlying assembly structure.},
  issue = {5},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X4MKNDQX\Harris - 2005 - Neural signatures of cell assembly organization.pdf}
}

@article{hastingsGenerationCircadianRhythms2018,
  title = {✅  {{Generation}} of Circadian Rhythms in the Suprachiasmatic Nucleus},
  author = {Hastings, Michael H. and Maywood, Elizabeth S. and Brancaccio, Marco},
  date = {2018-08},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {8},
  pages = {453--469},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-018-0026-z},
  url = {https://www.nature.com/articles/s41583-018-0026-z},
  urldate = {2023-02-16},
  abstract = {The suprachiasmatic nucleus (SCN) of the hypothalamus is remarkable. Despite numbering only about 10,000 neurons on each side of the third ventricle, the SCN is our principal circadian clock, directing the daily cycles of behaviour and physiology that set the tempo of our lives. When this nucleus is isolated in organotypic culture, its autonomous timing mechanism can persist indefinitely, with precision and robustness. The discovery of the cell-autonomous transcriptional and post-translational feedback loops that drive circadian activity in the SCN provided a powerful exemplar of the genetic specification of complex mammalian behaviours. However, the analysis of circadian time-keeping is moving beyond single cells. Technical and conceptual advances, including intersectional genetics, multidimensional imaging and network theory, are beginning to uncover the circuit-level mechanisms and emergent properties that make the SCN a uniquely precise and robust clock. However, much remains unknown about the SCN, not least the intrinsic properties of SCN neurons, its circuit topology and the neuronal computations that these circuits support. Moreover, the convention that the SCN is a neuronal clock has been overturned by the discovery that astrocytes are an integral part of the timepiece. As a test bed for examining the relationships between genes, cells and circuits in sculpting complex behaviours, the SCN continues to offer powerful lessons and opportunities for contemporary neuroscience.},
  issue = {8},
  langid = {english},
  keywords = {Circadian mechanisms,Circadian rhythms and sleep},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CVGW72UK\Hastings et al. - 2018 - Generation of circadian rhythms in the suprachiasm.pdf}
}

@article{hattoriFunctionsDysfunctionsNeocortical2017,
  title = {Functions and Dysfunctions of Neocortical Inhibitory Neuron Subtypes},
  author = {Hattori, Ryoma and Kuchibhotla, Kishore V. and Froemke, Robert C. and Komiyama, Takaki},
  date = {2017-09},
  journaltitle = {Nature Neuroscience},
  volume = {20},
  number = {9},
  pages = {1199--1208},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4619},
  url = {https://www.nature.com/articles/nn.4619},
  urldate = {2020-12-18},
  abstract = {Hattori et al. review the recent advances in our understanding of the roles of inhibitory neuron subtypes in shaping the activity and plasticity states of neocortical circuits, how neuromodulators control inhibitory neuron subtypes, and the role of inhibitory neuron dysfunction in neurological disorders.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S94R3PKG\\Hattori et al. - 2017 - Functions and dysfunctions of neocortical inhibito.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FGRLI9NM\\nn.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J2RHJYGF\\nn.html}
}

@article{hawkinsWhyNeuronsHave2016,
  title = {Why {{Neurons Have Thousands}} of {{Synapses}}, a {{Theory}} of {{Sequence Memory}} in {{Neocortex}}},
  author = {Hawkins, Jeff and Ahmad, Subutai},
  date = {2016},
  journaltitle = {Frontiers in Neural Circuits},
  volume = {10},
  issn = {1662-5110},
  url = {https://www.frontiersin.org/articles/10.3389/fncir.2016.00023},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons represent the majority of excitatory neurons in the neocortex. Each pyramidal neuron receives input from thousands of excitatory synapses that are segregated onto dendritic branches. The dendrites themselves are segregated into apical, basal, and proximal integration zones, which have different properties. It is a mystery how pyramidal neurons integrate the input from thousands of synapses, what role the different dendrites play in this integration, and what kind of network behavior this enables in cortical tissue. It has been previously proposed that non-linear properties of dendrites enable cortical neurons to recognize multiple independent patterns. In this paper we extend this idea in multiple ways. First we show that a neuron with several thousand synapses segregated on active dendrites can recognize hundreds of independent patterns of cellular activity even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where patterns detected on proximal dendrites lead to action potentials, defining the classic receptive field of the neuron, and patterns detected on basal and apical dendrites act as predictions by slightly depolarizing the neuron without generating an action potential. By this mechanism, a neuron can predict its activation in hundreds of independent contexts. We then present a network model based on neurons with these properties that learns time-based sequences. The network relies on fast local inhibition to preferentially activate neurons that are slightly depolarized. Through simulation we show that the network scales well and operates robustly over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. We contrast the properties of the new network model with several other neural network models to illustrate the relative capabilities of each. We conclude that pyramidal neurons with thousands of synapses, active dendrites, and multiple integration zones create a robust and powerful sequence memory. Given the prevalence and similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory may be a universal property of neocortical tissue.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JR88HUZS\Hawkins and Ahmad - 2016 - Why Neurons Have Thousands of Synapses, a Theory o.pdf}
}

@article{healdContextualInferenceUnderlies2021,
  title = {Contextual Inference Underlies the Learning of Sensorimotor Repertoires},
  author = {Heald, James B. and Lengyel, Máté and Wolpert, Daniel M.},
  date = {2021-12},
  journaltitle = {Nature},
  volume = {600},
  number = {7889},
  pages = {489--493},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-021-04129-3},
  url = {https://www.nature.com/articles/s41586-021-04129-3},
  urldate = {2024-03-13},
  abstract = {Humans spend a lifetime learning, storing and refining a repertoire of motor memories. For example, through experience, we become proficient at manipulating a large range of objects with distinct dynamical properties. However, it is unknown what principle underlies how our continuous stream of sensorimotor experience is segmented into separate memories and how we adapt and use this growing repertoire. Here we develop a theory of motor learning based on the key principle that memory creation, updating and expression are all controlled by a single computation—contextual inference. Our theory reveals that adaptation can arise both by creating and updating memories (proper learning) and by changing how existing memories are differentially expressed (apparent learning). This insight enables us to account for key features of motor learning that had no unified explanation: spontaneous recovery1, savings2, anterograde interference3, how environmental consistency affects learning rate4,5 and the distinction between explicit and implicit learning6. Critically, our theory also predicts new phenomena—evoked recovery and context-dependent single-trial learning—which we confirm experimentally. These results suggest that contextual inference, rather than classical single-context mechanisms1,4,7–9, is the key principle underlying how a diverse set of experiences is reflected in our motor behaviour.},
  langid = {english},
  keywords = {Human behaviour,Motor control},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9ALNCVH9\Heald et al. - 2021 - Contextual inference underlies the learning of sen.pdf}
}

@article{hellerTargetedDimensionalityReduction2022,
  title = {Targeted Dimensionality Reduction Enables Reliable Estimation of Neural Population Coding Accuracy from Trial-Limited Data},
  author = {Heller, Charles R. and David, Stephen V.},
  date = {2022-07-21},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {17},
  number = {7},
  pages = {e0271136},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0271136},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0271136},
  urldate = {2022-09-26},
  abstract = {Rapidly developing technology for large scale neural recordings has allowed researchers to measure the activity of hundreds to thousands of neurons at single cell resolution in vivo. Neural decoding analyses are a widely used tool used for investigating what information is represented in this complex, high-dimensional neural population activity. Most population decoding methods assume that correlated activity between neurons has been estimated accurately. In practice, this requires large amounts of data, both across observations and across neurons. Unfortunately, most experiments are fundamentally constrained by practical variables that limit the number of times the neural population can be observed under a single stimulus and/or behavior condition. Therefore, new analytical tools are required to study neural population coding while taking into account these limitations. Here, we present a simple and interpretable method for dimensionality reduction that allows neural decoding metrics to be calculated reliably, even when experimental trial numbers are limited. We illustrate the method using simulations and compare its performance to standard approaches for dimensionality reduction and decoding by applying it to single-unit electrophysiological data collected from auditory cortex.},
  langid = {english},
  keywords = {Action potentials,Behavior,Coding mechanisms,Covariance,Eigenvectors,Neurons,Principal component analysis,Sensory perception},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V8DHKHCR\\Heller and David - 2022 - Targeted dimensionality reduction enables reliable.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GLHA4VED\\article.html}
}

@article{heltbergTaleTwoRhythms2021,
  title = {✅ {{A}} Tale of Two Rhythms: {{Locked}} Clocks and Chaos in Biology},
  shorttitle = {A Tale of Two Rhythms},
  author = {Heltberg, Mathias L. and Krishna, Sandeep and Kadanoff, Leo P. and Jensen, Mogens H.},
  date = {2021-04-21},
  journaltitle = {Cell Systems},
  shortjournal = {Cell Systems},
  volume = {12},
  number = {4},
  pages = {291--303},
  issn = {2405-4712},
  doi = {10.1016/j.cels.2021.03.003},
  url = {https://www.sciencedirect.com/science/article/pii/S2405471221001083},
  urldate = {2023-01-26},
  abstract = {The fundamental mechanisms that control and regulate biological organisms exhibit a surprising level of complexity. Oscillators are perhaps the simplest motifs that produce time-varying dynamics and are ubiquitous in biological systems. It is also known that such biological oscillators interact with each other—for instance, circadian oscillators affect the cell cycle, and somitogenesis clock proteins in adjacent cells affect each other in developing embryos. Therefore, it is vital to understand the effects that can emerge from non-linear interaction between oscillations. Here, we show how oscillations typically arise in biology and take the reader on a tour through the great variety in dynamics that can emerge even from a single pair of coupled oscillators. We explain how chaotic dynamics can emerge and outline the methods of detecting this in experimental time traces. Finally, we discuss the potential role of such complex dynamical features in biological systems.},
  langid = {english},
  keywords = {cell signaling,chaos,coupled oscillators,dynamical systems,gene regulation,protein oscillations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\34JZZIPS\\Heltberg et al. - 2021 - A tale of two rhythms Locked clocks and chaos in .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\64ECSXIR\\S2405471221001083.html}
}

@article{hennequinDynamicalRegimeSensory2018,
  title = {The {{Dynamical Regime}} of {{Sensory Cortex}}: {{Stable Dynamics}} around a {{Single Stimulus-Tuned Attractor Account}} for {{Patterns}} of {{Noise Variability}}},
  shorttitle = {The {{Dynamical Regime}} of {{Sensory Cortex}}},
  author = {Hennequin, Guillaume and Ahmadian, Yashar and Rubin, Daniel B. and Lengyel, Máté and Miller, Kenneth D.},
  date = {2018-05-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {98},
  number = {4},
  eprint = {29772203},
  eprinttype = {pmid},
  pages = {846-860.e5},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2018.04.017},
  abstract = {Correlated variability in cortical activity is ubiquitously quenched following stimulus onset, in a stimulus-dependent manner. These modulations have been attributed to circuit dynamics involving either multiple stable states ("attractors") or chaotic activity. Here we show that a qualitatively different dynamical regime, involving fluctuations about a single, stimulus-driven attractor in a loosely balanced excitatory-inhibitory network (the stochastic "stabilized supralinear network"), best explains these modulations. Given the supralinear input/output functions of cortical neurons, increased stimulus drive strengthens effective network connectivity. This shifts the balance from interactions that amplify~variability to suppressive inhibitory feedback, quenching correlated variability around more strongly driven steady states. Comparing to previously published and original data analyses, we show that this mechanism, unlike previous proposals, uniquely accounts for the spatial patterns and fast temporal dynamics of variability suppression. Specifying the cortical operating regime is key~to understanding the computations underlying perception.},
  langid = {english},
  pmcid = {PMC5971207},
  keywords = {Animals,circuit dynamics,cortical variability,Macaca,MT,Neural Inhibition,Neural Networks Computer,Neurons,noise correlations,Nonlinear Dynamics,Occipital Lobe,theoretical neuroscience,V1,variability quenching,Visual Cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ULQ4KBNT\Hennequin et al. - 2018 - The Dynamical Regime of Sensory Cortex Stable Dyn.pdf}
}

@article{hensSpatiotemporalSignalPropagation2019,
  title = {Spatiotemporal Signal Propagation in Complex Networks},
  author = {Hens, Chittaranjan and Harush, Uzi and Haber, Simi and Cohen, Reuven and Barzel, Baruch},
  date = {2019-04},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {15},
  number = {4},
  pages = {403--412},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-018-0409-0},
  url = {https://www.nature.com/articles/s41567-018-0409-0},
  urldate = {2022-10-02},
  abstract = {A major achievement in the study of complex networks is the realization that diverse systems, from sub-cellular biology to social networks, exhibit universal topological characteristics. Yet, such universality does not naturally translate to the dynamics of these systems, as dynamic behaviour cannot be uniquely predicted from topology alone. Rather, it depends on the interplay of the network’s topology with the dynamic mechanisms of interaction between the nodes. Hence, systems with similar structure may exhibit profoundly different dynamic behaviour. We therefore seek a general theoretical framework to help us systematically translate topological elements into their predicted dynamic outcome. Here, we offer such a translation in the context of signal propagation, linking the topology of a network to the observed spatiotemporal spread of perturbative signals across it, thus capturing the network’s role in propagating local information. For a range of nonlinear dynamic models, we predict that the propagation rules condense into three highly distinctive dynamic regimes, characterized by the interplay between network paths, degree distribution and the interaction dynamics. As a result, classifying a system’s intrinsic interaction mechanisms into the relevant dynamic regime allows us to systematically translate topology into dynamic patterns of information propagation.},
  issue = {4},
  langid = {english},
  keywords = {Complex networks,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CPMCAARD\\Hens et al. - 2019 - Spatiotemporal signal propagation in complex netwo.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X7WVIBT6\\s41567-018-0409-0.html}
}

@article{herreroAttentionInducedVarianceNoise2013,
  title = {Attention-{{Induced Variance}} and {{Noise Correlation Reduction}} in {{Macaque V1 Is Mediated}} by {{NMDA Receptors}}},
  author = {Herrero, Jose L. and Gieselmann, Marc A. and Sanayei, Mehdi and Thiele, Alexander},
  date = {2013-05-22},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {78},
  number = {4},
  pages = {729--739},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.03.029},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627313002766},
  urldate = {2023-06-08},
  abstract = {Attention improves perception by affecting different aspects of the neuronal code. It enhances firing rates, it reduces firing rate variability and noise correlations of neurons, and it alters the strength of oscillatory activity. Attention-induced rate enhancement in striate cortex requires cholinergic mechanisms. The neuropharmacological mechanisms responsible for attention-induced variance and noise correlation reduction or those supporting changes in oscillatory activity are unknown. We show that ionotropic glutamatergic receptor activation is required for attention-induced rate variance, noise correlation, and LFP gamma power reduction in macaque V1, but not for attention-induced rate modulations. NMDA receptors mediate attention-induced variance reduction and attention-induced noise correlation reduction. Our results demonstrate that attention improves sensory processing by a variety of mechanisms that are dissociable at the receptor level.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A9XZJ28I\\Herrero et al. - 2013 - Attention-Induced Variance and Noise Correlation R.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FJEDMB3H\\S0896627313002766.html}
}

@article{hillPrimaryMotorCortex2011,
  title = {Primary {{Motor Cortex Reports Efferent Control}} of {{Vibrissa Motion}} on {{Multiple Timescales}}},
  author = {Hill, Daniel N. and Curtis, John C. and Moore, Jeffrey D. and Kleinfeld, David},
  date = {2011-10-20},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {72},
  number = {2},
  eprint = {22017992},
  eprinttype = {pmid},
  pages = {344--356},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2011.09.020},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(11)00871-3},
  urldate = {2023-04-12},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\934WZ58R\Hill et al. - 2011 - Primary Motor Cortex Reports Efferent Control of V.pdf}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018,
  title = {✅ {{Optimization}} by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.},
  keywords = {Avalanche,Optimization,Scaling Laws,Self-Organized Criticaility}
}

@article{hoffmannOptimizationSelfOrganizedCriticality2018a,
  title = {Optimization by {{Self-Organized Criticality}}},
  author = {Hoffmann, Heiko and Payton, David W.},
  date = {2018-02-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {2358},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-20275-7},
  url = {https://doi.org/10.1038/s41598-018-20275-7},
  abstract = {Self-organized criticality (SOC) is a phenomenon observed in certain complex systems of multiple interacting components, e.g., neural networks, forest fires, and power grids, that produce power-law distributed avalanche sizes. Here, we report the surprising result that the avalanches from an SOC process can be used to solve non-convex optimization problems. To generate avalanches, we use the Abelian sandpile model on a graph that mirrors the graph of the optimization problem. For optimization, we map the avalanche areas onto search patterns for optimization, while the SOC process receives no feedback from the optimization itself. The resulting method can be applied without parameter tuning to a wide range of optimization problems, as demonstrated on three problems: finding the ground-state of an Ising spin glass, graph coloring, and image segmentation. We find that SOC search is more efficient compared to other random search methods, including simulated annealing, and unlike annealing, it is parameter free, thereby eliminating the time-consuming requirement to tune an annealing temperature schedule.}
}

@article{holovatchComplexSystemsPhysics2017,
  title = {Complex Systems: Physics beyond Physics},
  shorttitle = {Complex Systems},
  author = {Holovatch, Yurij and Kenna, Ralph and Thurner, Stefan},
  date = {2017-02},
  journaltitle = {European Journal of Physics},
  shortjournal = {Eur. J. Phys.},
  volume = {38},
  number = {2},
  pages = {023002},
  publisher = {IOP Publishing},
  issn = {0143-0807},
  doi = {10.1088/1361-6404/aa5a87},
  url = {https://doi.org/10.1088/1361-6404/aa5a87},
  urldate = {2022-10-01},
  abstract = {Complex systems are characterised by specific time-dependent interactions among their many constituents. As a consequence they often manifest rich, non-trivial and unexpected behaviour. Examples arise both in the physical and non-physical worlds. The study of complex systems forms a new interdisciplinary research area that cuts across physics, biology, ecology, economics, sociology, and the humanities. In this paper we review the essence of complex systems from a physicists' point of view, and try to clarify what makes them conceptually different from systems that are traditionally studied in physics. Our goal is to demonstrate how the dynamics of such systems may be conceptualised in quantitative and predictive terms by extending notions from statistical physics and how they can often be captured in a framework of co-evolving multiplex network structures. We mention three areas of complex-systems science that are currently studied extensively, the science of cities, dynamics of societies, and the representation of texts as evolutionary objects. We discuss why these areas form complex systems in the above sense. We argue that there exists plenty of new ground for physicists to explore and that methodical and conceptual progress is needed most.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7MR562TG\Holovatch et al. - 2017 - Complex systems physics beyond physics.pdf}
}

@article{holovatchComplexSystemsPhysics2017a,
  title = {✅ {{Complex}} Systems: Physics beyond Physics},
  shorttitle = {Complex Systems},
  author = {Holovatch, Yurij and Kenna, Ralph and Thurner, Stefan},
  date = {2017-03-01},
  journaltitle = {European Journal of Physics},
  shortjournal = {Eur. J. Phys.},
  volume = {38},
  number = {2},
  eprint = {1610.01002},
  eprinttype = {arXiv},
  eprintclass = {physics},
  pages = {023002},
  issn = {0143-0807, 1361-6404},
  doi = {10.1088/1361-6404/aa5a87},
  url = {http://arxiv.org/abs/1610.01002},
  urldate = {2022-10-03},
  abstract = {Complex systems are characterized by specific time-dependent interactions among their many constituents. As a consequence they often manifest rich, non-trivial and unexpected behavior. Examples arise both in the physical and non-physical world. The study of complex systems forms a new interdisciplinary research area that cuts across physics, biology, ecology, economics, sociology, and the humanities. In this paper we review the essence of complex systems from a physicist's point of view, and try to clarify what makes them conceptually different from systems that are traditionally studied in physics. Our goal is to demonstrate how the dynamics of such systems may be conceptualized in quantitative and predictive terms by extending notions from statistical physics and how they can often be captured in a framework of co-evolving multiplex network structures. We mention three areas of complex-systems science that are currently studied extensively, the science of cities, dynamics of societies, and the representation of texts as evolutionary objects. We discuss why these areas form complex systems in the above sense. We argue that there exists plenty of new land for physicists to explore and that methodical and conceptual progress is needed most.},
  keywords = {Physics - Physics and Society},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E8GX9WPR\\Holovatch et al. - 2017 - Complex systems physics beyond physics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PR853AXB\\1610.html}
}

@article{homannNovelStimuliEvoke2022,
  title = {Novel Stimuli Evoke Excess Activity in the Mouse Primary Visual Cortex},
  author = {Homann, Jan and Koay, Sue Ann and Chen, Kevin S. and Tank, David W. and Berry, Michael J.},
  date = {2022-02},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {5},
  pages = {e2108882119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2108882119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2108882119},
  urldate = {2023-01-09},
  abstract = {To explore how neural circuits represent novel versus familiar inputs, we presented mice with repeated sets of images with novel images sparsely substituted. Using two-photon calcium imaging to record from layer 2/3 neurons in the mouse primary visual cortex, we found that novel images evoked excess activity in the majority of neurons. This novelty response rapidly emerged, arising with a time constant of 2.6 ± 0.9 s. When a new image set was repeatedly presented, a majority of neurons had similarly elevated activity for the first few presentations, which decayed to steady state with a time constant of 1.4 ± 0.4 s. When we increased the number of images in the set, the novelty response’s amplitude decreased, defining a capacity to store ∼15 familiar images under our conditions. These results could be explained quantitatively using an adaptive subunit model in which presynaptic neurons have individual tuning and gain control. This result shows that local neural circuits can create different representations for novel versus familiar inputs using generic, widely available mechanisms.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TCQIV63H\Homann et al. - 2022 - Novel stimuli evoke excess activity in the mouse p.pdf}
}

@article{hopfieldNeuralNetworksPhysical1982,
  title = {Neural Networks and Physical Systems with Emergent Collective Computational Abilities.},
  author = {Hopfield, J J},
  date = {1982-04},
  journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
  shortjournal = {Proc Natl Acad Sci U S A},
  volume = {79},
  number = {8},
  eprint = {6953413},
  eprinttype = {pmid},
  pages = {2554--2558},
  issn = {0027-8424},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238/},
  urldate = {2022-10-04},
  abstract = {Computational properties of use of biological organisms or to the construction of computers can emerge as collective properties of systems having a large number of simple equivalent components (or neurons). The physical meaning of content-addressable memory is described by an appropriate phase space flow of the state of a system. A model of such a system is given, based on aspects of neurobiology but readily adapted to integrated circuits. The collective properties of this model produce a content-addressable memory which correctly yields an entire memory from any subpart of sufficient size. The algorithm for the time evolution of the state of the system is based on asynchronous parallel processing. Additional emergent collective properties include some capacity for generalization, familiarity recognition, categorization, error correction, and time sequence retention. The collective properties are only weakly sensitive to details of the modeling or the failure of individual devices.},
  pmcid = {PMC346238},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4ISCMBCZ\Hopfield - 1982 - Neural networks and physical systems with emergent.pdf}
}

@article{hosoyaDynamicPredictiveCoding2005,
  title = {Dynamic Predictive Coding by the Retina},
  author = {Hosoya, Toshihiko and Baccus, Stephen A. and Meister, Markus},
  date = {2005-07},
  journaltitle = {Nature},
  volume = {436},
  number = {7047},
  pages = {71--77},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature03689},
  url = {https://www.nature.com/articles/nature03689},
  urldate = {2023-03-30},
  abstract = {Retinal ganglion cells convey the visual image from the eye to the brain. They generally encode local differences in space and changes in time rather than the raw image intensity. This can be seen as a strategy of predictive coding, adapted through evolution to the average image statistics of the natural environment. Yet animals encounter many environments with visual statistics different from the average scene. Here we show that when this happens, the retina adjusts its processing dynamically. The spatio-temporal receptive fields of retinal ganglion cells change after a few seconds in a new environment. The changes are adaptive, in that the new receptive field improves predictive coding under the new image statistics. We show that a network model with plastic synapses can account for the large variety of observed adaptations.},
  issue = {7047},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\697UZT2C\Hosoya et al. - 2005 - Dynamic predictive coding by the retina.pdf}
}

@online{hosseiniHierarchicalPredictiveCoding2020,
  title = {Hierarchical {{Predictive Coding Models}} in a {{Deep-Learning Framework}}},
  author = {Hosseini, Matin and Maida, Anthony},
  date = {2020-09-22},
  eprint = {2005.03230},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2005.03230},
  urldate = {2023-03-30},
  abstract = {Bayesian predictive coding is a putative neuromorphic method for acquiring higher-level neural representations to account for sensory input. Although originating in the neuroscience community, there are also efforts in the machine learning community to study these models. This paper reviews some of the more well known models. Our review analyzes module connectivity and patterns of information transfer, seeking to find general principles used across the models. We also survey some recent attempts to cast these models within a deep learning framework. A defining feature of Bayesian predictive coding is that it uses top-down, reconstructive mechanisms to predict incoming sensory inputs or their lower-level representations. Discrepancies between the predicted and the actual inputs, known as prediction errors, then give rise to future learning that refines and improves the predictive accuracy of learned higher-level representations. Predictive coding models intended to describe computations in the neocortex emerged prior to the development of deep learning and used a communication structure between modules that we name the Rao-Ballard protocol. This protocol was derived from a Bayesian generative model with some rather strong statistical assumptions. The RB protocol provides a rubric to assess the fidelity of deep learning models that claim to implement predictive coding.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QZKWCHSA\\Hosseini and Maida - 2020 - Hierarchical Predictive Coding Models in a Deep-Le.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LCYM6RGF\\2005.html}
}

@article{huangAttentionReducesBurstiness2021,
  title = {Attention Reduces the Burstiness of {{V1}} Neurons Involved in Attended Target Enhancement},
  author = {Huang, Dan and Xiong, Xingzhong and Chen, Yao},
  date = {2021},
  journaltitle = {European Journal of Neuroscience},
  volume = {54},
  number = {2},
  pages = {4565--4580},
  issn = {1460-9568},
  doi = {10.1111/ejn.15263},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ejn.15263},
  urldate = {2023-01-16},
  abstract = {Attention-dependent reduction in the tendency for neurons to fire bursts (burstiness) is widely observed in the visual cortex. However, the underlying mechanism and the functional role of this phenomenon remain unclear. We recorded well-isolated single-unit activities in primary visual cortex (V1) from two primates (Macaca mulatta) while they performed a detection task engaging spatial attention with two levels of difficulty (hard/easy). We found that attention modulated burstiness of V1 neurons in a cell-type specific manner. For neurons whose net response enhanced with the increase of task difficulty (difficulty-enhanced neuron), representing their involvement in boosting the signal of the attended stimulus, attention led to a reduction in burstiness during hard task but not during easy task. In contrast, regardless of the level of task difficulty, attention-dependent reduction in burstiness was not observed in neurons that showed a net suppression in firing rate with the increase of task difficulty (difficulty-suppressed neuron), indicating their commitment in filtering out the interference of distractor. This differentiation in the effects of attentional modulation on burstiness among the cells with distinct functional roles in attention suggests that the reduction in burstiness by attention is linked to target enhancement and is not associated with distractor suppression.},
  langid = {english},
  keywords = {attention,burstiness reduction,target enhancement,V1},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8YL4K5HF\\Huang et al. - 2021 - Attention reduces the burstiness of V1 neurons inv.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LDX74W6E\\ejn.html}
}

@article{huangCircuitModelsLowDimensional2019,
  title = {✅ {{Circuit Models}} of {{Low-Dimensional Shared Variability}} in {{Cortical Networks}}},
  author = {Huang, Chengcheng and Ruff, Douglas A. and Pyle, Ryan and Rosenbaum, Robert and Cohen, Marlene R. and Doiron, Brent},
  date = {2019-01-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {101},
  number = {2},
  eprint = {30581012},
  eprinttype = {pmid},
  pages = {337-348.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.11.034},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(18)31043-2},
  urldate = {2022-12-19},
  langid = {english},
  keywords = {attention,cortical model,excitatory/inhibitory balance,low dimensional,neuronal variability,noise correlations},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T974QZMN\Huang et al. - 2019 - Circuit Models of Low-Dimensional Shared Variabili.pdf}
}

@article{huangCircuitModelsLowDimensional2019a,
  title = {Circuit {{Models}} of {{Low-Dimensional Shared Variability}} in {{Cortical Networks}}},
  author = {Huang, Chengcheng and Ruff, Douglas A. and Pyle, Ryan and Rosenbaum, Robert and Cohen, Marlene R. and Doiron, Brent},
  date = {2019-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {101},
  number = {2},
  pages = {337-348.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.11.034},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318310432},
  urldate = {2023-11-22},
  abstract = {Trial-to-trial variability is a reflection of the circuitry and cellular physiology that make up a neuronal network. A pervasive yet puzzling feature of cortical circuits is that despite their complex wiring, population-wide shared spiking variability is low dimensional. Previous model cortical networks cannot explain this global variability, and rather assume it is from external sources. We show that if the spatial and temporal scales of inhibitory coupling match known physiology, networks of model spiking neurons internally generate low-dimensional shared variability that captures population activity recorded in vivo. Shifting spatial attention into the receptive field of visual neurons has been shown to differentially modulate shared variability within and between brain areas. A top-down modulation of inhibitory neurons in our network provides a parsimonious mechanism for this attentional modulation. Our work provides a critical link between observed cortical circuit structure and realistic shared neuronal variability and its modulation.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\C2QVACL4\Huang et al. - 2019 - Circuit Models of Low-Dimensional Shared Variabili.pdf}
}

@article{huangInternallyGeneratedPopulation2022,
  title = {Internally Generated Population Activity in Cortical Networks Hinders Information Transmission},
  author = {Huang, Chengcheng and Pouget, Alexandre and Doiron, Brent},
  date = {2022-06},
  journaltitle = {Science Advances},
  volume = {8},
  number = {22},
  pages = {eabg5244},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/sciadv.abg5244},
  url = {https://www.science.org/doi/full/10.1126/sciadv.abg5244},
  urldate = {2023-03-30},
  abstract = {How neuronal variability affects sensory coding is a central question in systems neuroscience, often with complex and model-dependent answers. Many studies explore population models with a parametric structure for response tuning and variability, preventing an analysis of how synaptic circuitry establishes neural codes. We study stimulus coding in networks of spiking neuron models with spatially ordered excitatory and inhibitory connectivity. The wiring structure is capable of producing rich population-wide shared neuronal variability that agrees with many features of recorded cortical activity. While both the spatial scales of feedforward and recurrent projections strongly affect noise correlations, only recurrent projections, and in particular inhibitory projections, can introduce correlations that limit the stimulus information available to a decoder. Using a spatial neural field model, we relate the recurrent circuit conditions for information limiting noise correlations to how recurrent excitation and inhibition can form spatiotemporal patterns of population-wide activity.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DZSE6ULR\Huang et al. - 2022 - Internally generated population activity in cortic.pdf}
}

@article{huangPredictiveCoding2011,
  title = {Predictive Coding},
  author = {Huang, Yanping and Rao, Rajesh P. N.},
  date = {2011},
  journaltitle = {WIREs Cognitive Science},
  volume = {2},
  number = {5},
  pages = {580--593},
  issn = {1939-5086},
  doi = {10.1002/wcs.142},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.142},
  urldate = {2023-03-30},
  abstract = {Predictive coding is a unifying framework for understanding redundancy reduction and efficient coding in the nervous system. By transmitting only the unpredicted portions of an incoming sensory signal, predictive coding allows the nervous system to reduce redundancy and make full use of the limited dynamic range of neurons. Starting with the hypothesis of efficient coding as a design principle in the sensory system, predictive coding provides a functional explanation for a range of neural responses and many aspects of brain organization. The lateral and temporal antagonism in receptive fields in the retina and lateral geniculate nucleus occur naturally as a consequence of predictive coding of natural images. In the higher visual system, predictive coding provides an explanation for oriented receptive fields and contextual effects as well as the hierarchical reciprocally connected organization of the cortex. Predictive coding has also been found to be consistent with a variety of neurophysiological and psychophysical data obtained from different areas of the brain. WIREs Cogni Sci 2011 2 580–593 DOI: 10.1002/wcs.142 This article is categorized under: Computer Science {$>$} Neural Networks},
  langid = {english}
}

@article{hubatzSpatiotemporalPropertiesWhiskerevoked2020,
  title = {Spatiotemporal Properties of Whisker-Evoked Tactile Responses in the Mouse Secondary Somatosensory Cortex},
  author = {Hubatz, Sophie and Hucher, Guillaume and Shulz, Daniel E. and Férézou, Isabelle},
  date = {2020-01-21},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {10},
  number = {1},
  pages = {763},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-57684-6},
  url = {https://www.nature.com/articles/s41598-020-57684-6},
  urldate = {2023-04-12},
  abstract = {The representation of rodents’ mystacial vibrissae within the primary somatosensory (S1) cortex has become a major model for studying the cortical processing of tactile sensory information. However, upon vibrissal stimulation, tactile information first reaches S1 but also, almost simultaneously, the secondary somatosensory cortex (S2). To further understand the role of S2 in the processing of whisker inputs, it is essential to characterize the spatio-temporal properties of whisker-evoked response dynamics in this area. Here we describe the topography of the whiskers representation in the mouse S2 with voltage sensitive dye imaging. Analysis of the spatial properties of the early S2 responses induced by stimulating individually 22 to 24 whiskers revealed that they are spatially ordered in a mirror symmetric map with respect to S1 responses. Evoked signals in S2 and S1 are of similar amplitude and closely correlated at the single trial level. They confirm a short delay (\textasciitilde 3\,ms) between S1 and S2 early activation. In both S1 and S2 caudo-dorsal whiskers induce stronger responses than rostro-ventral ones. Finally, analysis of early C2-evoked responses indicates a faster activation of neighboring whisker representations in S2 relative to S1, probably due to the reduced size of the whisker map in S2.},
  issue = {1},
  langid = {english},
  keywords = {Cortex,Sensory processing,Whisker system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\H5SI3U3V\Hubatz et al. - 2020 - Spatiotemporal properties of whisker-evoked tactil.pdf}
}

@article{hubenerMouseVisualCortex2003,
  title = {Mouse Visual Cortex},
  author = {Hübener, Mark},
  date = {2003-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {13},
  number = {4},
  pages = {413--420},
  issn = {0959-4388},
  doi = {10.1016/S0959-4388(03)00102-8},
  url = {http://www.sciencedirect.com/science/article/pii/S0959438803001028},
  urldate = {2020-10-15},
  abstract = {Neurons in mouse visual cortex have diverse receptive field properties and they respond selectively to specific features of visual stimuli. Owing to the lateral position of the eyes, only about a third of the visual cortex receives input from both eyes, but many cells in this region are binocular. Similar to higher mammals, closing one eye during a critical period shifts the responses of cells, such that they are better driven by the non-deprived eye. In this review I illustrate how the combination of transgenic mouse technology with single cell recording and modern imaging techniques might lead to a further understanding of the mechanisms that underlie the development, plasticity, and function of the mammalian visual cortex.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BAN77Y2N\\Hübener - 2003 - Mouse visual cortex.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HH6QDPMT\\S0959438803001028.html}
}

@article{hullPredictionSignalsCerebellum2020,
  title = {Prediction Signals in the Cerebellum: {{Beyond}} Supervised Motor Learning},
  shorttitle = {Prediction Signals in the Cerebellum},
  author = {Hull, Court},
  editor = {Ivry, Richard B},
  date = {2020-03-30},
  journaltitle = {eLife},
  volume = {9},
  pages = {e54073},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.54073},
  url = {https://doi.org/10.7554/eLife.54073},
  urldate = {2023-04-22},
  abstract = {While classical views of cerebellar learning have suggested that this structure predominantly operates according to an error-based supervised learning rule to refine movements, emerging evidence suggests that the cerebellum may also harness a wider range of learning rules to contribute to a variety of behaviors, including cognitive processes. Together, such evidence points to a broad role for cerebellar circuits in generating and testing predictions about movement, reward, and other non-motor operations. However, this expanded view of cerebellar processing also raises many new questions about how such apparent diversity of function arises from a structure with striking homogeneity. Hence, this review will highlight both current evidence for predictive cerebellar circuit function that extends beyond the classical view of error-driven supervised learning, as well as open questions that must be addressed to unify our understanding cerebellar circuit function.},
  keywords = {cerebellum,motor learning,neural circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WXGTTJV8\Hull - 2020 - Prediction signals in the cerebellum Beyond super.pdf}
}

@article{huSpatialAttentionModulates2022,
  title = {Spatial {{Attention Modulates Spike Count Correlations}} and {{Granger Causality}} in the {{Primary Visual Cortex}}},
  author = {Hu, Qiyi and Zheng, Zhiyan and Sui, Xiaohong and Li, Liming and Chai, Xinyu and Chen, Yao},
  date = {2022},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {16},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2022.838049},
  urldate = {2023-01-16},
  abstract = {The influence of spatial attention on neural interactions has been revealed even in early visual information processing stages. It resolves the process of competing for sensory information about objects perceived as targets and distractors. However, the attentional modulation of the interaction between pairs of neurons with non-overlapping receptive fields (RFs) is not well known. Here, we investigated the activity of anatomically distant neurons in two behaving monkeys’ primary visual cortex (V1), when they performed a spatial attention task detecting color change. We compared attentional modulation from the perspective of spike count correlations and Granger causality among simple and complex cells. An attention-related increase in spike count correlations and a decrease in Granger causality were found. The results showed that spatial attention significantly influenced only the interactions between rather than within simple and complex cells. Furthermore, we found that the attentional modulation of neuronal interactions changed with neuronal pairs’ preferred directions differences. Thus, we found that spatial attention increased the functional communications and competing connectivities when attending to the neurons’ RFs, which impacts the interactions only between simple and complex cells. Our findings enrich the model of simple and complex cells and further understand the way that attention influences the neurons’ activities.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZRZUH2X8\Hu et al. - 2022 - Spatial Attention Modulates Spike Count Correlatio.pdf}
}

@online{IdentificationMinimalNeuronal,
  title = {Identification of {{Minimal Neuronal Networks Involved}} in {{Flexor-Extensor Alternation}} in the {{Mammalian Spinal Cord}} | {{Elsevier Enhanced Reader}}},
  doi = {10.1016/j.neuron.2011.07.011},
  url = {https://reader.elsevier.com/reader/sd/pii/S0896627311006088?token=EFB8507C61FD4CEDFE6EC5A661668EEB75E3BB8F203F800196FA1F63BE6C5ECDB6BAEC52416E369ED41B06FC400D0CD3&originRegion=us-east-1&originCreation=20230321202417},
  urldate = {2023-03-21},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8XEQX5MP\Identification of Minimal Neuronal Networks Involv.pdf}
}

@article{inagakiSeparateOscillatingCell2007,
  title = {Separate Oscillating Cell Groups in Mouse Suprachiasmatic Nucleus Couple Photoperiodically to the Onset and End of Daily Activity},
  author = {Inagaki, Natsuko and Honma, Sato and Ono, Daisuke and Tanahashi, Yusuke and Honma, Ken-ichi},
  date = {2007-05},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {104},
  number = {18},
  pages = {7664--7669},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0607713104},
  url = {https://www.pnas.org/doi/10.1073/pnas.0607713104},
  urldate = {2023-02-22},
  abstract = {The pattern of circadian behavioral rhythms is photoperiod-dependent, highlighted by the conservation of a phase relation between the behavioral rhythm and photoperiod. A model of two separate, but mutually coupled, circadian oscillators has been proposed to explain photoperiodic responses of behavioral rhythm in nocturnal rodents: an evening oscillator, which drives the activity onset and entrains to dusk, and a morning oscillator, which drives the end of activity and entrains to dawn. Continuous measurement of circadian rhythms in clock gene Per1 expression by a bioluminescence reporter enabled us to identify the separate oscillating cell groups in the mouse suprachiasmatic nucleus (SCN), which composed circadian oscillations of different phases and responded to photoperiods differentially. The circadian oscillation in the posterior SCN was phase-locked to the end of activity under three photoperiods examined. On the other hand, the oscillation in the anterior SCN was phase-locked to the onset of activity but showed a bimodal pattern under a long photoperiod [light–dark cycle (LD)18:6]. The bimodality in the anterior SCN reflected two circadian oscillatory cell groups of early and late phases. The anterior oscillation was unimodal under intermediate (LD12:12) and short (LD6:18) photoperiods, which was always phase-lagged behind the posterior oscillation when the late phase in LD18:6 was taken. The phase difference was largest in LD18:6 and smallest in LD6:18. These findings indicate that three oscillating cell groups in the SCN constitute regionally specific circadian oscillations, and at least two of them are involved in photoperiodic response of behavioral rhythm.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3JSJX4U2\Inagaki et al. - 2007 - Separate oscillating cell groups in mouse suprachi.pdf}
}

@article{indicDesignPrinciplesPhasesplitting2008,
  title = {Design Principles for Phase-Splitting Behaviour of Coupled Cellular Oscillators: Clues from Hamsters with ‘Split’ Circadian Rhythms},
  shorttitle = {Design Principles for Phase-Splitting Behaviour of Coupled Cellular Oscillators},
  author = {Indic, Premananda and Schwartz, William J and Paydarfar, David},
  date = {2008-08-06},
  journaltitle = {Journal of the Royal Society Interface},
  shortjournal = {J R Soc Interface},
  volume = {5},
  number = {25},
  eprint = {18077247},
  eprinttype = {pmid},
  pages = {873--883},
  issn = {1742-5689},
  doi = {10.1098/rsif.2007.1248},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2607461/},
  urldate = {2023-02-22},
  abstract = {Nonlinear interactions among coupled cellular oscillators are likely to underlie a variety of complex rhythmic behaviours. Here we consider the case of one such behaviour, a doubling of rhythm frequency caused by the spontaneous splitting of a population of synchronized oscillators into two subgroups each oscillating in anti-phase (phase-splitting). An example of biological phase-splitting is the frequency doubling of the circadian locomotor rhythm in hamsters housed in constant light, in which the pacemaker in the suprachiasmatic nucleus (SCN) is reconfigured with its left and right halves oscillating in anti-phase. We apply the theory of coupled phase oscillators to show that stable phase-splitting requires the presence of negative coupling terms, through delayed and/or inhibitory interactions. We also find that the inclusion of real biological constraints (that the SCN contains a finite number of non-identical noisy oscillators) implies the existence of an underlying non-uniform network architecture, in which the population of oscillators must interact through at least two types of connections. We propose that a key design principle for the frequency doubling of a population of biological oscillators is inhomogeneity of oscillator coupling.},
  pmcid = {PMC2607461},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\IHJ64U7K\Indic et al. - 2008 - Design principles for phase-splitting behaviour of.pdf}
}

@article{indicModelingBehaviorCoupled2007,
  title = {Modeling the {{Behavior}} of {{Coupled Cellular Circadian Oscillators}} in the {{Suprachiasmatic Nucleus}}},
  author = {Indic, Premananda and Schwartz, William J. and Herzog, Erik D. and Foley, Nicholas C. and Antle, Michael C.},
  date = {2007-06-01},
  journaltitle = {Journal of Biological Rhythms},
  shortjournal = {J Biol Rhythms},
  volume = {22},
  number = {3},
  pages = {211--219},
  publisher = {SAGE Publications Inc},
  issn = {0748-7304},
  doi = {10.1177/0748730407301238},
  url = {https://doi.org/10.1177/0748730407301238},
  urldate = {2023-02-17},
  abstract = {The suprachiasmatic nucleus (SCN) in the hypothalamus is the site of the master circadian clock in mammals, a complex tissue composed of multiple, coupled, single-cell circadian oscillators. Mathematical modeling is now providing insights on how individual SCN cells might interact and assemble to create an integrated pacemaker that governs the circadian behavior of whole animals. In this article, we will discuss the neurobiological constraints for modeling SCN behavior, system precision, implications of cellular heterogeneity, and analysis of heterogeneously coupled oscillator networks. Mathematical approaches will be critical for better understanding intercellular interactions within the SCN.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SY8RNX8A\Indic et al. - 2007 - Modeling the Behavior of Coupled Cellular Circadia.pdf}
}

@online{InterplayGraphTopology,
  title = {Interplay between {{Graph Topology}} and {{Correlations}} of {{Third Order}} in {{Spiking Neuronal Networks}} | {{PLOS Computational Biology}}},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004963},
  urldate = {2022-10-06},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WULVBSIY\article.html}
}

@online{islahLearningCombineTopdown2023,
  title = {Learning to Combine Top-down Context and Feed-Forward Representations under Ambiguity with Apical and Basal Dendrites},
  author = {Islah, Nizar and Etter, Guillaume and Tugsbayar, Mashbayar and Gurbuz, Tugce and Richards, Blake and Muller, Eilif},
  date = {2023-12-09},
  eprint = {2312.05484},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  doi = {10.48550/arXiv.2312.05484},
  url = {http://arxiv.org/abs/2312.05484},
  urldate = {2024-02-13},
  abstract = {One of the most striking features of neocortical anatomy is the presence of extensive top-down projections into primary sensory areas. Notably, many of these top-down projections impinge on the distal apical dendrites of pyramidal neurons, where they exert a modulatory effect, altering the gain of responses. It is thought that these top-down projections carry contextual information that can help animals to resolve ambiguities in sensory data. However, it has yet to be demonstrated how such modulatory connections to the distal apical dendrites can serve this computational function. Here, we develop a computational model of pyramidal cells that integrates contextual information from top-down projections to apical compartments with sensory representations driven by bottom-up projections to basal compartments. When input stimuli are ambiguous and relevant contextual information is available, the apical feedback modulates the basal signals to recover unambiguous sensory representations. Importantly, when stimuli are unambiguous, contextual information which is irrelevant or opposes sensory evidence is appropriately ignored by the model. By generalizing the task to temporal sequences, we further show that our model can learn to integrate contextual information across time. Using layer-wise relevance propagation, we extract the importance of individual neurons to the prediction of each category, revealing that neurons that are most relevant for the overlap of categories receive the largest magnitude of top-down signals, and are necessary for solving the task. This work thus provides a proof-of-concept demonstrating how the top-down modulatory inputs to apical dendrites in sensory regions could be used by the cortex to handle the ambiguities that animals encounter in the real world.},
  pubstate = {prepublished},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C2I9YR48\\Islah et al. - 2023 - Learning to combine top-down context and feed-forw.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8CP9N2K4\\2312.html}
}

@article{isomuraMulticontextBlindSource2019,
  title = {Multi-Context Blind Source Separation by Error-Gated {{Hebbian}} Rule},
  author = {Isomura, Takuya and Toyoizumi, Taro},
  date = {2019-05-09},
  journaltitle = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {7127},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-43423-z},
  url = {https://www.nature.com/articles/s41598-019-43423-z},
  urldate = {2020-10-21},
  abstract = {Animals need to adjust their inferences according to the context they are in. This is required for the multi-context blind source separation (BSS) task, where an agent needs to infer hidden sources from their context-dependent mixtures. The agent is expected to invert this mixing process for all contexts. Here, we show that a neural network that implements the error-gated Hebbian rule (EGHR) with sufficiently redundant sensory inputs can successfully learn this task. After training, the network can perform the multi-context BSS without further updating synapses, by retaining memories of all experienced contexts. This demonstrates an attractive use of the EGHR for dimensionality reduction by extracting low-dimensional sources across contexts. Finally, if there is a common feature shared across contexts, the EGHR can extract it and generalize the task to even inexperienced contexts. The results highlight the utility of the EGHR as a model for perceptual adaptation in animals.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UB5RABYB\\Isomura and Toyoizumi - 2019 - Multi-context blind source separation by error-gat.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GEK5TACD\\s41598-019-43423-z.html}
}

@article{iyerAvoidingCatastropheActive2022,
  title = {Avoiding {{Catastrophe}}: {{Active Dendrites Enable Multi-Task Learning}} in {{Dynamic Environments}}},
  shorttitle = {Avoiding {{Catastrophe}}},
  author = {Iyer, Abhiram and Grewal, Karan and Velu, Akash and Souza, Lucas Oliveira and Forest, Jeremy and Ahmad, Subutai},
  date = {2022},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {16},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2022.846219},
  urldate = {2022-09-02},
  abstract = {A key challenge for AI is to build embodied systems that operate in dynamically changing environments. Such systems must adapt to changing task contexts and learn continuously. Although standard deep learning systems achieve state of the art results on static benchmarks, they often struggle in dynamic scenarios. In these settings, error signals from multiple contexts can interfere with one another, ultimately leading to a phenomenon known as catastrophic forgetting. In this article we investigate biologically inspired architectures as solutions to these problems. Specifically, we show that the biophysical properties of dendrites and local inhibitory systems enable networks to dynamically restrict and route information in a context-specific manner. Our key contributions are as follows: first, we propose a novel artificial neural network architecture that incorporates active dendrites and sparse representations into the standard deep learning framework. Next, we study the performance of this architecture on two separate benchmarks requiring task-based adaptation: Meta-World, a multi-task reinforcement learning environment where a robotic agent must learn to solve a variety of manipulation tasks simultaneously; and a continual learning benchmark in which the model's prediction task changes throughout training. Analysis on both benchmarks demonstrates the emergence of overlapping but distinct and sparse subnetworks, allowing the system to fluidly learn multiple tasks with minimal forgetting. Our neural implementation marks the first time a single architecture has achieved competitive results in both multi-task and continual learning settings. Our research sheds light on how biological properties of neurons can inform deep learning systems to address dynamic scenarios that are typically impossible for traditional ANNs to solve.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DMC2I9KH\Iyer et al. - 2022 - Avoiding Catastrophe Active Dendrites Enable Mult.pdf}
}

@article{iyerAvoidingCatastropheActive2022a,
  title = {Avoiding {{Catastrophe}}: {{Active Dendrites Enable Multi-Task Learning}} in {{Dynamic Environments}}},
  shorttitle = {Avoiding {{Catastrophe}}},
  author = {Iyer, Abhiram and Grewal, Karan and Velu, Akash and Souza, Lucas Oliveira and Forest, Jeremy and Ahmad, Subutai},
  date = {2022},
  journaltitle = {Frontiers in Neurorobotics},
  volume = {16},
  issn = {1662-5218},
  url = {https://www.frontiersin.org/articles/10.3389/fnbot.2022.846219},
  urldate = {2023-03-22},
  abstract = {A key challenge for AI is to build embodied systems that operate in dynamically changing environments. Such systems must adapt to changing task contexts and learn continuously. Although standard deep learning systems achieve state of the art results on static benchmarks, they often struggle in dynamic scenarios. In these settings, error signals from multiple contexts can interfere with one another, ultimately leading to a phenomenon known as catastrophic forgetting. In this article we investigate biologically inspired architectures as solutions to these problems. Specifically, we show that the biophysical properties of dendrites and local inhibitory systems enable networks to dynamically restrict and route information in a context-specific manner. Our key contributions are as follows: first, we propose a novel artificial neural network architecture that incorporates active dendrites and sparse representations into the standard deep learning framework. Next, we study the performance of this architecture on two separate benchmarks requiring task-based adaptation: Meta-World, a multi-task reinforcement learning environment where a robotic agent must learn to solve a variety of manipulation tasks simultaneously; and a continual learning benchmark in which the model's prediction task changes throughout training. Analysis on both benchmarks demonstrates the emergence of overlapping but distinct and sparse subnetworks, allowing the system to fluidly learn multiple tasks with minimal forgetting. Our neural implementation marks the first time a single architecture has achieved competitive results in both multi-task and continual learning settings. Our research sheds light on how biological properties of neurons can inform deep learning systems to address dynamic scenarios that are typically impossible for traditional ANNs to solve.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\23I3HJEZ\Iyer et al. - 2022 - Avoiding Catastrophe Active Dendrites Enable Mult.pdf}
}

@article{jacobsonSubthresholdVoltageNoise2005,
  title = {Subthreshold Voltage Noise of Rat Neocortical Pyramidal Neurones},
  author = {Jacobson, Gilad A and Diba, Kamran and Yaron-Jakoubovitch, Anat and Oz, Yasmin and Koch, Christof and Segev, Idan and Yarom, Yosef},
  date = {2005-04-01},
  journaltitle = {The Journal of Physiology},
  shortjournal = {J Physiol},
  volume = {564},
  eprint = {15695244},
  eprinttype = {pmid},
  pages = {145--160},
  issn = {0022-3751},
  doi = {10.1113/jphysiol.2004.080903},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1456039/},
  urldate = {2023-06-06},
  abstract = {Neurones are noisy elements. Noise arises from both intrinsic and extrinsic sources, and manifests itself as fluctuations in the membrane potential. These fluctuations limit the accuracy of a neurone's output but have also been suggested to play a computational role. We present a detailed study of the amplitude and spectrum of voltage noise recorded at the soma of layer IV–V pyramidal neurones in slices taken from rat neocortex. The dependence of the noise on holding potential, synaptic activity and Na+ conductance is systematically analysed. We demonstrate that voltage noise increases non-linearly as the cell depolarizes (from a standard deviation (s.d.) of 0.19 mV at −75 mV to an s.d. of 0.54 mV at −55 mV). The increase in voltage noise is accompanied by an increase in the cell impedance, due to voltage dependence of Na+ conductance. The impedance increase accounts for the majority (70\%) of the voltage noise increase. The increase in voltage noise and impedance is restricted to the low-frequency range (0.2–2 Hz). At the high frequency range (5–100 Hz) the voltage noise is dominated by synaptic activity. In our slice preparation, synaptic noise has little effect on the cell impedance. A minimal model reproduces qualitatively these data. Our results imply that ion channel noise contributes significantly to membrane voltage fluctuations at the subthreshold voltage range, and that Na+ conductance plays a key role in determining the amplitude of this noise by acting as a voltage-dependent amplifier of low-frequency transients.},
  issue = {Pt 1},
  pmcid = {PMC1456039},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7WQCTZS2\Jacobson et al. - 2005 - Subthreshold voltage noise of rat neocortical pyra.pdf}
}

@article{jagadeeshLearningIncreasesStimulus2001,
  title = {Learning {{Increases Stimulus Salience}} in {{Anterior Inferior Temporal Cortex}} of the {{Macaque}}},
  author = {Jagadeesh, Bharathi and Chelazzi, Leonardo and Mishkin, Mortimer and Desimone, Robert},
  date = {2001-07-01},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {Journal of Neurophysiology},
  volume = {86},
  number = {1},
  pages = {290--303},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.2001.86.1.290},
  url = {https://www.physiology.org/doi/10.1152/jn.2001.86.1.290},
  urldate = {2023-08-07},
  abstract = {With experience, an object can become behaviorally relevant and thereby quickly attract our interest when presented in a visual scene. A likely site of these learning effects is anterior inferior temporal (aIT) cortex, where neurons are thought to participate in the filtering of irrelevant information out of complex visual displays. We trained monkeys to saccade consistently to one of two pictures in an array, in return for a reward. The array was constructed by pairing two stimuli, one of which elicited a good response from the cell when presented alone (“good” stimulus) and the other of which elicited a poor response (“poor” stimulus). The activity of aIT cells was recorded while monkeys learned to saccade to either the good or poor stimulus in the array. We found that neuronal responses to the array were greater (before the saccade occurred) when training reinforced a saccade to the good stimulus than when training reinforced a saccade to the poor stimulus. This difference was not present on incorrect trials, i.e., when saccades to the incorrect stimulus were made. Thus the difference in activity was correlated with performance. The response difference grew over the course of the recording session, in parallel with the improvement in performance. The response difference was not preceded by a difference in the baseline activity of the cells, unlike what was found in studies of cued visual search and working memory in aIT cortex. Furthermore, we found similar effects in a version of the task in which any of 10 possible pairs of stimuli, prelearned before the recording session, could appear on a given trial, thereby precluding a working memory strategy. The results suggest that increasing the behavioral significance of a stimulus through training alters the neural representation of that stimulus in aIT cortex. As a result, neurons responding to features of the relevant stimulus may suppress neurons responding to features of irrelevant stimuli.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T9FDVL3S\Jagadeesh et al. - 2001 - Learning Increases Stimulus Salience in Anterior I.pdf}
}

@article{jaramilloPhasePrecessionNeural2017,
  title = {✅ {{Phase}} Precession: A Neural Code Underlying Episodic Memory?},
  shorttitle = {Phase Precession},
  author = {Jaramillo, Jorge and Kempter, Richard},
  date = {2017-04-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Neurobiology of {{Learning}} and {{Plasticity}}},
  volume = {43},
  pages = {130--138},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2017.02.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438817300533},
  urldate = {2023-03-26},
  abstract = {In the hippocampal formation, the sequential activation of place-specific cells represents a conceptual model for the spatio-temporal events that assemble episodic memories. The imprinting of behavioral sequences in hippocampal networks might be achieved via spike-timing-dependent plasticity and phase precession of the spiking activity of neurons. It is unclear, however, whether phase precession plays an active role by enabling sequence learning via synaptic plasticity or whether phase precession passively reflects retrieval dynamics. Here we examine these possibilities in the context of potential mechanisms generating phase precession. Knowledge of these mechanisms would allow to selectively alter phase precession and test its role in episodic memory. We finally review the few successful approaches to degrade phase precession and the resulting impact on behavior.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UCQEE534\\Jaramillo and Kempter - 2017 - Phase precession a neural code underlying episodi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CN4GDVJP\\S0959438817300533.html}
}

@article{jarvisNeuronalGainModulability2018,
  title = {Neuronal Gain Modulability Is Determined by Dendritic Morphology: {{A}} Computational Optogenetic Study},
  shorttitle = {Neuronal Gain Modulability Is Determined by Dendritic Morphology},
  author = {Jarvis, Sarah and Nikolic, Konstantin and Schultz, Simon R.},
  date = {2018-03-09},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {14},
  number = {3},
  pages = {e1006027},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006027},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006027},
  urldate = {2022-10-18},
  abstract = {The mechanisms by which the gain of the neuronal input-output function may be modulated have been the subject of much investigation. However, little is known of the role of dendrites in neuronal gain control. New optogenetic experimental paradigms based on spatial profiles or patterns of light stimulation offer the prospect of elucidating many aspects of single cell function, including the role of dendrites in gain control. We thus developed a model to investigate how competing excitatory and inhibitory input within the dendritic arbor alters neuronal gain, incorporating kinetic models of opsins into our modeling to ensure it is experimentally testable. To investigate how different topologies of the neuronal dendritic tree affect the neuron’s input-output characteristics we generate branching geometries which replicate morphological features of most common neurons, but keep the number of branches and overall area of dendrites approximately constant. We found a relationship between a neuron’s gain modulability and its dendritic morphology, with neurons with bipolar dendrites with a moderate degree of branching being most receptive to control of the gain of their input-output relationship. The theory was then tested and confirmed on two examples of realistic neurons: 1) layer V pyramidal cells—confirming their role in neural circuits as a regulator of the gain in the circuit in addition to acting as the primary excitatory neurons, and 2) stellate cells. In addition to providing testable predictions and a novel application of dual-opsins, our model suggests that innervation of all dendritic subdomains is required for full gain modulation, revealing the importance of dendritic targeting in the generation of neuronal gain control and the functions that it subserves. Finally, our study also demonstrates that neurophysiological investigations which use direct current injection into the soma and bypass the dendrites may miss some important neuronal functions, such as gain modulation.},
  langid = {english},
  keywords = {Action potentials,Biophysics,Membrane potential,Neuronal dendrites,Neuronal morphology,Neurons,Optogenetics,Pyramidal cells},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CHUGU4I2\Jarvis et al. - 2018 - Neuronal gain modulability is determined by dendri.pdf}
}

@online{ji-anDeepLearningWeight2024,
  title = {✅ {{Deep Learning}} without {{Weight Symmetry}}},
  author = {Ji-An, Li and Benna, Marcus K.},
  date = {2024-05-30},
  eprint = {2405.20594},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2405.20594},
  urldate = {2024-06-12},
  abstract = {Backpropagation (BP), a foundational algorithm for training artificial neural networks, predominates in contemporary deep learning. Although highly successful, it is often considered biologically implausible. A significant limitation arises from the need for precise symmetry between connections in the backward and forward pathways to backpropagate gradient signals accurately, which is not observed in biological brains. Researchers have proposed several algorithms to alleviate this symmetry constraint, such as feedback alignment and direct feedback alignment. However, their divergence from backpropagation dynamics presents challenges, particularly in deeper networks and convolutional layers. Here we introduce the Product Feedback Alignment (PFA) algorithm. Our findings demonstrate that PFA closely approximates BP and achieves comparable performance in deep convolutional networks while avoiding explicit weight symmetry. Our results offer a novel solution to the longstanding weight symmetry problem, leading to more biologically plausible learning in deep convolutional networks compared to earlier methods.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8IXUNFYB\Ji-An and Benna - 2024 - Deep Learning without Weight Symmetry.pdf}
}

@report{jiaMultiareaFunctionalModules2020,
  type = {preprint},
  title = {Multi-Area Functional Modules Mediate Feedforward and Recurrent Processing in Visual Cortical Hierarchy},
  author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina and Olsen, Shawn R.},
  date = {2020-08-31},
  institution = {Neuroscience},
  doi = {10.1101/2020.08.30.272948},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.08.30.272948},
  urldate = {2020-09-03},
  abstract = {The visual cortex is organized hierarchically, but extensive recurrent pathways make it challenging to decipher the flow of information with single neuron resolution. Here, we characterize spiking interactions in populations of neurons from six interconnected areas along the visual hierarchy in awake mice. We generated multi-area, directed graphs of neuronal communication and uncovered two spatially-distributed functional modules. One module is positioned to transmit feedforward sensory signals along the hierarchy, while the other receives convergent input and engages in recurrent processing. The modules differ in layer and area distributions, convergence and divergence, and population-level temporal dynamics. These results reveal a neuronal-resolution cortical network topology in which distinct processing modules are interlaced across multiple areas of the cortical hierarchy.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BLVG96MG\Jia et al. - 2020 - Multi-area functional modules mediate feedforward .pdf}
}

@article{jiaMultiregionalModulebasedSignal2022,
  title = {Multi-Regional Module-Based Signal Transmission in Mouse Visual Cortex},
  author = {Jia, Xiaoxuan and Siegle, Joshua H. and Durand, Séverine and Heller, Greggory and Ramirez, Tamina K. and Koch, Christof and Olsen, Shawn R.},
  date = {2022-05-04},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {9},
  pages = {1585-1598.e9},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.01.027},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322000848},
  urldate = {2023-01-09},
  abstract = {The visual cortex is hierarchically organized, yet the presence of extensive recurrent and parallel pathways make it challenging to decipher how signals flow between neuronal populations. Here, we tracked the flow of spiking activity recorded from six interconnected levels of the mouse visual hierarchy. By analyzing leading and lagging spike-timing relationships among pairs of simultaneously recorded neurons, we created a cellular-scale directed network graph. Using a module-detection algorithm to cluster neurons based on shared connectivity patterns, we uncovered two multi-regional communication modules distributed across the hierarchy. The direction of signal flow both between and within these modules, differences in layer and area distributions, and distinct temporal dynamics suggest that one module transmits feedforward sensory signals, whereas the other integrates inputs for recurrent processing. These results suggest that multi-regional functional modules may be a fundamental feature of organization beyond cortical areas that supports signal propagation across hierarchical recurrent networks.},
  langid = {english},
  keywords = {feedforward,functional network,modular,mouse,Neuropixels,processing stages,recurrent,visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TPPP436J\Jia et al. - 2022 - Multi-regional module-based signal transmission in.pdf}
}

@online{jiangDynamicPredictiveCoding2022,
  title = {Dynamic {{Predictive Coding}}: {{A New Model}} of {{Hierarchical Sequence Learning}} and {{Prediction}} in the {{Cortex}}},
  shorttitle = {Dynamic {{Predictive Coding}}},
  author = {Jiang, Linxing Preston and Rao, Rajesh P. N.},
  date = {2022-12-18},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.06.23.497415},
  doi = {10.1101/2022.06.23.497415},
  url = {https://www.biorxiv.org/content/10.1101/2022.06.23.497415v3},
  urldate = {2023-03-30},
  abstract = {We introduce dynamic predictive coding, a hierarchical model of spatiotemporal prediction and sequence learning in the cortex. The model assumes that higher cortical levels modulate the temporal dynamics of lower levels, correcting their predictions of dynamics using prediction errors. As a result, lower levels form representations that encode sequences at shorter timescales (e.g., a single step) while higher levels form representations that encode sequences at longer timescales (e.g., an entire sequence). We tested this model using a two-level neural network, where the top-down modulation is implemented as a low-dimensional mixture of possible temporal dynamics. When trained on natural videos, the lower-level model neurons developed space-time receptive fields similar to those of simple cells in the primary visual cortex while the higher-level responses spanned longer timescales, mimicking temporal response hierarchies in the cortex. Additionally, the network’s hierarchical sequence representation exhibited both predictive and postdictive effects resembling those observed in visual motion processing in humans (e.g., the flash-lag illusion). When coupled with an associative memory mimicking the role of the hippocampus, the model allowed episodic memories to be stored and retrieved, supporting cue-triggered recall of an input sequence similar to activity recall in the visual cortex. Taken together, our results suggest that cortical processing and learning of sequences can be interpreted as dynamic predictive coding based on a hierarchical spatiotemporal generative model of the visual world.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EMU7JDPS\Jiang and Rao - 2022 - Dynamic Predictive Coding A New Model of Hierarch.pdf}
}

@article{jiAsymptoticScalingDescribing2020,
  title = {Asymptotic Scaling Describing Signal Propagation in Complex Networks},
  author = {Ji, Peng and Lin, Wei and Kurths, Jürgen},
  date = {2020-11},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {16},
  number = {11},
  pages = {1082--1083},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-020-1025-3},
  url = {https://www.nature.com/articles/s41567-020-1025-3},
  urldate = {2022-10-02},
  issue = {11},
  langid = {english},
  keywords = {Applied mathematics,Complex networks,Nonlinear phenomena},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NBADIFTZ\Ji et al. - 2020 - Asymptotic scaling describing signal propagation i.pdf}
}

@unpublished{jonesCanSingleNeurons2020,
  title = {Can {{Single Neurons Solve MNIST}}? {{The Computational Power}} of {{Biological Dendritic Trees}}},
  shorttitle = {Can {{Single Neurons Solve MNIST}}?},
  author = {Jones, Ilenna Simone and Kording, Konrad Paul},
  date = {2020-09-02},
  eprint = {2009.01269},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  url = {http://arxiv.org/abs/2009.01269},
  urldate = {2020-10-20},
  abstract = {Physiological experiments have highlighted how the dendrites of biological neurons can nonlinearly process distributed synaptic inputs. This is in stark contrast to units in artificial neural networks that are generally linear apart from an output nonlinearity. If dendritic trees can be nonlinear, biological neurons may have far more computational power than their artificial counterparts. Here we use a simple model where the dendrite is implemented as a sequence of thresholded linear units. We find that such dendrites can readily solve machine learning problems, such as MNIST or CIFAR-10, and that they benefit from having the same input onto several branches of the dendritic tree. This dendrite model is a special case of sparse network. This work suggests that popular neuron models may severely underestimate the computational power enabled by the biological fact of nonlinear dendrites and multiple synapses per pair of neurons. The next generation of artificial neural networks may significantly benefit from these biologically inspired dendritic architectures.},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KM2A8TI3\\Jones and Kording - 2020 - Can Single Neurons Solve MNIST The Computational .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IJ669HZ2\\2009.html}
}

@article{jonesDynamicAttendingResponses,
  title = {Dynamic {{Attending}} and {{Responses}} to {{Time}}},
  author = {Jones, Mari Riess and Boltz, Marilyn},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3NPH69TA\Jones and Boltz - Dynamic Attending and Responses to Time.pdf}
}

@article{jonesDynamicAttendingResponses1989,
  title = {Dynamic Attending and Responses to Time},
  author = {Jones, M. R. and Boltz, M.},
  date = {1989-07},
  journaltitle = {Psychological Review},
  shortjournal = {Psychol Rev},
  volume = {96},
  number = {3},
  eprint = {2756068},
  eprinttype = {pmid},
  pages = {459--491},
  issn = {0033-295X},
  doi = {10.1037/0033-295x.96.3.459},
  langid = {english},
  keywords = {Attention,Humans,Music,Pitch Discrimination,Time Perception},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\K9A9PVYJ\Jones and Boltz - 1989 - Dynamic attending and responses to time.pdf}
}

@article{jonesThetaRhythmsCoordinate2005,
  title = {Theta {{Rhythms Coordinate Hippocampal}}–{{Prefrontal Interactions}} in a {{Spatial Memory Task}}},
  author = {Jones, Matthew W. and Wilson, Matthew A.},
  date = {2005-11-15},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {3},
  number = {12},
  pages = {e402},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.0030402},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0030402},
  urldate = {2023-03-28},
  abstract = {Decision-making requires the coordinated activity of diverse brain structures. For example, in maze-based tasks, the prefrontal cortex must integrate spatial information encoded in the hippocampus with mnemonic information concerning route and task rules in order to direct behavior appropriately. Using simultaneous tetrode recordings from CA1 of the rat hippocampus and medial prefrontal cortex, we show that correlated firing in the two structures is selectively enhanced during behavior that recruits spatial working memory, allowing the integration of hippocampal spatial information into a broader, decision-making network. The increased correlations are paralleled by enhanced coupling of the two structures in the 4- to 12-Hz theta-frequency range. Thus the coordination of theta rhythms may constitute a general mechanism through which the relative timing of disparate neural activities can be controlled, allowing specialized brain structures to both encode information independently and to interact selectively according to current behavioral demands.},
  langid = {english},
  keywords = {Action potentials,Behavior,Cognitive science,Decision making,Hippocampus,Neurons,Rats,Working memory},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZCAAG6TK\Jones and Wilson - 2005 - Theta Rhythms Coordinate Hippocampal–Prefrontal In.pdf}
}

@article{jordanOpposingInfluenceTopdown2020,
  title = {Opposing {{Influence}} of {{Top-down}} and {{Bottom-up Input}} on {{Excitatory Layer}} 2/3 {{Neurons}} in {{Mouse Primary Visual Cortex}}},
  author = {Jordan, Rebecca and Keller, Georg B.},
  date = {2020-10-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.09.024},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627320307480},
  urldate = {2020-11-13},
  abstract = {Processing in cortical circuits is driven by combinations of cortical and subcortical inputs. These inputs are often conceptually categorized as bottom-up, conveying sensory information, and top-down, conveying contextual information. Using intracellular recordings in mouse primary visual cortex, we measured neuronal responses to visual input, locomotion, and visuomotor mismatches. We show that layer 2/3 (L2/3) neurons compute a difference between top-down motor-related input and bottom-up visual flow input. Most L2/3 neurons responded to visuomotor mismatch with either hyperpolarization or depolarization, and the size of this response was correlated with distinct physiological properties. Consistent with a subtraction of bottom-up and top-down input, visual and motor-related inputs had opposing influence on L2/3 neurons. In infragranular neurons, we found no evidence of a difference computation and responses were consistent with positive integration of visuomotor inputs. Our results provide evidence that L2/3 functions as a bidirectional comparator of top-down and bottom-up input.},
  langid = {english},
  keywords = {cortical microcircuit,prediction error,predictive processing,sensorimotor integration,visual cortex,whole cell recording},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9J66EG4S\\Jordan and Keller - 2020 - Opposing Influence of Top-down and Bottom-up Input.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ABHFGI2Q\\S0896627320307480.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RYTLFSZT\\S0896627320307480.html}
}

@article{jovanovicCumulantsHawkesPoint2015,
  title = {Cumulants of {{Hawkes}} Point Processes},
  author = {Jovanović, Stojan and Hertz, John and Rotter, Stefan},
  date = {2015-04-07},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {91},
  number = {4},
  pages = {042802},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.91.042802},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.042802},
  urldate = {2022-09-30},
  abstract = {We derive explicit, closed-form expressions for the cumulant densities of a multivariate, self-exciting Hawkes point process, generalizing a result of Hawkes in his earlier work on the covariance density and Bartlett spectrum of such processes. To do this, we represent the Hawkes process in terms of a Poisson cluster process and show how the cumulant density formulas can be derived by enumerating all possible “family trees,” representing complex interactions between point events. We also consider the problem of computing the integrated cumulants, characterizing the average measure of correlated activity between events of different types, and derive the relevant equations.},
  keywords = {Hawkes process,point process},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QXV3QYP6\\Jovanović et al. - 2015 - Cumulants of Hawkes point processes.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z8RRLX3V\\PhysRevE.91.html}
}

@article{jovanovicCumulantsHawkesPoint2015a,
  title = {Cumulants of {{Hawkes}} Point Processes},
  author = {Jovanović, Stojan and Hertz, John and Rotter, Stefan},
  date = {2015-04-07},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {91},
  number = {4},
  pages = {042802},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.91.042802},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.91.042802},
  urldate = {2022-09-30},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TB5WA6L5\Jovanović et al. - 2015 - Cumulants of Hawkes point processes.pdf}
}

@article{jovanovicInterplayGraphTopology2016,
  title = {Interplay between {{Graph Topology}} and {{Correlations}} of {{Third Order}} in {{Spiking Neuronal Networks}}},
  author = {Jovanović, Stojan and Rotter, Stefan},
  date = {2016-06-06},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {6},
  pages = {e1004963},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004963},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004963},
  urldate = {2022-09-30},
  abstract = {The study of processes evolving on networks has recently become a very popular research field, not only because of the rich mathematical theory that underpins it, but also because of its many possible applications, a number of them in the field of biology. Indeed, molecular signaling pathways, gene regulation, predator-prey interactions and the communication between neurons in the brain can be seen as examples of networks with complex dynamics. The properties of such dynamics depend largely on the topology of the underlying network graph. In this work, we want to answer the following question: Knowing network connectivity, what can be said about the level of third-order correlations that will characterize the network dynamics? We consider a linear point process as a model for pulse-coded, or spiking activity in a neuronal network. Using recent results from theory of such processes, we study third-order correlations between spike trains in such a system and explain which features of the network graph (i.e. which topological motifs) are responsible for their emergence. Comparing two different models of network topology—random networks of Erdős-Rényi type and networks with highly interconnected hubs—we find that, in random networks, the average measure of third-order correlations does not depend on the local connectivity properties, but rather on global parameters, such as the connection probability. This, however, ceases to be the case in networks with a geometric out-degree distribution, where topological specificities have a strong impact on average correlations.},
  langid = {english},
  keywords = {Action potentials,Covariance,Leaves,Network analysis,Network motifs,Neural networks,Neurons,Trees},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\U49Y5CNX\\Jovanović and Rotter - 2016 - Interplay between Graph Topology and Correlations .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MEI3MJF9\\article.html}
}

@article{junFullyIntegratedSilicon2017,
  title = {Fully Integrated Silicon Probes for High-Density Recording of Neural Activity},
  author = {Jun, James J. and Steinmetz, Nicholas A. and Siegle, Joshua H. and Denman, Daniel J. and Bauza, Marius and Barbarits, Brian and Lee, Albert K. and Anastassiou, Costas A. and Andrei, Alexandru and Aydın, Çağatay and Barbic, Mladen and Blanche, Timothy J. and Bonin, Vincent and Couto, João and Dutta, Barundeb and Gratiy, Sergey L. and Gutnisky, Diego A. and Häusser, Michael and Karsh, Bill and Ledochowitsch, Peter and Lopez, Carolina Mora and Mitelut, Catalin and Musa, Silke and Okun, Michael and Pachitariu, Marius and Putzeys, Jan and Rich, P. Dylan and Rossant, Cyrille and Sun, Wei-lung and Svoboda, Karel and Carandini, Matteo and Harris, Kenneth D. and Koch, Christof and O’Keefe, John and Harris, Timothy D.},
  date = {2017-11},
  journaltitle = {Nature},
  volume = {551},
  number = {7679},
  pages = {232--236},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature24636},
  url = {https://www.nature.com/articles/nature24636},
  urldate = {2020-10-15},
  abstract = {New silicon probes known as Neuropixels are shown to record from hundreds of neurons simultaneously in awake and freely moving rodents.},
  issue = {7679},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SDC74U3U\\Jun et al. - 2017 - Fully integrated silicon probes for high-density r.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9ZALZIUX\\nature24636.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EAA9FGVT\\nature24636.html}
}

@article{kahnemanExchangeLettersRole2022,
  title = {An Exchange of Letters on the Role of Noise in Collective Intelligence},
  author = {Kahneman, Daniel and Krakauer, David C and Sibony, Olivier and Sunstein, Cass and Wolpert, David},
  date = {2022-08-01},
  journaltitle = {Collective Intelligence},
  volume = {1},
  number = {1},
  pages = {26339137221078593},
  publisher = {SAGE Publications},
  issn = {2633-9137},
  doi = {10.1177/26339137221078593},
  url = {https://doi.org/10.1177/26339137221078593},
  urldate = {2022-10-31},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UME9AXZ5\Kahneman et al. - 2022 - An exchange of letters on the role of noise in col.pdf}
}

@inproceedings{kajinoDifferentiablePointProcess2021,
  title = {A {{Differentiable Point Process}} with {{Its Application}} to {{Spiking Neural Networks}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Kajino, Hiroshi},
  date = {2021-07-01},
  pages = {5226--5235},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/kajino21a.html},
  urldate = {2023-03-05},
  abstract = {This paper is concerned about a learning algorithm for a probabilistic model of spiking neural networks (SNNs). Jimenez Rezende \& Gerstner (2014) proposed a stochastic variational inference algorithm to train SNNs with hidden neurons. The algorithm updates the variational distribution using the score function gradient estimator, whose high variance often impedes the whole learning algorithm. This paper presents an alternative gradient estimator for SNNs based on the path-wise gradient estimator. The main technical difficulty is a lack of a general method to differentiate a realization of an arbitrary point process, which is necessary to derive the path-wise gradient estimator. We develop a differentiable point process, which is the technical highlight of this paper, and apply it to derive the path-wise gradient estimator for SNNs. We investigate the effectiveness of our gradient estimator through numerical simulation.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7B48CRKR\\Kajino - 2021 - A Differentiable Point Process with Its Applicatio.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZCHIZLAK\\Kajino - 2021 - A Differentiable Point Process with Its Applicatio.pdf}
}

@online{kamataFullySpikingVariational2021,
  title = {Fully {{Spiking Variational Autoencoder}}},
  author = {Kamata, Hiromichi and Mukuta, Yusuke and Harada, Tatsuya},
  date = {2021-12-14},
  eprint = {2110.00375},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2110.00375},
  url = {http://arxiv.org/abs/2110.00375},
  urldate = {2023-03-05},
  abstract = {Spiking neural networks (SNNs) can be run on neuromorphic devices with ultra-high speed and ultra-low energy consumption because of their binary and event-driven nature. Therefore, SNNs are expected to have various applications, including as generative models being running on edge devices to create high-quality images. In this study, we build a variational autoencoder (VAE) with SNN to enable image generation. VAE is known for its stability among generative models; recently, its quality advanced. In vanilla VAE, the latent space is represented as a normal distribution, and floating-point calculations are required in sampling. However, this is not possible in SNNs because all features must be binary time series data. Therefore, we constructed the latent space with an autoregressive SNN model, and randomly selected samples from its output to sample the latent variables. This allows the latent variables to follow the Bernoulli process and allows variational learning. Thus, we build the Fully Spiking Variational Autoencoder where all modules are constructed with SNN. To the best of our knowledge, we are the first to build a VAE only with SNN layers. We experimented with several datasets, and confirmed that it can generate images with the same or better quality compared to conventional ANNs. The code is available at https://github.com/kamata1729/FullySpikingVAE},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5IAX8SQC\\Kamata et al. - 2021 - Fully Spiking Variational Autoencoder.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\92DMPUQV\\2110.html}
}

@article{kampaRequirementDendriticCalcium2006,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-15},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CDGWIY7R\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5VNZ9KCI\\jphysiol.2006.html}
}

@article{kampaRequirementDendriticCalcium2006a,
  title = {Requirement of Dendritic Calcium Spikes for Induction of Spike-Timing-Dependent Synaptic Plasticity},
  author = {Kampa, Björn M. and Letzkus, Johannes J. and Stuart, Greg J.},
  date = {2006},
  journaltitle = {The Journal of Physiology},
  volume = {574},
  number = {1},
  pages = {283--290},
  issn = {1469-7793},
  doi = {10.1113/jphysiol.2006.111062},
  url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.2006.111062},
  urldate = {2020-10-13},
  abstract = {Spike-timing-dependent synaptic plasticity (STDP) by definition requires the temporal association of pre- and postsynaptic action potentials (APs). Yet, in cortical pyramidal neurons pairing unitary EPSPs with single APs at low frequencies is ineffective at generating plasticity. Using recordings from synaptically coupled layer 5 pyramidal neurons, we show here that high-frequency (200 Hz) postsynaptic AP bursts, rather than single APs, are required for both long-term potentiation (LTP) induction and NMDA channel activation during EPSP–AP pairing at low frequencies. Furthermore, we find that AP bursts can lead to LTP induction and NMDA channel activation during EPSP–AP pairing at both positive and negative times. High-frequency AP bursts generated supralinear calcium signals in basal dendrites suggesting the generation of dendritic calcium spikes, as has been observed previously in apical dendrites during AP burst firing at frequencies greater than 100 Hz. Consistent with a role of these dendritic calcium spikes in LTP induction, pairing EPSPs with low frequency (50 Hz) AP bursts was ineffective in generating LTP. Furthermore, supralinear calcium signals in basal dendrites during AP bursts were blocked by low concentrations of the T- and R-type calcium channel antagonist nickel, which also blocked LTP and NMDA channel activation. These data suggest an important role of dendritic calcium spikes during AP bursts in determining both the efficacy and time window for STDP induction.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\395JAX93\\Kampa et al. - 2006 - Requirement of dendritic calcium spikes for induct.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UDTZJJIK\\jphysiol.2006.html}
}

@article{kanaiCerebralHierarchiesPredictive2015,
  title = {Cerebral Hierarchies: Predictive Processing, Precision and the Pulvinar},
  shorttitle = {Cerebral Hierarchies},
  author = {Kanai, Ryota and Komura, Yutaka and Shipp, Stewart and Friston, Karl},
  date = {2015-05-19},
  journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {370},
  number = {1668},
  pages = {20140169},
  publisher = {Royal Society},
  doi = {10.1098/rstb.2014.0169},
  url = {https://royalsocietypublishing.org/doi/10.1098/rstb.2014.0169},
  urldate = {2023-03-30},
  abstract = {This paper considers neuronal architectures from a computational perspective and asks what aspects of neuroanatomy and neurophysiology can be disclosed by the nature of neuronal computations? In particular, we extend current formulations of the brain as an organ of inference—based upon hierarchical predictive coding—and consider how these inferences are orchestrated. In other words, what would the brain require to dynamically coordinate and contextualize its message passing to optimize its computational goals? The answer that emerges rests on the delicate (modulatory) gain control of neuronal populations that select and coordinate (prediction error) signals that ascend cortical hierarchies. This is important because it speaks to a hierarchical anatomy of extrinsic (between region) connections that form two distinct classes, namely a class of driving (first-order) connections that are concerned with encoding the content of neuronal representations and a class of modulatory (second-order) connections that establish context—in the form of the salience or precision ascribed to content. We explore the implications of this distinction from a formal perspective (using simulations of feature–ground segregation) and consider the neurobiological substrates of the ensuing precision-engineered dynamics, with a special focus on the pulvinar and attention.},
  keywords = {attention,neuromodulation,neuronal computational,precision,predictive coding,pulvinar},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\L6PQSNY6\Kanai et al. - 2015 - Cerebral hierarchies predictive processing, preci.pdf}
}

@article{kanamoriIndependentResponseModulation2022,
  title = {Independent Response Modulation of Visual Cortical Neurons by Attentional and Behavioral States},
  author = {Kanamori, Takahiro and Mrsic-Flogel, Thomas D.},
  date = {2022-12-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {23},
  pages = {3907-3918.e6},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2022.08.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627322008030},
  urldate = {2022-12-23},
  abstract = {Sensory processing is influenced by cognitive and behavioral states, but how these states interact to modulate responses of individual neurons is unknown. We trained mice in a visual discrimination task wherein they attended to different locations within a hemifield while running or sitting still, enabling us to examine how visual responses are modulated by spatial attention and running behavior. We found that spatial attention improved discrimination performance and strengthened visual responses of excitatory neurons in the primary visual cortex whose receptive fields overlapped with the attended location. Although individual neurons were modulated by both spatial attention and running, the magnitudes of these influences were not correlated. While running-dependent modulation was stable across days, attentional modulation was dynamic, influencing individual neurons to different degrees after repeated changes in attentional states. Thus, despite similar effects on neural responses, spatial attention and running act independently with different dynamics, implying separable mechanisms for their implementation.},
  langid = {english},
  keywords = {brain state,mouse behavior,sensory processing,spatial attention,two-photon calcium imaging,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\N5PLNP2C\\Kanamori and Mrsic-Flogel - 2022 - Independent response modulation of visual cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZHUDC5F3\\S0896627322008030.html}
}

@article{kanashiroAttentionalModulationNeuronal2017,
  title = {Attentional Modulation of Neuronal Variability in Circuit Models of Cortex},
  author = {Kanashiro, Tatjana and Ocker, Gabriel Koch and Cohen, Marlene R and Doiron, Brent},
  editor = {Latham, Peter},
  date = {2017-06-07},
  journaltitle = {eLife},
  volume = {6},
  pages = {e23978},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.23978},
  url = {https://doi.org/10.7554/eLife.23978},
  urldate = {2023-08-28},
  abstract = {The circuit mechanisms behind shared neural variability (noise correlation) and its dependence on neural state are poorly understood. Visual attention is well-suited to constrain cortical models of response variability because attention both increases firing rates and their stimulus sensitivity, as well as decreases noise correlations. We provide a novel analysis of population recordings in rhesus primate visual area V4 showing that a single biophysical mechanism may underlie these diverse neural correlates of attention. We explore model cortical networks where top-down mediated increases in excitability, distributed across excitatory and inhibitory targets, capture the key neuronal correlates of attention. Our models predict that top-down signals primarily affect inhibitory neurons, whereas excitatory neurons are more sensitive to stimulus specific bottom-up inputs. Accounting for trial variability in models of state dependent modulation of neuronal activity is a critical step in building a mechanistic theory of neuronal cognition.},
  keywords = {inhibitory feedback,mean field model,neural correlates of attention,noise correlations},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PTUBG9UC\Kanashiro et al. - 2017 - Attentional modulation of neuronal variability in .pdf}
}

@article{kanitscheiderOriginInformationlimitingNoise2015,
  title = {Origin of Information-Limiting Noise Correlations},
  author = {Kanitscheider, Ingmar and Coen-Cagli, Ruben and Pouget, Alexandre},
  date = {2015-12-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {112},
  number = {50},
  pages = {E6973-E6982},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1508738112},
  url = {https://www.pnas.org/doi/10.1073/pnas.1508738112},
  urldate = {2023-03-22},
  abstract = {The ability to discriminate between similar sensory stimuli relies on the amount of information encoded in sensory neuronal populations. Such information can be substantially reduced by correlated trial-to-trial variability. Noise correlations have been measured across a wide range of areas in the brain, but their origin is still far from clear. Here we show analytically and with simulations that optimal computation on inputs with limited information creates patterns of noise correlations that account for a broad range of experimental observations while at same time causing information to saturate in large neural populations. With the example of a network of V1 neurons extracting orientation from a noisy image, we illustrate to our knowledge the first generative model of noise correlations that is consistent both with neurophysiology and with behavioral thresholds, without invoking suboptimal encoding or decoding or internal sources of variability such as stochastic network dynamics or cortical state fluctuations. We further show that when information is limited at the input, both suboptimal connectivity and internal fluctuations could similarly reduce the asymptotic information, but they have qualitatively different effects on correlations leading to specific experimental predictions. Our study indicates that noise at the sensory periphery could have a major effect on cortical representations in widely studied discrimination tasks. It also provides an analytical framework to understand the functional relevance of different sources of experimentally measured correlations.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\756JCKFY\Kanitscheider et al. - 2015 - Origin of information-limiting noise correlations.pdf}
}

@article{kaperIntroductionFocusIssue2013,
  title = {Introduction to {{Focus Issue}}: {{Rhythms}} and {{Dynamic Transitions}} in {{Neurological Disease}}: {{Modeling}}, {{Computation}}, and {{Experiment}}},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Kaper, Tasso J. and Kramer, Mark A. and Rotstein, Horacio G.},
  date = {2013-12-01},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {23},
  number = {4},
  pages = {046001},
  publisher = {American Institute of Physics},
  issn = {1054-1500},
  doi = {10.1063/1.4856276},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4856276},
  urldate = {2020-11-10},
  abstract = {Rhythmic neuronal oscillations across a broad range of frequencies, as well as spatiotemporal phenomena, such as waves and bumps, have been observed in various areas of the brain and proposed as critical to brain function. While there is a long and distinguished history of studying rhythms in nerve cells and neuronal networks in healthy organisms, the association and analysis of rhythms to diseases are more recent developments. Indeed, it is now thought that certain aspects of diseases of the nervous system, such as epilepsy, schizophrenia, Parkinson's, and sleep disorders, are associated with transitions or disruptions of neurological rhythms. This focus issue brings together articles presenting modeling, computational, analytical, and experimental perspectives about rhythms and dynamic transitions between them that are associated to various diseases.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5AMZ5KXF\\Kaper et al. - 2013 - Introduction to Focus Issue Rhythms and Dynamic T.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7XEGAMJP\\1.html}
}

@article{kappelVARIATIONALFRAMEWORKLOCAL2024,
  title = {A {{VARIATIONAL FRAMEWORK FOR LOCAL LEARNING WITH PROBABILISTIC LATENT REPRESENTATIONS}}},
  author = {Kappel, David and Nazeer, Khaleelulla Khan and Fokam, Cabrel Teguemne and Mayr, Christian and Subramoney, Anand},
  date = {2024},
  abstract = {We propose a new method for distributed learning by dividing a deep neural network into blocks and introducing a feedback network that propagates information from the targets backward to provide auxiliary local losses. Forward and backward propagation can operate in parallel and with different sets of weights, addressing the problems of locking and weight transport. Our approach derives from a statistical interpretation of training that treats output activations of network blocks as parameters of probability distributions. The resulting learning framework uses these parameters to evaluate the agreement between forward and backward information. Error backpropagation is then performed locally within each block, leading to “block-local” learning. We present preliminary results on a variety of tasks and architectures, demonstrating state-of-the-art performance using block-local learning. These results provide a new principled framework for distributed asynchronous learning.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BTGNX5ZC\Kappel et al. - 2024 - A VARIATIONAL FRAMEWORK FOR LOCAL LEARNING WITH PR.pdf}
}

@article{karakasReviewThetaOscillation2020,
  title = {A Review of Theta Oscillation and Its Functional Correlates},
  author = {Karakaş, Sirel},
  date = {2020-11},
  journaltitle = {International Journal of Psychophysiology},
  shortjournal = {International Journal of Psychophysiology},
  volume = {157},
  pages = {82--99},
  issn = {01678760},
  doi = {10.1016/j.ijpsycho.2020.04.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167876020300763},
  urldate = {2023-03-24},
  abstract = {Theta is an extensively studied oscillation of the nervous system, but there is only a paucity of reviews on the subject. A review of specifically the cognitive-affective correlates of the theta oscillation is currently unavailable. The present review aims to fill this gap. This review shows that theta-based hippocampal binding brings together the environmentally triggered multimodal elements of episodes or scenes, make multimodal sensory/perceptual and motor processing, facilitatory and inhibitory attention, navigation and episodic memory possible. Hippo­ campus is centrally located in a selectively distributed theta network. The association between different sources of information and between oscillations of different frequency bands, the connectivity in the theta network and coherences between selected brain areas contribute to the synchrony and hypersynchrony in the human brain. The densely associated pool of information that are represented by the theta oscillation travel over this densely interconnected, and highly synchronized hippocampal-cortical system. In this network, the theta-based corticohippocampal interplay produces many cognitive-affective processes, chief one being memory with its encoding, consolidation and retrieval stages. The present review does not make a comparative evaluation of the theta over the evolutionary spectrum; it is focused on the hippocampal-cortical system, and does not consider the subcortical and brain stem structures of the theta network; and among the many different types of memory, treats specifically the episodic memory. Future theta reviews may choose to also treat these issues. Providing a concise exposition of the currently available empirical findings and theoretical formulations, this state-of-the art that review may stimulate research, make new conclusions available, and lead to creative syntheses, allowing a detailed understanding of the contribution of the theta oscillation to the whole-brain work and to the human mind.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NQYBA6DJ\Karakaş - 2020 - A review of theta oscillation and its functional c.pdf}
}

@article{karEvidenceThatRecurrent2019,
  title = {Evidence That Recurrent Circuits Are Critical to the Ventral Stream’s Execution of Core Object Recognition Behavior},
  author = {Kar, Kohitij and Kubilius, Jonas and Schmidt, Kailyn and Issa, Elias B. and DiCarlo, James J.},
  date = {2019-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {6},
  pages = {974--983},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0392-5},
  url = {https://www.nature.com/articles/s41593-019-0392-5},
  urldate = {2024-06-18},
  abstract = {Non-recurrent deep convolutional neural networks (CNNs) are currently the best at modeling core object recognition, a behavior that is supported by the densely recurrent primate ventral stream, culminating in the inferior temporal (IT) cortex. If recurrence is critical to this behavior, then primates should outperform feedforward-only deep CNNs for images that require additional recurrent processing beyond the feedforward IT response. Here we first used behavioral methods to discover hundreds of these ‘challenge’ images. Second, using large-scale electrophysiology, we observed that behaviorally sufficient object identity solutions emerged \textasciitilde 30\,ms later in the IT cortex for challenge images compared with primate performance-matched ‘control’ images. Third, these behaviorally critical late-phase IT response patterns were poorly predicted by feedforward deep CNN activations. Notably, very-deep CNNs and shallower recurrent CNNs better predicted these late IT responses, suggesting that there is a functional equivalence between additional nonlinear transformations and recurrence. Beyond arguing that recurrent circuits are critical for rapid object identification, our results provide strong constraints for future recurrent model development.},
  langid = {english},
  keywords = {Neural decoding,Neural encoding,Object vision},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HIWR6AGJ\Kar et al. - 2019 - Evidence that recurrent circuits are critical to t.pdf}
}

@article{katsukiBottomUpTopDownAttention2014,
  title = {Bottom-{{Up}} and {{Top-Down Attention}}: {{Different Processes}} and {{Overlapping Neural Systems}}},
  shorttitle = {Bottom-{{Up}} and {{Top-Down Attention}}},
  author = {Katsuki, Fumi and Constantinidis, Christos},
  date = {2014-10-01},
  journaltitle = {The Neuroscientist},
  shortjournal = {Neuroscientist},
  volume = {20},
  number = {5},
  pages = {509--521},
  publisher = {SAGE Publications Inc STM},
  issn = {1073-8584},
  doi = {10.1177/1073858413514136},
  url = {https://doi.org/10.1177/1073858413514136},
  urldate = {2023-04-07},
  abstract = {The brain is limited in its capacity to process all sensory stimuli present in the physical world at any point in time and relies instead on the cognitive process of attention to focus neural resources according to the contingencies of the moment. Attention can be categorized into two distinct functions: bottom-up attention, referring to attentional guidance purely by externally driven factors to stimuli that are salient because of their inherent properties relative to the background; and top-down attention, referring to internal guidance of attention based on prior knowledge, willful plans, and current goals. Over the past few years, insights on the neural circuits and mechanisms of bottom-up and top-down attention have been gained through neurophysiological experiments. Attention affects the mean neuronal firing rate as well as its variability and correlation across neurons. Although distinct processes mediate the guidance of attention based on bottom-up and top-down factors, a common neural apparatus, the frontoparietal network, is essential in both types of attentional processes.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KF62UHK6\Katsuki and Constantinidis - 2014 - Bottom-Up and Top-Down Attention Different Proces.pdf}
}

@inproceedings{keeleyIdentifyingSignalNoise2020,
  title = {Identifying Signal and Noise Structure in Neural Population Activity with {{Gaussian}} Process Factor Models},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Keeley, Stephen and Aoi, Mikio and Yu, Yiyi and Smith, Spencer and Pillow, Jonathan W},
  date = {2020},
  volume = {33},
  pages = {13795--13805},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/9eed867b73ab1eab60583c9d4a789b1b-Abstract.html},
  urldate = {2024-07-15},
  abstract = {Neural datasets often contain measurements of neural activity across multiple trials of a repeated stimulus or behavior. An important problem in the analysis of such datasets is to characterize systematic aspects of neural activity that carry information about the repeated stimulus or behavior of interest, which can be considered signal'', and to separate them from the trial-to-trial fluctuations in activity that are not time-locked to the stimulus, which for purposes of such analyses can be considerednoise''. Gaussian Process factor models provide a powerful tool for identifying shared structure in high-dimensional neural data. However, they have not yet been adapted to the problem of characterizing signal and noise in multi-trial datasets. Here we address this shortcoming by proposing signal-noise'' Poisson-spiking Gaussian Process Factor Analysis (SNP-GPFA), a flexible latent variable model that resolves signal and noise latent structure in neural population spiking activity. To learn the parameters of our model, we introduce a Fourier-domain black box variational inference method that quickly identifies smooth latent structure. The resulting model reliably uncovers latent signal and trial-to-trial noise-related fluctuations in large-scale recordings. We use this model to show that in monkey V1, noise fluctuations perturb neural activity within a subspace orthogonal to signal activity, suggesting that trial-by-trial noise does not interfere with signal representations. Finally, we extend the model to capture statistical dependencies across brain regions in multi-region data. We show that in mouse visual cortex, models with shared noise across brain regions out-perform models with independent per-region noise.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\L62MPBIW\Keeley et al. - 2020 - Identifying signal and noise structure in neural p.pdf}
}

@article{kellerFeedbackGeneratesSecond2020,
  title = {Feedback Generates a Second Receptive Field in Neurons of the Visual Cortex},
  author = {Keller, Andreas J. and Roth, Morgane M. and Scanziani, Massimo},
  date = {2020-06},
  journaltitle = {Nature},
  volume = {582},
  number = {7813},
  pages = {545--549},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2319-4},
  url = {https://www.nature.com/articles/s41586-020-2319-4},
  urldate = {2020-10-05},
  abstract = {Animals sense the environment through pathways that link sensory organs to the brain. In the visual system, these feedforward pathways define the classical feedforward receptive field (ffRF), the area in space in which visual stimuli excite a neuron1. The visual system also uses visual context—the visual scene surrounding a stimulus—to predict the content of the stimulus2, and accordingly, neurons have been identified that are excited by stimuli outside their ffRF3–8. However, the mechanisms that generate excitation to stimuli outside the ffRF are unclear. Here we show that feedback projections onto excitatory neurons in the mouse primary visual cortex generate a second receptive field that is driven by stimuli outside the ffRF. The stimulation of this feedback receptive field (fbRF) elicits responses that are slower and are delayed in comparison with those resulting from the stimulation of the ffRF. These responses are preferentially reduced by anaesthesia and by silencing higher visual areas. Feedback inputs from higher visual areas have scattered receptive fields relative to their putative targets in the primary visual cortex, which enables the generation of the fbRF. Neurons with fbRFs are located in cortical layers that receive strong feedback projections and are absent in the main input layer, which is consistent with a laminar processing hierarchy. The observation that large, uniform stimuli—which cover both the fbRF and the ffRF—suppress these responses indicates that the fbRF and the ffRF are mutually antagonistic. Whereas somatostatin-expressing inhibitory neurons are driven by these large stimuli, inhibitory neurons that express parvalbumin and vasoactive intestinal peptide have mutually antagonistic fbRF and ffRF, similar to excitatory neurons. Feedback projections may therefore enable neurons to use context to estimate information that is missing from the ffRF and to report differences in stimulus features across visual space, regardless of whether excitation occurs inside or outside the ffRF. By complementing the ffRF, the fbRF that we identify here could contribute to predictive processing.},
  issue = {7813},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PLLQV9GI\\Keller et al. - 2020 - Feedback generates a second receptive field in neu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PRBPYWTW\\s41586-020-2319-4.html}
}

@article{kellerSensorimotorMismatchSignals2012,
  title = {Sensorimotor {{Mismatch Signals}} in {{Primary Visual Cortex}} of the {{Behaving Mouse}}},
  author = {Keller, Georg~B. and Bonhoeffer, Tobias and Hübener, Mark},
  date = {2012-06-07},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {74},
  number = {5},
  pages = {809--815},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.03.040},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627312003844},
  urldate = {2020-11-06},
  abstract = {Studies in anesthetized animals have suggested that activity in early visual cortex is mainly driven by visual input and is well described by a feedforward processing hierarchy. However, evidence from experiments on awake animals has shown that both eye movements and behavioral state can strongly modulate responses of neurons in visual cortex; the functional significance of this modulation, however, remains elusive. Using visual-flow feedback manipulations during locomotion in a virtual reality environment, we found that responses in layer 2/3 of mouse primary visual cortex are strongly driven by locomotion and by mismatch between actual and expected visual feedback. These data suggest that processing in visual cortex may be based on predictive coding strategies that use motor-related and visual input to detect mismatches between predicted and actual visual feedback.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZHN6855\\Keller et al. - 2012 - Sensorimotor Mismatch Signals in Primary Visual Co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QHCV6A7V\\S0896627312003844.html}
}

@article{khaledi-nasabInformationProcessingTree2021,
  title = {Information Processing in Tree Networks of Excitable Elements},
  author = {Khaledi-Nasab, Ali and Chauhan, Kanishk and Tass, Peter A. and Neiman, Alexander B.},
  date = {2021-01-22},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {103},
  number = {1},
  pages = {012308},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.103.012308},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.103.012308},
  urldate = {2022-10-03},
  abstract = {We study the collective response of small random tree networks of diffusively coupled excitable elements to stimuli applied to leaf nodes. Such networks model the morphology of certain sensory neurons that possess branched myelinated dendrites with excitable nodes of Ranvier at every branch point and at leaf nodes. Leaf nodes receive random inputs along with a stimulus and initiate action potentials that propagate through the tree. We quantify the collective response registered at the central node using mutual information. We show that in the strong-coupling limit, the statistics of the number of nodes and leaves determines the mutual information. At the same time, the collective response is insensitive to particular node connectivity and distribution of stimulus over leaf nodes. However, for intermediate coupling, the mutual information may strongly depend on the stimulus distribution among leaf nodes. We identify a mechanism behind the competition of leaf nodes that leads to nonmonotonous dependence of mutual information on coupling strength. We show that a localized stimulus given to a tree branch can be occluded by the background firing of unstimulated branches, thus suppressing mutual information. Nonetheless, the mutual information can be enhanced by a proper stimulus localization and tuning of coupling strength.}
}

@article{khamechianFrequencyModulationCortical2022,
  title = {Frequency Modulation of Cortical Rhythmicity Governs Behavioral Variability, Excitability and Synchrony of Neurons in the Visual Cortex},
  author = {Khamechian, Mohammad Bagher and Daliri, Mohammad Reza},
  date = {2022-12-03},
  journaltitle = {Scientific Reports},
  shortjournal = {Sci Rep},
  volume = {12},
  number = {1},
  pages = {20914},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-25264-5},
  url = {https://www.nature.com/articles/s41598-022-25264-5},
  urldate = {2022-12-28},
  abstract = {Research in cognitive neuroscience has renewed the idea that brain oscillations are a core organization implicated in fundamental brain functions. Growing evidence reveals that the characteristic features of these oscillations, including power, phase and frequency, are highly non-stationary, fluctuating alongside alternations in sensation, cognition and behavior. However, there is little consensus on the functional implications of the instantaneous frequency variation in cortical excitability and concomitant behavior. Here, we capitalized on intracortical electrophysiology in the macaque monkey’s visual area MT performing a visuospatial discrimination task with visual cues. We observed that the instantaneous frequency of the theta–alpha oscillations (4–13~Hz) is modulated among specific neurons whose RFs overlap with the cued stimulus location. Interestingly, we found that such frequency modulation is causally correlated with MT excitability at both scales of individual and ensemble of neurons. Moreover, studying the functional relevance of frequency variations indicated that the average theta–alpha frequencies foreshadow the monkey’s reaction time. Our results also revealed that the neural synchronization strength alters with the average frequency shift in theta–alpha oscillations, suggesting frequency modulation is critical for mutually adjusting MTs’ rhythms. Overall, our findings propose that theta–alpha frequency variations modulate MT’s excitability, regulate mutual neurons’ rhythmicity and indicate variability in behavior.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Perception,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DLBKBY9L\Khamechian and Daliri - 2022 - Frequency modulation of cortical rhythmicity gover.pdf}
}

@article{khamechianRoutingInformationFlow2019,
  title = {Routing Information Flow by Separate Neural Synchrony Frequencies Allows for “Functionally Labeled Lines” in Higher Primate Cortex},
  author = {Khamechian, Mohammad Bagher and Kozyrev, Vladislav and Treue, Stefan and Esghaei, Moein and Daliri, Mohammad Reza},
  date = {2019-06-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {25},
  pages = {12506--12515},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1819827116},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1819827116},
  urldate = {2023-02-13},
  abstract = {Efficient transfer of sensory information to higher (motor or associative) areas in primate visual cortical areas is crucial for transforming sensory input into behavioral actions. Dynamically increasing the level of coordination between single neurons has been suggested as an important contributor to this efficiency. We propose that differences between the functional coordination in different visual pathways might be used to unambiguously identify the source of input to the higher areas, ensuring a proper routing of the information flow. Here we determined the level of coordination between neurons in area MT in macaque visual cortex in a visual attention task via the strength of synchronization between the neurons’ spike timing relative to the phase of oscillatory activities in local field potentials. In contrast to reports on the ventral visual pathway, we observed the synchrony of spikes only in the range of high gamma (180 to 220 Hz), rather than gamma (40 to 70 Hz) (as reported previously) to predict the animal’s reaction speed. This supports a mechanistic role of the phase of high-gamma oscillatory activity in dynamically modulating the efficiency of neuronal information transfer. In addition, for inputs to higher cortical areas converging from the dorsal and ventral pathway, the distinct frequency bands of these inputs can be leveraged to preserve the identity of the input source. In this way source-specific oscillatory activity in primate cortex can serve to establish and maintain “functionally labeled lines” for dynamically adjusting cortical information transfer and multiplexing converging sensory signals.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3BVASFA5\Khamechian et al. - 2019 - Routing information flow by separate neural synchr.pdf}
}

@article{khamechianRoutingInformationFlow2019a,
  title = {Routing Information Flow by Separate Neural Synchrony Frequencies Allows for “Functionally Labeled Lines” in Higher Primate Cortex},
  author = {Khamechian, Mohammad Bagher and Kozyrev, Vladislav and Treue, Stefan and Esghaei, Moein and Daliri, Mohammad Reza},
  date = {2019-06-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {25},
  pages = {12506--12515},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1819827116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1819827116},
  urldate = {2023-03-22},
  abstract = {Efficient transfer of sensory information to higher (motor or associative) areas in primate visual cortical areas is crucial for transforming sensory input into behavioral actions. Dynamically increasing the level of coordination between single neurons has been suggested as an important contributor to this efficiency. We propose that differences between the functional coordination in different visual pathways might be used to unambiguously identify the source of input to the higher areas, ensuring a proper routing of the information flow. Here we determined the level of coordination between neurons in area MT in macaque visual cortex in a visual attention task via the strength of synchronization between the neurons’ spike timing relative to the phase of oscillatory activities in local field potentials. In contrast to reports on the ventral visual pathway, we observed the synchrony of spikes only in the range of high gamma (180 to 220 Hz), rather than gamma (40 to 70 Hz) (as reported previously) to predict the animal’s reaction speed. This supports a mechanistic role of the phase of high-gamma oscillatory activity in dynamically modulating the efficiency of neuronal information transfer. In addition, for inputs to higher cortical areas converging from the dorsal and ventral pathway, the distinct frequency bands of these inputs can be leveraged to preserve the identity of the input source. In this way source-specific oscillatory activity in primate cortex can serve to establish and maintain “functionally labeled lines” for dynamically adjusting cortical information transfer and multiplexing converging sensory signals.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LIX4TYAT\Khamechian et al. - 2019 - Routing information flow by separate neural synchr.pdf}
}

@article{khanContextualSignalsVisual2018,
  title = {Contextual Signals in Visual Cortex},
  author = {Khan, Adil G and Hofer, Sonja B},
  date = {2018-10-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Systems {{Neuroscience}}},
  volume = {52},
  pages = {131--138},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2018.05.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438818300825},
  urldate = {2023-01-10},
  abstract = {Vision is an active process. What we perceive strongly depends on our actions, intentions and expectations. During visual processing, these internal signals therefore need to be integrated with the visual information from the retina. The mechanisms of how this is achieved by the visual system are still poorly understood. Advances in recording and manipulating neuronal activity in specific cell types and axonal projections together with tools for circuit tracing are beginning to shed light on the neuronal circuit mechanisms of how internal, contextual signals shape sensory representations. Here we review recent work, primarily in mice, that has advanced our understanding of these processes, focusing on contextual signals related to locomotion, behavioural relevance and predictions.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PLAPVM4H\\Khan and Hofer - 2018 - Contextual signals in visual cortex.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KWVFR659\\S0959438818300825.html}
}

@article{khanDistinctLearninginducedChanges2018,
  title = {Distinct Learning-Induced Changes in Stimulus Selectivity and Interactions of {{GABAergic}} Interneuron Classes in Visual Cortex},
  author = {Khan, Adil G. and Poort, Jasper and Chadwick, Angus and Blot, Antonin and Sahani, Maneesh and Mrsic-Flogel, Thomas D. and Hofer, Sonja B.},
  date = {2018-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {6},
  pages = {851--859},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0143-z},
  url = {https://www.nature.com/articles/s41593-018-0143-z},
  urldate = {2023-01-13},
  abstract = {How learning enhances neural representations for behaviorally relevant stimuli via activity changes of cortical cell types remains unclear. We simultaneously imaged responses of pyramidal cells (PYR) along with parvalbumin (PV), somatostatin (SOM), and vasoactive intestinal peptide (VIP) inhibitory interneurons in primary visual cortex while mice learned to discriminate visual patterns. Learning increased selectivity for task-relevant stimuli of PYR, PV and SOM subsets but not VIP cells. Strikingly, PV neurons became as selective as PYR cells, and their functional interactions reorganized, leading to the emergence of stimulus-selective PYR–PV ensembles. Conversely, SOM activity became strongly decorrelated from the network, and PYR–SOM coupling before learning predicted selectivity increases in individual PYR cells. Thus, learning differentially shapes the activity and interactions of multiple cell classes: while SOM inhibition may gate selectivity changes, PV interneurons become recruited into stimulus-specific ensembles and provide more selective inhibition as the network becomes better at discriminating behaviorally relevant stimuli.},
  issue = {6},
  langid = {english},
  keywords = {Cortex,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WRKCH9GQ\Khan et al. - 2018 - Distinct learning-induced changes in stimulus sele.pdf}
}

@article{kiehnDecodingOrganizationSpinal2016,
  title = {Decoding the Organization of Spinal Circuits That Control Locomotion},
  author = {Kiehn, Ole},
  date = {2016-04},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {17},
  number = {4},
  pages = {224--238},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2016.9},
  url = {https://www.nature.com/articles/nrn.2016.9},
  urldate = {2023-03-17},
  abstract = {Locomotion is a complex motor act that, to a large degree, is controlled by neuronal circuits in the spinal cord. Using a systems neuroscience approach in several model systems of non-limbed and limbed animals, important advances have been made in revealing the functional organization of the spinal locomotor networks.The key circuit elements in the spinal locomotor networks are the rhythm-generating circuits and the pattern-generating circuits, which include circuits that control bilateral muscle activity, and circuits that control flexor–extensor muscles in limbed animals.Comparison of the network organization of the key circuit elements in limbed and non-limbed animals reveals both commonalities and differences in organization.The commonalities extend to the basic components of inhibitory left–right alternating circuits and excitatory neurons involved in rhythm generation.The differences include left–right alternating circuitries that have multiple components in legged animals compared with the control of axial muscles in fish where one component dominates, rhythm-generating neurons that originate from developmentally diverse progenitors in fish and mice, and elaborated reciprocal network circuits involved in the flexor–extensor coordination that is found in legged animals, which do not have direct counterparts in non-legged animals.Locomotor networks, whether they control swimming or over-ground locomotion, are built around modules of rhythm- and pattern-generating modules.Functional network reorganization occurs with changes in the speed of locomotion or changes in gait. This reconfiguration takes places both at the level of rhythm generation and at the level of pattern generation.The exact mechanisms of rhythm generation are not generally understood across phyla but seem to depend on an interplay between active membrane properties and network properties.Proprioception suggests an important role for phase switching during locomotion.The combination of electrophysiological and molecular genetic approaches has revealed details of the organization of large-scale spinal networks in limbed animals in considerably different ways than previous research has suggested and has allowed for comparison with network organization in leg-less animals with more limited numbers of cells in the spinal cord. Although these fundamental motor networks have begun to be decoded, there are still unresolved issues regarding their functional organization.},
  issue = {4},
  langid = {english},
  keywords = {Motor control,Neural circuits,Spinal cord},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WP6AXESH\Kiehn - 2016 - Decoding the organization of spinal circuits that .pdf}
}

@article{kiehnLOCOMOTORCIRCUITSMAMMALIAN2006,
  title = {{{LOCOMOTOR CIRCUITS IN THE MAMMALIAN SPINAL CORD}}},
  author = {Kiehn, Ole},
  date = {2006-07-21},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu. Rev. Neurosci.},
  volume = {29},
  number = {1},
  pages = {279--306},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev.neuro.29.051605.112910},
  url = {https://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.112910},
  urldate = {2023-03-17},
  abstract = {Intrinsic spinal networks, known as central pattern generators (CPGs), control the timing and pattern of the muscle activity underlying locomotion in mammals. This review discusses new advances in understanding the mammalian CPGs with a focus on experiments that address the overall network structure as well as the identification of CPG neurons. I address the identification of excitatory CPG neurons and their role in rhythm generation, the organization of flexor-extensor networks, and the diverse role of commissural interneurons in coordinating left-right movements. Molecular and genetic approaches that have the potential to elucidate the function of populations of CPG interneurons are also discussed.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\66HL8RIY\Kiehn - 2006 - LOCOMOTOR CIRCUITS IN THE MAMMALIAN SPINAL CORD.pdf}
}

@article{kiehnPlateauPotentialsActive1991,
  title = {Plateau Potentials and Active Integration in the ‘Final Common Pathway’ for Motor Behaviour},
  author = {Kiehn, Ole},
  date = {1991-02-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {14},
  number = {2},
  pages = {68--73},
  issn = {0166-2236},
  doi = {10.1016/0166-2236(91)90023-N},
  url = {https://www.sciencedirect.com/science/article/pii/016622369190023N},
  urldate = {2023-03-21},
  abstract = {Most studies of vertebrate spinal motoneurones have suggested that they possess relatively simple membrane properties, causing them to behave merely as passively driven output neurones in motor behaviour. According to this concept, motoneurones passively transform the net synaptic drive from pre-motoneuronel levels into spike trains. Recent research has demonstrated a more complex picture by showing that motoneurones can express nonlinear intrinsic response properties, such as plateau potentials and endogenous oscillatory properties. This work suggests that the ‘final common pathway’ is actively involved in shaping motor behaviour.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T2KLEQBJ\\Kiehn - 1991 - Plateau potentials and active integration in the ‘.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3WHHIINM\\016622369190023N.html}
}

@article{kienitzMicrostimulationVisualArea2022,
  title = {Microstimulation of Visual Area {{V4}} Improves Visual Stimulus Detection},
  author = {Kienitz, Ricardo and Kouroupaki, Kleopatra and Schmid, Michael C.},
  date = {2022-09-20},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Rep},
  volume = {40},
  number = {12},
  eprint = {36130494},
  eprinttype = {pmid},
  pages = {111392},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2022.111392},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9513802/},
  urldate = {2023-02-09},
  abstract = {Neuronal activity in visual area V4 is well known to be modulated by selective attention, and there are reports on V4 lesions leading to attentional deficits. However, it remains unclear whether V4 microstimulation can elicit attentional benefits. To test this hypothesis, we performed local microstimulation in area V4 and explored its spatial and time dynamics in two macaque monkeys performing a visual detection task. Microstimulation was delivered via chronically implanted multi-electrode arrays. We found that microstimulation increases average performance by 35\% and reduces luminance detection thresholds by −30\%. This benefit critically depends on the onset of microstimulation relative to the stimulus, consistent with known dynamics of endogenous attention. These results show that local microstimulation of V4 can improve behavior and highlight the critical role of V4 for attention.,                                        •               Microstimulation of visual area V4 improves visual stimulus detection                                         •               Effects of V4 microstimulation extend to the other hemifield                                         •               Microstimulation effects are time dependent and consistent with attention dynamics                                 , Kienitz et~al. report that microstimulation of visual area V4 improves visual stimulus detection in macaque monkeys. This faciliatory effect extends to the other hemifield and is time dependent, consistent with dynamics of endogenous attention. These results highlight the critical role of V4 for visual processing and attention.},
  pmcid = {PMC9513802},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X9LTV6S9\Kienitz et al. - 2022 - Microstimulation of visual area V4 improves visual.pdf}
}

@inproceedings{kimInferringLatentDynamics2021,
  title = {Inferring {{Latent Dynamics Underlying Neural Population Activity}} via {{Neural Differential Equations}}},
  booktitle = {Proceedings of the 38th {{International Conference}} on {{Machine Learning}}},
  author = {Kim, Timothy D. and Luo, Thomas Z. and Pillow, Jonathan W. and Brody, Carlos D.},
  date = {2021-07-01},
  pages = {5551--5561},
  publisher = {PMLR},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v139/kim21h.html},
  urldate = {2023-03-05},
  abstract = {An important problem in systems neuroscience is to identify the latent dynamics underlying neural population activity. Here we address this problem by introducing a low-dimensional nonlinear model for latent neural population dynamics using neural ordinary differential equations (neural ODEs), with noisy sensory inputs and Poisson spike train outputs. We refer to this as the Poisson Latent Neural Differential Equations (PLNDE) model. We apply the PLNDE framework to a variety of synthetic datasets, and show that it accurately infers the phase portraits and fixed points of nonlinear systems augmented to produce spike train data, including the FitzHugh-Nagumo oscillator, a 3-dimensional nonlinear spiral, and a nonlinear sensory decision-making model with attractor dynamics. Our model significantly outperforms existing methods at inferring single-trial neural firing rates and the corresponding latent trajectories that generated them, especially in the regime where the spike counts and number of trials are low. We then apply our model to multi-region neural population recordings from medial frontal cortex of rats performing an auditory decision-making task. Our model provides a general, interpretable framework for investigating the neural mechanisms of decision-making and other cognitive computations through the lens of dynamical systems.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\M3UTFU7Y\\Kim et al. - 2021 - Inferring Latent Dynamics Underlying Neural Popula.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TLHWQLL6\\Kim et al. - 2021 - Inferring Latent Dynamics Underlying Neural Popula.pdf}
}

@article{kimParallelFunctionalArchitectures2023,
  title = {✅ {{Parallel}} Functional Architectures within a Single Dendritic Tree},
  author = {Kim, Young Joon and Ujfalussy, Balázs B. and Lengyel, Máté},
  date = {2023-04-25},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {42},
  number = {4},
  pages = {112386},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2023.112386},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124723003972},
  urldate = {2023-05-01},
  abstract = {The input-output transformation of individual neurons is a key building block of neural circuit dynamics. While previous models of this transformation vary widely in their complexity, they all describe the underlying functional architecture as unitary, such that each synaptic input makes a single contribution to the neuronal response. Here, we show that the input-output transformation of CA1 pyramidal cells is instead best captured by two distinct functional architectures operating in parallel. We used statistically principled methods to fit flexible, yet interpretable, models of the transformation of input spikes into the somatic “output” voltage and to automatically select among alternative functional architectures. With dendritic Na+ channels blocked, responses are accurately captured by a single static and global nonlinearity. In contrast, dendritic Na+-dependent integration requires a functional architecture with multiple dynamic nonlinearities and clustered connectivity. These two architectures incorporate distinct morphological and biophysical properties of the neuron and its synaptic organization.},
  langid = {english},
  keywords = {action potential timing,biophysical model,cascade model,deep neural network,dendritic integration,dendritic Na+ channels,dendritic spikes,dynamic subunits,NMDA channels,subthreshold fluctuations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W47TPFR5\\Kim et al. - 2023 - Parallel functional architectures within a single .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WKSGPJNE\\1-s2.0-S2211124723003972-mmc1.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9IWVVXSM\\S2211124723003972.html}
}

@article{kindelUsingDeepLearning2019,
  title = {Using Deep Learning to Probe the Neural Code for Images in Primary Visual Cortex},
  author = {Kindel, William F. and Christensen, Elijah D. and Zylberberg, Joel},
  date = {2019-04-01},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {19},
  number = {4},
  pages = {29--29},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1534-7362},
  doi = {10.1167/19.4.29},
  url = {https://jov.arvojournals.org/article.aspx?articleid=2732380},
  urldate = {2020-10-08},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HMCBY5QM\\Kindel et al. - 2019 - Using deep learning to probe the neural code for i.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZYD6594X\\article.html}
}

@article{kinouchiOptimalDynamicalRange2006,
  title = {✅ {{Optimal}} Dynamical Range of Excitable Networks at Criticality},
  author = {Kinouchi, Osame and Copelli, Mauro},
  date = {2006-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {2},
  number = {5},
  pages = {348--351},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys289},
  url = {https://www.nature.com/articles/nphys289},
  urldate = {2022-10-01},
  abstract = {A recurrent idea in the study of complex systems is that optimal information processing is to be found near phase transitions. However, this heuristic hypothesis has few (if any) concrete realizations where a standard and biologically relevant quantity is optimized at criticality. Here we give a clear example of such a phenomenon: a network of excitable elements has its sensitivity and dynamic range maximized at the critical point of a non-equilibrium phase transition. Our results are compatible with the essential role of gap junctions in olfactory glomeruli and retinal ganglionar cell output. Synchronization and global oscillations also emerge from the network dynamics. We propose that the main functional role of electrical coupling is to provide an enhancement of dynamic range, therefore allowing the coding of information spanning several orders of magnitude. The mechanism could provide a microscopic neural basis for psychophysical laws.},
  issue = {5},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4ZZQFVXT\\Kinouchi and Copelli - 2006 - Optimal dynamical range of excitable networks at c.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9SE89ZS4\\nphys289.html}
}

@article{kjaerulffDistributionNetworksGenerating1996,
  title = {Distribution of {{Networks Generating}} and {{Coordinating Locomotor Activity}} in the {{Neonatal Rat Spinal Cord In Vitro}}: {{A Lesion Study}}},
  shorttitle = {Distribution of {{Networks Generating}} and {{Coordinating Locomotor Activity}} in the {{Neonatal Rat Spinal Cord In Vitro}}},
  author = {Kjaerulff, Ole and Kiehn, Ole},
  date = {1996-09-15},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {16},
  number = {18},
  eprint = {8795632},
  eprinttype = {pmid},
  pages = {5777--5794},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.16-18-05777.1996},
  url = {https://www.jneurosci.org/content/16/18/5777},
  urldate = {2023-03-22},
  abstract = {The isolated spinal cord of the newborn rat contains networks that are able to create a patterned motor output resembling normal locomotor movements. In this study, we sought to localize the regions of primary importance for rhythm and pattern generation using specific mechanical lesions. We used ventral root recordings to monitor neuronal activity and tested the ability of various isolated parts of the caudal thoracic-lumbar cord to generate rhythmic bursting in a combination of 5-HT and NMDA. In addition, pathways mediating left/right and rostrocaudal burst alternation were localized. We found that the isolated ventral third of the spinal cord can generate normally coordinated rhythmic activity, whereas lateral fragments resulting from sagittal sections showed little or no rhythmogenic capability compared with intact control preparations. The ability to generate fast and regular rhythmic activity decreased in the caudal direction, but the rhythm-generating network was found to be distributed over the entire lumbar region and to extend into the caudal thoracic region. The pathways mediating left/right alternation exist primarily in the ventral commissure. As with the rhythmogenic ability, these pathways were distributed along the lumbar enlargement. Both lateral and ventral funiculi were sufficient to coordinate activity in the rostral and caudal regions. We conclude that the networks organizing locomotor-related activity in the spinal cord of the newborn rat are distributed.},
  langid = {english},
  keywords = {5-HT,central pattern generator,locomotion,neonatal rat,NMDA,spinal cord},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\V7Z5J8WE\Kjaerulff and Kiehn - 1996 - Distribution of Networks Generating and Coordinati.pdf}
}

@article{kleinfeldActiveSensationInsights2006,
  title = {✅ {{Active}} Sensation: Insights from the Rodent Vibrissa Sensorimotor System},
  shorttitle = {Active Sensation},
  author = {Kleinfeld, David and Ahissar, Ehud and Diamond, Mathew E},
  date = {2006-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Sensory Systems},
  volume = {16},
  number = {4},
  pages = {435--444},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2006.06.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438806000821},
  urldate = {2023-04-12},
  abstract = {Rats sweep their vibrissae through space to locate objects in their immediate environment. In essence, their view of the proximal world is generated through pliable hairs that tap and palpate objects. The texture and shape of those objects must be discerned for the rat to assess the value of the object. Furthermore, the location of those objects must be specified with reference to the position of the rat's head for the rat to plan its movements. Recent in vivo and in vitro electrophysiological measurements provide insight into the algorithms and mechanisms that underlie these behavioral-based computations.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9VAPEXC2\\Kleinfeld et al. - 2006 - Active sensation insights from the rodent vibriss.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DY53IWDE\\S0959438806000821.html}
}

@article{kobakDemixedPrincipalComponent2016,
  title = {Demixed Principal Component Analysis of Neural Population Data},
  author = {Kobak, Dmitry and Brendel, Wieland and Constantinidis, Christos and Feierstein, Claudia E and Kepecs, Adam and Mainen, Zachary F and Qi, Xue-Lian and Romo, Ranulfo and Uchida, Naoshige and Machens, Christian K},
  editor = {van Rossum, Mark CW},
  options = {useprefix=true},
  date = {2016-04-12},
  journaltitle = {eLife},
  volume = {5},
  pages = {e10989},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.10989},
  url = {https://doi.org/10.7554/eLife.10989},
  urldate = {2024-07-11},
  abstract = {Neurons in higher cortical areas, such as the prefrontal cortex, are often tuned to a variety of sensory and motor variables, and are therefore said to display mixed selectivity. This complexity of single neuron responses can obscure what information these areas represent and how it is represented. Here we demonstrate the advantages of a new dimensionality reduction technique, demixed principal component analysis (dPCA), that decomposes population activity into a few components. In addition to systematically capturing the majority of the variance of the data, dPCA also exposes the dependence of the neural representation on task parameters such as stimuli, decisions, or rewards. To illustrate our method we reanalyze population data from four datasets comprising different species, different cortical areas and different experimental tasks. In each case, dPCA provides a concise way of visualizing the data that summarizes the task-dependent features of the population response in a single figure.},
  keywords = {dimensionality reduction,population activity,prefrontal cortex,principal component analysis},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\656WL7YL\Kobak et al. - 2016 - Demixed principal component analysis of neural pop.pdf}
}

@article{koronowskiCommunicatingClocksShape2021,
  title = {Communicating Clocks Shape Circadian Homeostasis},
  author = {Koronowski, Kevin B. and Sassone-Corsi, Paolo},
  date = {2021-02-12},
  journaltitle = {Science},
  volume = {371},
  number = {6530},
  pages = {eabd0951},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abd0951},
  url = {https://www.science.org/doi/abs/10.1126/science.abd0951},
  urldate = {2023-02-17},
  abstract = {Circadian clocks temporally coordinate physiology and align it with geophysical time, which enables diverse life-forms to anticipate daily environmental cycles. In complex organisms, clock function originates from the molecular oscillator within each cell and builds upward anatomically into an organism-wide system. Recent advances have transformed our understanding of how clocks are connected to achieve coherence across tissues. Circadian misalignment, often imposed in modern society, disrupts coordination among clocks and has been linked to diseases ranging from metabolic syndrome to cancer. Thus, uncovering the physiological circuits whereby biological clocks achieve coherence will inform on both challenges and opportunities in human health.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\F96HN8RP\\koronowski2021.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P772288W\\Koronowski and Sassone-Corsi - 2021 - Communicating clocks shape circadian homeostasis.pdf}
}

@article{kostalStatisticsInverseInterspike2018,
  title = {Statistics of Inverse Interspike Intervals: {{The}} Instantaneous Firing Rate Revisited},
  shorttitle = {Statistics of Inverse Interspike Intervals},
  author = {Kostal, Lubomir and Lansky, Petr and Stiber, Michael},
  date = {2018-10},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {28},
  number = {10},
  pages = {106305},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5036831},
  url = {http://aip.scitation.org/doi/10.1063/1.5036831},
  urldate = {2020-09-30},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KTQJDBMS\Kostal et al. - 2018 - Statistics of inverse interspike intervals The in.pdf}
}

@article{krakauerInformationTheoryIndividuality2020,
  title = {The Information Theory of Individuality},
  author = {Krakauer, David and Bertschinger, Nils and Olbrich, Eckehard and Flack, Jessica C. and Ay, Nihat},
  date = {2020-06},
  journaltitle = {Theory in Biosciences},
  shortjournal = {Theory Biosci.},
  volume = {139},
  number = {2},
  pages = {209--223},
  issn = {1431-7613, 1611-7530},
  doi = {10.1007/s12064-020-00313-7},
  url = {http://link.springer.com/10.1007/s12064-020-00313-7},
  urldate = {2022-09-21},
  abstract = {Despite the near universal assumption of individuality in biology, there is little agreement about what individuals are and few rigorous quantitative methods for their identification. Here, we propose that individuals are aggregates that preserve a measure of temporal integrity, i.e., “propagate” information from their past into their futures. We formalize this idea using information theory and graphical models. This mathematical formulation yields three principled and distinct forms of individuality—an organismal, a colonial, and a driven form—each of which varies in the degree of environmental dependence and inherited information. This approach can be thought of as a Gestalt approach to evolution where selection makes figure-ground (agent–environment) distinctions using suitable information-theoretic lenses. A benefit of the approach is that it expands the scope of allowable individuals to include adaptive aggregations in systems that are multi-scale, highly distributed, and do not necessarily have physical boundaries such as cell walls or clonal somatic tissue. Such individuals might be visible to selection but hard to detect by observers without suitable measurement principles. The information theory of individuality allows for the identification of individuals at all levels of organization from molecular to cultural and provides a basis for testing assumptions about the natural scales of a system and argues for the importance of uncertainty reduction through coarse-graining in adaptive systems.},
  langid = {english},
  keywords = {adaptation,coarse graining,information theory,synergy},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Q9S4KETP\Krakauer et al. - 2020 - The information theory of individuality.pdf}
}

@article{krakauerNeuroscienceNeedsBehavior2017,
  title = {Neuroscience {{Needs Behavior}}: {{Correcting}} a {{Reductionist Bias}}},
  shorttitle = {Neuroscience {{Needs Behavior}}},
  author = {Krakauer, John W. and Ghazanfar, Asif A. and Gomez-Marin, Alex and MacIver, Malcolm A. and Poeppel, David},
  date = {2017-02-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {3},
  eprint = {28182904},
  eprinttype = {pmid},
  pages = {480--490},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.12.041},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(16)31040-6},
  urldate = {2020-08-13},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9D7RDCNE\\Krakauer et al. - 2017 - Neuroscience Needs Behavior Correcting a Reductio.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9UAXXT2K\\S0896-6273(16)31040-6.html}
}

@article{krienerParvalbuminInterneuronDendrites2022,
  title = {Parvalbumin Interneuron Dendrites Enhance Gamma Oscillations},
  author = {Kriener, Birgit and Hu, Hua and Vervaeke, Koen},
  date = {2022-06-14},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {39},
  number = {11},
  pages = {110948},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2022.110948},
  url = {https://www.sciencedirect.com/science/article/pii/S2211124722007306},
  urldate = {2022-10-18},
  abstract = {Dendrites are essential determinants of the input-output relationship of single neurons, but their role in network computations is not well understood. Here, we use a combination of dendritic patch-clamp recordings and in silico modeling to determine how dendrites of parvalbumin (PV)-expressing basket cells contribute to network oscillations in the gamma frequency band. Simultaneous soma-dendrite recordings from PV basket cells in the dentate gyrus reveal that the slope, or gain, of the dendritic input-output relationship is exceptionally low, thereby reducing the cell’s sensitivity to changes in its input. By simulating gamma oscillations in detailed network models, we demonstrate that the low gain is key to increase spike synchrony in PV basket cell assemblies when cells are driven by spatially and temporally heterogeneous synaptic inputs. These results highlight the role of inhibitory neuron dendrites in synchronized network oscillations.},
  langid = {english},
  keywords = {dendritic integration,gamma oscillations,inhibitory interneurons,neural gain,neural synchrony,parvalbumin basket cells,patch clamp,synaptic integration},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HHBLTVVB\\Kriener et al. - 2022 - Parvalbumin interneuron dendrites enhance gamma os.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3IP84IPZ\\S2211124722007306.html}
}

@article{kuchibhotlaParallelProcessingCortical2017,
  title = {Parallel Processing by Cortical Inhibition Enables Context-Dependent Behavior},
  author = {Kuchibhotla, Kishore V. and Gill, Jonathan V. and Lindsay, Grace W. and Papadoyannis, Eleni S. and Field, Rachel E. and Sten, Tom A. Hindmarsh and Miller, Kenneth D. and Froemke, Robert C.},
  date = {2017-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {1},
  eprint = {27798631},
  eprinttype = {pmid},
  pages = {62--71},
  issn = {1546-1726},
  doi = {10.1038/nn.4436},
  abstract = {Physical features of sensory stimuli are fixed, but sensory perception is context dependent. The precise mechanisms that govern contextual modulation remain unknown. Here, we trained mice to switch between two contexts: passively listening to pure tones and performing a recognition task for the same stimuli. Two-photon imaging showed that many excitatory neurons in auditory cortex were suppressed during behavior, while some cells became more active. Whole-cell recordings showed that excitatory inputs were affected only modestly by context, but inhibition was more sensitive, with PV+, SOM+, and VIP+ interneurons balancing inhibition and disinhibition within the network. Cholinergic modulation was involved in context switching, with cholinergic axons increasing activity during behavior and directly depolarizing inhibitory cells. Network modeling captured these findings, but only when modulation coincidently drove all three interneuron subtypes, ruling out either inhibition or disinhibition alone as sole mechanism for active engagement. Parallel processing of cholinergic modulation by cortical interneurons therefore enables context-dependent behavior.},
  langid = {english},
  pmcid = {PMC5191967},
  keywords = {Animals,Auditory Cortex,Auditory Perception,Behavior Animal,Mice Transgenic,Neural Inhibition,Neurons,Somatostatin,Vasoactive Intestinal Peptide,Visual Cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MQGRNT5Z\Kuchibhotla et al. - 2017 - Parallel processing by cortical inhibition enables.pdf}
}

@article{lacefieldReinforcementLearningRecruits2019,
  title = {Reinforcement {{Learning Recruits Somata}} and {{Apical Dendrites}} across {{Layers}} of {{Primary Sensory Cortex}}},
  author = {Lacefield, Clay O. and Pnevmatikakis, Eftychios A. and Paninski, Liam and Bruno, Randy M.},
  date = {2019-02},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {26},
  number = {8},
  pages = {2000-2008.e2},
  issn = {22111247},
  doi = {10.1016/j.celrep.2019.01.093},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S2211124719301305},
  urldate = {2023-08-01},
  abstract = {The mammalian brain can form associations between behaviorally relevant stimuli in an animal’s environment. While such learning is thought to primarily involve high-order association cortex, even primary sensory areas receive long-range connections carrying information that could contribute to high-level representations. Here, we imaged layer 1 apical dendrites in the barrel cortex of mice performing a whisker-based operant behavior. In addition to sensory-motor events, calcium signals in apical dendrites of layers 2/3 and 5 neurons and in layer 2/3 somata track the delivery of rewards, both choice related and randomly administered. Reward-related tuft-wide dendritic spikes emerge gradually with training and are task specific. Learning recruits cells whose intrinsic activity coincides with the time of reinforcement. Layer 4 largely lacked reward-related signals, suggesting a source other than the primary thalamus. Our results demonstrate that a sensory cortex can acquire a set of associations outside its immediate sensory modality and linked to salient behavioral events.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4EYZEH6K\Lacefield et al. - 2019 - Reinforcement Learning Recruits Somata and Apical .pdf}
}

@article{lainscsekCorticalChimeraStates2019,
  title = {Cortical Chimera States Predict Epileptic Seizures},
  author = {Lainscsek, Claudia and Rungratsameetaweemana, Nuttida and Cash, Sydney S. and Sejnowski, Terrence J.},
  date = {2019-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {29},
  number = {12},
  pages = {121106},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/1.5139654},
  url = {http://aip.scitation.org/doi/10.1063/1.5139654},
  urldate = {2020-11-10},
  abstract = {A chimera state is a spatiotemporal pattern of broken symmetry, where synchrony (coherent state) and asynchrony (incoherent state) coexist. Here, we report chimera states in electrocorticography recordings preceding, by several hours, each of seven seizures in one patient with epilepsy. Before the seizures, the onset channels are not synchronized, while the remaining channels are synchronized. During the seizures, this pattern of behavior ips and the nononset channels show a more asynchronous behavior. At a seizure o set, synchrony can be observed that might facilitate termination.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XEUFDAHA\Lainscsek et al. - 2019 - Cortical chimera states predict epileptic seizures.pdf}
}

@article{lambiotteNetworksOptimalHigherorder2019,
  title = {From Networks to Optimal Higher-Order Models of Complex Systems},
  author = {Lambiotte, Renaud and Rosvall, Martin and Scholtes, Ingo},
  date = {2019-04},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {15},
  number = {4},
  pages = {313--320},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-019-0459-y},
  url = {https://www.nature.com/articles/s41567-019-0459-y},
  urldate = {2022-10-05},
  abstract = {Rich data are revealing that complex dependencies between the nodes of a network may not be captured by models based on pairwise interactions. Higher-order network models go beyond these limitations, offering new perspectives for understanding complex systems.},
  issue = {4},
  langid = {english},
  keywords = {Applied mathematics,Complex networks},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ANJ5Q7EE\\Lambiotte et al. - 2019 - From networks to optimal higher-order models of co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SZLAN4DT\\s41567-019-0459-y.html}
}

@article{landismanVPMPoMNuclei2007,
  title = {{{VPM}} and {{PoM}} Nuclei of the Rat Somatosensory Thalamus: Intrinsic Neuronal Properties and Corticothalamic Feedback},
  shorttitle = {{{VPM}} and {{PoM}} Nuclei of the Rat Somatosensory Thalamus},
  author = {Landisman, Carole E. and Connors, Barry W.},
  date = {2007-12},
  journaltitle = {Cerebral Cortex (New York, N.Y.: 1991)},
  shortjournal = {Cereb Cortex},
  volume = {17},
  number = {12},
  eprint = {17389627},
  eprinttype = {pmid},
  pages = {2853--2865},
  issn = {1460-2199},
  doi = {10.1093/cercor/bhm025},
  abstract = {Sensory information originating in individual whisker follicles ascends through focused projections to the brainstem, then to the ventral posteromedial nucleus (VPM) of the thalamus, and finally into barrels of the primary somatosensory cortex (S1). By contrast, the posteromedial complex (PoM) of the thalamus receives more diffuse sensory projections from the brainstem and projects to the interbarrel septa of S1. Both VPM and PoM receive abundant corticothalamic projections from S1. Using a thalamocortical slice preparation, we characterized differences in intrinsic neuronal properties and in responses to corticothalamic feedback in neurons of VPM and PoM. Due to the plane of the slice, the majority of our observed responses came from activation of layer VI because most or all of the layer V axons terminating in PoM are cut. We found that VPM neurons exhibit higher firing rates than PoM neurons when stimulated with injected current. Stimulation of corticothalamic fibers evoked monosynaptic excitation, disynaptic inhibition, or a combination of the two in both nuclei. A few differences in the feedback responses emerged: purely excitatory postsynaptic potentials (EPSPs) in VPM were smaller and facilitated more than those in PoM, and only the EPSPs in VPM had a strong NMDA component. For both nuclei, some of the feedback responses were purely disynaptic inhibitory postsynaptic potentials (IPSPs) from the thalamic reticular nucleus (TRN). This was due to EPSP failures within VPM and PoM combined with greater reliability of S1-originating synapses onto TRN. These findings suggest that despite the exclusively excitatory nature of corticothalamic fibers, activation of cortex can trigger excitation or inhibition in thalamic relay neurons.},
  langid = {english},
  keywords = {Afferent Pathways,Animals,Feedback,Nerve Net,Neurons Afferent,Rats,Somatosensory Cortex,Thalamus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6NKH3CKI\Landisman and Connors - 2007 - VPM and PoM nuclei of the rat somatosensory thalam.pdf}
}

@article{lankaranyDifferentiallySynchronizedSpiking2019,
  title = {Differentially Synchronized Spiking Enables Multiplexed Neural Coding},
  author = {Lankarany, Milad and Al-Basha, Dhekra and Ratté, Stéphanie and Prescott, Steven A.},
  date = {2019-05-14},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {20},
  pages = {10097--10102},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1812171116},
  url = {https://www.pnas.org/doi/10.1073/pnas.1812171116},
  urldate = {2023-03-05},
  abstract = {Multiplexing refers to the simultaneous encoding of two or more signals. Neurons have been shown to multiplex, but different stimuli require different multiplexing strategies. Whereas the frequency and amplitude of periodic stimuli can be encoded by the timing and rate of the same spikes, natural scenes, which comprise areas over which intensity varies gradually and sparse edges where intensity changes abruptly, require a different multiplexing strategy. Recording in vivo from neurons in primary somatosensory cortex during tactile stimulation, we found that stimulus onset and offset (edges) evoked highly synchronized spiking, whereas other spikes in the same neurons occurred asynchronously. Stimulus intensity modulated the rate of asynchronous spiking, but did not affect the timing of synchronous spikes. From this, we hypothesized that spikes driven by high- and low-contrast stimulus features can be distinguished on the basis of their synchronization, and that differentially synchronized spiking can thus be used to form multiplexed representations. Applying a Bayesian decoding method, we verified that information about high- and low-contrast features can be recovered from an ensemble of model neurons receiving common input. Equally good decoding was achieved by distinguishing synchronous from asynchronous spikes and applying reverse correlation methods separately to each spike type. This result, which we verified with patch clamp recordings in vitro, demonstrates that neurons receiving common input can use the rate of asynchronous spiking to encode the intensity of low-contrast features while using the timing of synchronous spikes to encode the occurrence of high-contrast features. We refer to this strategy as synchrony-division multiplexing.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KI7NNZRW\Lankarany et al. - 2019 - Differentially synchronized spiking enables multip.pdf}
}

@article{larkumCalciumElectrogenesisDistal1999,
  title = {Calcium Electrogenesis in Distal Apical Dendrites of Layer 5 Pyramidal Cells at a Critical Frequency of Back-Propagating Action Potentials},
  author = {Larkum, M. E. and Kaiser, K. M. M. and Sakmann, B.},
  date = {1999-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proceedings of the National Academy of Sciences},
  volume = {96},
  number = {25},
  pages = {14600--14604},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.96.25.14600},
  url = {http://www.pnas.org/cgi/doi/10.1073/pnas.96.25.14600},
  urldate = {2020-09-02},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6RMSCZEU\Larkum et al. - 1999 - Calcium electrogenesis in distal apical dendrites .pdf}
}

@article{larkumCellularMechanismCortical2013,
  title = {A Cellular Mechanism for Cortical Associations: An Organizing Principle for the Cerebral Cortex},
  shorttitle = {A Cellular Mechanism for Cortical Associations},
  author = {Larkum, Matthew},
  date = {2013-03},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {36},
  number = {3},
  pages = {141--151},
  issn = {01662236},
  doi = {10.1016/j.tins.2012.11.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0166223612002032},
  urldate = {2021-03-23},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MILLESZH\Larkum - 2013 - A cellular mechanism for cortical associations an.pdf}
}

@article{larkumDendriticSpikesApical2007,
  title = {Dendritic {{Spikes}} in {{Apical Dendrites}} of {{Neocortical Layer}} 2/3 {{Pyramidal Neurons}}},
  author = {Larkum, Matthew Evan and Waters, Jack and Sakmann, Bert and Helmchen, Fritjof},
  date = {2007-08-22},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J Neurosci},
  volume = {27},
  number = {34},
  eprint = {17715337},
  eprinttype = {pmid},
  pages = {8999--9008},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.1717-07.2007},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6672209/},
  urldate = {2023-02-01},
  abstract = {Layer 2/3 (L2/3) pyramidal neurons are the most abundant cells of the neocortex. Despite their key position in the cortical microcircuit, synaptic integration in dendrites of L2/3 neurons is far less understood than in L5 pyramidal cell dendrites, mainly because of the difficulties in obtaining electrical recordings from thin dendrites. Here we directly measured passive and active properties of the apical dendrites of L2/3 neurons in rat brain slices using dual dendritic–somatic patch-clamp recordings and calcium imaging. Unlike L5 cells, L2/3 dendrites displayed little sag in response to long current pulses, which suggests a low density of Ih in the dendrites and soma. This was also consistent with a slight increase in input resistance with distance from the soma. Brief current injections into the apical dendrite evoked relatively short (half-width 2–4 ms) dendritic spikes that were isolated from the soma for near-threshold currents at sites beyond the middle of the apical dendrite. Regenerative dendritic potentials and large concomitant calcium transients were also elicited by trains of somatic action potentials (APs) above a critical frequency (130 Hz), which was slightly higher than in L5 neurons. Initiation of dendritic spikes was facilitated by backpropagating somatic APs and could cause an additional AP at the soma. As in L5 neurons, we found that distal dendritic calcium transients are sensitive to a long-lasting block by GABAergic inhibition. We conclude that L2/3 pyramidal neurons can generate dendritic spikes, sharing with L5 pyramidal neurons fundamental properties of dendritic excitability and control by inhibition.},
  pmcid = {PMC6672209},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4F2ABUZV\Larkum et al. - 2007 - Dendritic Spikes in Apical Dendrites of Neocortica.pdf}
}

@article{larkumNewCellularMechanism1999,
  title = {A New Cellular Mechanism for Coupling Inputs Arriving at Different Cortical Layers},
  author = {Larkum, Matthew E. and Zhu, J. Julius and Sakmann, Bert},
  date = {1999-03},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {398},
  number = {6725},
  pages = {338--341},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/18686},
  url = {http://www.nature.com/articles/18686},
  urldate = {2020-09-02},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UTWC2UTY\Larkum et al. - 1999 - A new cellular mechanism for coupling inputs arriv.pdf}
}

@article{larkumTopdownDendriticInput2004,
  title = {✅ {{Top-down Dendritic Input Increases}} the {{Gain}} of {{Layer}} 5 {{Pyramidal Neurons}}},
  author = {Larkum, Matthew E. and Senn, Walter and Lüscher, Hans-R.},
  date = {2004-10-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {14},
  number = {10},
  pages = {1059--1070},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhh065},
  url = {https://doi.org/10.1093/cercor/bhh065},
  urldate = {2022-10-13},
  abstract = {The cerebral cortex is organized so that an important component of feedback input from higher to lower cortical areas arrives at the distal apical tufts of pyramidal neurons. Yet, distal inputs are predicted to have much less impact on firing than proximal inputs. Here we show that even weak asynchronous dendritic input to the distal tuft region can significantly increase the gain of layer 5 pyramidal neurons and thereby the output of columns in the primary somatosensory cortex of the rat. Noisy currents injected in ramps at different dendritic locations showed that the initial slope of the frequency–current (f/I) relationship increases with the distance of the current injection from the soma. The increase was due to the interaction of dendritic depolarization with back-propagating APs which activated dendritic calcium conductances. Gain increases were accompanied by a change of firing mode from isolated spikes to bursting where the timing of bursts coded the presence of coincident somatic and dendritic inputs. We propose that this dendritic gain modulation and the timing of bursts may serve to associate top-down and bottom-up input on different time scales.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9SL6VH6E\\Larkum et al. - 2004 - Top-down Dendritic Input Increases the Gain of Lay.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TJQPSLSR\\275677.html}
}

@article{lavzinNonlinearDendriticProcessing2012,
  title = {Nonlinear Dendritic Processing Determines Angular Tuning of Barrel Cortex Neurons in Vivo},
  author = {Lavzin, Maria and Rapoport, Sophia and Polsky, Alon and Garion, Liora and Schiller, Jackie},
  date = {2012-10},
  journaltitle = {Nature},
  volume = {490},
  number = {7420},
  pages = {397--401},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature11451},
  url = {https://www.nature.com/articles/nature11451},
  urldate = {2022-09-02},
  abstract = {In vivo whole-cell recordings combined with an intracellular N-methyl-d-aspartate receptor (NMDAR) blocker and membrane hyperpolarization are used to examine the contribution of dendritic NMDAR-dependent regenerative responses to the angular tuning of layer 4 neurons; the results show that active dendritic processing sharpens the sensory responses of cortical neurons in vivo.},
  issue = {7420},
  langid = {english},
  keywords = {Action potential generation,Sensorimotor processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6IHP82TD\Lavzin et al. - 2012 - Nonlinear dendritic processing determines angular .pdf}
}

@article{lawhernPopulationDecodingMotor2010,
  title = {Population {{Decoding}} of {{Motor Cortical Activity}} Using a {{Generalized Linear Model}} with {{Hidden States}}},
  author = {Lawhern, Vernon and Wu, Wei and Hatsopoulos, Nicholas G. and Paninski, Liam},
  date = {2010-06-15},
  journaltitle = {Journal of neuroscience methods},
  shortjournal = {J Neurosci Methods},
  volume = {189},
  number = {2},
  eprint = {20359500},
  eprinttype = {pmid},
  pages = {267--280},
  issn = {0165-0270},
  doi = {10.1016/j.jneumeth.2010.03.024},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2921213/},
  urldate = {2024-07-16},
  abstract = {Generalized linear models (GLMs) have been developed for modeling and decoding population neuronal spiking activity in the motor cortex. These models provide reasonable characterizations between neural activity and motor behavior. However, they lack a description of movement-related terms which are not observed directly in these experiments, such as muscular activation, the subject's level of attention, and other internal or external states. Here we propose to include a multi-dimensional hidden state to address these states in a GLM framework where the spike count at each time is described as a function of the hand state (position, velocity, and acceleration), truncated spike history, and the hidden state. The model can be identified by an Expectation-Maximization algorithm. We tested this new method in two datasets where spikes were simultaneously recorded using a multi-electrode array in the primary motor cortex of two monkeys. It was found that this method significantly improves the model-fitting over the classical GLM, for hidden dimensions varying from 1 to 4. This method also provides more accurate decoding of hand state (lowering the Mean Square Error by up to 29\% in some cases), while retaining real-time computational efficiency. These improvements on representation and decoding over the classical GLM model suggest that this new approach could contribute as a useful tool to motor cortical decoding and prosthetic applications.},
  pmcid = {PMC2921213},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\32478PU2\Lawhern et al. - 2010 - Population Decoding of Motor Cortical Activity usi.pdf}
}

@video{LectureWalkthroughMammalian,
  entrysubtype = {video},
  title = {Lecture 1: {{A Walk-through}} of the {{Mammalian Visual System}}},
  shorttitle = {Lecture 1},
  url = {https://www.youtube.com/watch?v=mtPgW1ebxmE&t=2278s},
  urldate = {2020-09-25},
  abstract = {From the retina to the superior colliculus, the lateral geniculate nucleus into primary visual cortex and beyond, R. Clay Reid gives a tour of the mammalian visual system highlighting the Nobel-prize winning discoveries of Hubel \&amp; Wiesel. This is the first lecture of a 12-part series entitled Coding \&amp; Vision 101, produced by the Allen Institute for Brain Science as an educational resource for the community.}
}

@article{leeActivationSpecificInterneurons2012,
  title = {Activation of Specific Interneurons Improves {{V1}} Feature Selectivity and Visual Perception},
  author = {Lee, Seung-Hee and Kwan, Alex C. and Zhang, Siyu and Phoumthipphavong, Victoria and Flannery, John G. and Masmanidis, Sotiris C. and Taniguchi, Hiroki and Huang, Z. Josh and Zhang, Feng and Boyden, Edward S. and Deisseroth, Karl and Dan, Yang},
  date = {2012-08-16},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {488},
  number = {7411},
  eprint = {22878719},
  eprinttype = {pmid},
  pages = {379--383},
  issn = {1476-4687},
  doi = {10.1038/nature11312},
  abstract = {Inhibitory interneurons are essential components of the neural circuits underlying various brain functions. In the neocortex, a large diversity of GABA (γ-aminobutyric acid) interneurons has been identified on the basis of their morphology, molecular markers, biophysical properties and innervation pattern. However, how the activity of each subtype of interneurons contributes to sensory processing remains unclear. Here we show that optogenetic activation of parvalbumin-positive (PV+) interneurons in the mouse primary visual cortex (V1) sharpens neuronal feature selectivity and improves perceptual discrimination. Using multichannel recording with silicon probes and channelrhodopsin-2 (ChR2)-mediated optical activation, we found that increased spiking of PV+ interneurons markedly sharpened orientation tuning and enhanced direction selectivity of nearby neurons. These effects were caused by the activation of inhibitory neurons rather than a decreased spiking of excitatory neurons, as archaerhodopsin-3 (Arch)-mediated optical silencing of calcium/calmodulin-dependent protein kinase IIα (CAMKIIα)-positive excitatory neurons caused no significant change in V1 stimulus selectivity. Moreover, the improved selectivity specifically required PV+ neuron activation, as activating somatostatin or vasointestinal peptide interneurons had no significant effect. Notably, PV+ neuron activation in awake mice caused a significant improvement in their orientation discrimination, mirroring the sharpened V1 orientation tuning. Together, these results provide the first demonstration that visual coding and perception can be improved by increased spiking of a specific subtype of cortical inhibitory interneurons.},
  langid = {english},
  pmcid = {PMC3422431},
  keywords = {Animals,Calcium-Calmodulin-Dependent Protein Kinase Type 2,Channelrhodopsins,Discrimination Learning,gamma-Aminobutyric Acid,Interneurons,Mice,Models Neurological,Neural Inhibition,Parvalbumins,Rhodopsins Microbial,Visual Cortex,Visual Perception,Wakefulness},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\59YYI44H\Lee et al. - 2012 - Activation of specific interneurons improves V1 fe.pdf}
}

@article{leeHippocampalPlaceFields2012,
  title = {Hippocampal {{Place Fields Emerge}} upon {{Single-Cell Manipulation}} of {{Excitability During Behavior}}},
  author = {Lee, Doyun and Lin, Bei-Jung and Lee, Albert K.},
  date = {2012-08-17},
  journaltitle = {Science},
  volume = {337},
  number = {6096},
  pages = {849--853},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1221489},
  url = {https://www.science.org/doi/10.1126/science.1221489},
  urldate = {2023-04-16},
  abstract = {The origin of the spatial receptive fields of hippocampal place cells has not been established. A hippocampal CA1 pyramidal cell receives thousands of synaptic inputs, mostly from other spatially tuned neurons; however, how the postsynaptic neuron’s cellular properties determine the response to these inputs during behavior is unknown. We discovered that, contrary to expectations from basic models of place cells and neuronal integration, a small, spatially uniform depolarization of the spatially untuned somatic membrane potential of a silent cell leads to the sudden and reversible emergence of a spatially tuned subthreshold response and place-field spiking. Such gating of inputs by postsynaptic neuronal excitability reveals a cellular mechanism for receptive field origin and may be critical for the formation of hippocampal memory representations.}
}

@article{lefortExcitatoryNeuronalNetwork2009,
  title = {The {{Excitatory Neuronal Network}} of the {{C2 Barrel Column}} in {{Mouse Primary Somatosensory Cortex}}},
  author = {Lefort, Sandrine and Tomm, Christian and Sarria, J.-C. Floyd and Petersen, Carl C. H.},
  date = {2009-01-29},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {61},
  number = {2},
  eprint = {19186171},
  eprinttype = {pmid},
  pages = {301--316},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2008.12.020},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(08)01092-1},
  urldate = {2023-04-10},
  langid = {english},
  keywords = {SYSNEURO},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YLRVYQH8\Lefort et al. - 2009 - The Excitatory Neuronal Network of the C2 Barrel C.pdf}
}

@article{legatesLightCentralModulator2014,
  title = {✅  {{Light}} as a Central Modulator of Circadian Rhythms, Sleep and Affect},
  author = {LeGates, Tara A. and Fernandez, Diego C. and Hattar, Samer},
  date = {2014-07},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {15},
  number = {7},
  pages = {443--454},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn3743},
  url = {https://www.nature.com/articles/nrn3743},
  urldate = {2023-02-27},
  abstract = {Extreme light conditions, as experienced in shift-work schedules, shortened day length during winter months or transmeridian travel, can cause negative health effects, which include cognitive deficits and mood alterations.Aberrant light schedules can cause circadian rhythm alterations and/or sleep disruptions, leading to mood disorders and depression-like states. This has led to a model in which the negative effects of irregular light on mood and cognitive functions are secondary to circadian and/or sleep disruptions.However, light can also directly influence mood and learning without causing circadian arrhythmicity or sleep disruptions.Intrinsically photosensitive retinal ganglion cells (ipRGCs) project to a wide range of brain regions, including areas that have been associated with mood and anxiety. These cells emerge as leading candidates for mediating the direct effects of irregular light on mood.Rodent models have been used to define the mechanisms involved in the effects of light on circadian rhythms, sleep and mood. Several animal models and light schedules were used to recapitulate important aspects of irregular light schedules observed in humans, which cause mood and cognitive disorders.A better understanding of the connections that ipRGCs form in the brain and their influence on circadian, sleep and mood controlling centres will be the first step to determine the comprehensive role of light on these complex, inter-related behaviours.},
  issue = {7},
  langid = {english},
  keywords = {Circadian regulation,Emotion,Sleep},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DB9P6KZC\LeGates et al. - 2014 - Light as a central modulator of circadian rhythms,.pdf}
}

@article{lengyelComputationalTheoriesFunction2005,
  title = {Computational Theories on the Function of Theta Oscillations},
  author = {Lengyel, Máté and Huhn, Zsófia and Érdi, Péter},
  date = {2005-06-01},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol Cybern},
  volume = {92},
  number = {6},
  pages = {393--408},
  issn = {1432-0770},
  doi = {10.1007/s00422-005-0567-x},
  url = {https://doi.org/10.1007/s00422-005-0567-x},
  urldate = {2023-03-24},
  abstract = {Neural rhythms can be studied in terms of conditions for their generation, or in terms of their functional significance. The theta oscillation is a particularly prominent rhythm, reported to be present in many brain areas, and related to many important cognitive processes. The generating mechanisms of theta have extensively been studied and reviewed elsewhere; here we discuss ideas that have accumulated over the past decades on the computational roles it may subserve. Theories propose different aspects of theta oscillations as being relevant for their cognitive functions: limit cycle oscillations in neuronal firing rates, subthreshold membrane potential oscillations, periodic modulation of synaptic transmission and plasticity, and phase precession of hippocampal place cells. The relevant experimental data is briefly summarized in the light of these theories. Specific models proposing a function for theta in pattern recognition, memory, sequence learning and navigation are reviewed critically. Difficulties with testing and comparing alternative models are discussed, along with potentially important future research directions in the field.},
  langid = {english},
  keywords = {Firing Rate,Neuronal Firing,Place Cell,Potential Oscillation,Sequence Learning},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KEBIKATQ\Lengyel et al. - 2005 - Computational theories on the function of theta os.pdf}
}

@article{leutgebDistinctEnsembleCodes2004,
  title = {Distinct {{Ensemble Codes}} in {{Hippocampal Areas CA3}} and {{CA1}}},
  author = {Leutgeb, Stefan and Leutgeb, Jill K. and Treves, Alessandro and Moser, May-Britt and Moser, Edvard I.},
  date = {2004-08-27},
  journaltitle = {Science},
  volume = {305},
  number = {5688},
  pages = {1295--1298},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1100265},
  url = {https://www.science.org/doi/10.1126/science.1100265},
  urldate = {2023-04-17},
  abstract = {The hippocampus has differentiated into an extensively connected recurrent stage (CA3) followed by a feed-forward stage (CA1). We examined the function of this structural differentiation by determining how cell ensembles in rat CA3 and CA1 generate representations of rooms with common spatial elements. In CA3, distinct subsets of pyramidal cells were activated in each room, regardless of the similarity of the testing enclosure. In CA1, the activated populations overlapped, and the overlap increased in similar enclosures. After exposure to a novel room, ensemble activity developed slower in CA3 than CA1, suggesting that the representations emerged independently.}
}

@article{levinaDynamicalSynapsesCausing2007,
  title = {Dynamical Synapses Causing Self-Organized Criticality in Neural Networks},
  author = {Levina, A. and Herrmann, J. M. and Geisel, T.},
  date = {2007-12},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {3},
  number = {12},
  pages = {857--860},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys758},
  url = {https://www.nature.com/articles/nphys758},
  urldate = {2022-10-03},
  abstract = {Self-organized criticality1 is one of the key concepts to describe the emergence of complexity in natural systems. The concept asserts that a system self-organizes into a critical state where system observables are distributed according to a power law. Prominent examples of self-organized critical dynamics include piling of granular media2, plate tectonics3 and stick–slip motion4. Critical behaviour has been shown to bring about optimal computational capabilities5, optimal transmission6, storage of information7 and sensitivity to sensory stimuli8,9,10. In neuronal systems, the existence of critical avalanches was predicted11 and later observed experimentally6,12,13. However, whereas in the experiments generic critical avalanches were found, in the model of ref.~11 they only show up if the set of parameters is fine-tuned externally to a critical transition state. Here, we demonstrate analytically and numerically that by assuming (biologically more realistic) dynamical synapses14 in a spiking neural network, the neuronal avalanches turn from an exceptional phenomenon into a typical and robust self-organized critical behaviour, if the total resources of neurotransmitter are sufficiently large.},
  issue = {12},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7KYABN2M\\Levina et al. - 2007 - Dynamical synapses causing self-organized critical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2XEEWP6E\\nphys758.html}
}

@article{liDistinctSubnetworksThalamic2020,
  title = {Distinct Subnetworks of the Thalamic Reticular Nucleus},
  author = {Li, Yinqing and Lopez-Huerta, Violeta G. and Adiconis, Xian and Levandowski, Kirsten and Choi, Soonwook and Simmons, Sean K. and Arias-Garcia, Mario A. and Guo, Baolin and Yao, Annie Y. and Blosser, Timothy R. and Wimmer, Ralf D. and Aida, Tomomi and Atamian, Alexander and Naik, Tina and Sun, Xuyun and Bi, Dasheng and Malhotra, Diya and Hession, Cynthia C. and Shema, Reut and Gomes, Marcos and Li, Taibo and Hwang, Eunjin and Krol, Alexandra and Kowalczyk, Monika and Peça, João and Pan, Gang and Halassa, Michael M. and Levin, Joshua Z. and Fu, Zhanyan and Feng, Guoping},
  date = {2020-07},
  journaltitle = {Nature},
  volume = {583},
  number = {7818},
  pages = {819--824},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2504-5},
  url = {https://www.nature.com/articles/s41586-020-2504-5},
  urldate = {2024-07-08},
  abstract = {The thalamic reticular nucleus (TRN), the major source of thalamic inhibition, regulates thalamocortical interactions that are critical for sensory processing, attention and cognition1–5. TRN dysfunction has been linked to sensory abnormality, attention deficit and sleep disturbance across multiple neurodevelopmental disorders6–9. However, little is known about the organizational principles that~underlie its divergent functions. Here we performed an integrative study linking single-cell molecular and electrophysiological features of the mouse TRN to connectivity and systems-level function. We found that cellular heterogeneity in the TRN is characterized by a transcriptomic gradient of two negatively correlated gene-expression profiles, each containing hundreds of genes. Neurons in the extremes of this transcriptomic gradient express mutually exclusive markers, exhibit core or shell-like anatomical structure and have distinct electrophysiological properties. The two TRN subpopulations make differential connections with the functionally distinct first-order and higher-order thalamic nuclei to form molecularly defined TRN–thalamus subnetworks. Selective perturbation of the two subnetworks in vivo revealed their differential role in regulating sleep. In sum, our study provides a comprehensive atlas of TRN neurons at single-cell resolution and links molecularly defined subnetworks to the functional organization of thalamocortical circuits.},
  langid = {english},
  keywords = {Molecular neuroscience,Neural circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3JEGW6BL\Li et al. - 2020 - Distinct subnetworks of the thalamic reticular nuc.pdf}
}

@article{limInferringLearningRules2015,
  title = {Inferring Learning Rules from Distributions of Firing Rates in Cortical Neurons},
  author = {Lim, Sukbin and McKee, Jillian L. and Woloszyn, Luke and Amit, Yali and Freedman, David J. and Sheinberg, David L. and Brunel, Nicolas},
  date = {2015-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {12},
  pages = {1804--1810},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4158},
  url = {https://www.nature.com/articles/nn.4158},
  urldate = {2024-01-08},
  abstract = {Experience-dependent synaptic modifications are one of the fundamental mechanisms of learning and memory, yet they are difficult to measure in vivo. Here the authors introduce a network model–based method that infers synaptic plasticity rules from the analysis of the statistics of neuronal responses to novel versus familiar stimuli.},
  issue = {12},
  langid = {english},
  keywords = {Long-term memory,Network models,Neural circuits,Synaptic plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\F272IGBY\Lim et al. - 2015 - Inferring learning rules from distributions of fir.pdf}
}

@article{linaroCorrelationTransferLayer2019,
  title = {Correlation {{Transfer}} by {{Layer}} 5 {{Cortical Neurons Under Recreated Synaptic Inputs}} {{{\emph{In Vitro}}}}},
  author = {Linaro, Daniele and Ocker, Gabriel K. and Doiron, Brent and Giugliano, Michele},
  date = {2019-09-25},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {39},
  number = {39},
  pages = {7648--7663},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3169-18.2019},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.3169-18.2019},
  urldate = {2023-08-28},
  abstract = {Correlated electrical activity in neurons is a prominent characteristic of cortical microcircuits. Despite a growing amount of evidence concerning both spike-count and subthreshold membrane potential pairwise correlations, little is known about how different types of cortical neurons convert correlated inputs into correlated outputs. We studied pyramidal neurons and two classes of GABAergic interneurons of layer 5 in neocortical brain slices obtained from rats of both sexes, and we stimulated them with biophysically realistic correlated inputs, generated using dynamic clamp. We found that the physiological differences between cell types manifested unique features in their capacity to transfer correlated inputs. We used linear response theory and computational modeling to gain clear insights into how cellular properties determine both the gain and timescale of correlation transfer, thus tying single-cell features with network interactions. Our results provide further ground for the functionally distinct roles played by various types of neuronal cells in the cortical microcircuit.                            SIGNIFICANCE STATEMENT               No matter how we probe the brain, we find correlated neuronal activity over a variety of spatial and temporal scales. For the cerebral cortex, significant evidence has accumulated on trial-to-trial covariability in synaptic inputs activation, subthreshold membrane potential fluctuations, and output spike trains. Although we do not yet fully understand their origin and whether they are detrimental or beneficial for information processing, we believe that clarifying how correlations emerge is pivotal for understanding large-scale neuronal network dynamics and computation. Here, we report quantitative differences between excitatory and inhibitory cells, as they relay input correlations into output correlations. We explain this heterogeneity by simple biophysical models and provide the most experimentally validated test of a theory for the emergence of correlations.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2BFTFJMA\Linaro et al. - 2019 - Correlation Transfer by Layer 5 Cortical Neurons U.pdf}
}

@article{lindsayAttentionPsychologyNeuroscience2020,
  title = {Attention in {{Psychology}}, {{Neuroscience}}, and {{Machine Learning}}},
  author = {Lindsay, Grace W.},
  date = {2020},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {14},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2020.00029},
  urldate = {2023-01-18},
  abstract = {Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7CGZEUA9\Lindsay - 2020 - Attention in Psychology, Neuroscience, and Machine.pdf}
}

@article{liNeuralCodeNeural2017,
  title = {Neural {{Code}}—{{Neural Self-information Theory}} on {{How Cell-Assembly Code Rises}} from {{Spike Time}} and {{Neuronal Variability}}},
  author = {Li, Meng and Tsien, Joe Z.},
  date = {2017},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {11},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2017.00236},
  urldate = {2022-10-17},
  abstract = {A major stumbling block to cracking the real-time neural code is neuronal variability - neurons discharge spikes with enormous variability not only across trials within the same experiments but also in resting states. Such variability is widely regarded as a noise which is often deliberately averaged out during data analyses. In contrast to such a dogma, we put forth the Neural Self-Information Theory that neural coding is operated based on the self-information principle under which variability in the time durations of inter-spike-intervals (ISI), or neuronal silence durations, is self-tagged with discrete information. As the self-information processor, each ISI carries a certain amount of information based on its variability-probability distribution; higher-probability ISIs which reflect the balanced excitation-inhibition ground state convey minimal information, whereas lower-probability ISIs which signify rare-occurrence surprisals in the form of extremely transient or prolonged silence carry most information. These variable silence durations are naturally coupled with intracellular biochemical cascades, energy equilibrium and dynamic regulation of protein and gene expression levels. As such, this silence variability-based self-information code is completely intrinsic to the neurons themselves, with no need for outside observers to set any reference point as typically used in the rate code, population code and temporal code models. Moreover, temporally coordinated ISI surprisals across cell population can inherently give rise to robust real-time cell-assembly codes which can be readily sensed by the downstream neural clique assemblies. One immediate utility of this self-information code is a general decoding strategy to uncover a variety of cell-assembly patterns underlying external and internal categorical or continuous variables in an unbiased manner.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\C6IPDQPB\Li and Tsien - 2017 - Neural Code—Neural Self-information Theory on How .pdf}
}

@article{liptonKuramotoModelSphere2021,
  title = {The {{Kuramoto}} Model on a Sphere: {{Explaining}} Its Low-Dimensional Dynamics with Group Theory and Hyperbolic Geometry},
  shorttitle = {The {{Kuramoto}} Model on a Sphere},
  author = {Lipton, Max and Mirollo, Renato and Strogatz, Steven H.},
  date = {2021-09},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {31},
  number = {9},
  pages = {093113},
  publisher = {American Institute of Physics},
  issn = {1054-1500},
  doi = {10.1063/5.0060233},
  url = {https://aip.scitation.org/doi/abs/10.1063/5.0060233},
  urldate = {2022-10-05},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZEW7R9PM\Lipton et al. - 2021 - The Kuramoto model on a sphere Explaining its low.pdf}
}

@article{lismanThetaGammaNeuralCode2013,
  title = {The {{Theta-Gamma Neural Code}}},
  author = {Lisman, John E. and Jensen, Ole},
  date = {2013-03-20},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {77},
  number = {6},
  eprint = {23522038},
  eprinttype = {pmid},
  pages = {1002--1016},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.03.007},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(13)00231-6},
  urldate = {2023-03-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\G63MXVL5\Lisman and Jensen - 2013 - The Theta-Gamma Neural Code.pdf}
}

@unpublished{liStatisticalMechanicsDeep2020,
  title = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}: {{The Back-Propagating Renormalization Group}}},
  shorttitle = {Statistical {{Mechanics}} of {{Deep Linear Neural Networks}}},
  author = {Li, Qianyi and Sompolinsky, Haim},
  date = {2020-12-07},
  eprint = {2012.04030},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/2012.04030},
  urldate = {2021-03-04},
  abstract = {The success of deep learning in many real-world tasks has triggered an effort to theoretically understand the power and limitations of deep learning in training and generalization of complex tasks, so far with limited progress. In this work, we study the statistical mechanics of learning in Deep Linear Neural Networks (DLNNs) in which the input-output function of an individual unit is linear. Despite the linearity of the units, learning in DLNNs is highly nonlinear, hence studying its properties reveals some of the essential features of nonlinear Deep Neural Networks (DNNs). We solve exactly the network properties following supervised learning using an equilibrium Gibbs distribution in the weight space. To do this, we introduce the Back-Propagating Renormalization Group (BPRG) which allows for the incremental integration of the network weights layer by layer from the network output layer and progressing backward. This procedure allows us to evaluate important network properties such as its generalization error, the role of network width and depth, the impact of the size of the training set, and the effects of weight regularization and learning stochasticity. Furthermore, by performing partial integration of layers, BPRG allows us to compute the emergent properties of the neural representations across the different hidden layers. We have proposed a heuristic extension of the BPRG to nonlinear DNNs with rectified linear units (ReLU). Surprisingly, our numerical simulations reveal that despite the nonlinearity, the predictions of our theory are largely shared by ReLU networks with modest depth, in a wide regime of parameters. Our work is the first exact statistical mechanical study of learning in a family of Deep Neural Networks, and the first development of the Renormalization Group approach to the weight space of these systems.},
  keywords = {Computer Science - Machine Learning,Physics - Applied Physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SBDNST6E\\Li and Sompolinsky - 2020 - Statistical Mechanics of Deep Linear Neural Networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A7ID7JS8\\2012.html}
}

@article{liuCellularConstructionCircadian1997,
  title = {Cellular {{Construction}} of a {{Circadian Clock}}: {{Period Determination}} in the {{Suprachiasmatic Nuclei}}},
  shorttitle = {Cellular {{Construction}} of a {{Circadian Clock}}},
  author = {Liu, Chen and Weaver, David R. and Strogatz, Steven H. and Reppert, Steven M.},
  date = {1997-12-12},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {91},
  number = {6},
  eprint = {9413994},
  eprinttype = {pmid},
  pages = {855--860},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/S0092-8674(00)80473-0},
  url = {https://www.cell.com/cell/abstract/S0092-8674(00)80473-0},
  urldate = {2023-01-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\453YPBKU\Liu et al. - 1997 - Cellular Construction of a Circadian Clock Period.pdf}
}

@online{livezeyNotOptimalJust2022,
  title = {Not Optimal, Just Noisy: The Geometry of Correlated Variability Leads to Highly Suboptimal Sensory Coding},
  shorttitle = {Not Optimal, Just Noisy},
  author = {Livezey, Jesse A. and Sachdeva, Pratik S. and Dougherty, Maximilian E. and Summers, Mathew T. and Bouchard, Kristofer E.},
  date = {2022-03-09},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.03.08.483488},
  doi = {10.1101/2022.03.08.483488},
  url = {https://www.biorxiv.org/content/10.1101/2022.03.08.483488v1},
  urldate = {2023-01-13},
  abstract = {The brain represents the world through the activity of neural populations. Correlated variability across simultaneously recorded neurons (noise correlations) has been observed across cortical areas and experimental paradigms. Many studies have shown that correlated variability improves stimulus coding compared to a null model with no correlations. However, such results do not shed light on whether neural populations’ correlated variability achieves optimal coding. Here, we assess optimality of noise correlations in diverse datasets by developing two novel null models each with a unique biological interpretation: a uniform correlations null model and a factor analysis null model. We show that across datasets, the correlated variability in neural populations leads to highly suboptimal coding performance according to these null models. We demonstrate that biological constraints prevent many subsets of the neural populations from achieving optimality according to these null models, and that subselecting based on biological criteria leaves coding performance suboptimal. Finally, we show that the optimal subpopulation is exponentially small as a function of neural dimensionality. Together, these results show that the geometry of correlated variability leads to highly suboptimal sensory coding.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9E5CIKTX\Livezey et al. - 2022 - Not optimal, just noisy the geometry of correlate.pdf}
}

@article{londonConductingSynapticMusic2004,
  title = {Conducting Synaptic Music in Dendrites},
  author = {London, Michael and Segev, Idan},
  date = {2004-09},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {7},
  number = {9},
  pages = {904--905},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn0904-904},
  url = {https://www.nature.com/articles/nn0904-904},
  urldate = {2022-10-05},
  abstract = {Thousands of active synapses on the dendrites drastically increase membrane conductance. Williams now shows that local processing is unaffected by conductance changes in distant regions, highlighting how functionally independent dendritic regions interact.},
  issue = {9},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FAY7K47F\\London and Segev - 2004 - Conducting synaptic music in dendrites.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\N4P8QATB\\nn0904-904.html}
}

@article{londonDendriticComputation2005,
  title = {Dendritic {{Computation}}},
  author = {London, Michael and Häusser, Michael},
  date = {2005},
  journaltitle = {Annual Review of Neuroscience},
  volume = {28},
  number = {1},
  eprint = {16033324},
  eprinttype = {pmid},
  pages = {503--532},
  doi = {10.1146/annurev.neuro.28.061604.135703},
  url = {https://doi.org/10.1146/annurev.neuro.28.061604.135703},
  urldate = {2022-09-08},
  abstract = {One of the central questions in neuroscience is how particular tasks, or computations, are implemented by neural networks to generate behavior. The prevailing view has been that information processing in neural networks results primarily from the properties of synapses and the connectivity of neurons within the network, with the intrinsic excitability of single neurons playing a lesser role. As a consequence, the contribution of single neurons to computation in the brain has long been underestimated. Here we review recent work showing that neuronal dendrites exhibit a range of linear and nonlinear mechanisms that allow them to implement elementary computations. We discuss why these dendritic properties may be essential for the computations performed by the neuron and the network and provide theoretical and experimental examples to support this view.},
  keywords = {coding,dendrites,ion channels,spikes,synaptic integration}
}

@article{lotfiStatisticalComplexityMaximized2021,
  title = {Statistical Complexity Is Maximized Close to Criticality in Cortical Dynamics},
  author = {Lotfi, Nastaran and Feliciano, Thaís and Aguiar, Leandro A. A. and Silva, Thais Priscila Lima and Carvalho, Tawan T. A. and Rosso, Osvaldo A. and Copelli, Mauro and Matias, Fernanda S. and Carelli, Pedro V.},
  date = {2021-01-25},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {103},
  number = {1},
  pages = {012415},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.103.012415},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.103.012415},
  urldate = {2022-10-02},
  abstract = {Complex systems are typically characterized as an intermediate situation between a complete regular structure and a random system. Brain signals can be studied as a striking example of such systems: cortical states can range from highly synchronous and ordered neuronal activity (with higher spiking variability) to desynchronized and disordered regimes (with lower spiking variability). It has been recently shown, by testing independent signatures of criticality, that a phase transition occurs in a cortical state of intermediate spiking variability. Here we use a symbolic information approach to show that, despite the monotonical increase of the Shannon entropy between ordered and disordered regimes, we can determine an intermediate state of maximum complexity based on the Jensen disequilibrium measure. More specifically, we show that statistical complexity is maximized close to criticality for cortical spiking data of urethane-anesthetized rats, as well as for a network model of excitable elements that presents a critical point of a nonequilibrium phase transition.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6RIL64QJ\Lotfi et al. - 2021 - Statistical complexity is maximized close to criti.pdf}
}

@article{luCurrentDirectionsVisual2022,
  title = {Current Directions in Visual Perceptual Learning},
  author = {Lu, Zhong-Lin and Dosher, Barbara Anne},
  date = {2022-11},
  journaltitle = {Nature reviews psychology},
  shortjournal = {Nat Rev Psychol},
  volume = {1},
  number = {11},
  eprint = {37274562},
  eprinttype = {pmid},
  pages = {654--668},
  issn = {2731-0574},
  doi = {10.1038/s44159-022-00107-2},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10237053/},
  urldate = {2024-02-26},
  abstract = {The visual expertise of adult humans is jointly determined by evolution, visual development, and visual perceptual learning. Perceptual learning refers to performance improvements in perceptual tasks after practice or training in the task. It occurs in almost all visual tasks, ranging from simple feature detection to complex scene analysis. In this Review, we focus on key behavioral aspects of visual perceptual learning. We begin by describing visual perceptual learning tasks and manipulations that influence the magnitude of learning, and then discuss specificity of learning. Next, we present theories and computational models of learning and specificity. We then review applications of visual perceptual learning in visual rehabilitation. Finally, we summarize the general principles of visual perceptual learning, discuss the tension between plasticity and stability, and conclude with new research directions., Perceptual learning, or performance improvements after training on perceptual tasks, is a widespread phenomenon in visual perception. In this Review, Lu and Dosher describe findings of specificity and transfer of perceptual learning, mechanisms of learning, and key applications in visual rehabilitation},
  pmcid = {PMC10237053},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UW8EUKZ3\Lu and Dosher - 2022 - Current directions in visual perceptual learning.pdf}
}

@article{luczakNeuronsLearnPredicting2022,
  title = {Neurons Learn by Predicting Future Activity},
  author = {Luczak, Artur and McNaughton, Bruce L. and Kubo, Yoshimasa},
  date = {2022-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {1},
  pages = {62--72},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00430-y},
  url = {https://www.nature.com/articles/s42256-021-00430-y},
  urldate = {2022-10-03},
  abstract = {Understanding how the brain learns may lead to machines with human-like intellectual capacities. It was previously proposed that the brain may operate on the principle of predictive coding. However, it is still not well understood how a predictive system could be implemented in the brain. Here we demonstrate that the ability of a single neuron to predict its future activity may provide an effective learning mechanism. Interestingly, this predictive learning rule can be derived from a metabolic principle, whereby neurons need to minimize their own synaptic activity (cost) while maximizing their impact on local blood supply by recruiting other neurons. We show how this mathematically derived learning rule can provide a theoretical connection between diverse types of brain-inspired algorithm, thus offering a step towards the development of a general theory of neuronal learning. We tested this predictive learning rule in neural network simulations and in data recorded from awake animals. Our results also suggest that spontaneous brain activity provides ‘training data’ for neurons to learn to predict cortical dynamics. Thus, the ability of a single neuron to minimize surprise—that is, the difference between actual and expected activity—could be an important missing element to understand computation in the brain.},
  issue = {1},
  langid = {english},
  keywords = {Cortex,Learning algorithms},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KDLSWEP9\\Luczak et al. - 2022 - Neurons learn by predicting future activity.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NHM383MJ\\s42256-021-00430-y.html}
}

@article{luczakNeuronsLearnPredicting2022a,
  title = {Neurons Learn by Predicting Future Activity},
  author = {Luczak, Artur and McNaughton, Bruce L. and Kubo, Yoshimasa},
  date = {2022-01},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  volume = {4},
  number = {1},
  pages = {62--72},
  publisher = {Nature Publishing Group},
  issn = {2522-5839},
  doi = {10.1038/s42256-021-00430-y},
  url = {https://www.nature.com/articles/s42256-021-00430-y},
  urldate = {2022-10-24},
  abstract = {Understanding how the brain learns may lead to machines with human-like intellectual capacities. It was previously proposed that the brain may operate on the principle of predictive coding. However, it is still not well understood how a predictive system could be implemented in the brain. Here we demonstrate that the ability of a single neuron to predict its future activity may provide an effective learning mechanism. Interestingly, this predictive learning rule can be derived from a metabolic principle, whereby neurons need to minimize their own synaptic activity (cost) while maximizing their impact on local blood supply by recruiting other neurons. We show how this mathematically derived learning rule can provide a theoretical connection between diverse types of brain-inspired algorithm, thus offering a step towards the development of a general theory of neuronal learning. We tested this predictive learning rule in neural network simulations and in data recorded from awake animals. Our results also suggest that spontaneous brain activity provides ‘training data’ for neurons to learn to predict cortical dynamics. Thus, the ability of a single neuron to minimize surprise—that is, the difference between actual and expected activity—could be an important missing element to understand computation in the brain.},
  issue = {1},
  langid = {english},
  keywords = {Cortex,Learning algorithms},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G6Y5EI77\\Luczak et al. - 2022 - Neurons learn by predicting future activity.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8XCWRTU7\\s42256-021-00430-y.html}
}

@article{luResynchronizationCircadianOscillators2016,
  title = {Resynchronization of Circadian Oscillators and the East-West Asymmetry of Jet-Lag},
  author = {Lu, Zhixin and Klein-Cardeña, Kevin and Lee, Steven and Antonsen, Thomas M. and Girvan, Michelle and Ott, Edward},
  date = {2016-07-12},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {26},
  number = {9},
  pages = {094811},
  publisher = {American Institute of Physics},
  issn = {1054-1500},
  doi = {10.1063/1.4954275},
  url = {https://aip.scitation.org/doi/full/10.1063/1.4954275},
  urldate = {2020-11-10},
  abstract = {Cells in the brain's Suprachiasmatic Nucleus (SCN) are known to regulate circadian rhythms in mammals. We model synchronization of SCN cells using the forced Kuramoto model, which consists of a large population of coupled phase oscillators (modeling individual SCN cells) with heterogeneous intrinsic frequencies and external periodic forcing. Here, the periodic forcing models diurnally varying external inputs such as sunrise, sunset, and alarm clocks. We reduce the dimensionality of the system using the ansatz of Ott and Antonsen and then study the effect of a sudden change of clock phase to simulate cross-time-zone travel. We estimate model parameters from previous biological experiments. By examining the phase space dynamics of the model, we study the mechanism leading to the difference typically experienced in the severity of jet-lag resulting from eastward and westward travel.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\386DU3WN\\Lu et al. - 2016 - Resynchronization of circadian oscillators and the.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T66BF8L3\\1.html}
}

@article{lynnHeavytailedNeuronalConnectivity2024,
  title = {Heavy-Tailed Neuronal Connectivity Arises from {{Hebbian}} Self-Organization},
  author = {Lynn, Christopher W. and Holmes, Caroline M. and Palmer, Stephanie E.},
  date = {2024-03},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {20},
  number = {3},
  pages = {484--491},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-023-02332-9},
  url = {https://www.nature.com/articles/s41567-023-02332-9},
  urldate = {2024-04-17},
  abstract = {The connections in networks of neurons are heavy-tailed, with a small number of neurons connected much more strongly than the vast majority of pairs. However, it remains unclear whether this heavy-tailed connectivity emerges from simple underlying mechanisms. Here we propose a minimal model of synaptic self-organization: connections are pruned at random, and the synaptic strength rearranges under a mixture of preferential and random dynamics. Under these generic rules, networks evolve to produce distributions of connectivity strength that are asymptotically scale-free, with a power-law exponent that depends only on the probability of preferential (rather than random) growth. Extending our model to include neuronal activity and Hebbian plasticity, we find that clustering in the network also emerges naturally. We confirm these predictions in the connectomes of several animals, suggesting that heavy-tailed and clustered connectivity may arise from general principles of network self-organization rather than mechanisms specific to individual species or systems.},
  langid = {english},
  keywords = {Biological physics,Complex networks,Computational biophysics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4CHNHWY6\Lynn et al. - 2024 - Heavy-tailed neuronal connectivity arises from Heb.pdf}
}

@article{lynnSyntheticLikelihoodSolution2020,
  title = {A {{Synthetic Likelihood Solution}} to the {{Silent Synapse Estimation Problem}}},
  author = {Lynn, Michael B. and Lee, Kevin F. H. and Soares, Cary and Naud, Richard and Béïque, Jean-Claude},
  date = {2020-07-21},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {32},
  number = {3},
  eprint = {32697998},
  eprinttype = {pmid},
  publisher = {Elsevier},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2020.107916},
  url = {https://www.cell.com/cell-reports/abstract/S2211-1247(20)30897-4},
  urldate = {2020-10-22},
  langid = {english},
  keywords = {plasticity,silent synapses,statistical inference,synthetic likelihood},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FVJHXBBC\\Lynn et al. - 2020 - A Synthetic Likelihood Solution to the Silent Syna.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V6576NK9\\S2211-1247(20)30897-4.html}
}

@article{majdandzicSpontaneousRecoveryDynamical2014,
  title = {Spontaneous Recovery in Dynamical Networks},
  author = {Majdandzic, Antonio and Podobnik, Boris and Buldyrev, Sergey V. and Kenett, Dror Y. and Havlin, Shlomo and Eugene Stanley, H.},
  date = {2014-01},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {10},
  number = {1},
  pages = {34--38},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys2819},
  url = {https://www.nature.com/articles/nphys2819},
  urldate = {2022-10-05},
  abstract = {Networks that fail can sometimes recover spontaneously—think of traffic jams suddenly easing or people waking from a coma. A model for such recoveries reveals spontaneous ‘phase flipping’ between high-activity and low-activity modes, in analogy with first-order phase transitions near a critical point.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3I3E9APB\\Majdandzic et al. - 2014 - Spontaneous recovery in dynamical networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CPFB3Z6D\\nphys2819.html}
}

@online{maleUnattendedVisualStimuli2022,
  title = {Unattended Visual Stimuli Do Not Produce Prediction Error Responses despite Being Initially Encoded},
  author = {Male, Alie G. and O’Shea, Robert P.},
  date = {2022-10-10},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.10.04.510779},
  doi = {10.1101/2022.10.04.510779},
  url = {https://www.biorxiv.org/content/10.1101/2022.10.04.510779v1},
  urldate = {2023-03-30},
  abstract = {Prediction error is a basic component of predictive-coding theory of brain processing. According to the theory, each stage of brain processing of sensory information generates a model of the current sensory input; subsequent input is compared against the model and only if there is a mismatch, a prediction error, is further processing performed. Recently, Smout et al. [1] found that a signature of prediction error, the visual (v) mismatch negativity (MMN), for a fundamental property of visual input—its orientation—was absent without attention on the stimuli. This is remarkable because the weight of evidence for MMNs from audition and vision is that they occur without attention. To resolve this discrepancy, we conducted an experiment addressing two alternative explanations for Smout et al.’s finding: that it was from a lack of reproducibility or that participants’ visual systems did not encode the stimuli when attention was on something else. We conducted a similar experiment to Smout et al.’s. We showed 21 participants sequences of identically oriented Gabor patches, standards, and, unpredictably, otherwise identical, Gabor patches differing in orientation by ±15°, ±30°, and ±60°, deviants. To test whether participants encoded the orientation of the standards, we varied the numbers of standards preceding a deviant, allowing us to search for a decrease in activity with the number of repetitions of standards—repetition suppression. We diverted participants’ attention from the oriented stimuli with a central, letter-detection task. We reproduced Smout et al.’s finding of no vMMN without attention, strengthening their finding. We also found that our participants showed repetition suppression: they did encode the stimuli pre-attentively. We also found early processing of deviants. We discuss whether this earlier processing of deviants may be why no further processing, in the vMMN time window, occurs.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\E483Z89V\Male and O’Shea - 2022 - Unattended visual stimuli do not produce predictio.pdf}
}

@article{mannellaActiveInferenceWhiskers2021,
  title = {Active Inference through Whiskers},
  author = {Mannella, Francesco and Maggiore, Federico and Baltieri, Manuel and Pezzulo, Giovanni},
  date = {2021-12},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {144},
  pages = {428--437},
  issn = {08936080},
  doi = {10.1016/j.neunet.2021.08.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608021003506},
  urldate = {2023-08-10},
  abstract = {Rodents use whisking to probe actively their environment and to locate objects in space, hence providing a paradigmatic biological example of active sensing. Numerous studies show that the control of whisking has anticipatory aspects. For example, rodents target their whisker protraction to the distance at which they expect objects, rather than just reacting fast to contacts with unexpected objects. Here we characterize the anticipatory control of whisking in rodents as an active inference process. In this perspective, the rodent is endowed with a prior belief that it will touch something at the end of the whisker protraction, and it continuously modulates its whisking amplitude to minimize (proprioceptive and somatosensory) prediction errors arising from an unexpected whisker–object contact, or from a lack of an expected contact. We will use the model to qualitatively reproduce key empirical findings about the ways rodents modulate their whisker amplitude during exploration and the scanning of (expected or unexpected) objects. Furthermore, we will discuss how the components of active inference model can in principle map to the neurobiological circuits of rodent whisking.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9CS4HBZJ\Mannella et al. - 2021 - Active inference through whiskers.pdf}
}

@article{manteContextdependentComputationRecurrent2013,
  title = {Context-Dependent Computation by Recurrent Dynamics in Prefrontal Cortex},
  author = {Mante, Valerio and Sussillo, David and Shenoy, Krishna V. and Newsome, William T.},
  date = {2013-11},
  journaltitle = {Nature},
  volume = {503},
  number = {7474},
  pages = {78--84},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature12742},
  url = {https://www.nature.com/articles/nature12742},
  urldate = {2024-07-05},
  abstract = {Prefrontal cortex is thought to have a fundamental role in flexible, context-dependent behaviour, but the exact nature of the computations underlying this role remains largely unknown. In particular, individual prefrontal neurons often generate remarkably complex responses that defy deep understanding of their contribution to behaviour. Here we study prefrontal cortex activity in macaque monkeys trained to flexibly select and integrate noisy sensory inputs towards a choice. We find that the observed complexity and functional roles of single neurons are readily understood in the framework of a dynamical process unfolding at the level of the population. The population dynamics can be reproduced by a trained recurrent neural network, which suggests a previously unknown mechanism for selection and integration of task-relevant inputs. This mechanism indicates that selection and integration are two aspects of a single dynamical process unfolding within the same prefrontal circuits, and potentially provides a novel, general framework for understanding context-dependent computations.},
  langid = {english},
  keywords = {Cognitive neuroscience},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TWEWSQWR\Mante et al. - 2013 - Context-dependent computation by recurrent dynamic.pdf}
}

@article{maoDynamicsWinnerTakeAllCompetition2007,
  title = {Dynamics of {{Winner-Take-All Competition}} in {{Recurrent Neural Networks With Lateral Inhibition}}},
  author = {Mao, Zhi-Hong and Massaquoi, Steve G.},
  date = {2007-01},
  journaltitle = {IEEE Transactions on Neural Networks},
  volume = {18},
  number = {1},
  pages = {55--69},
  issn = {1941-0093},
  doi = {10.1109/TNN.2006.883724},
  abstract = {This paper studies the behavior of recurrent neural networks with lateral inhibition. Such network architecture is important in biological neural systems. General conditions determining the existence, number, and stability of network equilibria are derived. The manner in which these features depend upon steepness of neuronal activation functions and the strength of lateral inhibition is demonstrated for a broad range of nondecreasing activation functions including the discontinuous threshold function which represents the infinite gain limit. For uniform lateral inhibitory networks, the lateral inhibition is shown to sharpen neuron output patterns by increasing separation of suprathreshold activity levels of competing neurons. This results in the tendency of one neuron's output to dominate those of the others which can afford a “winner-take-all” (WTA) mechanism. Importantly, multiple stable equilibria may exist and shifts in inputs levels may yield network state transitions that exhibit hysteresis. A limitation of using lateral inhibition to implement WTA is further demonstrated. The possible significance of these identified network dynamics to physiology and pathophysiology of the striatum (particularly in Parkinsonian rest tremor) is discussed.},
  eventtitle = {{{IEEE Transactions}} on {{Neural Networks}}},
  keywords = {Analytical models,Basal ganglia,Discontinuous neuron activations,equilibrium,Hippocampus,Hysteresis,lateral inhibition,Neural networks,Neurons,Physiology,Recurrent neural networks,Rhythm,Stability,striatum,winner-take-all (WTA)},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WWTKV3VW\\Mao and Massaquoi - 2007 - Dynamics of Winner-Take-All Competition in Recurre.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QQDYQXBQ\\4049830.html}
}

@article{markovicPhysicsNeuromorphicComputing2020,
  title = {Physics for Neuromorphic Computing},
  author = {Marković, Danijela and Mizrahi, Alice and Querlioz, Damien and Grollier, Julie},
  date = {2020-09},
  journaltitle = {Nature Reviews Physics},
  shortjournal = {Nat Rev Phys},
  volume = {2},
  number = {9},
  pages = {499--510},
  publisher = {Nature Publishing Group},
  issn = {2522-5820},
  doi = {10.1038/s42254-020-0208-2},
  url = {https://www.nature.com/articles/s42254-020-0208-2},
  urldate = {2022-10-02},
  abstract = {Neuromorphic computing takes inspiration from the brain to create energy-efficient hardware for information processing, capable of highly sophisticated tasks. Systems built with standard electronics achieve gains in speed and energy by mimicking the distributed topology of the brain. Scaling-up such systems and improving their energy usage, speed and performance by several orders of magnitude requires a revolution in hardware. We discuss how including more physics in the algorithms and nanoscale materials used for data processing could have a major impact in the field of neuromorphic computing. We review striking results that leverage physics to enhance the computing capabilities of artificial neural networks, using resistive switching materials, photonics, spintronics and other technologies. We discuss the paths that could lead these approaches to maturity, towards low-power, miniaturized chips that could infer and learn in real time.},
  issue = {9},
  langid = {english},
  keywords = {Electronics,Nanoscale devices,photonics and device physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NASQEFUD\\Marković et al. - 2020 - Physics for neuromorphic computing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9B9T3VEB\\s42254-020-0208-2.html}
}

@article{marshelFunctionalSpecializationSeven2011,
  title = {Functional {{Specialization}} of {{Seven Mouse Visual Cortical Areas}}},
  author = {Marshel, James H. and Garrett, Marina E. and Nauhaus, Ian and Callaway, Edward M.},
  date = {2011-12-22},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {72},
  number = {6},
  eprint = {22196338},
  eprinttype = {pmid},
  pages = {1040--1054},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2011.12.004},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(11)01046-4},
  urldate = {2024-04-05},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9X3L3RE3\Marshel et al. - 2011 - Functional Specialization of Seven Mouse Visual Co.pdf}
}

@article{marshelFunctionalSpecializationSeven2011a,
  title = {Functional {{Specialization}} of {{Seven Mouse Visual Cortical Areas}}},
  author = {Marshel, James H. and Garrett, Marina E. and Nauhaus, Ian and Callaway, Edward M.},
  date = {2011-12-22},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {72},
  number = {6},
  eprint = {22196338},
  eprinttype = {pmid},
  pages = {1040--1054},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2011.12.004},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(11)01046-4},
  urldate = {2024-04-09},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\36TQV7GL\Marshel et al. - 2011 - Functional Specialization of Seven Mouse Visual Co.pdf}
}

@article{martinez-trujilloFeatureBasedAttentionIncreases2004,
  title = {Feature-{{Based Attention Increases}} the {{Selectivity}} of {{Population Responses}} in {{Primate Visual Cortex}}},
  author = {Martinez-Trujillo, Julio C. and Treue, Stefan},
  date = {2004-05-04},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {14},
  number = {9},
  eprint = {15120065},
  eprinttype = {pmid},
  pages = {744--751},
  publisher = {Elsevier},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2004.04.028},
  url = {https://www.cell.com/current-biology/abstract/S0960-9822(04)00268-4},
  urldate = {2023-01-30},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\V9QH6P4F\Martinez-Trujillo and Treue - 2004 - Feature-Based Attention Increases the Selectivity .pdf}
}

@article{martinez-trujilloVisualAttentionPrefrontal2022,
  title = {Visual {{Attention}} in the {{Prefrontal Cortex}}},
  author = {Martinez-Trujillo, Julio},
  date = {2022},
  journaltitle = {Annual Review of Vision Science},
  volume = {8},
  number = {1},
  eprint = {35679625},
  eprinttype = {pmid},
  pages = {407--425},
  doi = {10.1146/annurev-vision-100720-031711},
  url = {https://doi.org/10.1146/annurev-vision-100720-031711},
  urldate = {2023-01-30},
  abstract = {Voluntary attention selects behaviorally relevant signals for further processing while filtering out distracter signals. Neural correlates of voluntary visual attention have been reported across multiple areas of the primate visual processing streams, with the earliest and strongest effects isolated in the prefrontal cortex. In this article, I review evidence supporting the hypothesis that signals guiding the allocation of voluntary attention emerge in areas of the prefrontal cortex and reach upstream areas to modulate the processing of incoming visual information according to its behavioral relevance. Areas located anterior and dorsal to the arcuate sulcus and the frontal eye fields produce signals that guide the allocation of spatial attention. Areas located anterior and ventral to the arcuate sulcus produce signals for feature-based attention. Prefrontal microcircuits are particularly suited to supporting voluntary attention because of their ability to generate attentional template signals and implement signal gating and their extensive connectivity with the rest of the brain.},
  keywords = {feature-based attention,frontal eye fields,prefrontal cortex,primates,spatial attention},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CNS77I6Y\Martinez-Trujillo - 2022 - Visual Attention in the Prefrontal Cortex.pdf}
}

@article{marvanApicalAmplificationCellular2021,
  title = {Apical Amplification—a Cellular Mechanism of Conscious Perception?},
  author = {Marvan, Tomáš and Polák, Michal and Bachmann, Talis and Phillips, William A},
  date = {2021-12-01},
  journaltitle = {Neuroscience of Consciousness},
  shortjournal = {Neuroscience of Consciousness},
  volume = {2021},
  number = {2},
  pages = {niab036},
  issn = {2057-2107},
  doi = {10.1093/nc/niab036},
  url = {https://doi.org/10.1093/nc/niab036},
  urldate = {2022-10-18},
  abstract = {We present a theoretical view of the cellular foundations for network-level processes involved in producing our conscious experience. Inputs to apical synapses in layer 1 of a large subset of neocortical cells are summed at an integration zone near the top of their apical trunk. These inputs come from diverse sources and provide a context within which the transmission of information abstracted from sensory input to their basal and perisomatic synapses can be amplified when relevant. We argue that apical amplification enables conscious perceptual experience and makes it more flexible, and thus more adaptive, by being sensitive to context. Apical amplification provides a possible mechanism for recurrent processing theory that avoids strong loops. It makes the broadcasting hypothesized by global neuronal workspace theories feasible while preserving the distinct contributions of the individual cells receiving the broadcast. It also provides mechanisms that contribute to the holistic aspects of integrated information theory. As apical amplification is highly dependent on cholinergic, aminergic, and other neuromodulators, it relates the specific contents of conscious experience to global mental states and to fluctuations in arousal when awake. We conclude that apical dendrites provide a cellular mechanism for the context-sensitive selective amplification that is a cardinal prerequisite of conscious perception.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\GVRDU67D\Marvan et al. - 2021 - Apical amplification—a cellular mechanism of consc.pdf}
}

@article{marvanApicalAmplificationCellular2021a,
  title = {Apical Amplification—a Cellular Mechanism of Conscious Perception?},
  author = {Marvan, Tomáš and Polák, Michal and Bachmann, Talis and Phillips, William A},
  date = {2021-10-13},
  journaltitle = {Neuroscience of Consciousness},
  volume = {2021},
  number = {2},
  pages = {niab036},
  issn = {2057-2107},
  doi = {10.1093/nc/niab036},
  url = {https://academic.oup.com/nc/article/doi/10.1093/nc/niab036/6395042},
  urldate = {2023-08-10},
  abstract = {We present a theoretical view of the cellular foundations for network-level processes involved in producing our conscious experience. Inputs to apical synapses in layer 1 of a large subset of neocortical cells are summed at an integration zone near the top of their apical trunk. These inputs come from diverse sources and provide a context within which the transmission of information abstracted from sensory input to their basal and perisomatic synapses can be amplified when relevant. We argue that apical amplification enables conscious perceptual experience and makes it more flexible, and thus more adaptive, by being sensitive to context. Apical amplification provides a possible mechanism for recurrent processing theory that avoids strong loops. It makes the broadcasting hypothesized by global neuronal workspace theories feasible while preserving the distinct contributions of the individual cells receiving the broadcast. It also provides mechanisms that contribute to the holistic aspects of integrated information theory. As apical amplification is highly dependent on cholinergic, aminergic, and other neuromodulators, it relates the specific contents of conscious experience to global mental states and to fluctuations in arousal when awake. We conclude that apical dendrites provide a cellular mechanism for the context-sensitive selective amplification that is a cardinal prerequisite of conscious perception.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\H7DY9NYS\Marvan et al. - 2021 - Apical amplification—a cellular mechanism of consc.pdf}
}

@article{masoliverControlCoherenceResonance2021,
  title = {Control of Coherence Resonance in Multiplex Neural Networks},
  author = {Masoliver, Maria and Masoller, Cristina and Zakharova, Anna},
  date = {2021-04-01},
  journaltitle = {Chaos, Solitons \& Fractals},
  shortjournal = {Chaos, Solitons \& Fractals},
  volume = {145},
  pages = {110666},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2021.110666},
  url = {https://www.sciencedirect.com/science/article/pii/S0960077921000199},
  urldate = {2022-10-05},
  abstract = {We study the dynamics of two neuronal populations weakly and mutually coupled in a multiplexed ring configuration. We simulate the neuronal activity with the stochastic FitzHugh–Nagumo (FHN) model. The two neuronal populations perceive different levels of noise: one population exhibits spiking activity induced by supra-threshold noise (layer 1), while the other population is silent in the absence of inter-layer coupling because its own level of noise is sub-threshold (layer 2). We find that, for appropriate levels of noise in layer 1, weak inter-layer coupling can induce coherence resonance (CR), anti-coherence resonance (ACR) and inverse stochastic resonance (ISR) in layer 2. We also find that a small number of randomly distributed inter-layer links is sufficient to induce these phenomena in layer 2. Our results hold for small and large neuronal populations.},
  langid = {english},
  keywords = {Coherence resonance,FitzHugh–Nagumo neuron,Multiplex network,Synchronization},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V5BZCQYX\\Masoliver et al. - 2021 - Control of coherence resonance in multiplex neural.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ELYLNR22\\S0960077921000199.html}
}

@article{masoliverEmbeddedChimeraStates2022,
  title = {Embedded Chimera States in Recurrent Neural Networks},
  author = {Masoliver, Maria and Davidsen, Jörn and Nicola, Wilten},
  date = {2022-08-11},
  journaltitle = {Communications Physics},
  shortjournal = {Commun Phys},
  volume = {5},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2399-3650},
  doi = {10.1038/s42005-022-00984-2},
  url = {https://www.nature.com/articles/s42005-022-00984-2},
  urldate = {2022-10-05},
  abstract = {Fully and partially synchronized brain activity plays a key role in normal cognition and in some neurological disorders, such as epilepsy. However, the mechanism by which synchrony and asynchrony co-exist in a population of neurons remains elusive. Chimera states, where synchrony and asynchrony coexist, have been documented only for precisely specified connectivity and network topologies. Here, we demonstrate how chimeras can emerge in recurrent neural networks by training the networks to display chimeras with machine learning. These solutions, which we refer to as embedded chimeras, are generically produced by recurrent neural networks with connectivity matrices only slightly perturbed from random networks. We also demonstrate that learning is robust to different biological constraints, such as the excitatory/inhibitory classification of neurons (Dale’s law), and the sparsity of connections in neural circuits. The recurrent neural networks can also be trained to switch chimera solutions: an input pulse can trigger the neural network to switch the synchronized and the unsynchronized groups of the embedded chimera, reminiscent of uni-hemispheric sleep in a variety of animals. Our results imply that the emergence of chimeras is quite generic at the meso- and macroscale suggesting their general relevance in neuroscience.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Computational science,Nonlinear phenomena},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IK8LZZL6\\Masoliver et al. - 2022 - Embedded chimera states in recurrent neural networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EMBZ8G6D\\s42005-022-00984-2.html}
}

@online{maxLearningEfficientBackprojections2022,
  title = {Learning Efficient Backprojections across Cortical Hierarchies in Real Time},
  author = {Max, Kevin and Kriener, Laura and García, Garibaldi Pineda and Nowotny, Thomas and Senn, Walter and Petrovici, Mihai A.},
  date = {2022-12-20},
  eprint = {2212.10249},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2212.10249},
  urldate = {2023-01-22},
  abstract = {Models of sensory processing and learning in the cortex need to efficiently assign credit to synapses in all areas. In deep learning, a known solution is error backpropagation, which however requires biologically implausible weight transport from feed-forward to feedback paths. We introduce Phaseless Alignment Learning (PAL), a bio-plausible method to learn efficient feedback weights in layered cortical hierarchies. This is achieved by exploiting the noise naturally found in biophysical systems as an additional carrier of information. In our dynamical system, all weights are learned simultaneously with always-on plasticity and using only information locally available to the synapses. Our method is completely phase-free (no forward and backward passes or phased learning) and allows for efficient error propagation across multi-layer cortical hierarchies, while maintaining biologically plausible signal transport and learning. Our method is applicable to a wide class of models and improves on previously known biologically plausible ways of credit assignment: compared to random synaptic feedback, it can solve complex tasks with less neurons and learn more useful latent representations. We demonstrate this on various classification tasks using a cortical microcircuit model with prospective coding.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YBQ5YJ3P\\Max et al. - 2022 - Learning efficient backprojections across cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NP3CXPDB\\2212.html}
}

@article{mcadamsEffectsAttentionOrientationTuning1999,
  title = {Effects of {{Attention}} on {{Orientation-Tuning Functions}} of {{Single Neurons}} in {{Macaque Cortical Area V4}}},
  author = {McAdams, Carrie J. and Maunsell, John H. R.},
  date = {1999-01-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {19},
  number = {1},
  eprint = {9870971},
  eprinttype = {pmid},
  pages = {431--441},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.19-01-00431.1999},
  url = {https://www.jneurosci.org/content/19/1/431},
  urldate = {2023-01-03},
  abstract = {We examined how attention affected the orientation tuning of 262 isolated neurons in extrastriate area V4 and 135 neurons in area V1 of two rhesus monkeys. The animals were trained to perform a delayed match-to-sample task in which oriented stimuli were presented in the receptive field of the neuron being recorded. On some trials the animals were instructed to pay attention to those stimuli, and on other trials they were instructed to pay attention to other stimuli outside the receptive field. In this way, orientation-tuning curves could be constructed from neuronal responses collected in two behavioral states: one in which those stimuli were attended by the animal and one in which those stimuli were ignored by the animal. We fit Gaussians to the neuronal responses to twelve different orientations for each behavioral state. Although attention enhanced the responses of V4 neurons (median 26\% increase) and V1 neurons (median 8\% increase), selectivity, as measured by the width of its orientation-tuning curve, was not systematically altered by attention. The effects of attention were consistent with a multiplicative scaling of the driven response to all orientations. We also found that attention did not cause systematic changes in the undriven activity of the neurons.},
  langid = {english},
  keywords = {area V4,attention,cortex,extrastriate,monkey,orientation,tuning,visual},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\I7CWWJ4I\McAdams and Maunsell - 1999 - Effects of Attention on Orientation-Tuning Functio.pdf}
}

@article{mcadamsEffectsAttentionReliability1999,
  title = {✅ {{Effects}} of {{Attention}} on the {{Reliability}} of {{Individual Neurons}} in {{Monkey Visual Cortex}}},
  author = {McAdams, Carrie J. and Maunsell, John H. R.},
  date = {1999-08-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {23},
  number = {4},
  pages = {765--773},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(01)80034-9},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627301800349},
  urldate = {2022-12-28},
  abstract = {To determine the physiological mechanisms underlying the enhancement of performance by attention, we examined how attention affects the ability of isolated neurons to discriminate orientation by investigating the reliability of responses with and without attention. Recording from 262 neurons in cortical area V4 while two rhesus macaques did a delayed match-to-sample task with oriented stimuli, we found that attention did not produce detectable changes in the variability of neuronal responses but did improve the orientation discriminability of the neurons. We also found that attention did not change the relationship between burst rate and response rate. Our results are consistent with the idea that attention selects groups of neurons for a multiplicative enhancement in response strength.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DMA3B28A\\McAdams and Maunsell - 1999 - Effects of Attention on the Reliability of Individ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XUA8X5S8\\S0896627301800349.html}
}

@article{mcdonnellBenefitsNoiseNeural2011,
  title = {The Benefits of Noise in Neural Systems: Bridging Theory and Experiment},
  shorttitle = {The Benefits of Noise in Neural Systems},
  author = {McDonnell, Mark D. and Ward, Lawrence M.},
  date = {2011-07},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {12},
  number = {7},
  pages = {415--425},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn3061},
  url = {https://www.nature.com/articles/nrn3061},
  urldate = {2023-03-30},
  abstract = {Both theoretical and experimental approaches have demonstrated that noise can improve information processing, but there is substantial scope for new biologically appropriate computational hypotheses and noise sources to be investigated. McDonnell and Ward propose a unifying framework for reconciling theory with experiment.},
  issue = {7},
  langid = {english},
  keywords = {Computational neuroscience,Nonlinear dynamics,Stochastic modelling,Synaptic transmission},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8PV3UBCQ\McDonnell and Ward - 2011 - The benefits of noise in neural systems bridging .pdf}
}

@article{medinaTeachingCerebellumReward2019,
  title = {Teaching the Cerebellum about Reward},
  author = {Medina, Javier F.},
  date = {2019-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {6},
  pages = {846--848},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0409-0},
  url = {https://www.nature.com/articles/s41593-019-0409-0},
  urldate = {2023-04-23},
  abstract = {Selecting the most rewarding action and performing it accurately are two separable brain functions that are thought to rely upon different neural systems. New evidence suggests that the cerebellum could learn to do both.},
  issue = {6},
  langid = {english},
  keywords = {Motor control,Neural circuits,Neuroscience,Reward},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\249YTHRE\Medina - 2019 - Teaching the cerebellum about reward.pdf}
}

@online{MemoriesTopYour,
  title = {Memories off the Top of Your Head | {{Science}}},
  url = {https://www.science.org/doi/10.1126/science.abk1859#.YXvFmCeh6kY.twitter},
  urldate = {2022-10-06},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5EAJUVSA\science.html}
}

@article{menesseHomeostaticCriticalityNeuronal2022,
  title = {Homeostatic Criticality in Neuronal Networks},
  author = {Menesse, Gustavo and Marin, Bóris and Girardi-Schappo, Mauricio and Kinouchi, Osame},
  date = {2022-03-01},
  journaltitle = {Chaos, Solitons \& Fractals},
  shortjournal = {Chaos, Solitons \& Fractals},
  volume = {156},
  pages = {111877},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2022.111877},
  url = {https://www.sciencedirect.com/science/article/pii/S0960077922000881},
  urldate = {2022-10-03},
  abstract = {In self-organized criticality (SOC) models, as well as in standard phase transitions, criticality is only present for vanishing external fields h→0. Considering that this is rarely the case for natural systems, such a restriction poses a challenge to the explanatory power of these models. Besides that, in models of dissipative systems like earthquakes, forest fires, and neuronal networks, there is no true critical behavior, as expressed in clean power laws obeying finite-size scaling, but a scenario called “dirty” criticality or self-organized quasi-criticality (SOqC). Here, we propose simple homeostatic mechanisms which promote self-organization of coupling strengths, gains, and firing thresholds in neuronal networks. We show that with an adequate separation of the timescales for the coupling strength and firing threshold dynamics, near criticality (SOqC) can be reached and sustained even in the presence of significant external input. The firing thresholds adapt to and cancel the inputs (h decreases towards zero). Similar mechanisms can be proposed for the couplings and local thresholds in spin systems and cellular automata, which could lead to applications in earthquake, forest fire, stellar flare, voting, and epidemic modeling.},
  langid = {english},
  keywords = {Adaptive networks,Homeostasis,Neuronal avalanches,Neuronal networks,Self-organization,Self-organized criticality,Synaptic depression},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6M6DL3UY\\Menesse et al. - 2022 - Homeostatic criticality in neuronal networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WPDHJ8HH\\S0960077922000881.html}
}

@online{mengDynamicStochasticGradient2020,
  title = {Dynamic of {{Stochastic Gradient Descent}} with {{State-Dependent Noise}}},
  author = {Meng, Qi and Gong, Shiqi and Chen, Wei and Ma, Zhi-Ming and Liu, Tie-Yan},
  date = {2020-10-12},
  eprint = {2006.13719},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2006.13719},
  urldate = {2024-01-08},
  abstract = {Stochastic gradient descent (SGD) and its variants are mainstream methods to train deep neural networks. Since neural networks are non-convex, more and more works study the dynamic behavior of SGD and the impact to its generalization, especially the escaping efficiency from local minima. However, these works take the over-simplified assumption that the covariance of the noise in SGD is (or can be upper bounded by) constant, although it is actually state-dependent. In this work, we conduct a formal study on the dynamic behavior of SGD with state-dependent noise. Specifically, we show that the covariance of the noise of SGD in the local region of the local minima is a quadratic function of the state. Thus, we propose a novel power-law dynamic with state-dependent diffusion to approximate the dynamic of SGD. We prove that, power-law dynamic can escape from sharp minima exponentially faster than flat minima, while the previous dynamics can only escape sharp minima polynomially faster than flat minima. Our experiments well verified our theoretical results. Inspired by our theory, we propose to add additional state-dependent noise into (large-batch) SGD to further improve its generalization ability. Experiments verify that our method is effective.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E9LTR6UB\\Meng et al. - 2020 - Dynamic of Stochastic Gradient Descent with State-.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IATGXHSN\\2006.html}
}

@article{mengualEfficientLowPassDendroSomatic2020,
  title = {Efficient {{Low-Pass Dendro-Somatic Coupling}} in the {{Apical Dendrite}} of {{Layer}} 5 {{Pyramidal Neurons}} in the {{Anterior Cingulate Cortex}}},
  author = {Mengual, Ulisses Marti and Wybo, Willem A. M. and Spierenburg, Lotte J. E. and Santello, Mirko and Senn, Walter and Nevian, Thomas},
  date = {2020-11-11},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {40},
  number = {46},
  eprint = {33046549},
  eprinttype = {pmid},
  pages = {8799--8815},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.3028-19.2020},
  url = {https://www.jneurosci.org/content/40/46/8799},
  urldate = {2020-11-11},
  abstract = {Signal propagation in the dendrites of many neurons, including cortical pyramidal neurons in sensory cortex, is characterized by strong attenuation toward the soma. In contrast, using dual whole-cell recordings from the apical dendrite and soma of layer 5 (L5) pyramidal neurons in the anterior cingulate cortex (ACC) of adult male mice we found good coupling, particularly of slow subthreshold potentials like NMDA spikes or trains of EPSPs from dendrite to soma. Only the fastest EPSPs in the ACC were reduced to a similar degree as in primary somatosensory cortex, revealing differential low-pass filtering capabilities. Furthermore, L5 pyramidal neurons in the ACC did not exhibit dendritic Ca2+ spikes as prominently found in the apical dendrite of S1 (somatosensory cortex) pyramidal neurons. Fitting the experimental data to a NEURON model revealed that the specific distribution of Ileak, Iir, Im, and Ih was sufficient to explain the electrotonic dendritic structure causing a leaky distal dendritic compartment with correspondingly low input resistance and a compact perisomatic region, resulting in a decoupling of distal tuft branches from each other while at the same time efficiently connecting them to the soma. Our results give a biophysically plausible explanation of how a class of prefrontal cortical pyramidal neurons achieve efficient integration of subthreshold distal synaptic inputs compared with the same cell type in sensory cortices. SIGNIFICANCE STATEMENT Understanding cortical computation requires the understanding of its fundamental computational subunits. Layer 5 pyramidal neurons are the main output neurons of the cortex, integrating synaptic inputs across different cortical layers. Their elaborate dendritic tree receives, propagates, and transforms synaptic inputs into action potential output. We found good coupling of slow subthreshold potentials like NMDA spikes or trains of EPSPs from the distal apical dendrite to the soma in pyramidal neurons in the ACC, which was significantly better compared with S1. This suggests that frontal pyramidal neurons use a different integration scheme compared with the same cell type in somatosensory cortex, which has important implications for our understanding of information processing across different parts of the neocortex.},
  langid = {english},
  keywords = {anterior cingulate cortex,biophysical model,dendrite,electrical properties,NMDA spike,pyramidal neuron},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FHJDYBBD\8799.html}
}

@article{meshulamCollectiveBehaviorPlace2017,
  title = {✅ {{Collective Behavior}} of {{Place}} and {{Non-place Neurons}} in the {{Hippocampal Network}}},
  author = {Meshulam, Leenoy and Gauthier, Jeffrey L. and Brody, Carlos D. and Tank, David W. and Bialek, William},
  date = {2017-12-06},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {96},
  number = {5},
  eprint = {29154129},
  eprinttype = {pmid},
  pages = {1178-1191.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.10.027},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30996-0},
  urldate = {2023-04-13},
  langid = {english},
  keywords = {collective phenomena,hippocampus,maximum entropy,pairwise correlations,place cells},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3NKLS9W7\\Meshulam et al. - 2017 - Collective Behavior of Place and Non-place Neurons.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ECGXMJRG\\mmc1 (1).pdf}
}

@online{meulemansLeastcontrolPrincipleLocal2022,
  title = {The Least-Control Principle for Local Learning at Equilibrium},
  author = {Meulemans, Alexander and Zucchet, Nicolas and Kobayashi, Seijin and von Oswald, Johannes and Sacramento, João},
  options = {useprefix=true},
  date = {2022-10-31},
  eprint = {2207.01332},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2207.01332},
  url = {http://arxiv.org/abs/2207.01332},
  urldate = {2023-04-28},
  abstract = {Equilibrium systems are a powerful way to express neural computations. As special cases, they include models of great current interest in both neuroscience and machine learning, such as deep neural networks, equilibrium recurrent neural networks, deep equilibrium models, or meta-learning. Here, we present a new principle for learning such systems with a temporally- and spatially-local rule. Our principle casts learning as a least-control problem, where we first introduce an optimal controller to lead the system towards a solution state, and then define learning as reducing the amount of control needed to reach such a state. We show that incorporating learning signals within a dynamics as an optimal control enables transmitting activity-dependent credit assignment information, avoids storing intermediate states in memory, and does not rely on infinitesimal learning signals. In practice, our principle leads to strong performance matching that of leading gradient-based learning methods when applied to an array of problems involving recurrent neural networks and meta-learning. Our results shed light on how the brain might learn and offer new ways of approaching a broad class of machine learning problems.},
  pubstate = {prepublished},
  keywords = {68T07,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,I.2.6},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AKHH8M6A\\Meulemans et al. - 2022 - The least-control principle for local learning at .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NNVHASMW\\2207.html}
}

@article{miehlFormationComputationalImplications,
  title = {Formation and Computational Implications of Assemblies in Neural Circuits},
  author = {Miehl, Christoph and Onasch, Sebastian and Festa, Dylan and Gjorgjieva, Julijana},
  journaltitle = {The Journal of Physiology},
  volume = {n/a},
  number = {n/a},
  issn = {1469-7793},
  doi = {10.1113/JP282750},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/JP282750},
  urldate = {2022-09-28},
  abstract = {In the brain, patterns of neural activity represent sensory information and store it in non-random synaptic connectivity. A prominent theoretical hypothesis states that assemblies, groups of neurons that are strongly connected to each other, are the key computational units underlying perception and memory formation. Compatible with these hypothesised assemblies, experiments have revealed groups of neurons that display synchronous activity, either spontaneously or upon stimulus presentation, and exhibit behavioural relevance. While it remains unclear how assemblies form in the brain, theoretical work has vastly contributed to the understanding of various interacting mechanisms in this process. Here, we review the recent theoretical literature on assembly formation by categorising the involved mechanisms into four components: synaptic plasticity, symmetry breaking, competition and stability. We highlight different approaches and assumptions behind assembly formation and discuss recent ideas of assemblies as the key computational unit in the brain.},
  langid = {english},
  keywords = {assemblies,assembly,network model,neural circuits,pattern formation,symmetry breaking,synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZHIC5L9H\\Miehl et al. - Formation and computational implications of assemb.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YLU6CK92\\JP282750.html}
}

@article{mikulaschLocalDendriticBalance2021,
  title = {✅ {{Local}} Dendritic Balance Enables Learning of Efficient Representations in Networks of Spiking Neurons},
  author = {Mikulasch, Fabian A. and Rudelt, Lucas and Priesemann, Viola},
  date = {2021-12-14},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {50},
  pages = {e2021925118},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2021925118},
  url = {https://www.pnas.org/doi/10.1073/pnas.2021925118},
  urldate = {2023-04-03},
  abstract = {How can neural networks learn to efficiently represent complex and high-dimensional inputs via local plasticity mechanisms? Classical models of representation learning assume that feedforward weights are learned via pairwise Hebbian-like plasticity. Here, we show that pairwise Hebbian-like plasticity works only under unrealistic requirements on neural dynamics and input statistics. To overcome these limitations, we derive from first principles a learning scheme based on voltage-dependent synaptic plasticity rules. Here, recurrent connections learn to locally balance feedforward input in individual dendritic compartments and thereby can modulate synaptic plasticity to learn efficient representations. We demonstrate in simulations that this learning scheme works robustly even for complex high-dimensional inputs and with inhibitory transmission delays, where Hebbian-like plasticity fails. Our results draw a direct connection between dendritic excitatory–inhibitory balance and voltage-dependent synaptic plasticity as observed in vivo and suggest that both are crucial for representation learning.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3QT87MSU\\Mikulasch et al. - 2021 - Local dendritic balance enables learning of effici.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LF24UGWT\\pnas.2021925118.sapp.pdf}
}

@article{mikulaschWhereErrorHierarchical2023,
  title = {Where Is the Error? {{Hierarchical}} Predictive Coding through Dendritic Error Computation},
  shorttitle = {Where Is the Error?},
  author = {Mikulasch, Fabian A. and Rudelt, Lucas and Wibral, Michael and Priesemann, Viola},
  date = {2023-01-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {46},
  number = {1},
  eprint = {36577388},
  eprinttype = {pmid},
  pages = {45--59},
  publisher = {Elsevier},
  issn = {0166-2236, 1878-108X},
  doi = {10.1016/j.tins.2022.09.007},
  url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(22)00186-2},
  urldate = {2023-03-24},
  langid = {english},
  keywords = {cortical hierarchy,inference,predictive processing,pyramidal neuron,sensory processing,voltage-dependent plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5GWBTYPN\Mikulasch et al. - 2023 - Where is the error Hierarchical predictive coding.pdf}
}

@article{mikulaschWhereErrorHierarchical2023a,
  title = {Where Is the Error? {{Hierarchical}} Predictive Coding through Dendritic Error Computation},
  shorttitle = {Where Is the Error?},
  author = {Mikulasch, Fabian A. and Rudelt, Lucas and Wibral, Michael and Priesemann, Viola},
  date = {2023-01-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {46},
  number = {1},
  eprint = {36577388},
  eprinttype = {pmid},
  pages = {45--59},
  publisher = {Elsevier},
  issn = {0166-2236, 1878-108X},
  doi = {10.1016/j.tins.2022.09.007},
  url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(22)00186-2},
  urldate = {2023-03-30},
  langid = {english},
  keywords = {cortical hierarchy,inference,predictive processing,pyramidal neuron,sensory processing,voltage-dependent plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DEWRNV9A\Mikulasch et al. - 2023 - Where is the error Hierarchical predictive coding.pdf}
}

@article{millanExplosiveHigherOrderKuramoto2020,
  title = {Explosive {{Higher-Order Kuramoto Dynamics}} on {{Simplicial Complexes}}},
  author = {Millán, Ana P. and Torres, Joaquín J. and Bianconi, Ginestra},
  date = {2020-05-27},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {124},
  number = {21},
  pages = {218301},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.124.218301},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.124.218301},
  urldate = {2022-10-05},
  abstract = {The higher-order interactions of complex systems, such as the brain, are captured by their simplicial complex structure and have a significant effect on dynamics. However, the existing dynamical models defined on simplicial complexes make the strong assumption that the dynamics resides exclusively on the nodes. Here we formulate the higher-order Kuramoto model which describes the interactions between oscillators placed not only on nodes but also on links, triangles, and so on. We show that higher-order Kuramoto dynamics can lead to an explosive synchronization transition by using an adaptive coupling dependent on the solenoidal and the irrotational component of the dynamics.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CBD2X5ZU\\Millán et al. - 2020 - Explosive Higher-Order Kuramoto Dynamics on Simpli.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AFM6KACB\\PhysRevLett.124.html}
}

@article{millerNewInsightsMammalian1996,
  title = {New {{Insights Into}} the {{Mammalian Circadian Clock}}},
  author = {Miller, Joseph D. and Morin, Lawrence P. and Schwartz, William J. and Moore, Robert Y.},
  date = {1996-10-01},
  journaltitle = {Sleep},
  shortjournal = {Sleep},
  volume = {19},
  number = {8},
  pages = {641--667},
  issn = {0161-8105},
  doi = {10.1093/sleep/19.8.641},
  url = {https://doi.org/10.1093/sleep/19.8.641},
  urldate = {2023-02-17},
  abstract = {The focus of this review is recent studies of the mammalian circadian pacemaker in the suprachiasmatic nucleus (SCN) of the hypothalamus. The anatomy of the SCN and its major afferents from the retina, raphe, and intergeniculate leaflet (IGL) of the thalamus are considered, with a special emphasis on the effects of afferent interaction on the circadian timekeeping system. What is known of the endogenous clock mechanism is reviewed in comparison with known molecular circadian mechanisms in other species. Efferents of the SCN are also discussed with a view toward understanding how circadian information is transmitted to the rest of the central nervous system. Where possible, anatomical, electrophysiological, neuropharmacological, molecular, and behavioral data are integrated in an attempt to illuminate the mechanisms of circadian timekeeping.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GWL6TDMK\\Miller et al. - 1996 - New Insights Into the Mammalian Circadian Clock.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J68Y9QF4\\2749883.html}
}

@online{millidgePredictiveCodingNetworks2023,
  title = {Predictive {{Coding Networks}} for {{Temporal Prediction}}},
  author = {Millidge, Beren and Tang, Mufeng and Osanlouy, Mahyar and Bogacz, Rafal},
  date = {2023-05-16},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2023.05.15.540906},
  doi = {10.1101/2023.05.15.540906},
  url = {https://www.biorxiv.org/content/10.1101/2023.05.15.540906v1},
  urldate = {2024-01-15},
  abstract = {One of the key problems the brain faces is inferring the state of the world from a sequence of dynamically changing stimuli, and it is not yet clear how the sensory system achieves this task. A well-established computational framework for describing perceptual processes in the brain is provided by the theory of predictive coding. Although the original proposals of predictive coding have discussed temporal prediction, later work developing this theory mostly focused on static stimuli, and key questions on neural implementation and computational properties of temporal predictive coding networks remain open. Here, we address these questions and present a formulation of the temporal predictive coding model that can be naturally implemented in recurrent networks, in which activity dynamics rely only on local inputs to the neurons, and learning only utilises local Hebbian plasticity. Additionally, we show that predictive coding networks can approximate the performance of the Kalman filter in predicting behaviour of linear systems, and behave as a variant of a Kalman filter which does not track its own subjective posterior variance. Importantly, predictive coding networks can achieve similar accuracy as the Kalman filter without performing complex mathematical operations, but just employing simple computations that can be implemented by biological networks. Moreover, we demonstrate how the model can be effectively generalized to non-linear systems. Overall, models presented in this paper show how biologically plausible circuits can predict future stimuli and may guide research on understanding specific neural circuits in brain areas involved in temporal prediction. Author summary While significant advances have been made in the neuroscience of how the brain processes static stimuli, the time dimension has often been relatively neglected. However, time is crucial since the stimuli perceived by our senses typically dynamically vary in time, and the cortex needs to make sense of these changing inputs. This paper describes a computational model of cortical networks processing temporal stimuli. This model is able to infer and track the state of the environment based on noisy inputs, and predict future sensory stimuli. By ensuring that these predictions match the following stimuli, the model is able to learn the structure and statistics of its temporal inputs. The model may help in further understanding neural circuits in sensory cortical areas.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\74YLS6VQ\Millidge et al. - 2023 - Predictive Coding Networks for Temporal Prediction.pdf}
}

@online{millidgePredictiveCodingTheoretical2022,
  title = {Predictive {{Coding}}: A {{Theoretical}} and {{Experimental Review}}},
  shorttitle = {Predictive {{Coding}}},
  author = {Millidge, Beren and Seth, Anil and Buckley, Christopher L.},
  date = {2022-07-12},
  eprint = {2107.12979},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  url = {http://arxiv.org/abs/2107.12979},
  urldate = {2022-12-12},
  abstract = {Predictive coding offers a potentially unifying account of cortical function -- postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. A large body of research has arisen based on both empirically testing improved and extended theoretical and mathematical models of predictive coding, as well as in evaluating their potential biological plausibility for implementation in the brain and the concrete neurophysiological and psychological predictions made by the theory. Despite this enduring popularity, however, no comprehensive review of predictive coding theory, and especially of recent developments in this field, exists. Here, we provide a comprehensive review both of the core mathematical structure and logic of predictive coding, thus complementing recent tutorials in the literature. We also review a wide range of classic and recent work within the framework, ranging from the neurobiologically realistic microcircuits that could implement predictive coding, to the close relationship between predictive coding and the widely-used backpropagation of error algorithm, as well as surveying the close relationships between predictive coding and modern machine learning techniques.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZIPQ6F5M\\Millidge et al. - 2022 - Predictive Coding a Theoretical and Experimental .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XZQGP24D\\2107.html}
}

@online{millidgePredictiveCodingTheoretical2022a,
  title = {Predictive {{Coding}}: A {{Theoretical}} and {{Experimental Review}}},
  shorttitle = {Predictive {{Coding}}},
  author = {Millidge, Beren and Seth, Anil and Buckley, Christopher L.},
  date = {2022-07-12},
  eprint = {2107.12979},
  eprinttype = {arXiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2107.12979},
  url = {http://arxiv.org/abs/2107.12979},
  urldate = {2023-05-14},
  abstract = {Predictive coding offers a potentially unifying account of cortical function -- postulating that the core function of the brain is to minimize prediction errors with respect to a generative model of the world. The theory is closely related to the Bayesian brain framework and, over the last two decades, has gained substantial influence in the fields of theoretical and cognitive neuroscience. A large body of research has arisen based on both empirically testing improved and extended theoretical and mathematical models of predictive coding, as well as in evaluating their potential biological plausibility for implementation in the brain and the concrete neurophysiological and psychological predictions made by the theory. Despite this enduring popularity, however, no comprehensive review of predictive coding theory, and especially of recent developments in this field, exists. Here, we provide a comprehensive review both of the core mathematical structure and logic of predictive coding, thus complementing recent tutorials in the literature. We also review a wide range of classic and recent work within the framework, ranging from the neurobiologically realistic microcircuits that could implement predictive coding, to the close relationship between predictive coding and the widely-used backpropagation of error algorithm, as well as surveying the close relationships between predictive coding and modern machine learning techniques.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Neural and Evolutionary Computing,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NUC56GSY\\Millidge et al. - 2022 - Predictive Coding a Theoretical and Experimental .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCCJPG2S\\2107.html}
}

@article{milojkovicVoltageCalciumTransients2007,
  title = {Voltage and Calcium Transients in Basal Dendrites of the Rat Prefrontal Cortex},
  author = {Milojkovic, Bogdan A and Zhou, Wen-Liang and Antic, Srdjan D},
  date = {2007-12-01},
  journaltitle = {The Journal of Physiology},
  shortjournal = {J Physiol},
  volume = {585},
  eprint = {17932150},
  eprinttype = {pmid},
  pages = {447--468},
  issn = {0022-3751},
  doi = {10.1113/jphysiol.2007.142315},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2375496/},
  urldate = {2022-09-04},
  abstract = {Higher cortical functions (perception, cognition, learning and memory) are in large part based on the integration of electrical and calcium signals that takes place in thin dendritic branches of neocortical pyramidal cells (synaptic integration). The mechanisms underlying the synaptic integration in thin basal dendrites are largely unexplored. We use a recently developed technique, multisite voltage–calcium imaging, to compare voltage and calcium transients from multiple locations along individual dendritic branches. Our results reveal characteristic electrical transients (plateau potentials) that trigger and shape dendritic calcium dynamics and calcium distribution during suprathreshold glutamatergic synaptic input. We regularly observed three classes of voltage–calcium interactions occurring simultaneously in three different zones of the same dendritic branch: (1) proximal to the input site, (2) at the input site, and (3) distal to the input site. One hundred micrometers away from the synaptic input site, both proximally and distally, dendritic calcium transients are in tight temporal correlation with the dendritic plateau potential. However, on the same dendrite, at the location of excitatory input, calcium transients outlast local dendritic plateau potentials by severalfold. These Ca2+ plateaus (duration 0.5–2 s) are spatially restricted to the synaptic input site, where they cause a brief down-regulation of dendritic excitability. Ca2+ plateaus are not mediated by Ca2+ release from intracellular stores, but rather by an NMDA-dependent small-amplitude depolarization, which persists after the collapse of the dendritic plateau potential. These unique features of dendritic voltage and calcium distributions may provide distinct zones for simultaneous long-term (bidirectional) modulation of synaptic contacts along the same basal branch.},
  issue = {Pt 2},
  pmcid = {PMC2375496},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SJANQFB9\Milojkovic et al. - 2007 - Voltage and calcium transients in basal dendrites .pdf}
}

@article{mincesCholinergicShapingNeural2017,
  title = {Cholinergic Shaping of Neural Correlations},
  author = {Minces, Victor and Pinto, Lucas and Dan, Yang and Chiba, Andrea A.},
  date = {2017-05-30},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {114},
  number = {22},
  pages = {5725--5730},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1621493114},
  url = {https://www.pnas.org/doi/10.1073/pnas.1621493114},
  urldate = {2023-03-22},
  abstract = {A primary function of the brain is to form representations of the sensory world. Its capacity to do so depends on the relationship between signal correlations, associated with neuronal receptive fields, and noise correlations, associated with neuronal response variability. It was recently shown that the behavioral relevance of sensory stimuli can modify the relationship between signal and noise correlations, presumably increasing the encoding capacity of the brain. In this work, we use data from the visual cortex of the awake mouse watching naturalistic stimuli and show that a similar modification is observed under heightened cholinergic modulation. Increasing cholinergic levels in the cortex through optogenetic stimulation of basal forebrain cholinergic neurons decreases the dependency that is commonly observed between signal and noise correlations. Simulations of correlated neural networks with realistic firing statistics indicate that this change in the correlation structure increases the encoding capacity of the network.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9LJALWSK\Minces et al. - 2017 - Cholinergic shaping of neural correlations.pdf}
}

@article{miryQuestHippocampalMemory2021,
  title = {The {{Quest}} for the {{Hippocampal Memory Engram}}: {{From Theories}} to {{Experimental Evidence}}},
  shorttitle = {The {{Quest}} for the {{Hippocampal Memory Engram}}},
  author = {Miry, Omid and Li, Jie and Chen, Lu},
  date = {2021},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  volume = {14},
  issn = {1662-5153},
  url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2020.632019},
  urldate = {2023-04-15},
  abstract = {More than a century after Richard Semon's theoretical proposal of the memory engram, technological advancements have finally enabled experimental access to engram cells and their functional contents. In this review, we summarize theories and their experimental support regarding hippocampal memory engram formation and function. Specifically, we discuss recent advances in the engram field which help to reconcile two main theories for how the hippocampus supports memory formation: The Memory Indexing and Cognitive Map theories. We also highlight the latest evidence for engram allocation mechanisms through which memories can be linked or separately encoded. Finally, we identify unanswered questions for future investigations, through which a more comprehensive understanding of memory formation and retrieval may be achieved.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EWCUSSFR\Miry et al. - 2021 - The Quest for the Hippocampal Memory Engram From .pdf}
}

@article{miryQuestHippocampalMemory2021a,
  title = {The {{Quest}} for the {{Hippocampal Memory Engram}}: {{From Theories}} to {{Experimental Evidence}}},
  shorttitle = {The {{Quest}} for the {{Hippocampal Memory Engram}}},
  author = {Miry, Omid and Li, Jie and Chen, Lu},
  date = {2021},
  journaltitle = {Frontiers in Behavioral Neuroscience},
  volume = {14},
  issn = {1662-5153},
  url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2020.632019},
  urldate = {2023-04-16},
  abstract = {More than a century after Richard Semon's theoretical proposal of the memory engram, technological advancements have finally enabled experimental access to engram cells and their functional contents. In this review, we summarize theories and their experimental support regarding hippocampal memory engram formation and function. Specifically, we discuss recent advances in the engram field which help to reconcile two main theories for how the hippocampus supports memory formation: The Memory Indexing and Cognitive Map theories. We also highlight the latest evidence for engram allocation mechanisms through which memories can be linked or separately encoded. Finally, we identify unanswered questions for future investigations, through which a more comprehensive understanding of memory formation and retrieval may be achieved.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SAYSQD6E\Miry et al. - 2021 - The Quest for the Hippocampal Memory Engram From .pdf}
}

@article{mitchellDifferentialAttentionDependentResponse2007,
  title = {Differential {{Attention-Dependent Response Modulation}} across {{Cell Classes}} in {{Macaque Visual Area V4}}},
  author = {Mitchell, Jude F. and Sundberg, Kristy A. and Reynolds, John H.},
  date = {2007-07-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {55},
  number = {1},
  eprint = {17610822},
  eprinttype = {pmid},
  pages = {131--141},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2007.06.018},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(07)00449-7},
  urldate = {2023-02-10},
  langid = {english},
  keywords = {SYSNEURO},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VPDXK566\Mitchell et al. - 2007 - Differential Attention-Dependent Response Modulati.pdf}
}

@article{mitchellSpatialAttentionDecorrelates2009,
  title = {Spatial {{Attention Decorrelates Intrinsic Activity Fluctuations}} in {{Macaque Area V4}}},
  author = {Mitchell, Jude F. and Sundberg, Kristy A. and Reynolds, John H.},
  date = {2009-09-24},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {63},
  number = {6},
  eprint = {19778515},
  eprinttype = {pmid},
  pages = {879--888},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.09.013},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(09)00695-3},
  urldate = {2023-01-16},
  langid = {english},
  keywords = {SIGNALING,SYSBIO,SYSNEURO},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4B9NKDV2\Mitchell et al. - 2009 - Spatial Attention Decorrelates Intrinsic Activity .pdf}
}

@article{mlynarskiEfficientCodingTheory2022,
  title = {Efficient Coding Theory of Dynamic Attentional Modulation},
  author = {Młynarski, Wiktor and Tkačik, Gašper},
  date = {2022-12-21},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {20},
  number = {12},
  pages = {e3001889},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001889},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001889},
  urldate = {2022-12-23},
  abstract = {Activity of sensory neurons is driven not only by external stimuli but also by feedback signals from higher brain areas. Attention is one particularly important internal signal whose presumed role is to modulate sensory representations such that they only encode information currently relevant to the organism at minimal cost. This hypothesis has, however, not yet been expressed in a normative computational framework. Here, by building on normative principles of probabilistic inference and efficient coding, we developed a model of dynamic population coding in the visual cortex. By continuously adapting the sensory code to changing demands of the perceptual observer, an attention-like modulation emerges. This modulation can dramatically reduce the amount of neural activity without deteriorating the accuracy of task-specific inferences. Our results suggest that a range of seemingly disparate cortical phenomena such as intrinsic gain modulation, attention-related tuning modulation, and response variability could be manifestations of the same underlying principles, which combine efficient sensory coding with optimal probabilistic inference in dynamic environments.},
  langid = {english},
  keywords = {Attention,Coding mechanisms,Neuronal tuning,Neurons,Sensory neurons,Sensory perception,Vision,Visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7MLMZ978\Młynarski and Tkačik - 2022 - Efficient coding theory of dynamic attentional mod.pdf}
}

@article{mlynarskiEfficientCodingTheory2022a,
  title = {Efficient Coding Theory of Dynamic Attentional Modulation},
  author = {Młynarski, Wiktor and Tkačik, Gašper},
  date = {2022-12-21},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {20},
  number = {12},
  pages = {e3001889},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3001889},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001889},
  urldate = {2023-01-20},
  abstract = {Activity of sensory neurons is driven not only by external stimuli but also by feedback signals from higher brain areas. Attention is one particularly important internal signal whose presumed role is to modulate sensory representations such that they only encode information currently relevant to the organism at minimal cost. This hypothesis has, however, not yet been expressed in a normative computational framework. Here, by building on normative principles of probabilistic inference and efficient coding, we developed a model of dynamic population coding in the visual cortex. By continuously adapting the sensory code to changing demands of the perceptual observer, an attention-like modulation emerges. This modulation can dramatically reduce the amount of neural activity without deteriorating the accuracy of task-specific inferences. Our results suggest that a range of seemingly disparate cortical phenomena such as intrinsic gain modulation, attention-related tuning modulation, and response variability could be manifestations of the same underlying principles, which combine efficient sensory coding with optimal probabilistic inference in dynamic environments.},
  langid = {english},
  keywords = {Attention,Coding mechanisms,Neuronal tuning,Neurons,Sensory neurons,Sensory perception,Vision,Visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\32IM4JYV\Młynarski and Tkačik - 2022 - Efficient coding theory of dynamic attentional mod.pdf}
}

@inproceedings{mnihRecurrentModelsVisual2014,
  title = {Recurrent {{Models}} of {{Visual Attention}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and {kavukcuoglu}, koray},
  date = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2014/hash/09c6c3783b4a70054da74f2538ed47c6-Abstract.html},
  urldate = {2023-01-23},
  abstract = {Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T6LLUZB3\Mnih et al. - 2014 - Recurrent Models of Visual Attention.pdf}
}

@article{ModelCircadianOscillations1995,
  title = {A Model for Circadian Oscillations in the {{{\emph{Drosophila}}}} Period Protein ({{PER}})},
  date = {1995-09-22},
  journaltitle = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
  shortjournal = {Proc. R. Soc. Lond. B},
  volume = {261},
  number = {1362},
  pages = {319--324},
  issn = {0962-8452, 1471-2954},
  doi = {10.1098/rspb.1995.0153},
  url = {https://royalsocietypublishing.org/doi/10.1098/rspb.1995.0153},
  urldate = {2023-02-23},
  abstract = {The mechanism of circadian oscillations in the period protein (PER) in Drosophila is investigated by means of a theoretical model. Taking into account recent experimental observations, the model for the circadian clock is based on multiple phosphorylation of PER and on the negative feedback exerted by PER on the transcription of the period (per) gene. This minimal biochemical model provides a molecular basis for circadian oscillations of the limit cycle type. During oscillations, the peak in per mRNA precedes by several hours the peak in total PER protein. The results support the view that multiple PER phosphorylation introduces times delays which strengthen the capability of negative feedback to produce oscillations. The analysis shows that the rhythm only occurs in a range bounded by two critical values of the maximum rate of PER degradation. A similar result is obtained with respect to the rate of PER transport into the nucleus. The results suggest a tentative explanation for the altered period of per mutants, in terms of variations in the rate of PER degradation.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NG54ZL7L\1995 - A model for circadian oscillations in the Droso.pdf}
}

@article{mohawkCentralPeripheralCircadian2012,
  title = {✅  {{Central}} and {{Peripheral Circadian Clocks}} in {{Mammals}}},
  author = {Mohawk, Jennifer A. and Green, Carla B. and Takahashi, Joseph S.},
  date = {2012},
  journaltitle = {Annual Review of Neuroscience},
  volume = {35},
  number = {1},
  eprint = {22483041},
  eprinttype = {pmid},
  pages = {445--462},
  doi = {10.1146/annurev-neuro-060909-153128},
  url = {https://doi.org/10.1146/annurev-neuro-060909-153128},
  urldate = {2023-02-16},
  abstract = {The circadian system of mammals is composed of a hierarchy of oscillators that function at the cellular, tissue, and systems levels. A common molecular mechanism underlies the cell-autonomous circadian oscillator throughout the body, yet this clock system is adapted to different functional contexts. In the central suprachiasmatic nucleus (SCN) of the hypothalamus, a coupled population of neuronal circadian oscillators acts as a master pacemaker for the organism to drive rhythms in activity and rest, feeding, body temperature, and hormones. Coupling within the SCN network confers robustness to the SCN pacemaker, which in turn provides stability to the overall temporal architecture of the organism. Throughout the majority of the cells in the body, cell-autonomous circadian clocks are intimately enmeshed within metabolic pathways. Thus, an emerging view for the adaptive significance of circadian clocks is their fundamental role in orchestrating metabolism.},
  keywords = {clock genes,metabolism,oscillator coupling,suprachiasmatic nucleus,temperature},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\857S2X7B\\Mohawk et al. - 2012 - Central and Peripheral Circadian Clocks in Mammals.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PX4B6XTM\\mohawk2012.pdf}
}

@article{montangieAutonomousEmergenceConnectivity2020,
  title = {Autonomous Emergence of Connectivity Assemblies via Spike Triplet Interactions},
  author = {Montangie, Lisandro and Miehl, Christoph and Gjorgjieva, Julijana},
  date = {2020-05-08},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {16},
  number = {5},
  pages = {e1007835},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007835},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007835},
  urldate = {2022-09-30},
  abstract = {Non-random connectivity can emerge without structured external input driven by activity-dependent mechanisms of synaptic plasticity based on precise spiking patterns. Here we analyze the emergence of global structures in recurrent networks based on a triplet model of spike timing dependent plasticity (STDP), which depends on the interactions of three precisely-timed spikes, and can describe plasticity experiments with varying spike frequency better than the classical pair-based STDP rule. We derive synaptic changes arising from correlations up to third-order and describe them as the sum of structural motifs, which determine how any spike in the network influences a given synaptic connection through possible connectivity paths. This motif expansion framework reveals novel structural motifs under the triplet STDP rule, which support the formation of bidirectional connections and ultimately the spontaneous emergence of global network structure in the form of self-connected groups of neurons, or assemblies. We propose that under triplet STDP assembly structure can emerge without the need for externally patterned inputs or assuming a symmetric pair-based STDP rule common in previous studies. The emergence of non-random network structure under triplet STDP occurs through internally-generated higher-order correlations, which are ubiquitous in natural stimuli and neuronal spiking activity, and important for coding. We further demonstrate how neuromodulatory mechanisms that modulate the shape of the triplet STDP rule or the synaptic transmission function differentially promote structural motifs underlying the emergence of assemblies, and quantify the differences using graph theoretic measures.},
  langid = {english},
  keywords = {Action potentials,Clustering coefficients,Fourier analysis,Network motifs,Neural networks,Neuronal plasticity,Neurons,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YYU8ERIK\\Montangie et al. - 2020 - Autonomous emergence of connectivity assemblies vi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CNHXWIAD\\article.html}
}

@article{mooremdCIRCADIANRHYTHMSBasic1997,
  title = {{{CIRCADIAN RHYTHMS}}: {{Basic Neurobiology}} and {{Clinical Applications}}},
  shorttitle = {{{CIRCADIAN RHYTHMS}}},
  author = {Moore MD, Robert Y.},
  date = {1997},
  journaltitle = {Annual Review of Medicine},
  volume = {48},
  number = {1},
  eprint = {9046960},
  eprinttype = {pmid},
  pages = {253--266},
  doi = {10.1146/annurev.med.48.1.253},
  url = {https://doi.org/10.1146/annurev.med.48.1.253},
  urldate = {2023-02-16},
  abstract = {Circadian rhythms are major features of adaptation to our environment. In mammals, circadian rhythms are generated and regulated by a circadian timing system. This system consists of entrainment pathways, pacemakers, and pacemaker output to effector systems that are under circadian control. The primary entrainment pathway is the retinohypothalamic tract, which terminates in the circadian pacemakers, the suprachiasmatic nuclei of the hypothalamus. The output of the suprachiasmatic nuclei is principally to the hypothalamus, the midline thalamus, and the basal forebrain. This provides a temporal organization to the sleep-wake cycle, to many physiological and endocrine functions, and to psychomotor performance functions. Disorders of circadian timing primarily affect entrainment and pacemaker functions. The pineal hormone, melatonin, appears to be a promising agent for therapy of some circadian timing disorders.},
  keywords = {affective disorders,melatonin,retinohypothalamic tract,sleep disorders,suprachiasmatic nucleus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FRW7VUI4\Moore MD - 1997 - CIRCADIAN RHYTHMS Basic Neurobiology and Clinical.pdf}
}

@article{mooreSuprachiasmaticNucleusOrganization2002,
  title = {Suprachiasmatic Nucleus Organization},
  author = {Moore, Robert and Speh, Joan and Leak, Rehana},
  date = {2002-08-01},
  journaltitle = {Cell and tissue research},
  shortjournal = {Cell and tissue research},
  volume = {309},
  pages = {89--98},
  doi = {10.1007/s00441-002-0575-2},
  abstract = {The suprachiasmatic nucleus (SCN) of the hypothalamus is a dominant circadian pacemaker in the mammalian brain controlling the rest-activity cycle and a series of physiological and endocrine functions to provide a foundation for the successful elaboration of adaptive sleep and waking behavior. The SCN is anatomically and functionally organized into two subdivisions: (1) a core that lies adjacent to the optic chiasm, comprises predominantly neurons producing vasoactive intestinal polypeptide (VIP) or gastrin-releasing peptide (GRP) colocalized with GABA and receives dense visual and midbrain raphe afferents, and (2) a shell that surrounds the core, contains a large population of arginine vasopressin (AVP)-producing neurons in its dorsomedial portion, and a smaller population of calretinin (CAR)-producing neurons dorsally and laterally, colocalized with GABA, and receives input from non-visual cortical and subcortical regions. In this paper, we present a detailed quantitative analysis of the organization of the SCN core and shell in the rat and place this in the context of the functional significance of the subdivisions in the circadian control of regulatory systems.}
}

@article{mooreSuprachiasmaticNucleusSleep2007,
  title = {✅ {{Suprachiasmatic}} Nucleus in Sleep–Wake Regulation},
  author = {Moore, Robert Y.},
  date = {2007-12-01},
  journaltitle = {Sleep Medicine},
  shortjournal = {Sleep Medicine},
  series = {The Roles of Melatonin and the Suprachiasmatic Nucleus in Sleep Regulation. {{Proceedings}} from a {{Roundtable Discussion}}},
  volume = {8},
  pages = {27--33},
  issn = {1389-9457},
  doi = {10.1016/j.sleep.2007.10.003},
  url = {https://www.sciencedirect.com/science/article/pii/S1389945707003577},
  urldate = {2023-02-23},
  abstract = {The evolution of animals is a consequence of selective specialization of cells, tissues, functional systems, and behavior. The objective of all life is successful reproduction and maintenance of the species. In order to accomplish this, all animals have evolved a division of behavior into two fundamental behavioral states: one characterized by the elaboration of adaptive behavior (activity) and the other by rest and behavioral quiescence (rest). In mammals, these states are designated wake and sleep. Activity and rest, wake and sleep, occur in precise 24-h cycles that have evolved as an adaptation to the solar cycle of light and dark. These cycles are referred to as circadian rhythms. Over the last 40years, we have gained detailed knowledge about the neurobiology of both wake and sleep and the circadian control of their timing. We now know that circadian rhythms are present in cells throughout the body. In the brain, a small group of hypothalamic nerve cells, the suprachiasmatic nucleus (SCN), functions as a master circadian pacemaker controlling the timing of the sleep–wake cycle and coordinating this with circadian rhythms in other brain areas and other tissues to enhance behavioral adaptation. In this review, I will summarize our current understanding of the organization and function of the circadian timing system and its role in the regulation of brain mechanisms of sleep and wake.},
  langid = {english},
  keywords = {Circadian rhythm,Homeostatic drive,NREM sleep,Pineal gland,VLPO},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A6NHPDIN\\Moore - 2007 - Suprachiasmatic nucleus in sleep–wake regulation.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\67ANNFCN\\S1389945707003577.html}
}

@article{morales-gregorioNeuralManifoldsV12024,
  title = {✅ {{Neural}} Manifolds in {{V1}} Change with Top-down Signals from {{V4}} Targeting the Foveal Region},
  author = {Morales-Gregorio, Aitor and Kurth, Anno C. and Ito, Junji and Kleinjohann, Alexander and Barthélemy, Frédéric V. and Brochier, Thomas and Grün, Sonja and van Albada, Sacha J.},
  date = {2024-07-23},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {43},
  number = {7},
  eprint = {38923458},
  eprinttype = {pmid},
  publisher = {Elsevier},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2024.114371},
  url = {https://www.cell.com/cell-reports/abstract/S2211-1247(24)00699-5},
  urldate = {2024-07-01},
  langid = {english},
  keywords = {CP: Neuroscience,dimensionality,electrophysiology,macaque,neural manifold,resting state,top-down signals,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\33GTTR67\\mmc1.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\VHXEYNU5\\Morales-Gregorio et al. - 2024 - Neural manifolds in V1 change with top-down signal.pdf}
}

@article{moranSelectiveAttentionGates1985,
  title = {Selective Attention Gates Visual Processing in the Extrastriate Cortex},
  author = {Moran, J. and Desimone, R.},
  date = {1985-08-23},
  journaltitle = {Science (New York, N.Y.)},
  shortjournal = {Science},
  volume = {229},
  number = {4715},
  eprint = {4023713},
  eprinttype = {pmid},
  pages = {782--784},
  issn = {0036-8075},
  doi = {10.1126/science.4023713},
  abstract = {Single cells were recorded in the visual cortex of monkeys trained to attend to stimuli at one location in the visual field and ignore stimuli at another. When both locations were within the receptive field of a cell in prestriate area V4 or the inferior temporal cortex, the response to the unattended stimulus was dramatically reduced. Cells in the striate cortex were unaffected by attention. The filtering of irrelevant information from the receptive fields of extrastriate neurons may underlie the ability to identify and remember the properties of a particular object out of the many that may be represented on the retina.},
  langid = {english},
  keywords = {Animals,Attention,Brain Mapping,Macaca mulatta,Visual Cortex,Visual Perception}
}

@online{MoreDifferentScience,
  title = {More {{Is Different}} | {{Science}}},
  url = {https://www.science.org/doi/10.1126/science.177.4047.393},
  urldate = {2022-10-03}
}

@article{moreno-boteTheoryInputSpike2008,
  title = {Theory of {{Input Spike Auto-}} and {{Cross-Correlations}} and {{Their Effect}} on the {{Response}} of {{Spiking Neurons}}},
  author = {Moreno-Bote, Rubén and Renart, Alfonso and Parga, Néstor},
  date = {2008-07},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {20},
  number = {7},
  pages = {1651--1705},
  issn = {0899-7667, 1530-888X},
  doi = {10.1162/neco.2008.03-07-497},
  url = {https://direct.mit.edu/neco/article/20/7/1651-1705/7332},
  urldate = {2023-06-08},
  abstract = {Spike correlations between neurons are ubiquitous in the cortex, but their role is not understood. Here we describe the firing response of a leaky integrate-and-fire neuron (LIF) when it receives a temporarily correlated input generated by presynaptic correlated neuronal populations. Input correlations are characterized in terms of the firing rates, Fano factors, correlation coefficients, and correlation timescale of the neurons driving the target neuron. We show that the sum of the presynaptic spike trains cannot be well described by a Poisson process. In fact, the total input current has a nontrivial two-point correlation function described by two main parameters: the correlation timescale (how precise the input correlations are in time) and the correlation magnitude (how strong they are). Therefore, the total current generated by the input spike trains is not well described by a white noise gaussian process. Instead, we model the total current as a colored gaussian process with the same mean and two-point correlation function, leading to the formulation of the problem in terms of a Fokker-Planck equation. Solutions of the output firing rate are found in the limit of short and long correlation timescales. The solutions described here expand and improve on our previous results (Moreno, de la Rocha, Renart, \& Parga, 2002) by presenting new analytical expressions for the output firing rate for general IF neurons, extending the validity of the results for arbitrarily large correlation magnitude, and by describing the differential effect of correlations on the mean-driven or noise-dominated firing regimes. Also the details of this novel formalism are given here for the first time. We employ numerical simulations to confirm the analytical solutions and study the firing response to sudden changes in the input correlations. We expect this formalism to be useful for the study of correlations in neuronal networks and their role in neural processing and information transmission.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CNSR9YCM\Moreno-Bote et al. - 2008 - Theory of Input Spike Auto- and Cross-Correlations.pdf}
}

@article{moSensorimotorPathwayHigherOrder2019,
  title = {A {{Sensorimotor Pathway}} via {{Higher-Order Thalamus}}},
  author = {Mo, Christina and Sherman, S. Murray},
  date = {2019-01-23},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {39},
  number = {4},
  eprint = {30504278},
  eprinttype = {pmid},
  pages = {692--704},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1467-18.2018},
  url = {https://www.jneurosci.org/content/39/4/692},
  urldate = {2023-08-03},
  abstract = {We now know that sensory processing in cortex occurs not only via direct communication between primary to secondary areas, but also via their parallel cortico-thalamo-cortical (i.e., trans-thalamic) pathways. Both corticocortical and trans-thalamic pathways mainly signal through glutamatergic class 1 (driver) synapses, which have robust and efficient synaptic dynamics suited for the transfer of information such as receptive field properties, suggesting the importance of class 1 synapses in feedforward, hierarchical processing. However, such a parallel arrangement has only been identified in sensory cortical areas: visual, somatosensory, and auditory. To test the generality of trans-thalamic pathways, we sought to establish its presence beyond purely sensory cortices to determine whether there is a trans-thalamic pathway parallel to the established primary somatosensory (S1) to primary motor (M1) pathway. We used trans-synaptic viral tracing, optogenetics in slice preparations, and bouton size analysis in the mouse (both sexes) to document that a circuit exists from layer 5 of S1 through the posterior medial nucleus of the thalamus to M1 with glutamatergic class 1 properties. This represents a hitherto unknown, robust sensorimotor linkage and suggests that the arrangement of parallel direct and trans-thalamic corticocortical circuits may be present as a general feature of cortical functioning. SIGNIFICANCE STATEMENT During sensory processing, feedforward pathways carry information such as receptive field properties via glutamatergic class 1 synapses, which have robust and efficient synaptic dynamics. As expected, class 1 synapses subserve the feedforward projection from primary to secondary sensory cortex, but also a route through specific higher-order thalamic nuclei, creating a parallel feedforward trans-thalamic pathway. We now extend the concept of cortical areas being connected via parallel, direct, and trans-thalamic circuits from purely sensory cortices to a sensorimotor cortical circuit (i.e., primary sensory cortex to primary motor cortex). This suggests a generalized arrangement for corticocortical communication.},
  langid = {english},
  keywords = {driver pathway,motor cortex,posterior medial nucleus,sensorimotor,somatosensory cortex,trans-thalamic},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KCDPVAMM\Mo and Sherman - 2019 - A Sensorimotor Pathway via Higher-Order Thalamus.pdf}
}

@article{munchUserGuideTopological2017,
  title = {✅ {{A User}}’s {{Guide}} to {{Topological Data Analysis}}},
  author = {Munch, Elizabeth},
  date = {2017-07-05},
  journaltitle = {Journal of Learning Analytics},
  volume = {4},
  number = {2},
  pages = {47--61},
  issn = {1929-7750},
  doi = {10.18608/jla.2017.42.6},
  url = {https://learning-analytics.info/index.php/JLA/article/view/5196},
  urldate = {2024-07-02},
  abstract = {Topological data analysis (TDA) is a collection of powerful tools that can quantify shape and structure in data in order to answer questions from the data’s domain. This is done by representing some aspect of the structure of the data in a simplified topological signature. In this article, we introduce two of the most commonly used topological signatures. First, the persistence diagram represents loops and holes in the space by considering connectivity of the data points for a continuum of values rather than a single fixed value. The second topological signature, the mapper graph, returns a 1-dimensional structure representing the shape of the data, and is particularly good for exploration and visualization of the data. While these techniques are based on very sophisticated mathematics, the current ubiquity of available software means that these tools are more accessible than ever to be applied to data by researchers in education and learning, as well as all domain scientists.},
  issue = {2},
  langid = {english},
  keywords = {Mapper},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\536FUNS9\Munch - 2017 - A User’s Guide to Topological Data Analysis.pdf}
}

@article{murakamiThreedimensionalSinglecellresolutionWholebrain2018,
  title = {A Three-Dimensional Single-Cell-Resolution Whole-Brain Atlas Using {{CUBIC-X}} Expansion Microscopy and Tissue Clearing},
  author = {Murakami, Tatsuya C. and Mano, Tomoyuki and Saikawa, Shu and Horiguchi, Shuhei A. and Shigeta, Daichi and Baba, Kousuke and Sekiya, Hiroshi and Shimizu, Yoshihiro and Tanaka, Kenji F. and Kiyonari, Hiroshi and Iino, Masamitsu and Mochizuki, Hideki and Tainaka, Kazuki and Ueda, Hiroki R.},
  date = {2018-04},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {4},
  pages = {625--637},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-018-0109-1},
  url = {http://www.nature.com/articles/s41593-018-0109-1},
  urldate = {2020-09-02},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YRT4C5FC\Murakami et al. - 2018 - A three-dimensional single-cell-resolution whole-b.pdf}
}

@article{nagaiHyperactivityDisruptedAttention2019,
  title = {Hyperactivity with {{Disrupted Attention}} by {{Activation}} of an {{Astrocyte Synaptogenic Cue}}},
  author = {Nagai, Jun and Rajbhandari, Abha K. and Gangwani, Mohitkumar R. and Hachisuka, Ayaka and Coppola, Giovanni and Masmanidis, Sotiris C. and Fanselow, Michael S. and Khakh, Baljit S.},
  date = {2019-05-16},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {177},
  number = {5},
  eprint = {31031006},
  eprinttype = {pmid},
  pages = {1280-1292.e20},
  publisher = {Elsevier},
  issn = {0092-8674, 1097-4172},
  doi = {10.1016/j.cell.2019.03.019},
  url = {https://www.cell.com/cell/abstract/S0092-8674(19)30281-8},
  urldate = {2020-11-19},
  abstract = {{$<$}h2{$>$}Summary{$<$}/h2{$><$}p{$>$}Hyperactivity and disturbances of attention are common behavioral disorders whose underlying cellular and neural circuit causes are not understood. We report the discovery that striatal astrocytes drive such phenotypes through a hitherto unknown synaptic mechanism. We found that striatal medium spiny neurons (MSNs) triggered astrocyte signaling via γ-aminobutyric acid B (GABA\textsubscript{B}) receptors. Selective chemogenetic activation of this pathway in striatal astrocytes \emph{in vivo} resulted in acute behavioral hyperactivity and disrupted attention. Such responses also resulted in upregulation of the synaptogenic cue thrombospondin-1 (TSP1) in astrocytes, increased excitatory synapses, enhanced corticostriatal synaptic transmission, and increased MSN action potential firing \emph{in vivo}. All of these changes were reversed by blocking TSP1 effects. Our data identify a form of bidirectional neuron-astrocyte communication and demonstrate that acute reactivation of a single latent astrocyte synaptogenic cue alters striatal circuits controlling behavior, revealing astrocytes and the TSP1 pathway as therapeutic targets in hyperactivity, attention deficit, and related psychiatric disorders.{$<$}/p{$>$}},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QL43PTNP\\Nagai et al. - 2019 - Hyperactivity with Disrupted Attention by Activati.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EIJG9CWV\\S0092-8674(19)30281-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J9QEMWAI\\S0092-8674(19)30281-8.html}
}

@article{naglerImpactSingleLinks2011,
  title = {Impact of Single Links in Competitive Percolation},
  author = {Nagler, Jan and Levina, Anna and Timme, Marc},
  date = {2011-03},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {7},
  number = {3},
  pages = {265--270},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys1860},
  url = {https://www.nature.com/articles/nphys1860},
  urldate = {2022-10-01},
  abstract = {How a complex network is connected crucially impacts its dynamics and function. Percolation, the transition to extensive connectedness on gradual addition of links, was long believed to be continuous, but recent numerical evidence of ‘explosive percolation’ suggests that it might also be discontinuous if links compete for addition. Here we analyse the microscopic mechanisms underlying discontinuous percolation processes and reveal a strong impact of single-link additions. We show that in generic competitive percolation processes, including those showing explosive percolation, single links do not induce a discontinuous gap in the largest cluster size in the thermodynamic limit. Nevertheless, our results highlight that for large finite systems single links may still induce substantial gaps, because gap sizes scale weakly algebraically with system size. Several essentially macroscopic clusters coexist immediately before the transition, announcing discontinuous percolation. These results explain how single links may drastically change macroscopic connectivity in networks where links add competitively.},
  issue = {3},
  langid = {english},
  keywords = {Atomic,Classical and Continuum Physics,Complex Systems,Condensed Matter Physics,general,Mathematical and Computational Physics,Molecular,Optical and Plasma Physics,Physics,Theoretical},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Y3TTQWLS\\Nagler et al. - 2011 - Impact of single links in competitive percolation.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NLFW9HBM\\nphys1860.html}
}

@article{nandyLaminarOrganizationAttentional2017,
  title = {Laminar {{Organization}} of {{Attentional Modulation}} in {{Macaque Visual Area V4}}},
  author = {Nandy, Anirvan S. and Nassi, Jonathan J. and Reynolds, John H.},
  date = {2017-01-04},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {93},
  number = {1},
  eprint = {27989456},
  eprinttype = {pmid},
  pages = {235--246},
  issn = {1097-4199},
  doi = {10.1016/j.neuron.2016.11.029},
  abstract = {Attention is critical to perception, serving to select behaviorally relevant information for privileged processing. To understand the neural mechanisms of attention, we must discern how attentional modulation varies by cell type and across cortical layers. Here, we test whether attention acts non-selectively across cortical layers or whether it engages the laminar circuit in specific and selective ways. We find layer- and cell-class-specific differences in several different forms of attentional modulation in area V4. Broad-spiking neurons in the superficial layers exhibit attention-mediated increases in firing rate and decreases in variability. Spike count correlations are highest in the input layer and attention serves to reduce these correlations. Superficial and input layer neurons exhibit attention-dependent decreases in low-frequency ({$<$}10~Hz) coherence, but deep layer neurons exhibit increases in coherence in the beta and gamma frequency ranges. Our study provides a template for attention-mediated laminar information processing that might be applicable across sensory modalities.},
  langid = {english},
  pmcid = {PMC5217483},
  keywords = {Animals,area V4,attention,Attention,Brain Waves,laminar circuit,Macaca mulatta,Neurons,Visual Cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2T79HJHX\Nandy et al. - 2017 - Laminar Organization of Attentional Modulation in .pdf}
}

@online{naudConnectingLevelsAnalysis2023,
  title = {✅ {{Connecting}} Levels of Analysis in the Computational Era},
  author = {Naud, Richard and Longtin, André},
  date = {2023-05-10},
  eprint = {2305.06037},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  doi = {10.48550/arXiv.2305.06037},
  url = {http://arxiv.org/abs/2305.06037},
  urldate = {2023-05-17},
  abstract = {Neuroscience and artificial intelligence are closely intertwined, but so are the physics of dynamical system, philosophy and psychology. Each of these fields try in their own way to relate observations at the level of molecules, synapses, neurons or behavior, to a function. An influential conceptual approach to this end was popularized by David Marr, which focused on the interaction between three theoretical 'levels of analysis'. With the convergence of simulation-based approaches, algorithm-oriented Neuro-AI and high-throughput data, we currently see much research organized around four levels of analysis: observations, models, algorithms and functions. Bidirectional interaction between these levels influences how we undertake interdisciplinary science.},
  pubstate = {prepublished},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\V84RZBYU\\Naud and Longtin - 2023 - Connecting levels of analysis in the computational.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\85JQMGH2\\2305.html}
}

@article{naudNoiseGatedDendrosomatic2017,
  title = {Noise {{Gated}} by {{Dendrosomatic Interactions Increases Information Transmission}}},
  author = {Naud, Richard and Payeur, Alexandre and Longtin, André},
  date = {2017-09-13},
  journaltitle = {Physical Review X},
  shortjournal = {Phys. Rev. X},
  volume = {7},
  number = {3},
  pages = {031045},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.7.031045},
  url = {https://link.aps.org/doi/10.1103/PhysRevX.7.031045},
  urldate = {2022-09-21},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\GKLW9AKX\Naud et al. - 2017 - Noise Gated by Dendrosomatic Interactions Increase.pdf}
}

@article{naudSparseBurstsOptimize2018,
  title = {Sparse Bursts Optimize Information Transmission in a Multiplexed Neural Code},
  author = {Naud, Richard and Sprekeler, Henning},
  date = {2018-07-03},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {115},
  number = {27},
  eprint = {29934400},
  eprinttype = {pmid},
  pages = {E6329-E6338},
  publisher = {National Academy of Sciences},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1720995115},
  url = {https://www.pnas.org/content/115/27/E6329},
  urldate = {2020-08-25},
  abstract = {Many cortical neurons combine the information ascending and descending the cortical hierarchy. In the classical view, this information is combined nonlinearly to give rise to a single firing-rate output, which collapses all input streams into one. We analyze the extent to which neurons can simultaneously represent multiple input streams by using a code that distinguishes spike timing patterns at the level of a neural ensemble. Using computational simulations constrained by experimental data, we show that cortical neurons are well suited to generate such multiplexing. Interestingly, this neural code maximizes information for short and sparse bursts, a regime consistent with in vivo recordings. Neurons can also demultiplex this information, using specific connectivity patterns. The anatomy of the adult mammalian cortex suggests that these connectivity patterns are used by the nervous system to maintain sparse bursting and optimal multiplexing. Contrary to firing-rate coding, our findings indicate that the physiology and anatomy of the cortex may be interpreted as optimizing the transmission of multiple independent signals to different targets.},
  langid = {english},
  keywords = {cerebral cortex,dendritic computation,multiplexing,neural coding,short-term plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\OneDrive - University of Ottawa\\Research Paper Notes\\Notes_BurstEnsembleMultiplexing_NuadSprekeler.docx;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JTWG4V7X\\Naud and Sprekeler - 2018 - Sparse bursts optimize information transmission in.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W6RKQU5B\\BEM_Supplemental.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DFQ65QTH\\E6329.html}
}

@article{naudSpiketimingPredictionCortical2014,
  title = {Spike-Timing Prediction in Cortical Neurons with Active Dendrites},
  author = {Naud, Richard and Bathellier, Brice and Gerstner, Wulfram},
  date = {2014-08-13},
  journaltitle = {Frontiers in Computational Neuroscience},
  shortjournal = {Front Comput Neurosci},
  volume = {8},
  eprint = {25165443},
  eprinttype = {pmid},
  issn = {1662-5188},
  doi = {10.3389/fncom.2014.00090},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4131408/},
  urldate = {2020-09-05},
  abstract = {A complete single-neuron model must correctly reproduce the firing of spikes and bursts. We present a study of a simplified model of deep pyramidal cells of the cortex with active dendrites. We hypothesized that we can model the soma and its apical dendrite with only two compartments, without significant loss in the accuracy of spike-timing predictions. The model is based on experimentally measurable impulse-response functions, which transfer the effect of current injected in one compartment to current reaching the other. Each compartment was modeled with a pair of non-linear differential equations and a small number of parameters that approximate the Hodgkin-and-Huxley equations. The predictive power of this model was tested on electrophysiological experiments where noisy current was injected in both the soma and the apical dendrite simultaneously. We conclude that a simple two-compartment model can predict spike times of pyramidal cells stimulated in the soma and dendrites simultaneously. Our results support that regenerating activity in the apical dendritic is required to properly account for the dynamics of layer 5 pyramidal cells under in-vivo-like conditions.},
  pmcid = {PMC4131408},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5NAATHCA\Naud et al. - 2014 - Spike-timing prediction in cortical neurons with a.pdf}
}

@report{naudTernaryNeuralCode2022,
  type = {preprint},
  title = {A Ternary Neural Code Resolves Error and Sharpening Signals},
  author = {Naud, Richard and Wang, Xingyun and Friedenberger, Zachary and Payeur, Alexandre and Shin, Jiyun N. and Béïque, Jean-Claude and Richards, Blake A. and Drüke, Moritz and Larkum, Matthew E. and Doron, Guy},
  date = {2022-10-07},
  institution = {Neuroscience},
  doi = {10.1101/2022.10.07.511138},
  url = {http://biorxiv.org/lookup/doi/10.1101/2022.10.07.511138},
  urldate = {2022-12-28},
  abstract = {Theories of attention and learning have hypothesized a central role for high-frequency bursting in cognitive functions, but experimental reports of burstmediated representations in vivo have been limited. Here we used a novel demultiplexing approach to separate independent streams of information from considering neurons as having three possible states: silent, singlet- and burst-firing. We studied this ternary neural code in vivo while animals learned to behaviorally report direct electrical stimulation of the somatosensory cortex and found two acquired yet independent representations. One code, the event rate, represented the stimulus in a small fraction of cells and showed a small modulation upon detection errors. The other code, the burst fraction, correlated more globally with stimulation and more promptly responded to detection errors. Bursting modulation was potent and its time course evolved, even in cells that were considered unresponsive based on the firing rate. During the later stages of training, this modulation in bursting happened earlier, gradually aligning temporally with the representation in event rate. The alignment of bursting and event rate modulation sharpened firing rate coded representations, and was strongly associated behavioral accuracy. Thus a fine grain separation of spike timing patterns reveals two signals that accompany stimulus representations: an error signal that can be essential to guide learning and a sharpening signal that could enact top-down attention.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Q4DNEIPU\Naud et al. - 2022 - A ternary neural code resolves error and sharpenin.pdf}
}

@inproceedings{nayebiIdentifyingLearningRules2020,
  title = {Identifying {{Learning Rules From Neural Network Observables}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Nayebi, Aran and Srivastava, Sanjana and Ganguli, Surya and Yamins, Daniel L},
  date = {2020},
  volume = {33},
  pages = {2639--2650},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/1ba922ac006a8e5f2b123684c2f4d65f-Abstract.html},
  urldate = {2024-01-08},
  abstract = {The brain modifies its synaptic strengths during learning in order to better adapt to its environment. However, the underlying plasticity rules that govern learning are unknown. Many proposals have been suggested, including Hebbian mechanisms, explicit error backpropagation, and a variety of alternatives. It is an open question as to what specific experimental measurements would need to be made to determine whether any given learning rule is operative in a real biological system. In this work, we take a "virtual experimental" approach to this problem. Simulating idealized neuroscience experiments with artificial neural networks, we generate a large-scale dataset of learning trajectories of aggregate statistics measured in a variety of neural network architectures, loss functions, learning rule hyperparameters, and parameter initializations. We then take a discriminative approach, training linear and simple non-linear classifiers to identify learning rules from features based on these observables. We show that different classes of learning rules can be separated solely on the basis of aggregate statistics of the weights, activations, or instantaneous layer-wise activity changes, and that these results generalize to limited access to the trajectory and held-out architectures and learning curricula. We identify the statistics of each observable that are most relevant for rule identification, finding that statistics from network activities across training are more robust to unit undersampling and measurement noise than those obtained from the synaptic strengths. Our results suggest that activation patterns, available from electrophysiological recordings of post-synaptic activities on the order of several hundred units, frequently measured at wider intervals over the course of learning, may provide a good basis on which to identify learning rules.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8TSNJ2UB\Nayebi et al. - 2020 - Identifying Learning Rules From Neural Network Obs.pdf}
}

@article{nayebiMouseVisualCortex2023,
  title = {✅ {{Mouse}} Visual Cortex as a Limited Resource System That Self-Learns an Ecologically-General Representation},
  author = {Nayebi, Aran and Kong, Nathan C. L. and Zhuang, Chengxu and Gardner, Justin L. and Norcia, Anthony M. and Yamins, Daniel L. K.},
  date = {2023-10-02},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {19},
  number = {10},
  pages = {e1011506},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1011506},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011506},
  urldate = {2024-06-17},
  abstract = {Studies of the mouse visual system have revealed a variety of visual brain areas that are thought to support a multitude of behavioral capacities, ranging from stimulus-reward associations, to goal-directed navigation, and object-centric discriminations. However, an overall understanding of the mouse’s visual cortex, and how it supports a range of behaviors, remains unknown. Here, we take a computational approach to help address these questions, providing a high-fidelity quantitative model of mouse visual cortex and identifying key structural and functional principles underlying that model’s success. Structurally, we find that a comparatively shallow network structure with a low-resolution input is optimal for modeling mouse visual cortex. Our main finding is functional—that models trained with task-agnostic, self-supervised objective functions based on the concept of contrastive embeddings are much better matches to mouse cortex, than models trained on supervised objectives or alternative self-supervised methods. This result is very much unlike in primates where prior work showed that the two were roughly equivalent, naturally leading us to ask the question of why these self-supervised objectives are better matches than supervised ones in mouse. To this end, we show that the self-supervised, contrastive objective builds a general-purpose visual representation that enables the system to achieve better transfer on out-of-distribution visual scene understanding and reward-based navigation tasks. Our results suggest that mouse visual cortex is a low-resolution, shallow network that makes best use of the mouse’s limited resources to create a light-weight, general-purpose visual system—in contrast to the deep, high-resolution, and more categorization-dominated visual system of primates.},
  langid = {english},
  keywords = {Calcium imaging,Mice,Mouse models,Primates,Rodents,Vision,Visual cortex,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CUVAEH7F\Nayebi et al. - 2023 - Mouse visual cortex as a limited resource system t.pdf}
}

@online{nejadTheoryTemporalSelfsupervised2024,
  title = {A Theory of Temporal Self-Supervised Learning in Neocortical Layers},
  author = {Nejad, Kevin Kermani and Anastasiades, Paul and Hertag, Loreen and Costa, Rui Ponte},
  date = {2024-04-25},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.04.24.590916},
  doi = {10.1101/2024.04.24.590916},
  url = {https://www.biorxiv.org/content/10.1101/2024.04.24.590916v1},
  urldate = {2024-04-29},
  abstract = {The neocortex constructs an internal representation of the world, but the underlying circuitry and computational principles remain unclear. Inspired by self-supervised learning algorithms, we introduce a computational model wherein layer 2/3 (L2/3) learns to predict incoming sensory stimuli by comparing previous sensory inputs, relayed via layer 4, with current thalamic inputs arriving at layer 5 (L5). We demonstrate that our model accurately predicts sensory information in a contextual temporal task, and that its predictions are robust to noisy or partial sensory input. Additionally, our model generates layer-specific sparsity and latent representations, consistent with experimental observations. Next, using a sensorimotor task, we show that the model's L2/3 and L5 prediction errors mirror mismatch responses observed in awake, behaving mice. Finally, through manipulations, we offer testable predictions to unveil the computational roles of various cortical features. In summary, our findings suggest that the multi-layered neocortex empowers the brain with self-supervised learning capabilities.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\I2A68DBL\Nejad et al. - 2024 - A theory of temporal self-supervised learning in n.pdf}
}

@inproceedings{NEURIPS2022_99088dff,
  title = {Single-Phase Deep Learning in Cortico-Cortical Networks},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Greedy, Will and Zhu, Heng Wei and Pemberton, Joseph and Mellor, Jack and Ponte Costa, Rui},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  date = {2022},
  volume = {35},
  pages = {24213--24225},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/99088dffd5eab0babebcda4bc58bbcea-Paper-Conference.pdf}
}

@online{NeurophysiologicalComputationalPrinciples,
  title = {Neurophysiological and {{Computational Principles}} of {{Cortical Rhythms}} in {{Cognition}}},
  doi = {10.1152/physrev.00035.2008},
  url = {https://journals.physiology.org/doi/epdf/10.1152/physrev.00035.2008},
  urldate = {2023-04-02},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IV3CG6XM\\physrev.00035.2008.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JJWUY57A\\Neurophysiological and Computational Principles of.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\G4N3VSWK\\physrev.00035.html}
}

@article{newmanPowerLawsPareto2005,
  title = {Power Laws, {{Pareto}} Distributions and {{Zipf}}'s Law},
  author = {Newman, Mej},
  date = {2005-09},
  journaltitle = {Contemporary Physics},
  shortjournal = {Contemporary Physics},
  volume = {46},
  number = {5},
  pages = {323--351},
  issn = {0010-7514, 1366-5812},
  doi = {10.1080/00107510500052444},
  url = {http://www.tandfonline.com/doi/abs/10.1080/00107510500052444},
  urldate = {2022-10-03},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QVUXQUJK\Newman - 2005 - Power laws, Pareto distributions and Zipf's law.pdf}
}

@online{NextLevelNeuromorphicComputing,
  title = {Next-{{Level Neuromorphic Computing}}: {{Intel Lab}}'s {{Loihi}} 2 {{Chip}}},
  shorttitle = {Next-{{Level Neuromorphic Computing}}},
  url = {https://www.intel.com/content/www/us/en/research/neuromorphic-computing-loihi-2-technology-brief.html},
  urldate = {2022-10-26},
  abstract = {Intel Lab’s Loihi 2 chip delivers outstanding performance \& new features, including an open-source, community-driven neuromorphic computing framework.},
  langid = {english},
  organization = {Intel},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3YYCCDHV\neuromorphic-computing-loihi-2-technology-brief.html}
}

@article{niLearningAttentionReveal2018,
  title = {✅  {{Learning}} and Attention Reveal a General Relationship between Population Activity and Behavior},
  author = {Ni, A. M. and Ruff, D. A. and Alberts, J. J. and Symmonds, J. and Cohen, M. R.},
  date = {2018-01-26},
  journaltitle = {Science},
  volume = {359},
  number = {6374},
  pages = {463--465},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aao0284},
  url = {https://www.science.org/doi/abs/10.1126/science.aao0284},
  urldate = {2022-12-19},
  abstract = {Prior studies have demonstrated that correlated variability changes with cognitive processes that improve perceptual performance. We tested whether correlated variability covaries with subjects’ performance—whether performance improves quickly with attention or slowly with perceptual learning. We found a single, consistent relationship between correlated variability and behavioral performance, regardless of the time frame of correlated variability change. This correlated variability was oriented along the dimensions in population space used by the animal on a trial-by-trial basis to make decisions. That subjects’ choices were predicted by specific dimensions that were aligned with the correlated variability axis clarifies long-standing paradoxes about the relationship between shared variability and behavior.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QL8LQ3PA\Ni et al. - 2018 - Learning and attention reveal a general relationsh.pdf}
}

@article{nogueiraGeometryCorticalRepresentations2023,
  title = {The Geometry of Cortical Representations of Touch in Rodents},
  author = {Nogueira, Ramon and Rodgers, Chris C. and Bruno, Randy M. and Fusi, Stefano},
  date = {2023-02},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {26},
  number = {2},
  pages = {239--250},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-022-01237-9},
  url = {https://www.nature.com/articles/s41593-022-01237-9},
  urldate = {2023-04-11},
  abstract = {Neurons often encode highly heterogeneous non-linear functions of multiple task variables, a signature of a high-dimensional geometry. We studied the representational geometry in the somatosensory cortex of mice trained to report the curvature of objects touched by their whiskers. High-speed videos of the whiskers revealed that the task can be solved by linearly integrating multiple whisker contacts over time. However, the neural activity in somatosensory cortex reflects non-linear integration of spatio-temporal features of the sensory inputs. Although the responses at first appeared disorganized, we identified an interesting structure in the representational geometry: different whisker contacts are disentangled variables represented in approximately, but not fully, orthogonal subspaces of the neural activity space. This geometry allows linear readouts to perform a broad class of tasks of different complexities without compromising the ability to generalize to novel situations.},
  issue = {2},
  langid = {english},
  keywords = {Network models,Neural encoding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SBQZKQ2H\Nogueira et al. - 2023 - The geometry of cortical representations of touch .pdf}
}

@article{nunezThetaRhythmHippocampus2021,
  title = {The {{Theta Rhythm}} of the {{Hippocampus}}: {{From Neuronal}} and {{Circuit Mechanisms}} to {{Behavior}}},
  shorttitle = {The {{Theta Rhythm}} of the {{Hippocampus}}},
  author = {Nuñez, Angel and Buño, Washington},
  date = {2021},
  journaltitle = {Frontiers in Cellular Neuroscience},
  volume = {15},
  issn = {1662-5102},
  url = {https://www.frontiersin.org/articles/10.3389/fncel.2021.649262},
  urldate = {2023-03-23},
  abstract = {This review focuses on the neuronal and circuit mechanisms involved in the generation of the theta (θ) rhythm and of its participation in behavior. Data have accumulated indicating that θ arises from interactions between medial septum-diagonal band of Broca (MS-DbB) and intra-hippocampal circuits. The intrinsic properties of MS-DbB and hippocampal neurons have also been shown to play a key role in θ generation. A growing number of studies suggest that θ may represent a timing mechanism to temporally organize movement sequences, memory encoding, or planned trajectories for spatial navigation. To accomplish those functions, θ and gamma (γ) oscillations interact during the awake state and REM sleep, which are considered to be critical for learning and memory processes. Further, we discuss that the loss of this interaction is at the base of various neurophatological conditions.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5LYXE4RK\Nuñez and Buño - 2021 - The Theta Rhythm of the Hippocampus From Neuronal.pdf}
}

@article{ockerSelfOrganizationMicrocircuitsNetworks2015,
  title = {Self-{{Organization}} of {{Microcircuits}} in {{Networks}} of {{Spiking Neurons}} with {{Plastic Synapses}}},
  author = {Ocker, Gabriel Koch and Litwin-Kumar, Ashok and Doiron, Brent},
  date = {2015-08-20},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {11},
  number = {8},
  pages = {e1004458},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1004458},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004458},
  urldate = {2022-09-30},
  abstract = {The synaptic connectivity of cortical networks features an overrepresentation of certain wiring motifs compared to simple random-network models. This structure is shaped, in part, by synaptic plasticity that promotes or suppresses connections between neurons depending on their joint spiking activity. Frequently, theoretical studies focus on how feedforward inputs drive plasticity to create this network structure. We study the complementary scenario of self-organized structure in a recurrent network, with spike timing-dependent plasticity driven by spontaneous dynamics. We develop a self-consistent theory for the evolution of network structure by combining fast spiking covariance with a slow evolution of synaptic weights. Through a finite-size expansion of network dynamics we obtain a low-dimensional set of nonlinear differential equations for the evolution of two-synapse connectivity motifs. With this theory in hand, we explore how the form of the plasticity rule drives the evolution of microcircuits in cortical networks. When potentiation and depression are in approximate balance, synaptic dynamics depend on weighted divergent, convergent, and chain motifs. For additive, Hebbian STDP these motif interactions create instabilities in synaptic dynamics that either promote or suppress the initial network structure. Our work provides a consistent theoretical framework for studying how spiking activity in recurrent networks interacts with synaptic plasticity to determine network structure.},
  langid = {english},
  keywords = {Action potentials,Covariance,Network motifs,Neural networks,Neuronal plasticity,Neurons,Synapses,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\44JAQDKB\\Ocker et al. - 2015 - Self-Organization of Microcircuits in Networks of .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FX9AXXTW\\article.html}
}

@article{ockerTrainingSpontaneousReinforcement2019,
  title = {Training and {{Spontaneous Reinforcement}} of {{Neuronal Assemblies}} by {{Spike Timing Plasticity}}},
  author = {Ocker, Gabriel Koch and Doiron, Brent},
  date = {2019-03-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {29},
  number = {3},
  pages = {937--951},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhy001},
  url = {https://doi.org/10.1093/cercor/bhy001},
  urldate = {2022-09-30},
  abstract = {The synaptic connectivity of cortex is plastic, with experience shaping the ongoing interactions between neurons. Theoretical studies of spike timing-dependent plasticity (STDP) have focused on either just pairs of neurons or large-scale simulations. A simple analytic account for how fast spike time correlations affect both microscopic and macroscopic network structure is lacking. We develop a low-dimensional mean field theory for STDP in recurrent networks and show the emergence of assemblies of strongly coupled neurons with shared stimulus preferences. After training, this connectivity is actively reinforced by spike train correlations during the spontaneous dynamics. Furthermore, the stimulus coding by cell assemblies is actively maintained by these internally generated spiking correlations, suggesting a new role for noise correlations in neural coding. Assembly formation has often been associated with firing rate-based plasticity schemes; our theory provides an alternative and complementary framework, where fine temporal correlations and STDP form and actively maintain learned structure in cortical networks.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QC2JAK6C\\Ocker and Doiron - 2019 - Training and Spontaneous Reinforcement of Neuronal.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\L3QTM8K5\\4836778.html}
}

@article{oconnorNeuralCodingActive2013,
  title = {✅ {{Neural}} Coding during Active Somatosensation Revealed Using Illusory Touch},
  author = {O'Connor, Daniel H. and Hires, S. Andrew and Guo, Zengcai V. and Li, Nuo and Yu, Jianing and Sun, Qian-Quan and Huber, Daniel and Svoboda, Karel},
  date = {2013-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {16},
  number = {7},
  pages = {958--965},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3419},
  url = {https://www.nature.com/articles/nn.3419},
  urldate = {2023-04-09},
  abstract = {The authors use mouse behavior, electrophysiology and optogenetics to dissect the temporal interactions between whisker movement, neural activity and sensation of touch. Their results suggest that mice integrate coding of touch with movement over timescales of a whisking bout to produce perception of active touch.},
  issue = {7},
  langid = {english},
  keywords = {Barrel cortex,Decision,Neural decoding,Neural encoding},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5UHD9LMY\\41593_2013_BFnn3419_MOESM19_ESM.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZFDBV62Z\\O'Connor et al. - 2013 - Neural coding during active somatosensation reveal.pdf}
}

@article{ohyamaWhatCerebellumComputes2003,
  title = {What the Cerebellum Computes},
  author = {Ohyama, Tatsuya and Nores, William L. and Murphy, Matthew and Mauk, Michael D.},
  date = {2003-04-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {26},
  number = {4},
  eprint = {12689774},
  eprinttype = {pmid},
  pages = {222--227},
  publisher = {Elsevier},
  issn = {0166-2236, 1878-108X},
  doi = {10.1016/S0166-2236(03)00054-7},
  url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(03)00054-7},
  urldate = {2023-04-23},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EMH6TJHS\Ohyama et al. - 2003 - What the cerebellum computes.pdf}
}

@article{oldenburgLogicRecurrentCircuits2024,
  title = {The Logic of Recurrent Circuits in the Primary Visual Cortex},
  author = {Oldenburg, Ian Antón and Hendricks, William D. and Handy, Gregory and Shamardani, Kiarash and Bounds, Hayley A. and Doiron, Brent and Adesnik, Hillel},
  date = {2024-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {27},
  number = {1},
  pages = {137--147},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01510-5},
  url = {https://www.nature.com/articles/s41593-023-01510-5},
  urldate = {2024-06-12},
  abstract = {Recurrent cortical activity sculpts visual perception by refining, amplifying or suppressing visual input. However, the rules that govern the influence of recurrent activity remain enigmatic. We used ensemble-specific two-photon optogenetics in the mouse visual cortex to isolate the impact of recurrent activity from external visual input. We found that the spatial arrangement and the visual feature preference of the stimulated ensemble and the neighboring neurons jointly determine the net effect of recurrent activity. Photoactivation of these ensembles drives suppression in all cells beyond 30\,µm but uniformly drives activation in closer similarly tuned cells. In nonsimilarly tuned cells, compact, cotuned ensembles drive net suppression, while diffuse, cotuned ensembles drive activation. Computational modeling suggests that highly local recurrent excitatory connectivity and selective convergence onto inhibitory neurons explain these effects. Our findings reveal a straightforward logic in which space and feature preference of cortical ensembles determine their impact on local recurrent activity.},
  langid = {english},
  keywords = {Dynamical systems,Network models,Neural circuits,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AHG7GP4F\Oldenburg et al. - 2024 - The logic of recurrent circuits in the primary vis.pdf}
}

@incollection{olmoMathematicalModelingCircadian2022,
  title = {Mathematical {{Modeling}} in {{Circadian Rhythmicity}}},
  booktitle = {Circadian {{Regulation}}: {{Methods}} and {{Protocols}}},
  author = {del Olmo, Marta and Grabe, Saskia and Herzel, Hanspeter},
  editor = {Solanas, Guiomar and Welz, Patrick -Simon},
  date = {2022},
  series = {Methods in {{Molecular Biology}}},
  pages = {55--80},
  publisher = {Springer US},
  location = {New York, NY},
  doi = {10.1007/978-1-0716-2249-0_4},
  url = {https://doi.org/10.1007/978-1-0716-2249-0_4},
  urldate = {2023-01-26},
  abstract = {Circadian clocks are autonomous systems able to oscillate in a self-sustained manner in the absence of external cues, although such Zeitgebers are typically present. At the cellular level, the molecular clockwork consists of a complex network of interlocked feedback loops. This chapter discusses self-sustained circadian oscillators in the context of nonlinear dynamics theory. We suggest basic steps that can help in constructing a mathematical model and introduce how self-sustained generations can be modeled using ordinary differential equations. Moreover, we discuss how coupled oscillators synchronize among themselves or entrain to periodic signals. The development of mathematical models over the last years has helped to understand such complex network systems and to highlight the basic building blocks in which oscillating systems are built upon. We argue that, through theoretical predictions, the use of simple models can guide experimental research and is thus suitable to model biological systems qualitatively.},
  isbn = {978-1-07-162249-0},
  langid = {english},
  keywords = {Bifurcations,Clocks,Coupled oscillators,Entrainment,Feedback loops,Limit cycles,Modeling,Nonlinearities,Ordinary differential equations,Oscillations,Synchronization},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9AMCETJF\Olmo et al. - 2022 - Mathematical Modeling in Circadian Rhythmicity.pdf}
}

@article{onagaBurstingTransitionLinear2014,
  title = {Bursting Transition in a Linear Self-Exciting Point Process},
  author = {Onaga, Tomokatsu and Shinomoto, Shigeru},
  date = {2014-04-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {89},
  number = {4},
  pages = {042817},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.89.042817},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.89.042817},
  urldate = {2022-10-26},
  abstract = {Self-exciting point processes describe the manner in which every event facilitates the occurrence of succeeding events, as in the case of epidemics or human activity. By increasing excitability, the event occurrences start to exhibit bursts even in the absence of external stimuli. We revealed that the transition is uniquely determined by the average number of events added by a single event, 1−1/√2≈0.2929, independently of the temporal excitation profile. We further extended the theory to multidimensional processes, to be able to incite or inhibit bursting in networks of agents by altering their connections.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MCCB8TUW\\Onaga and Shinomoto - 2014 - Bursting transition in a linear self-exciting poin.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ESHW23XP\\PhysRevE.89.html}
}

@article{onoGABAergicMechanismsSuprachiasmatic2021,
  title = {{{GABAergic}} Mechanisms in the Suprachiasmatic Nucleus That Influence Circadian Rhythm},
  author = {Ono, Daisuke and Honma, Ken-ichi and Honma, Sato},
  date = {2021},
  journaltitle = {Journal of Neurochemistry},
  volume = {157},
  number = {1},
  pages = {31--41},
  issn = {1471-4159},
  doi = {10.1111/jnc.15012},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jnc.15012},
  urldate = {2023-02-22},
  abstract = {The mammalian central circadian clock is located in the suprachiasmatic nucleus (SCN) of the hypothalamus. The SCN contains multiple circadian oscillators which synchronize with each other via several neurotransmitters. Importantly, an inhibitory neurotransmitter, γ-amino butyric acid (GABA), is expressed in almost all SCN neurons. In this review, we discuss how GABA influences circadian rhythms in the SCN. Excitatory and inhibitory effects of GABA may depend on intracellular Cl- concentration, in which several factors such as day-length, time of day, development, and region in the SCN may be involved. GABA also mediates oscillatory coupling of the circadian rhythms in the SCN. Recent genetic approaches reveal that GABA refines circadian output rhythms, but not circadian oscillations in the SCN. Since several efferent projections of the SCN have been suggested, GABA might work downstream of neuronal pathways from the SCN which regulate the temporal order of physiology and behavior.},
  langid = {english},
  keywords = {circadian rhythm,GABA,neuronal network,suprachiasmatic nucleus},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FM5YRFV4\\Ono et al. - 2021 - GABAergic mechanisms in the suprachiasmatic nucleu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E87F5T52\\jnc.html}
}

@article{onoratoDistinctClassBursting2020,
  title = {A Distinct Class of Bursting Neurons with Strong Gamma Synchronization and Stimulus Selectivity in Monkey {{V1}}},
  author = {Onorato, Irene and Neuenschwander, Sergio and Hoy, Jennifer and Lima, Bruss and Rocha, Katia-Simone and Broggini, Ana Clara and Uran, Cem and Spyropoulos, Georgios and Klon-Lipok, Johanna and Womelsdorf, Thilo},
  date = {2020},
  journaltitle = {Neuron},
  volume = {105},
  number = {1},
  pages = {180--197},
  publisher = {Elsevier}
}

@article{onoratoDistinctClassBursting2020a,
  title = {A {{Distinct Class}} of {{Bursting Neurons}} with {{Strong Gamma Synchronization}} and {{Stimulus Selectivity}} in {{Monkey V1}}},
  author = {Onorato, Irene and Neuenschwander, Sergio and Hoy, Jennifer and Lima, Bruss and Rocha, Katia-Simone and Broggini, Ana Clara and Uran, Cem and Spyropoulos, Georgios and Klon-Lipok, Johanna and Womelsdorf, Thilo and Fries, Pascal and Niell, Cristopher and Singer, Wolf and Vinck, Martin},
  date = {2020-01-08},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {105},
  number = {1},
  pages = {180-197.e5},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.09.039},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319308426},
  urldate = {2023-01-17},
  abstract = {Cortical computation depends on interactions between excitatory and inhibitory neurons. The contributions of distinct neuron types to sensory processing and network synchronization in primate visual cortex remain largely undetermined. We show that in awake monkey V1, there exists a distinct cell type (››30\% of neurons) that has narrow-waveform (NW) action potentials and high spontaneous discharge rates and fires in high-frequency bursts. These neurons are more stimulus selective and phase locked to 30- to 80-Hz gamma oscillations than other neuron types. Unlike other neuron types, their gamma-phase locking is highly predictive of~orientation tuning. We find evidence for strong rhythmic inhibition in these neurons, suggesting that they interact with interneurons to act as excitatory pacemakers for the V1 gamma rhythm. We did not find a similar class of NW bursting neurons in L2-L4 of mouse V1. Given its properties, this class of NW bursting neurons should be pivotal for the encoding and transmission of stimulus information.},
  langid = {english},
  keywords = {bursting,cell class,cell type,excitatory,gamma,interneuron,orientation tuning,oscillation,synchronization,V1},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J9EVQNCV\\Onorato et al. - 2020 - A Distinct Class of Bursting Neurons with Strong G.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NU9EQFLV\\S0896627319308426.html}
}

@article{orbanNeuralVariabilitySamplingBased2016,
  title = {Neural {{Variability}} and {{Sampling-Based Probabilistic Representations}} in the {{Visual Cortex}}},
  author = {Orbán, Gergő and Berkes, Pietro and Fiser, József and Lengyel, Máté},
  date = {2016-10-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {92},
  number = {2},
  pages = {530--543},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.09.038},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627316306390},
  urldate = {2022-10-18},
  abstract = {Neural responses in the visual cortex are variable, and there is now an abundance of data characterizing how the magnitude and structure of this variability depends on the stimulus. Current theories of cortical computation fail to account for these data; they either ignore variability altogether or only model its unstructured Poisson-like aspects. We develop a theory in which the cortex performs probabilistic inference such that population activity patterns represent statistical samples from the inferred probability distribution. Our main prediction is that perceptual uncertainty is directly encoded by the variability, rather than the average, of cortical responses. Through direct comparisons to previously published data as well as original data analyses, we show that a sampling-based probabilistic representation accounts for the structure of noise, signal, and spontaneous response variability and correlations in the primary visual cortex. These results suggest a novel role for neural variability in cortical dynamics and computations.},
  langid = {english},
  keywords = {Bayesian computations,natural images,noise correlations,normative model,spontaneous activity,stochastic sampling,theory,V1,variability,vision},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AUBIUFM2\\Orbán et al. - 2016 - Neural Variability and Sampling-Based Probabilisti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TPFG8XFD\\S0896627316306390.html}
}

@article{oreganSensorimotorAccountVision2001,
  title = {A Sensorimotor Account of Vision and Visual Consciousness},
  author = {O'Regan, J. Kevin and Noë, Alva},
  date = {2001-10},
  journaltitle = {Behavioral and Brain Sciences},
  volume = {24},
  number = {5},
  pages = {939--973},
  publisher = {Cambridge University Press},
  issn = {1469-1825, 0140-525X},
  doi = {10.1017/S0140525X01000115},
  url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/sensorimotor-account-of-vision-and-visual-consciousness/BA1638CB7389102A12B336CE687EC270},
  urldate = {2023-04-09},
  abstract = {Many current neurophysiological, psychophysical, and psychological approaches to vision rest on the idea that when we see, the brain produces an internal representation of the world. The activation of this internal representation is assumed to give rise to the experience of seeing. The problem with this kind of approach is that it leaves unexplained how the existence of such a detailed internal representation might produce visual consciousness. An alternative proposal is made here. We propose that seeing is a way of acting. It is a particular way of exploring the environment. Activity in internal representations does not generate the experience of seeing. The outside world serves as its own, external, representation. The experience of seeing occurs when the organism masters what we call the governing laws of sensorimotor contingency. The advantage of this approach is that it provides a natural and principled way of accounting for visual consciousness, and for the differences in the perceived quality of sensory experience in the different sensory modalities. Several lines of empirical evidence are brought forward in support of the theory, in particular: evidence from experiments in sensorimotor adaptation, visual “filling in,” visual stability despite eye movements, change blindness, sensory substitution, and color perception.},
  langid = {english},
  keywords = {action,change blindness,consciousness,experience,perception,qualia,sensation,sensorimotor}
}

@article{oreillyBiologicallyPlausibleErrorDriven1996,
  title = {Biologically {{Plausible Error-Driven Learning Using Local Activation Differences}}: {{The Generalized Recirculation Algorithm}}},
  shorttitle = {Biologically {{Plausible Error-Driven Learning Using Local Activation Differences}}},
  author = {O'Reilly, Randall C.},
  date = {1996-07},
  journaltitle = {Neural Computation},
  volume = {8},
  number = {5},
  pages = {895--938},
  issn = {0899-7667},
  doi = {10.1162/neco.1996.8.5.895},
  url = {https://ieeexplore.ieee.org/document/6796552},
  urldate = {2024-01-10},
  abstract = {The error backpropagation learning algorithm (BP) is generally considered biologically implausible because it does not use locally available, activation-based variables. A version of BP that can be computed locally using bidirectional activation recirculation (Hinton and McClelland 1988) instead of backpropagated error derivatives is more biologically plausible. This paper presents a generalized version of the recirculation algorithm (GeneRec), which overcomes several limitations of the earlier algorithm by using a generic recurrent network with sigmoidal units that can learn arbitrary input/output mappings. However, the contrastive Hebbian learning algorithm (CHL, also known as DBM or mean field learning) also uses local variables to perform error-driven learning in a sigmoidal recurrent network. CHL was derived in a stochastic framework (the Boltzmann machine), but has been extended to the deterministic case in various ways, all of which rely on problematic approximations and assumptions, leading some to conclude that it is fundamentally flawed. This paper shows that CHL can be derived instead from within the BP framework via the GeneRec algorithm. CHL is a symmetry-preserving version of GeneRec that uses a simple approximation to the midpoint or second-order accurate Runge-Kutta method of numerical integration, which explains the generally faster learning speed of CHL compared to BI. Thus, all known fully general error-driven learning algorithms that use local activation-based variables in deterministic networks can be considered variations of the GeneRec algorithm (and indirectly, of the backpropagation algorithm). GeneRec therefore provides a promising framework for thinking about how the brain might perform error-driven learning. To further this goal, an explicit biological mechanism is proposed that would be capable of implementing GeneRec-style learning. This mechanism is consistent with available evidence regarding synaptic modification in neurons in the neocortex and hippocampus, and makes further predictions.},
  eventtitle = {Neural {{Computation}}},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9I796U34\6796552.html}
}

@article{ororbiaNeuralCodingFramework2022,
  title = {The Neural Coding Framework for Learning Generative Models},
  author = {Ororbia, Alexander and Kifer, Daniel},
  date = {2022-04-19},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {2064},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29632-7},
  url = {https://www.nature.com/articles/s41467-022-29632-7},
  urldate = {2024-03-15},
  abstract = {Neural generative models can be used to learn complex probability distributions from data, to sample from them, and to produce probability density estimates. We propose a computational framework for developing neural generative models inspired by the theory of predictive processing in the brain. According to predictive processing theory, the neurons in the brain form a hierarchy in which neurons in one level form expectations about sensory inputs from another level. These neurons update their local models based on differences between their expectations and the observed signals. In a similar way, artificial neurons in our generative models predict what neighboring neurons will do, and adjust their parameters based on how well the predictions matched reality. In this work, we show that the neural generative models learned within our framework perform well in practice across several benchmark datasets and metrics and either remain competitive with or significantly outperform other generative models with similar functionality (such as the variational auto-encoder).},
  langid = {english},
  keywords = {Computer science,Dynamical systems,Learning algorithms,Network models,Statistics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RM2Z3ET4\Ororbia and Kifer - 2022 - The neural coding framework for learning generativ.pdf}
}

@online{ororbiaReviewNeuroscienceInspiredMachine2024,
  title = {A {{Review}} of {{Neuroscience-Inspired Machine Learning}}},
  author = {Ororbia, Alexander and Mali, Ankur and Kohan, Adam and Millidge, Beren and Salvatori, Tommaso},
  date = {2024-02-16},
  eprint = {2403.18929},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.18929},
  urldate = {2024-06-12},
  abstract = {One major criticism of deep learning centers around the biological implausibility of the credit assignment schema used for learning – backpropagation of errors. This implausibility translates into practical limitations, spanning scientific fields, including incompatibility with hardware and non-differentiable implementations, thus leading to expensive energy requirements. In contrast, biologically plausible credit assignment is compatible with practically any learning condition and is energy-efficient. As a result, it accommodates hardware and scientific modeling, e.g. learning with physical systems and non-differentiable behavior. Furthermore, it can lead to the development of real-time, adaptive neuromorphic processing systems. In addressing this problem, an interdisciplinary branch of artificial intelligence research that lies at the intersection of neuroscience, cognitive science, and machine learning has emerged. In this paper, we survey several vital algorithms that model bio-plausible rules of credit assignment in artificial neural networks, discussing the solutions they provide for different scientific fields as well as their advantages on CPUs, GPUs, and novel implementations of neuromorphic hardware. We conclude by discussing the future challenges that will need to be addressed in order to make such algorithms more useful in practical applications.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3C2VH7FB\Ororbia et al. - 2024 - A Review of Neuroscience-Inspired Machine Learning.pdf}
}

@article{osatOptimalPercolationMultiplex2017,
  title = {Optimal Percolation on Multiplex Networks},
  author = {Osat, Saeed and Faqeeh, Ali and Radicchi, Filippo},
  date = {2017-11-16},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {1540},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-01442-2},
  url = {https://www.nature.com/articles/s41467-017-01442-2},
  urldate = {2022-10-06},
  abstract = {Optimal percolation is the problem of finding the minimal set of nodes whose removal from a network fragments the system into non-extensive disconnected clusters. The solution to this problem is important for strategies of immunization in disease spreading, and influence maximization in opinion dynamics. Optimal percolation has received considerable attention in the context of isolated networks. However, its generalization to multiplex networks has not yet been considered. Here we show that approximating the solution of the optimal percolation problem on a multiplex network with solutions valid for single-layer networks extracted from the multiplex may have serious consequences in the characterization of the true robustness of the system. We reach this conclusion by extending many of the methods for finding approximate solutions of the optimal percolation problem from single-layer to multiplex networks, and performing a systematic analysis on synthetic and real-world multiplex networks.},
  issue = {1},
  langid = {english},
  keywords = {Complex networks,Phase transitions and critical phenomena},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EVPH2CKG\Osat et al. - 2017 - Optimal percolation on multiplex networks.pdf}
}

@incollection{pachitariuFastAccurateSpike2016,
  title = {Fast and Accurate Spike Sorting of High-Channel Count Probes with {{KiloSort}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 29},
  author = {Pachitariu, Marius and Steinmetz, Nicholas A and Kadir, Shabnam N and Carandini, Matteo and Harris, Kenneth D},
  editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
  date = {2016},
  pages = {4448--4456},
  publisher = {Curran Associates, Inc.},
  url = {http://papers.nips.cc/paper/6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.pdf},
  urldate = {2020-10-15},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NJBHFKT6\\Pachitariu et al. - 2016 - Fast and accurate spike sorting of high-channel co.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HN68L2G4\\6326-fast-and-accurate-spike-sorting-of-high-channel-count-probes-with-kilosort.html}
}

@article{palmerNMDASpikesEnhance2014,
  title = {{{NMDA}} Spikes Enhance Action Potential Generation during Sensory Input},
  author = {Palmer, Lucy M. and Shai, Adam S. and Reeve, James E. and Anderson, Harry L. and Paulsen, Ole and Larkum, Matthew E.},
  date = {2014-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {3},
  pages = {383--390},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3646},
  url = {https://www.nature.com/articles/nn.3646},
  urldate = {2022-09-04},
  abstract = {In vitro evidence suggests that the tuft dendrites of pyramidal neurons can evoke local NMDA spikes. The authors find that these local NMDA spikes occur spontaneously and following sensory input, and influence the number of output action potentials.},
  issue = {3},
  langid = {english},
  keywords = {Cellular neuroscience,Dendritic excitability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FZIBQNTR\\Palmer et al. - 2014 - NMDA spikes enhance action potential generation du.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2LGQI8DY\\nn.html}
}

@article{panzeriStructuresFunctionsCorrelations2022,
  title = {The Structures and Functions of Correlations in Neural Population Codes},
  author = {Panzeri, Stefano and Moroni, Monica and Safaai, Houman and Harvey, Christopher D.},
  date = {2022-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {23},
  number = {9},
  pages = {551--567},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00606-4},
  url = {https://www.nature.com/articles/s41583-022-00606-4},
  urldate = {2022-10-05},
  abstract = {The collective activity of a population of neurons, beyond the properties of individual cells, is crucial for many brain functions. A fundamental question is how activity correlations between neurons affect how neural populations process information. Over the past 30 years, major progress has been made on how the levels and structures of correlations shape the encoding of information in population codes. Correlations influence population coding through the organization of pairwise-activity correlations with respect to the similarity of tuning of individual neurons, by their stimulus modulation and by the presence of higher-order correlations. Recent work has shown that correlations also profoundly shape other important functions performed by neural populations, including generating codes across multiple timescales and facilitating information transmission to, and readout by, downstream brain areas to guide behaviour. Here, we review this recent work and discuss how the structures of correlations can have opposite effects on the different functions of neural populations, thus creating trade-offs and constraints for the structure–function relationships of population codes. Further, we present ideas on how to combine large-scale simultaneous recordings of neural populations, computational models, analyses of behaviour, optogenetics and anatomy to unravel how the structures of correlations might be optimized to serve multiple functions.},
  issue = {9},
  langid = {english},
  keywords = {Neural decoding,Sensory processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YH9MYXEJ\\Panzeri et al. - 2022 - The structures and functions of correlations in ne.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8UKVUZGD\\s41583-022-00606-4.html}
}

@article{pardiThalamocorticalTopdownCircuit2020,
  title = {A Thalamocortical Top-down Circuit for Associative Memory},
  author = {Pardi, M. Belén and Vogenstahl, Johanna and Dalmay, Tamas and Spanò, Teresa and Pu, De-Lin and Naumann, Laura B. and Kretschmer, Friedrich and Sprekeler, Henning and Letzkus, Johannes J.},
  date = {2020-11-13},
  journaltitle = {Science},
  volume = {370},
  number = {6518},
  eprint = {33184213},
  eprinttype = {pmid},
  pages = {844--848},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.abc2399},
  url = {https://science.sciencemag.org/content/370/6518/844},
  urldate = {2020-11-17},
  abstract = {Higher-order thalamus input to the cortex Sensory information can only be used meaningfully in the brain when integrated with and compared with internally generated top-down signals. However, we know little about the brainwide afferents that convey such top-down signals, their information content, and learning-related plasticity. Pardi et al. identified the higher-order thalamus as a major source of top-down input to mouse auditory cortex and investigated a circuit in cortical layer 1 that facilitates plastic changes and flexible responses. These results demonstrate how top-down feedback information can reach cortical areas through a noncortical structure that has received little attention despite its widespread connections with the cortex. Science, this issue p. 844 The sensory neocortex is a critical substrate for memory. Despite its strong connection with the thalamus, the role of direct thalamocortical communication in memory remains elusive. We performed chronic in vivo two-photon calcium imaging of thalamic synapses in mouse auditory cortex layer 1, a major locus of cortical associations. Combined with optogenetics, viral tracing, whole-cell recording, and computational modeling, we find that the higher-order thalamus is required for associative learning and transmits memory-related information that closely correlates with acquired behavioral relevance. In turn, these signals are tightly and dynamically controlled by local presynaptic inhibition. Our results not only identify the higher-order thalamus as a highly plastic source of cortical top-down information but also reveal a level of computational flexibility in layer 1 that goes far beyond hard-wired connectivity. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information. Synaptic imaging identifies thalamic afferents to the cortex as a highly experience-dependent, dynamically controlled source of top-down information.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CTWAH3UM\\Pardi et al. - 2020 - A thalamocortical top-down circuit for associative.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7C8C24Q6\\844.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FA2FWMZJ\\844.html}
}

@report{parkBayesianEfficientCoding2017,
  type = {preprint},
  title = {Bayesian {{Efficient Coding}}},
  author = {Park, Il Memming and Pillow, Jonathan W.},
  date = {2017-08-22},
  institution = {Neuroscience},
  doi = {10.1101/178418},
  url = {http://biorxiv.org/lookup/doi/10.1101/178418},
  urldate = {2020-10-27},
  abstract = {The efficient coding hypothesis, which proposes that neurons are optimized to maximize information about the environment, has provided a guiding theoretical framework for sensory and systems neuroscience. More recently, a theory known as the Bayesian Brain hypothesis has focused on the brain’s ability to integrate sensory and prior sources of information in order to perform Bayesian inference. However, there is as yet no comprehensive theory connecting these two theoretical frameworks. We bridge this gap by formalizing a Bayesian theory of efficient coding. We define Bayesian efficient codes in terms of four basic ingredients: (1) a stimulus prior distribution; (2) an encoding model; (3) a capacity constraint, specifying a neural resource limit; and (4) a loss function, quantifying the desirability or undesirability of various posterior distributions. Classic efficient codes can be seen as a special case in which the loss function is the posterior entropy, leading to a code that maximizes mutual information, but alternate loss functions give solutions that differ dramatically from information-maximizing codes. In particular, we show that decorrelation of sensory inputs, which is optimal under classic efficient codes in low-noise settings, can be disadvantageous for loss functions that penalize large errors. Bayesian efficient coding therefore enlarges the family of normatively optimal codes and provides a more general framework for understanding the design principles of sensory systems. We examine Bayesian efficient codes for linear receptive fields and nonlinear input-output functions, and show that our theory invites reinterpretation of Laughlin’s seminal analysis of efficient coding in the blowfly visual system.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4MLSRRNP\Park and Pillow - 2017 - Bayesian Efficient Coding.pdf}
}

@article{parkContributionApicalBasal2019,
  title = {Contribution of Apical and Basal Dendrites to Orientation Encoding in Mouse {{V1 L2}}/3 Pyramidal Neurons},
  author = {Park, Jiyoung and Papoutsi, Athanasia and Ash, Ryan T. and Marin, Miguel A. and Poirazi, Panayiota and Smirnakis, Stelios M.},
  date = {2019-11-26},
  journaltitle = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5372},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-13029-0},
  url = {https://www.nature.com/articles/s41467-019-13029-0},
  urldate = {2020-10-20},
  abstract = {Pyramidal neurons integrate synaptic inputs from basal and apical dendrites to generate stimulus-specific responses. It has been proposed that feed-forward inputs to basal dendrites drive a neuron’s stimulus preference, while feedback inputs to apical dendrites sharpen selectivity. However, how a neuron’s dendritic domains relate to its functional selectivity has not been demonstrated experimentally. We performed 2-photon dendritic micro-dissection on layer-2/3 pyramidal neurons in mouse primary visual cortex. We found that removing the apical dendritic tuft did not alter orientation-tuning. Furthermore, orientation-tuning curves were remarkably robust to the removal of basal dendrites: ablation of 2 basal dendrites was needed to cause a small shift in orientation preference, without significantly altering tuning width. Computational modeling corroborated our results and put limits on how orientation preferences among basal dendrites differ in order to reproduce the post-ablation data. In conclusion, neuronal orientation-tuning appears remarkably robust to loss of dendritic input.},
  issue = {1},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\QJKJEM4W\\Park et al. - 2019 - Contribution of apical and basal dendrites to orie.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JR34UK2M\\s41467-019-13029-0.html}
}

@article{parrondoThermodynamicsInformation2015,
  title = {Thermodynamics of Information},
  author = {Parrondo, Juan M. R. and Horowitz, Jordan M. and Sagawa, Takahiro},
  date = {2015-02},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {2},
  pages = {131--139},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys3230},
  url = {https://www.nature.com/articles/nphys3230},
  urldate = {2022-10-03},
  abstract = {By its very nature, the second law of thermodynamics is probabilistic, in that its formulation requires a probabilistic description of the state of a system. This raises questions about the objectivity of the second law: does it depend, for example, on what we know about the system? For over a century, much effort has been devoted to incorporating information into thermodynamics and assessing the entropic and energetic costs of manipulating information. More recently, this historically theoretical pursuit has become relevant in practical situations where information is manipulated at small scales, such as in molecular and cell biology, artificial nano-devices or quantum computation. Here we give an introduction to a novel theoretical framework for the thermodynamics of information based on stochastic thermodynamics and fluctuation theorems, review some recent experimental results, and present an overview of the state of the art in the field.},
  issue = {2},
  langid = {english},
  keywords = {Statistical physics,thermodynamics and nonlinear dynamics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NME93QIZ\Parrondo et al. - 2015 - Thermodynamics of information.pdf}
}

@article{patelTravelingThetaWaves2012,
  title = {Traveling {{Theta Waves}} along the {{Entire Septotemporal Axis}} of the {{Hippocampus}}},
  author = {Patel, Jagdish and Fujisawa, Shigeyoshi and Berényi, Antal and Royer, Sébastien and Buzsáki, György},
  date = {2012-08-09},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {75},
  number = {3},
  eprint = {22884325},
  eprinttype = {pmid},
  pages = {410--417},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2012.07.015},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(12)00666-6},
  urldate = {2023-03-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VWRW5W5J\Patel et al. - 2012 - Traveling Theta Waves along the Entire Septotempor.pdf}
}

@article{patkeMolecularMechanismsPhysiological2020,
  title = {Molecular Mechanisms and Physiological Importance of Circadian Rhythms},
  author = {Patke, Alina and Young, Michael W. and Axelrod, Sofia},
  date = {2020-02},
  journaltitle = {Nature Reviews Molecular Cell Biology},
  shortjournal = {Nat Rev Mol Cell Biol},
  volume = {21},
  number = {2},
  pages = {67--84},
  publisher = {Nature Publishing Group},
  issn = {1471-0080},
  doi = {10.1038/s41580-019-0179-2},
  url = {https://www.nature.com/articles/s41580-019-0179-2},
  urldate = {2023-01-26},
  abstract = {To accommodate daily recurring environmental changes, animals show cyclic variations in behaviour and physiology, which include prominent behavioural states such as sleep–wake cycles but also a host of less conspicuous oscillations in neurological, metabolic, endocrine, cardiovascular and immune functions. Circadian rhythmicity is created endogenously by genetically encoded molecular clocks, whose components cooperate to generate cyclic changes in their own abundance and activity, with a periodicity of about a day. Throughout the body, such molecular clocks convey temporal control to the function of organs and tissues by regulating pertinent downstream programmes. Synchrony between the different circadian oscillators and resonance with the solar day is largely enabled by a neural pacemaker, which is directly responsive to certain environmental cues and able to transmit internal time-of-day representations to the entire body. In this Review, we discuss aspects of the circadian clock in Drosophila melanogaster and mammals, including the components of these molecular oscillators, the function and mechanisms of action of central and peripheral clocks, their synchronization and their relevance to human health.},
  issue = {2},
  langid = {english},
  keywords = {Circadian mechanisms,Circadian regulation,Circadian rhythm signalling peptides and proteins},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NU76YQ9F\Patke et al. - 2020 - Molecular mechanisms and physiological importance .pdf}
}

@article{pattonSuprachiasmaticNucleus2018,
  title = {✅ {{The}} Suprachiasmatic Nucleus},
  author = {Patton, Andrew P. and Hastings, Michael H.},
  date = {2018-08-06},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {28},
  number = {15},
  pages = {R816-R822},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2018.06.052},
  url = {https://www.sciencedirect.com/science/article/pii/S0960982218308431},
  urldate = {2023-02-17},
  abstract = {Like it or not, your two suprachiasmatic nuclei (SCN) govern your life: from when you wake up and fall asleep, to when you feel hungry or can best concentrate. Each is composed of approximately 10,000 tightly interconnected neurons, and the pair sit astride the mid-line third ventricle of the hypothalamus, immediately dorsal to the optic chiasm (Figure 1A). Together, they constitute the master circadian clock of the mammalian brain. They generate an internal representation of solar time that is conveyed to every cell in our body and in this way they co-ordinate the daily cycles of physiology and behaviour that adapt us to the twenty-four hour world. The temporary discomfort associated with jetlag is a reminder of the importance of this daily programme, but there is growing recognition that its chronic disruption carries a cost for health of far greater scale. In this primer, we shall briefly review the historical identification of the SCN as the master circadian clock, and then discuss it on three different levels: the cell-autonomous SCN, the SCN as a cellular network and, finally, the SCN as circadian orchestrator. We shall focus on the intrinsic electrical and transcriptional properties of the SCN and how these properties are thought to form an input to, and an output from, its intrinsic cellular clockwork. Second, we shall describe the anatomical arrangement of the SCN, how its sub-regions are delineated by different neuropeptides, and how SCN neurons communicate with each other via these neuropeptides and the neurotransmitter γ-aminobutyric acid (GABA). Finally, we shall discuss how the SCN functions as a circadian oscillator that dictates behaviour, and how intersectional genetic approaches are being used to try to unravel the specific contributions to pacemaking of specific SCN cell populations.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CRZ7XE8Z\\Patton and Hastings - 2018 - The suprachiasmatic nucleus.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YI2XWG5W\\S0960982218308431.html}
}

@article{paulsDeconstructingCircadianRhythmicity2016,
  title = {✅ {{Deconstructing Circadian Rhythmicity}} with {{Models}} and {{Manipulations}}},
  author = {Pauls, Scott D. and Honma, Ken-Ichi and Honma, Sato and Silver, Rae},
  date = {2016-06-01},
  journaltitle = {Trends in Neurosciences},
  shortjournal = {Trends in Neurosciences},
  volume = {39},
  number = {6},
  eprint = {27090429},
  eprinttype = {pmid},
  pages = {405--419},
  publisher = {Elsevier},
  issn = {0166-2236, 1878-108X},
  doi = {10.1016/j.tins.2016.03.006},
  url = {https://www.cell.com/trends/neurosciences/abstract/S0166-2236(16)00058-8},
  urldate = {2023-02-16},
  langid = {english},
  keywords = {clock genes,connectome,coupling,multiplex models,neural circuits,suprachiasmatic nucleus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KJ5R4L3S\Pauls et al. - 2016 - Deconstructing Circadian Rhythmicity with Models a.tmp}
}

@article{pavliotisSTOCHASTICPROCESSESAPPLICATIONS,
  title = {{{STOCHASTIC PROCESSES AND APPLICATIONS}}},
  author = {Pavliotis, G A},
  pages = {155},
  langid = {english},
  keywords = {Stochastic processes},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7Y9QSWS9\Pavliotis - STOCHASTIC PROCESSES AND APPLICATIONS.pdf}
}

@report{payeurBurstdependentSynapticPlasticity2020,
  type = {preprint},
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  date = {2020-03-31},
  institution = {Neuroscience},
  doi = {10.1101/2020.03.30.015511},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.03.30.015511},
  urldate = {2020-08-30},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well-established that it depends on pre and postsynaptic activity. However, models that rely solely on pre and postsynaptic activity for synaptic changes have, to date, not been able to account for learning complex tasks that demand hierarchical networks. Here, we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then neurons higher in the hierarchy can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites, and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses, and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LYLJ22WE\Payeur et al. - 2020 - Burst-dependent synaptic plasticity can coordinate.pdf}
}

@article{payeurBurstdependentSynapticPlasticity2021,
  title = {Burst-Dependent Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  date = {2021-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {24},
  number = {7},
  pages = {1010--1019},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-021-00857-x},
  url = {https://www.nature.com/articles/s41593-021-00857-x},
  urldate = {2023-04-25},
  abstract = {Synaptic plasticity is believed to be a key physiological mechanism for learning. It is well established that it depends on pre- and postsynaptic activity. However, models that rely solely on pre- and postsynaptic activity for synaptic changes have, so far, not been able to account for learning complex tasks that demand credit assignment in hierarchical networks. Here we show that if synaptic plasticity is regulated by high-frequency bursts of spikes, then pyramidal neurons higher in a hierarchical circuit can coordinate the plasticity of lower-level connections. Using simulations and mathematical analyses, we demonstrate that, when paired with short-term synaptic dynamics, regenerative activity in the apical dendrites and synaptic plasticity in feedback pathways, a burst-dependent learning rule can solve challenging tasks that require deep network architectures. Our results demonstrate that well-known properties of dendrites, synapses and synaptic plasticity are sufficient to enable sophisticated learning in hierarchical circuits.},
  issue = {7},
  langid = {english},
  keywords = {Learning algorithms,Sensory processing,Spike-timing-dependent plasticity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FWVPNQ49\Payeur et al. - 2021 - Burst-dependent synaptic plasticity can coordinate.pdf}
}

@article{payeurBurstdependentSynapticPlasticity2021a,
  title = {✅ {{Burst-dependent}} Synaptic Plasticity Can Coordinate Learning in Hierarchical Circuits},
  author = {Payeur, Alexandre and Guerguiev, Jordan and Zenke, Friedemann and Richards, Blake A. and Naud, Richard},
  date = {2021-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {24},
  number = {7},
  pages = {1010--1019},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-021-00857-x},
  url = {https://www.nature.com/articles/s41593-021-00857-x},
  urldate = {2023-04-25},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KS6ZEESL\\Payeur et al. - 2021 - Burst-dependent synaptic plasticity can coordinate.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\W2G94KYT\\41593_2021_857_MOESM1_ESM.pdf}
}

@article{payeurClassesDendriticInformation2019,
  title = {Classes of Dendritic Information Processing},
  author = {Payeur, Alexandre and Béïque, Jean-Claude and Naud, Richard},
  date = {2019-10},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {58},
  pages = {78--85},
  issn = {09594388},
  doi = {10.1016/j.conb.2019.07.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818302162},
  urldate = {2020-10-08},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VCG2EM7P\Payeur et al. - 2019 - Classes of dendritic information processing.pdf}
}

@article{pazziniNeuronalAvalanchesWattsStrogatz2021,
  title = {Neuronal Avalanches in {{Watts-Strogatz}} Networks of Stochastic Spiking Neurons},
  author = {Pazzini, Renata and Kinouchi, Osame and Costa, Ariadne A.},
  date = {2021-07-26},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {1},
  pages = {014137},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.104.014137},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.014137},
  urldate = {2022-10-01},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5YYICFYD\Pazzini et al. - 2021 - Neuronal avalanches in Watts-Strogatz networks of .pdf}
}

@article{pazziniNeuronalAvalanchesWattsStrogatz2021a,
  title = {Neuronal Avalanches in {{Watts-Strogatz}} Networks of Stochastic Spiking Neurons},
  author = {Pazzini, Renata and Kinouchi, Osame and Costa, Ariadne A.},
  date = {2021-07-26},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {104},
  number = {1},
  pages = {014137},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.104.014137},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.014137},
  urldate = {2022-10-01},
  abstract = {Networks of stochastic leaky integrate-and-fire neurons, both at the mean-field level and in square lattices, present a continuous absorbing phase transition with power-law neuronal avalanches at the critical point. Here we complement these results showing that small-world Watts-Strogatz networks have mean-field critical exponents for any rewiring probability p{$>$}0. For the ring (p=0), the exponents are the same from the dimension d=1 of the directed-percolation class. In the model, firings are stochastic and occur in discrete time steps, based on a sigmoidal firing probability function. Each neuron has a membrane potential that integrates the signals received from its neighbors. The membrane potentials are subject to a leakage parameter. We study topologies with a varied number of neuron connections and different values of the leakage parameter. Results indicate that the dynamic range is larger for p=0. We also study a homeostatic synaptic depression mechanism to self-organize the network towards the critical region. These stochastic oscillations are characteristic of the so-called self-organized quasicriticality.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TFDT4MUA\PhysRevE.104.html}
}

@article{pedreschiTemporalRichClub2022,
  title = {The Temporal Rich Club Phenomenon},
  author = {Pedreschi, Nicola and Battaglia, Demian and Barrat, Alain},
  date = {2022-08},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {18},
  number = {8},
  pages = {931--938},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-022-01634-8},
  url = {https://www.nature.com/articles/s41567-022-01634-8},
  urldate = {2022-10-03},
  abstract = {Identifying the hidden organizational principles and relevant structures of complex networks is fundamental to understand their properties. To this end, uncovering the structures involving the prominent nodes in a network is an effective approach. In temporal networks, the simultaneity of connections is crucial for temporally stable structures to arise. Here, we propose a measure to quantitatively investigate the tendency of well-connected nodes to form simultaneous and stable structures in a temporal network. We refer to this tendency as the temporal rich club phenomenon, characterized by a coefficient defined as the maximal value of the density of links between nodes with a minimal required degree, which remain stable for a certain duration. We illustrate the use of this concept by analysing diverse data sets and their temporal properties, from the role of cohesive structures in relation to processes unfolding on top of the network to the study of specific moments of interest in the evolution of the network.},
  issue = {8},
  langid = {english},
  keywords = {Complex networks,Computational science,Statistical physics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CAQ32Q4D\Pedreschi et al. - 2022 - The temporal rich club phenomenon.pdf}
}

@article{pellegrinoDimensionalityReductionNeural2024,
  title = {Dimensionality Reduction beyond Neural Subspaces with Slice Tensor Component Analysis},
  author = {Pellegrino, Arthur and Stein, Heike and Cayco-Gajic, N. Alex},
  date = {2024-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {27},
  number = {6},
  pages = {1199--1210},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-024-01626-2},
  url = {https://www.nature.com/articles/s41593-024-01626-2},
  urldate = {2024-07-03},
  abstract = {Recent work has argued that large-scale neural recordings are often well described by patterns of coactivation across neurons. Yet the view that neural variability is constrained to a fixed, low-dimensional subspace may overlook higher-dimensional structure, including stereotyped neural sequences or slowly evolving latent spaces. Here we argue that task-relevant variability in neural data can also cofluctuate over trials or time, defining distinct ‘covariability classes’ that may co-occur within the same dataset. To demix these covariability classes, we develop sliceTCA (slice tensor component analysis), a new unsupervised dimensionality reduction method for neural data tensors. In three example datasets, including motor cortical activity during a classic reaching task in primates and recent multiregion recordings in mice, we show that sliceTCA can capture more task-relevant structure in neural data using fewer components than traditional methods. Overall, our theoretical framework extends the classic view of low-dimensional population activity by incorporating additional classes of latent variables capturing higher-dimensional structure.},
  langid = {english},
  keywords = {Neural circuits,Neural decoding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\K2C6S2BD\Pellegrino et al. - 2024 - Dimensionality reduction beyond neural subspaces w.pdf}
}

@article{pereiraSleepingBrainExcitation2020,
  title = {Sleeping through Brain Excitation and Inhibition},
  author = {Pereira, Sofia I. R. and Lewis, Penelope A.},
  date = {2020-09},
  journaltitle = {Nature Neuroscience},
  volume = {23},
  number = {9},
  pages = {1037--1039},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0697-4},
  url = {https://www.nature.com/articles/s41593-020-0697-4},
  urldate = {2020-11-21},
  abstract = {Sleep is controlled by a cocktail of neurotransmitters, but it is difficult to measure these in the brain. A new study by Tamaki et al. reveals how the balance between excitation and inhibition oscillates as the brain moves through sleep stages and how this impacts upon memory consolidation and stabilization.},
  issue = {9},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\H2WSKIDR\\Pereira and Lewis - 2020 - Sleeping through brain excitation and inhibition.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\EPJLDYWY\\s41593-020-0697-4.html}
}

@inproceedings{perez-nievesSparseSpikingGradient2021,
  title = {Sparse {{Spiking Gradient Descent}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Perez-Nieves, Nicolas and Goodman, Dan},
  date = {2021},
  volume = {34},
  pages = {11795--11808},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2021/hash/61f2585b0ebcf1f532c4d1ec9a7d51aa-Abstract.html},
  urldate = {2023-01-24},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KDDJBZ5F\Perez-Nieves and Goodman - 2021 - Sparse Spiking Gradient Descent.pdf}
}

@article{petersenSensorimotorProcessingRodent2019,
  title = {✅ {{Sensorimotor}} Processing in the Rodent Barrel Cortex},
  author = {Petersen, Carl C. H.},
  date = {2019-09},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {20},
  number = {9},
  pages = {533--546},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-019-0200-y},
  url = {https://www.nature.com/articles/s41583-019-0200-y},
  urldate = {2023-04-10},
  abstract = {Tactile sensory information from facial whiskers provides nocturnal tunnel-dwelling rodents, including mice and rats, with important spatial and textural information about their immediate surroundings. Whiskers are moved back and forth to scan the environment (whisking), and touch signals from each whisker evoke sparse patterns of neuronal activity in whisker-related primary somatosensory cortex (wS1; barrel cortex). Whisking is accompanied by desynchronized brain states and cell-type-specific changes in spontaneous and evoked neuronal activity. Tactile information, including object texture and location, appears to be computed in wS1 through integration of motor and sensory signals. wS1 also directly controls whisker movements and contributes to learned, whisker-dependent, goal-directed behaviours. The cell-type-specific neuronal circuitry in wS1 that contributes to whisker sensory perception is beginning to be defined.},
  issue = {9},
  langid = {english},
  keywords = {Barrel cortex,Neural circuits,Sensorimotor processing,Whisker system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\9B4QBEJH\Petersen - 2019 - Sensorimotor processing in the rodent barrel corte.pdf}
}

@article{petriTopologicalLimitsParallel2021,
  title = {Topological Limits to the Parallel Processing Capability of Network Architectures},
  author = {Petri, Giovanni and Musslick, Sebastian and Dey, Biswadip and Özcimder, Kayhan and Turner, David and Ahmed, Nesreen K. and Willke, Theodore L. and Cohen, Jonathan D.},
  date = {2021-05},
  journaltitle = {Nature Physics},
  shortjournal = {Nat. Phys.},
  volume = {17},
  number = {5},
  pages = {646--651},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-021-01170-x},
  url = {https://www.nature.com/articles/s41567-021-01170-x},
  urldate = {2022-10-02},
  abstract = {The ability to learn new tasks and generalize to others is a remarkable characteristic of both human brains and recent artificial intelligence systems. The ability to perform multiple tasks simultaneously is also a key characteristic of parallel architectures, as is evident in the human brain and exploited in traditional parallel architectures. Here we show that these two characteristics reflect a fundamental tradeoff between interactive parallelism, which supports learning and generalization, and independent parallelism, which supports processing efficiency through concurrent multitasking. Although the maximum number of possible parallel tasks grows linearly with network size, under realistic scenarios their expected number grows sublinearly. Hence, even modest reliance on shared representations, which support learning and generalization, constrains the number of parallel tasks. This has profound consequences for understanding the human brain’s mix of sequential and parallel capabilities, as well as for the development of artificial intelligence systems that can optimally manage the tradeoff between learning and processing efficiency.},
  issue = {5},
  langid = {english},
  keywords = {Complex networks,Computational science,Information theory and computation,Statistical physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CDGAD2EA\\Petri et al. - 2021 - Topological limits to the parallel processing capa.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RGLREJ2F\\s41567-021-01170-x.html}
}

@online{PhysicsBrainNetwork,
  title = {The Physics of Brain Network Structure, Function and Control | {{Nature Reviews Physics}}},
  url = {https://www.nature.com/articles/s42254-019-0040-8},
  urldate = {2022-10-03}
}

@incollection{piantanidaInformationBottleneckRepresentation2021,
  title = {Information {{Bottleneck}} and {{Representation Learning}}},
  booktitle = {Information-{{Theoretic Methods}} in {{Data Science}}},
  author = {Piantanida, Pablo and Vega, Leonardo Rey},
  editor = {Rodrigues, Miguel R. D. and Eldar, Yonina C.},
  date = {2021},
  pages = {330--358},
  publisher = {Cambridge University Press},
  location = {Cambridge},
  doi = {10.1017/9781108616799.012},
  url = {https://www.cambridge.org/core/books/informationtheoretic-methods-in-data-science/information-bottleneck-and-representation-learning/8709B5FE5F7FBC9CB1518FFEB6DEEE7A},
  urldate = {2023-05-29},
  abstract = {A grand challenge in representation learning is the development of computational algorithms that learn the explanatory factors of variation behind high-dimensional data. Representation models (encoders) are often determined for optimizing performance on training data when the real objective is to generalize well to other (unseen) data. This chapter provides an overview of fundamental concepts in statistical learning theory and the information-bottleneck principle. This serves as a mathematical basis for the technical results, in which an upper bound to the generalization gap corresponding to the cross-entropy risk is given. When this penalty term times a suitable multiplier and the cross-entropy empirical risk are minimized jointly, the problem is equivalent to optimizing the information-bottleneck objective with respect to the empirical data distribution. This result provides an interesting connection between mutual information and generalization, and helps to explain why noise injection during the training phase can improve the generalization ability of encoder models and enforce invariances in the resulting representations.},
  isbn = {978-1-108-55828-0},
  keywords = {deep learning,generalization,information bottleneck,learning,supervised learning,unsupervised learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SWQWI4JQ\\Piantanida and Vega - 2021 - Information Bottleneck and Representation Learning.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\3RYWE8KQ\\8709B5FE5F7FBC9CB1518FFEB6DEEE7A.html}
}

@article{pietBehavioralStrategyShapes2024,
  title = {Behavioral Strategy Shapes Activation of the {{Vip-Sst}} Disinhibitory Circuit in Visual Cortex},
  author = {Piet, Alex and Ponvert, Nick and Ollerenshaw, Douglas and Garrett, Marina and Groblewski, Peter A. and Olsen, Shawn and Koch, Christof and Arkhipov, Anton},
  date = {2024-06-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {112},
  number = {11},
  eprint = {38447579},
  eprinttype = {pmid},
  pages = {1876-1890.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2024.02.008},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(24)00092-8},
  urldate = {2024-06-12},
  langid = {english},
  keywords = {behavior,cell type circuitry visual cortex,strategy models},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KQMF8N39\\mmc1.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Y9SIBQZS\\Piet et al. - 2024 - Behavioral strategy shapes activation of the Vip-S.pdf}
}

@online{PIIB978008045046901648XElsevier,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=AEB3F00B9ED104FD4F7E76606FE19588C21B83127810BF9F8C6E89BE1FCAE11CE6A6ABBA6EC91D454A1A3CDF6D25E6CB},
  urldate = {2020-10-29},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2B6LN9IY\B978008045046901648X.html}
}

@online{PIIB978008045046901648XElseviera,
  title = {{{PII}}: {{B978008045046901648X}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {{{PII}}},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {https://reader.elsevier.com/reader/sd/pii/B978008045046901648X?token=14DC8ABDF47BDB43F752CBB1A87E260A22FE7927547DE250D49B496B9F9F47BEEB1A020E3297C1075FAAFF93B56178B3},
  urldate = {2020-10-29},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DLMW5R2M\B978008045046901648X.html}
}

@article{pillowSpatiotemporalCorrelationsVisual2008,
  title = {Spatio-Temporal Correlations and Visual Signalling in a Complete Neuronal Population},
  author = {Pillow, Jonathan W. and Shlens, Jonathon and Paninski, Liam and Sher, Alexander and Litke, Alan M. and Chichilnisky, E. J. and Simoncelli, Eero P.},
  date = {2008-08},
  journaltitle = {Nature},
  volume = {454},
  number = {7207},
  pages = {995--999},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature07140},
  url = {https://www.nature.com/articles/nature07140},
  urldate = {2024-07-16},
  abstract = {Correlated activity between sensory neurons governs both the stimulus information conveyed by a neural population and how downstream neurons can extract it. Although previous studies looking at pairs of cells have examined correlations, their functional origin and impact on the neural code are still not understood. Pillow et al. address the question in a complete population of primate retinal ganglion cells. Fitting the physiological data to a model of multi-neuron spike responses, the authors find that a significant fraction of what is usually considered single-cell noise in trial-to-trial response variability can be explained by correlations, and that a significant amount of sensory information can be decoded from the correlation structure.},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\V7PLEH52\Pillow et al. - 2008 - Spatio-temporal correlations and visual signalling.pdf}
}

@online{pinchettiPredictiveCodingGaussian2022,
  title = {Predictive {{Coding}} beyond {{Gaussian Distributions}}},
  author = {Pinchetti, Luca and Salvatori, Tommaso and Yordanov, Yordan and Millidge, Beren and Song, Yuhang and Lukasiewicz, Thomas},
  date = {2022-11-07},
  eprint = {2211.03481},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2211.03481},
  urldate = {2023-03-30},
  abstract = {A large amount of recent research has the far-reaching goal of finding training methods for deep neural networks that can serve as alternatives to backpropagation (BP). A prominent example is predictive coding (PC), which is a neuroscience-inspired method that performs inference on hierarchical Gaussian generative models. These methods, however, fail to keep up with modern neural networks, as they are unable to replicate the dynamics of complex layers and activation functions. In this work, we solve this problem by generalizing PC to arbitrary probability distributions, enabling the training of architectures, such as transformers, that are hard to approximate with only Gaussian assumptions. We perform three experimental analyses. First, we study the gap between our method and the standard formulation of PC on multiple toy examples. Second, we test the reconstruction quality on variational autoencoders, where our method reaches the same reconstruction quality as BP. Third, we show that our method allows us to train transformer networks and achieve a performance comparable with BP on conditional language models. More broadly, this method allows neuroscience-inspired learning to be applied to multiple domains, since the internal distributions can be flexibly adapted to the data, tasks, and architectures used.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\K5XJ4PWY\\Pinchetti et al. - 2022 - Predictive Coding beyond Gaussian Distributions.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SJZJ5QZA\\2211.html}
}

@article{pittendrighCircadianRhythmsCircadian1960,
  title = {Circadian {{Rhythms}} and the {{Circadian Organization}} of {{Living Systems}}},
  author = {Pittendrigh, Colin S.},
  date = {1960-01-01},
  journaltitle = {Cold Spring Harbor Symposia on Quantitative Biology},
  shortjournal = {Cold Spring Harb Symp Quant Biol},
  volume = {25},
  eprint = {13736116},
  eprinttype = {pmid},
  pages = {159--184},
  publisher = {Cold Spring Harbor Laboratory Press},
  issn = {0091-7451, 1943-4456},
  doi = {10.1101/SQB.1960.025.01.015},
  url = {http://symposium.cshlp.org/content/25/159},
  urldate = {2023-02-23},
  abstract = {Excerpt The writing of this paper has been influenced by strongly held convictions. This does not concern the validity of the theoretical scheme it offers; it concerns the need at this juncture in the study of “daily” rhythms for bold and explicit theory formation. We are beset rather than blessed with an enormous number of observations about a great diversity of organisms that range from unicellulars through African violets to man. Moreover, the fact that a majority of these observations is highly fascinating is itself a danger—the common danger threatening the biologist of mistaking acquisition of more fascinating facts, and more concrete detail, for analytic progress. To make progress analyzing circadian rhythms we must perceive what the problems are—or rather state what we take them to be—and proceed with accumulation of new information only as it tests, and alas probably eliminates, theory. The low life-expectancy of any detailed explanatory scheme in...},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SWEDPLQC\Pittendrigh - 1960 - Circadian Rhythms and the Circadian Organization o.pdf}
}

@article{poiraziIlluminatingDendriticFunction2020,
  title = {Illuminating Dendritic Function with Computational Models},
  author = {Poirazi, Panayiota and Papoutsi, Athanasia},
  date = {2020-06},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {6},
  pages = {303--321},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0301-7},
  url = {https://www.nature.com/articles/s41583-020-0301-7},
  urldate = {2020-09-17},
  abstract = {Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires — and drives — new technological advances, thus closing the loop with theory-driven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities.},
  issue = {6},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\I6KH3YVI\\Poirazi and Papoutsi - 2020 - Illuminating dendritic function with computational.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NCYGZ98Z\\s41583-020-0301-7.html}
}

@article{pooresmaeiliSimultaneousSelectionObjectbased2014,
  title = {Simultaneous Selection by Object-Based Attention in Visual and Frontal Cortex},
  author = {Pooresmaeili, Arezoo and Poort, Jasper and Roelfsema, Pieter R.},
  date = {2014-04-29},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {17},
  pages = {6467--6472},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1316181111},
  url = {https://www.pnas.org/doi/10.1073/pnas.1316181111},
  urldate = {2023-01-19},
  abstract = {Models of visual attention hold that top-down signals from frontal cortex influence information processing in visual cortex. It is unknown whether situations exist in which visual cortex actively participates in attentional selection. To investigate this question, we simultaneously recorded neuronal activity in the frontal eye fields (FEF) and primary visual cortex (V1) during a curve-tracing task in which attention shifts are object-based. We found that accurate performance was associated with similar latencies of attentional selection in both areas and that the latency in both areas increased if the task was made more difficult. The amplitude of the attentional signals in V1 saturated early during a trial, whereas these selection signals kept increasing for a longer time in FEF, until the moment of an eye movement, as if FEF integrated attentional signals present in early visual cortex. In erroneous trials, we observed an interareal latency difference because FEF selected the wrong curve before V1 and imposed its erroneous decision onto visual cortex. The neuronal activity in visual and frontal cortices was correlated across trials, and this trial-to-trial coupling was strongest for the attended curve. These results imply that selective attention relies on reciprocal interactions within a large network of areas that includes V1 and FEF.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6NSWL2HX\Pooresmaeili et al. - 2014 - Simultaneous selection by object-based attention i.pdf}
}

@article{poortLearningAttentionIncrease2022,
  title = {✅ {{Learning}} and Attention Increase Visual Response Selectivity through Distinct Mechanisms},
  author = {Poort, Jasper and Wilmes, Katharina A. and Blot, Antonin and Chadwick, Angus and Sahani, Maneesh and Clopath, Claudia and Mrsic-Flogel, Thomas D. and Hofer, Sonja B. and Khan, Adil G.},
  date = {2022-02-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {110},
  number = {4},
  pages = {686-697.e6},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.11.016},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627321009545},
  urldate = {2022-12-23},
  abstract = {Selectivity of cortical neurons for sensory stimuli can increase across days as animals learn their behavioral relevance and across seconds when animals switch attention. While both phenomena occur in the same circuit, it is unknown whether they rely on similar mechanisms. We imaged primary visual cortex as mice learned a visual discrimination task and subsequently performed an attention switching task. Selectivity changes due to learning and attention were uncorrelated in individual neurons. Selectivity increases after learning mainly arose from selective suppression of responses to one of the stimuli but from selective enhancement and suppression during attention. Learning and attention differentially affected interactions between excitatory and PV, SOM, and VIP inhibitory cells. Circuit modeling revealed that cell class-specific top-down inputs best explained attentional modulation, while reorganization of local functional connectivity accounted for learning-related changes. Thus, distinct mechanisms underlie increased discriminability of relevant sensory stimuli across longer and shorter timescales.},
  langid = {english},
  keywords = {attention,GABAergic interneurons,learning,neural circuits,plasticity,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Q44AHZ78\\Poort et al. - 2022 - Learning and attention increase visual response se.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZN2V47JY\\S0896627321009545.html}
}

@article{popovkinaTaskContextModulates2022,
  title = {Task {{Context Modulates Feature-Selective Responses}} in {{Area V4}}},
  author = {Popovkina, Dina V. and Pasupathy, Anitha},
  date = {2022-08-17},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {42},
  number = {33},
  eprint = {35840322},
  eprinttype = {pmid},
  pages = {6408--6423},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1386-21.2022},
  url = {https://www.jneurosci.org/content/42/33/6408},
  urldate = {2023-01-16},
  abstract = {Feature selectivity of visual cortical responses measured during passive fixation provides only a partial view of selectivity because it does not account for the influence of cognitive factors. Here we focus on primate area V4 and ask how neuronal tuning is modulated by task engagement. We investigated whether responses to colored shapes during active shape discrimination are simple, stimulus-agnostic, scaled versions of responses during passive fixation, akin to results from attentional studies. Alternatively, responses could be subject to stimulus-specific scaling, that is, responses to different stimuli are modulated differently, resulting in changes in underlying shape/color selectivity. Among 83 well-isolated V4 neurons in two male macaques, only a minority (16 of 83), which were weakly tuned to both shape and color, displayed responses during fixation and discrimination tasks that could be related by stimulus-agnostic scaling. The majority (67 of 83), which were strongly tuned to shape, color, or both, displayed stimulus-dependent response changes during discrimination. For some of these neurons (39 of 83), the shape or color of the stimulus dictated the magnitude of the change, and for others (28 of 83) it was the combination of stimulus shape and color. Importantly, for neurons with one strong and one weak tuning dimension, stimulus-dependent response changes during discrimination were associated with a relative increase in selectivity along the stronger tuning dimension, without changes in tuning peak. These results reveal that more strongly tuned V4 neurons may also be more flexible in their selectivity, and imbalances in selectivity are amplified during active task contexts. SIGNIFICANCE STATEMENT Tuning for stimulus features is typically characterized by recording responses during passive fixation, but cognitive factors, including attention, influence responses in visual cortex. To determine how behavioral engagement influences neuronal responses in area V4, we compared responses to colored shapes during passive fixation and active behavior. For a large fraction of neurons, differences in responses between passive fixation and active behavior depended on the identity of the visual stimulus. For a subgroup of strongly feature-selective neurons, this response modulation was associated with enhanced selectivity for one feature at the expense of selectivity for the other. Such flexibility in tuning strength could improve performance in tasks requiring active judgment of stimuli.},
  langid = {english},
  keywords = {behavioral modulation,feature tuning,primate area V4,selectivity change,stimulus identity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DEN2DXSY\Popovkina and Pasupathy - 2022 - Task Context Modulates Feature-Selective Responses.pdf}
}

@article{postnovaSleepModellingPhysiological2019,
  title = {Sleep {{Modelling}} across {{Physiological Levels}}},
  author = {Postnova, Svetlana},
  date = {2019-03},
  journaltitle = {Clocks \& Sleep},
  volume = {1},
  number = {1},
  pages = {166--184},
  publisher = {Multidisciplinary Digital Publishing Institute},
  doi = {10.3390/clockssleep1010015},
  url = {https://www.mdpi.com/2624-5175/1/1/15},
  urldate = {2020-11-20},
  abstract = {Sleep and circadian rhythms are regulated across multiple functional, spatial and temporal levels: from genes to networks of coupled neurons and glial cells, to large scale brain dynamics and behaviour. The dynamics at each of these levels are complex and the interaction between the levels is even more so, so research have mostly focused on interactions within the levels to understand the underlying mechanisms\&mdash;the so-called reductionist approach. Mathematical models were developed to test theories of sleep regulation and guide new experiments at each of these levels and have become an integral part of the field. The advantage of modelling, however, is that it allows us to simulate and test the dynamics of complex biological systems and thus provides a tool to investigate the connections between the different levels and study the system as a whole. In this paper I review key models of sleep developed at different physiological levels and discuss the potential for an integrated systems biology approach for sleep regulation across these levels. I also highlight the necessity of building mechanistic connections between models of sleep and circadian rhythms across these levels.},
  issue = {1},
  langid = {english},
  keywords = {behaviour,circadian clocks,EEG,mathematical modelling,mean field,molecular mechanisms,multi-scale,neurons,sleep,systems biology},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6FZZQ2G\\Postnova - 2019 - Sleep Modelling across Physiological Levels.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8U7C9SQC\\15.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9V3LXKLZ\\15.html}
}

@article{pougetComputationalApproachesSensorimotor2000,
  title = {Computational Approaches to Sensorimotor Transformations},
  author = {Pouget, Alexandre and Snyder, Lawrence H.},
  date = {2000-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {3},
  number = {11},
  pages = {1192--1198},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/81469},
  url = {https://www.nature.com/articles/nn1100_1192},
  urldate = {2023-04-10},
  abstract = {Behaviors such as sensing an object and then moving your eyes or your hand toward it require that sensory information be used to help generate a motor command, a process known as a sensorimotor transformation. Here we review models of sensorimotor transformations that use a flexible intermediate representation that relies on basis functions. The use of basis functions as an intermediate is borrowed from the theory of nonlinear function approximation. We show that this approach provides a unifying insight into the neural basis of three crucial aspects of sensorimotor transformations, namely, computation, learning and short-term memory. This mathematical formalism is consistent with the responses of cortical neurons and provides a fresh perspective on the issue of frames of reference in spatial representations.},
  issue = {11},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\A3JX2GZ3\Pouget and Snyder - 2000 - Computational approaches to sensorimotor transform.pdf}
}

@inproceedings{pozziAttentionGatedBrainPropagation2020,
  title = {✅ {{Attention-Gated Brain Propagation}}: {{How}} the Brain Can Implement Reward-Based Error Backpropagation},
  shorttitle = {Attention-{{Gated Brain Propagation}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Pozzi, Isabella and Bohte, Sander and Roelfsema, Pieter},
  date = {2020},
  volume = {33},
  pages = {2516--2526},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html},
  urldate = {2023-01-22},
  abstract = {Much recent work has focused on biologically plausible variants of supervised learning algorithms. However, there is no teacher in the motor cortex that instructs the motor neurons and learning in the brain depends on reward and punishment. We demonstrate a biologically plausible reinforcement learning scheme for deep networks with an arbitrary number of layers. The network chooses an action by selecting a unit in the output layer and uses feedback connections to assign credit to the units in successively lower layers that are responsible for this action. After the choice, the network receives reinforcement and there is no teacher correcting the errors. We show how the new learning scheme – Attention-Gated Brain Propagation (BrainProp) – is mathematically equivalent to error backpropagation, for one output unit at a time. We demonstrate successful learning of deep fully connected, convolutional and locally connected networks on classical and hard image-classification benchmarks; MNIST, CIFAR10, CIFAR100 and Tiny ImageNet. BrainProp achieves an accuracy that is equivalent to that of standard error-backpropagation, and better than state-of-the-art biologically inspired learning schemes. The trial-and-error nature of learning is associated with limited additional training time so that BrainProp is a factor of 1-3.5 times slower. Our results thereby provide new insights into how deep learning may be implemented in the brain.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FXYSNN98\Pozzi et al. - 2020 - Attention-Gated Brain Propagation How the brain c.pdf}
}

@inproceedings{pozziQAGRELBiologicallyPlausible2019,
  title = {✅ {{Q-AGREL}}: {{Biologically Plausible Attention Gated Deep Reinforcement Learning}}},
  shorttitle = {Q-{{AGREL}}},
  booktitle = {2019 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  author = {Pozzi, Isabella and Bohté, Sander M. and Roelfsema, Pieter R.},
  date = {2019},
  publisher = {Cognitive Computational Neuroscience},
  location = {Berlin, Germany},
  doi = {10.32470/CCN.2019.1243-0},
  url = {https://ccneuro.org/2019/Papers/ViewPapers.asp?PaperNum=1243},
  urldate = {2023-01-18},
  abstract = {The success of deep learning in end-to-end learning on a wide range of complex tasks is now fuelling the search for similar deep learning principles in the brain. While most work has focused on biologically plausible variants of error-backpropagation, learning in the brain seems to mostly adhere to a reinforcement learning paradigm, and while biologically plausible neural reinforcement learning has been proposed, these studies focused on shallow networks learning from compact and abstract sensory representations. Here, we demonstrate how these learning schemes generalize to deep networks with an arbitrary number of layers. The resulting reinforcement learning rule is equivalent to a particular form of error-backpropagation that trains one output unit at any time. We demonstrate the learning scheme on classical and hard image-classification benchmarks, namely MNIST, CIFAR10 and CIFAR100, cast as direct reward tasks, both for fully connected, convolutional and locally connected architectures. We show that our learning rule - Q-AGREL - performs comparably to supervised learning via error-backpropagation, requiring only 1.5-2.5 times more epochs, even when classifying 100 different classes as in CIFAR100. Our results provide new insights into how deep learning may be implemented in the brain.},
  eventtitle = {2019 {{Conference}} on {{Cognitive Computational Neuroscience}}},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MCAIFUPF\Pozzi et al. - 2019 - Q-AGREL Biologically Plausible Attention Gated De.pdf}
}

@online{PredictiveProcessingCanonical,
  title = {✅ {{Predictive Processing}}: {{A Canonical Cortical Computation}} | {{Elsevier Enhanced Reader}}},
  shorttitle = {Predictive {{Processing}}},
  doi = {10.1016/j.neuron.2018.10.003},
  url = {https://reader.elsevier.com/reader/sd/pii/S0896627318308572?token=16D1B58BBA59081B9A1DDDF0C9C395772869C8C42CB4FF4FB236417930D577C8B6B4EE81AFBD16251E6B7D5B0BB93757&originRegion=us-east-1&originCreation=20230411155857},
  urldate = {2023-04-11},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\K2L6FJM7\Predictive Processing A Canonical Cortical Comput.pdf}
}

@online{PrefrontalCortexExhibits,
  title = {Prefrontal Cortex Exhibits Multidimensional Dynamic Encoding during Decision-Making | {{Nature Neuroscience}}},
  url = {https://www.nature.com/articles/s41593-020-0696-5},
  urldate = {2021-02-15},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\C89LMXCN\s41593-020-0696-5.html}
}

@article{priceBayesianSyntheticLikelihood2018,
  title = {Bayesian {{Synthetic Likelihood}}},
  author = {Price, L. F. and Drovandi, C. C. and Lee, A. and Nott, D. J.},
  date = {2018-01-02},
  journaltitle = {Journal of Computational and Graphical Statistics},
  shortjournal = {Journal of Computational and Graphical Statistics},
  volume = {27},
  number = {1},
  pages = {1--11},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1302882},
  url = {https://www.tandfonline.com/doi/full/10.1080/10618600.2017.1302882},
  urldate = {2020-10-26},
  abstract = {Having the ability to work with complex models can be highly beneficial. However, complex models often have intractable likelihoods, so methods that involve evaluation of the likelihood function are infeasible. In these situations, the benefits of working with likelihood-free methods become apparent. Likelihood-free methods, such as parametric Bayesian indirect likelihood that uses the likelihood of an alternative parametric auxiliary model, have been explored throughout the literature as a viable alternative when the model of interest is complex. One of these methods is called the synthetic likelihood (SL), which uses a multivariate normal approximation of the distribution of a set of summary statistics. This article explores the accuracy and computational efficiency of the Bayesian version of the synthetic likelihood (BSL) approach in comparison to a competitor known as approximate Bayesian computation (ABC) and its sensitivity to its tuning parameters and assumptions. We relate BSL to pseudo-marginal methods and propose to use an alternative SL that uses an unbiased estimator of the SL, when the summary statistics have a multivariate normal distribution. Several applications of varying complexity are considered to illustrate the findings of this article. Supplemental materials are available online. Computer code for implementing the methods on all examples is available at https://github.com/cdrovandi/Bayesian-Synthetic-Likelihood.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\A8HQ55AT\Price et al. - 2018 - Bayesian Synthetic Likelihood.pdf}
}

@article{pureswaranParadigmsEasternSpruce2016,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-12-01},
  journaltitle = {Environmental Entomology},
  shortjournal = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  urldate = {2020-12-28},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.}
}

@article{pureswaranParadigmsEasternSpruce2016a,
  title = {Paradigms in {{Eastern Spruce Budworm}} ({{Lepidoptera}}: {{Tortricidae}}) {{Population Ecology}}: {{A Century}} of {{Debate}}},
  author = {Pureswaran, Deepa S. and Johns, Rob and Heard, Stephen B. and Quiring, Dan},
  date = {2016-09},
  journaltitle = {Environmental Entomology},
  volume = {45},
  number = {6},
  pages = {1333--1342},
  issn = {0046-225X},
  doi = {10.1093/ee/nvw103},
  url = {https://doi.org/10.1093/ee/nvw103},
  abstract = {Three main hypotheses have been postulated over the past century to explain the outbreaking population dynamics of eastern spruce budworm, Choristoneura fumiferana (Clemens). The Silviculture Hypothesis first arose in the 1920s, with the idea that outbreaks were driven by forestry practices favoring susceptible softwood species. In the 1960s, it was proposed that populations were governed by Multiple Equilibria, with warm weather conditions releasing low-density populations from the regulatory control of natural enemies. Dispersal from outbreak foci, or “epicenters,” was seen as causing widespread outbreaks that eventually collapsed following resource depletion. However, in the 1980s, following the re-analysis of data from the 1940s outbreak in New Brunswick, this interpretation was challenged. The alternative Oscillatory Hypothesis proposed that budworm population dynamics were governed by a second-order density-dependent process, with oscillations being driven by natural enemy–victim interactions. Under this hypothesis, weather and resource availability contribute to secondary fluctuations around the main oscillation, and weather and moth dispersal serve to synchronize population cycles regionally. Intensive, independent population studies during the peak and declining phases of the 1980s outbreak supported the principal tenet of the Oscillatory Hypothesis, but concluded that host plant quality played a more important role than this hypothesis proposed. More recent research on the early phase of spruce budworm cycles suggests that mate-finding and natural-enemy-driven Allee effects in low-density populations might be overcome by immigration of moths, which can facilitate the onset of outbreaks. Even more recent research has supported components of all three hypotheses attempting to explain spruce budworm dynamics. In the midst of a new rising outbreak (2006-present), we discuss the evolution of debates surrounding these hypotheses from a historic perspective, examine gaps in current knowledge, and suggest avenues for future research (e.g., intensive studies on low-density populations) to better understand and manage spruce budworm populations.}
}

@article{qasimHumanHippocampalTheta2016,
  title = {Human {{Hippocampal Theta Oscillations}} during {{Movement}} without {{Visual Cues}}},
  author = {Qasim, Salman~E. and Jacobs, Joshua},
  date = {2016-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {89},
  number = {6},
  pages = {1121--1123},
  issn = {08966273},
  doi = {10.1016/j.neuron.2016.03.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627316001823},
  urldate = {2023-03-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ILEAQSK2\Qasim and Jacobs - 2016 - Human Hippocampal Theta Oscillations during Moveme.pdf}
}

@article{qasimHumanHippocampalTheta2016a,
  title = {Human {{Hippocampal Theta Oscillations}} during {{Movement}} without {{Visual Cues}}},
  author = {Qasim, Salman E. and Jacobs, Joshua},
  date = {2016-03-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {89},
  number = {6},
  eprint = {26985718},
  eprinttype = {pmid},
  pages = {1121--1123},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2016.03.003},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(16)00182-3},
  urldate = {2023-03-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NZGKMKA3\Qasim and Jacobs - 2016 - Human Hippocampal Theta Oscillations during Moveme.pdf}
}

@article{quirogaSpikeSorting2007,
  title = {Spike Sorting},
  author = {Quiroga, Rodrigo Quian},
  date = {2007-12-21},
  journaltitle = {Scholarpedia},
  volume = {2},
  number = {12},
  pages = {3583},
  issn = {1941-6016},
  doi = {10.4249/scholarpedia.3583},
  url = {http://www.scholarpedia.org/article/Spike_sorting},
  urldate = {2020-10-15},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HDCQMX5J\\Spike_sorting.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P6AG63MP\\Spike_sorting.html}
}

@article{rabinowitzAttentionStabilizesShared2015,
  title = {Attention Stabilizes the Shared Gain of {{V4}} Populations},
  author = {Rabinowitz, Neil C and Goris, Robbe L and Cohen, Marlene and Simoncelli, Eero P},
  editor = {Carandini, Matteo},
  date = {2015-11-02},
  journaltitle = {eLife},
  volume = {4},
  pages = {e08998},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.08998},
  url = {https://doi.org/10.7554/eLife.08998},
  urldate = {2022-12-21},
  abstract = {Responses of sensory neurons represent stimulus information, but are also influenced by internal state. For example, when monkeys direct their attention to a visual stimulus, the response gain of specific subsets of neurons in visual cortex changes. Here, we develop a functional model of population activity to investigate the structure of this effect. We fit the model to the spiking activity of bilateral neural populations in area V4, recorded while the animal performed a stimulus discrimination task under spatial attention. The model reveals four separate time-varying shared modulatory signals, the dominant two of which each target task-relevant neurons in one hemisphere. In attention-directed conditions, the associated shared modulatory signal decreases in variance. This finding provides an interpretable and parsimonious explanation for previous observations that attention reduces variability and noise correlations of sensory neurons. Finally, the recovered modulatory signals reflect previous reward, and are predictive of subsequent choice behavior.},
  keywords = {attention,computation,sensory,statistic,vision},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\G6GFNFWE\Rabinowitz et al. - 2015 - Attention stabilizes the shared gain of V4 populat.pdf}
}

@article{radulescuHolisticReinforcementLearning2019,
  title = {Holistic {{Reinforcement Learning}}: {{The Role}} of {{Structure}} and {{Attention}}},
  shorttitle = {Holistic {{Reinforcement Learning}}},
  author = {Radulescu, Angela and Niv, Yael and Ballard, Ian},
  date = {2019-04-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {4},
  eprint = {30824227},
  eprinttype = {pmid},
  pages = {278--292},
  publisher = {Elsevier},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2019.01.010},
  url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(19)30036-1},
  urldate = {2023-01-19},
  langid = {english},
  keywords = {approximate inference,Bayesian inference,category learning,corticostriatal circuits,dopamine,representation learning,rule learning,striatum},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EHUN9XEG\Radulescu et al. - 2019 - Holistic Reinforcement Learning The Role of Struc.pdf}
}

@article{ralphTransplantedSuprachiasmaticNucleus1990,
  title = {✅ {{Transplanted Suprachiasmatic Nucleus Determines Circadian Period}}},
  author = {Ralph, Martin R. and Foster, Russell G. and Davis, Fred C. and Menaker, Michael},
  date = {1990-02-23},
  journaltitle = {Science},
  volume = {247},
  number = {4945},
  pages = {975--978},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.2305266},
  url = {https://www.science.org/doi/10.1126/science.2305266},
  urldate = {2023-02-24},
  abstract = {The pacemaker role of the suprachiasmatic nucleus in a mammalian circadian system was tested by neural transplantation by using a mutant strain of hamster that shows a short circadian period. Small neural grafts from the suprachiasmatic region restored circadian rhythms to arrhythmic animals whose own nucleus had been ablated. The restored rhythms always exhibited the period of the donor genotype regardless of the direction of the transplant or genotype of the host. The basic period of the overt circadian rhythm therefore is determined by cells of the suprachiasmatic region.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8YYFKH6U\Ralph et al. - 1990 - Transplanted Suprachiasmatic Nucleus Determines Ci.pdf}
}

@article{ramamurthyVIPInterneuronsSensory2023,
  title = {{{VIP}} Interneurons in Sensory Cortex Encode Sensory and Action Signals but Not Direct Reward Signals},
  author = {Ramamurthy, Deepa L. and Chen, Andrew and Zhou, Jiayu and Park, Chanbin and Huang, Patrick C. and Bharghavan, Priyanka and Krishna, Gayathri and Liu, Jinjian and Casale, Kayla and Feldman, Daniel E.},
  date = {2023-07-18},
  journaltitle = {Current biology: CB},
  shortjournal = {Curr Biol},
  eprint = {37499665},
  eprinttype = {pmid},
  pages = {S0960-9822(23)00872-2},
  issn = {1879-0445},
  doi = {10.1016/j.cub.2023.06.086},
  abstract = {Vasoactive intestinal peptide (VIP) interneurons in sensory cortex modulate sensory responses based on global exploratory behavior and arousal state, but their function during non-exploratory, goal-directed behavior is not well understood. In particular, whether VIP cells are activated by sensory cues, reward-seeking actions, or directly by reinforcement is unclear. We trained mice on a Go/NoGo whisker touch detection task that included a delay period and other features designed to separate sensory-evoked, action-related, and reward-related neural activity. Mice had to lick in response to a whisker stimulus to receive a variable-sized reward. Using two-photon calcium imaging, we measured ΔF/F responses of L2/3 VIP neurons in whisker somatosensory cortex (S1) during behavior. In both expert and novice mice, VIP cells were strongly activated by whisker stimuli and goal-directed actions (licking), but not by reinforcement. VIP cells showed somatotopic whisker tuning that was spatially organized relative to anatomical columns in S1, unlike lick-related signals which were spatially widespread. In expert mice, lick-related VIP responses were suppressed, not enhanced, when a reward was delivered, and the amount of suppression increased with reward size. This reward-related suppression was not seen in novice mice, where reward delivery was not yoked to licking. These results indicate that besides arousal and global state variables, VIP cells are activated by local sensory features and goal-directed actions, but not directly by reinforcement. Instead, our results are consistent with a role for VIP cells in encoding the expectation of reward associated with motor actions.},
  langid = {english},
  keywords = {barrel cortex,GABAergic neurons,goal-directed behavior,sensory maps,vibrissa},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KBUD86J5\Ramamurthy et al. - 2023 - VIP interneurons in sensory cortex encode sensory .pdf}
}

@article{ramsteadBayesianMechanicsPhysics2023,
  title = {On {{Bayesian}} Mechanics: A Physics of and by Beliefs},
  shorttitle = {On {{Bayesian}} Mechanics},
  author = {Ramstead, Maxwell J. D. and Sakthivadivel, Dalton A. R. and Heins, Conor and Koudahl, Magnus and Millidge, Beren and Da Costa, Lancelot and Klein, Brennan and Friston, Karl J.},
  date = {2023-04-14},
  journaltitle = {Interface Focus},
  volume = {13},
  number = {3},
  pages = {20220029},
  publisher = {Royal Society},
  doi = {10.1098/rsfs.2022.0029},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsfs.2022.0029},
  urldate = {2023-04-25},
  abstract = {The aim of this paper is to introduce a field of study that has emerged over the last decade, called Bayesian mechanics. Bayesian mechanics is a probabilistic mechanics, comprising tools that enable us to model systems endowed with a particular partition (i.e. into particles), where the internal states (or the trajectories of internal states) of a particular system encode the parameters of beliefs about external states (or their trajectories). These tools allow us to write down mechanical theories for systems that look as if they are estimating posterior probability distributions over the causes of their sensory states. This provides a formal language for modelling the constraints, forces, potentials and other quantities determining the dynamics of such systems, especially as they entail dynamics on a space of beliefs (i.e. on a statistical manifold). Here, we will review the state of the art in the literature on the free energy principle, distinguishing between three ways in which Bayesian mechanics has been applied to particular systems (i.e. path-tracking, mode-tracking and mode-matching). We go on to examine a duality between the free energy principle and the constrained maximum entropy principle, both of which lie at the heart of Bayesian mechanics, and discuss its implications.},
  keywords = {active inference,Bayesian mechanics,free energy principle,gauge theory,information geometry,maximum entropy},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HPN43483\Ramstead et al. - 2023 - On Bayesian mechanics a physics of and by beliefs.pdf}
}

@article{ramsteadBayesianMechanicsPhysics2023a,
  title = {On {{Bayesian}} Mechanics: A Physics of and by Beliefs},
  shorttitle = {On {{Bayesian}} Mechanics},
  author = {Ramstead, Maxwell J. D. and Sakthivadivel, Dalton A. R. and Heins, Conor and Koudahl, Magnus and Millidge, Beren and Da Costa, Lancelot and Klein, Brennan and Friston, Karl J.},
  date = {2023-04-14},
  journaltitle = {Interface Focus},
  volume = {13},
  number = {3},
  pages = {20220029},
  publisher = {Royal Society},
  doi = {10.1098/rsfs.2022.0029},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsfs.2022.0029},
  urldate = {2023-04-27},
  abstract = {The aim of this paper is to introduce a field of study that has emerged over the last decade, called Bayesian mechanics. Bayesian mechanics is a probabilistic mechanics, comprising tools that enable us to model systems endowed with a particular partition (i.e. into particles), where the internal states (or the trajectories of internal states) of a particular system encode the parameters of beliefs about external states (or their trajectories). These tools allow us to write down mechanical theories for systems that look as if they are estimating posterior probability distributions over the causes of their sensory states. This provides a formal language for modelling the constraints, forces, potentials and other quantities determining the dynamics of such systems, especially as they entail dynamics on a space of beliefs (i.e. on a statistical manifold). Here, we will review the state of the art in the literature on the free energy principle, distinguishing between three ways in which Bayesian mechanics has been applied to particular systems (i.e. path-tracking, mode-tracking and mode-matching). We go on to examine a duality between the free energy principle and the constrained maximum entropy principle, both of which lie at the heart of Bayesian mechanics, and discuss its implications.},
  keywords = {active inference,Bayesian mechanics,free energy principle,gauge theory,information geometry,maximum entropy},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FIFT2ZY5\Ramstead et al. - 2023 - On Bayesian mechanics a physics of and by beliefs.pdf}
}

@article{ranganathanActiveDendriticIntegration2018,
  title = {Active Dendritic Integration and Mixed Neocortical Network Representations during an Adaptive Sensing Behavior},
  author = {Ranganathan, Gayathri N. and Apostolides, Pierre F. and Harnett, Mark T. and Xu, Ning-Long and Druckmann, Shaul and Magee, Jeffrey C.},
  date = {2018-11},
  journaltitle = {Nature neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {11},
  eprint = {30349100},
  eprinttype = {pmid},
  pages = {1583--1590},
  issn = {1097-6256},
  doi = {10.1038/s41593-018-0254-6},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6203624/},
  urldate = {2022-09-02},
  abstract = {Animals strategically scan the environment to form an accurate perception of their surroundings. Here we investigated the neuronal representations that mediate this behavior. Ca2+ imaging and selective optogenetic manipulation during an active sensing task reveals that L5 pyramidal neurons in the vibrissae cortex produce a diverse and distributed representation that is required for mice to adapt their whisking motor strategy to changing sensory cues. The optogenetic perturbation degraded single-neuron selectivity and network population encoding through a selective inhibition of active dendritic integration. Together the data indicate that active dendritic integration in pyramidal neurons produces a nonlinearly mixed network representation of joint sensorimotor parameters that is used to transform sensory information into motor commands during adaptive behavior. The prevalence of the L5 cortical circuit motif suggests that this is a general circuit computation.},
  pmcid = {PMC6203624},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8H923HS2\Ranganathan et al. - 2018 - Active dendritic integration and mixed neocortical.pdf}
}

@article{ranganathanActiveDendriticIntegration2018a,
  title = {✅ {{Active}} Dendritic Integration and Mixed Neocortical Network Representations during an Adaptive Sensing Behavior},
  author = {Ranganathan, Gayathri N. and Apostolides, Pierre F. and Harnett, Mark T. and Xu, Ning-Long and Druckmann, Shaul and Magee, Jeffrey C.},
  date = {2018-11},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {21},
  number = {11},
  pages = {1583--1590},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0254-6},
  url = {https://www.nature.com/articles/s41593-018-0254-6},
  urldate = {2023-04-09},
  abstract = {Animals strategically scan the environment to form an accurate perception of their surroundings. Here we investigated the neuronal representations that mediate this behavior. Ca2+ imaging and selective optogenetic manipulation during an active sensing task reveals that layer 5 pyramidal neurons in the vibrissae cortex produce a diverse and distributed representation that is required for mice to adapt their whisking motor strategy to changing sensory cues. The optogenetic perturbation degraded single-neuron selectivity and network population encoding through a selective inhibition of active dendritic integration. Together the data indicate that active dendritic integration in pyramidal neurons produces a nonlinearly mixed network representation of joint sensorimotor parameters that is used to transform sensory information into motor commands during adaptive behavior. The prevalence of the layer 5 cortical circuit motif suggests that this is a general circuit computation.},
  issue = {11},
  langid = {english},
  keywords = {Barrel cortex,Cellular neuroscience,Neural circuits,Sensorimotor processing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9YWESTEU\\Ranganathan et al. - 2018 - Active dendritic integration and mixed neocortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RYQQBLL8\\41593_2018_254_MOESM1_ESM.pdf}
}

@online{ransomThreeProblemsPredictive2015,
  title = {Three {{Problems}} for the {{Predictive Coding Theory}} of {{Attention}}},
  author = {Ransom, Madeleine},
  date = {2015-09-19T06:00:55+00:00},
  url = {https://mindsonline.philosophyofbrains.com/2015/session4/three-problems-for-the-predictive-coding-theory-of-attention/},
  urldate = {2023-03-30},
  abstract = {Madeleine Ransom~(University of British Columbia) Sina Fazelpour (University of British Columbia) [PDF of Ransom \& Fazelpour’s paper] [Jump to Jakob Hohwy’s comment] [Jump to Carolyn Dicey Jennings’ comment] [Jump to Ransom \& Fazelpour’s response] ~ Abstract While philosophers of science and epistemologists are well acquainted with Bayesian methods of belief updating, there is a new … Continue reading Three Problems for the Predictive Coding Theory of Attention},
  langid = {american},
  organization = {Minds Online}
}

@article{raoPredictiveCodingVisual1999,
  title = {Predictive Coding in the Visual Cortex: A Functional Interpretation of Some Extra-Classical Receptive-Field Effects},
  shorttitle = {Predictive Coding in the Visual Cortex},
  author = {Rao, Rajesh P. N. and Ballard, Dana H.},
  date = {1999-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {2},
  number = {1},
  pages = {79--87},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/4580},
  url = {https://www.nature.com/articles/nn0199_79},
  urldate = {2023-03-29},
  abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
  issue = {1},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Z978MHL4\Rao and Ballard - 1999 - Predictive coding in the visual cortex a function.pdf}
}

@article{raoPredictiveCodingVisual1999a,
  title = {Predictive Coding in the Visual Cortex: A Functional Interpretation of Some Extra-Classical Receptive-Field Effects},
  shorttitle = {Predictive Coding in the Visual Cortex},
  author = {Rao, Rajesh P. N. and Ballard, Dana H.},
  date = {1999-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {2},
  number = {1},
  pages = {79--87},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/4580},
  url = {https://www.nature.com/articles/nn0199_79},
  urldate = {2024-03-23},
  abstract = {We describe a model of visual processing in which feedback connections from a higher- to a lower-order visual cortical area carry predictions of lower-level neural activities, whereas the feedforward connections carry the residual errors between the predictions and the actual lower-level activities. When exposed to natural images, a hierarchical network of model neurons implementing such a model developed simple-cell-like receptive fields. A subset of neurons responsible for carrying the residual errors showed endstopping and other extra-classical receptive-field effects. These results suggest that rather than being exclusively feedforward phenomena, nonclassical surround effects in the visual cortex may also result from cortico-cortical feedback as a consequence of the visual system using an efficient hierarchical strategy for encoding natural images.},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T3G8862J\Rao and Ballard - 1999 - Predictive coding in the visual cortex a function.pdf}
}

@book{rasmussenGaussianProcessesMachine2006,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {MIT Press},
  location = {Cambridge, Mass},
  isbn = {978-0-262-18253-9},
  langid = {english},
  pagetotal = {248},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4NSIZ4H7\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf}
}

@book{rasmussenGaussianProcessesMachine2006a,
  title = {Gaussian Processes for Machine Learning},
  author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
  date = {2006},
  series = {Adaptive Computation and Machine Learning},
  publisher = {MIT Press},
  location = {Cambridge, Mass},
  isbn = {978-0-262-18253-9},
  langid = {english},
  pagetotal = {248},
  keywords = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  annotation = {OCLC: ocm61285753},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8BTNNTU8\Rasmussen and Williams - 2006 - Gaussian processes for machine learning.pdf}
}

@article{reichInterspikeIntervalsReceptive2000,
  title = {Interspike {{Intervals}}, {{Receptive Fields}}, and {{Information Encoding}} in {{Primary Visual Cortex}}},
  author = {Reich, Daniel S. and Mechler, Ferenc and Purpura, Keith P. and Victor, Jonathan D.},
  date = {2000-03-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J Neurosci},
  volume = {20},
  number = {5},
  eprint = {10684897},
  eprinttype = {pmid},
  pages = {1964--1974},
  issn = {0270-6474},
  doi = {10.1523/JNEUROSCI.20-05-01964.2000},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6772912/},
  urldate = {2023-01-16},
  abstract = {In the primate primary visual cortex (V1), the significance of individual action potentials has been difficult to determine, particularly in light of the considerable trial-to-trial variability of responses to visual stimuli. We show here that the information conveyed by an action potential depends on the duration of the immediately preceding interspike interval (ISI). The interspike intervals can be grouped into several different classes on the basis of reproducible features in the interspike interval histograms. Spikes in different classes bear different relationships to the visual stimulus, both qualitatively (in terms of the average stimulus preceding each spike) and quantitatively (in terms of the amount of information encoded per spike and per second). Spikes preceded by very short intervals (3 msec or less) convey information most efficiently and contribute disproportionately to the overall receptive-field properties of the neuron. Overall, V1 neurons can transmit between 5 and 30 bits of information per second in response to rapidly varying, pseudorandom stimuli, with an efficiency of ∼25\%. Although some (but not all) of our results would be expected from neurons that use a firing-rate code to transmit information, the evidence suggests that visual neurons are well equipped to decode stimulus-related information on the basis of relative spike timing and ISI duration.},
  pmcid = {PMC6772912},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5NX8KC6J\Reich et al. - 2000 - Interspike Intervals, Receptive Fields, and Inform.pdf}
}

@article{reinholdDistinctRecurrentAfferent2015,
  title = {Distinct Recurrent versus Afferent Dynamics in Cortical Visual Processing},
  author = {Reinhold, Kimberly and Lien, Anthony D. and Scanziani, Massimo},
  date = {2015-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {12},
  pages = {1789--1797},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4153},
  url = {https://www.nature.com/articles/nn.4153},
  urldate = {2024-06-13},
  abstract = {How intracortical recurrent circuits in mammalian sensory cortex influence dynamics of sensory representation is not understood. Previous methods could not distinguish the relative contributions of recurrent circuits and thalamic afferents to cortical dynamics. We accomplish this by optogenetically manipulating thalamus and cortex. Over the initial 40 ms of visual stimulation, excitation from recurrent circuits in visual cortex progressively increased to exceed direct thalamocortical excitation. Even when recurrent excitation exceeded thalamic excitation, upon silencing thalamus, sensory-evoked activity in cortex decayed rapidly, with a time constant of 10 ms, which is similar to a neuron's integration time window. In awake mice, this cortical decay function predicted the time-locking of cortical activity to thalamic input at frequencies {$<$}15 Hz and attenuation of the cortical response to higher frequencies. Under anesthesia, depression at thalamocortical synapses disrupted the fidelity of sensory transmission. Thus, we determine dynamics intrinsic to cortical recurrent circuits that transform afferent input in time.},
  langid = {english},
  keywords = {Striate cortex,Synaptic transmission,Thalamus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7RGJPQIP\Reinhold et al. - 2015 - Distinct recurrent versus afferent dynamics in cor.pdf}
}

@article{renartAsynchronousStateCortical2010,
  title = {The {{Asynchronous State}} in {{Cortical Circuits}}},
  author = {Renart, Alfonso and de la Rocha, Jaime and Bartho, Peter and Hollender, Liad and Parga, Néstor and Reyes, Alex and Harris, Kenneth D.},
  options = {useprefix=true},
  date = {2010-01-29},
  journaltitle = {Science},
  volume = {327},
  number = {5965},
  pages = {587--590},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1179850},
  url = {https://www.science.org/doi/10.1126/science.1179850},
  urldate = {2023-06-16},
  abstract = {Correlated spiking is often observed in cortical circuits, but its functional role is controversial. It is believed that correlations are a consequence of shared inputs between nearby neurons and could severely constrain information decoding. Here we show theoretically that recurrent neural networks can generate an asynchronous state characterized by arbitrarily low mean spiking correlations despite substantial amounts of shared input. In this state, spontaneous fluctuations in the activity of excitatory and inhibitory populations accurately track each other, generating negative correlations in synaptic currents which cancel the effect of shared input. Near-zero mean correlations were seen experimentally in recordings from rodent neocortex in vivo. Our results suggest a reexamination of the sources underlying observed correlations and their functional consequences for information processing.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\53A4XBII\Renart et al. - 2010 - The Asynchronous State in Cortical Circuits.pdf}
}

@article{renartAsynchronousStateCortical2010a,
  title = {The {{Asynchronous State}} in {{Cortical Circuits}}},
  author = {Renart, Alfonso and De La Rocha, Jaime and Bartho, Peter and Hollender, Liad and Parga, Néstor and Reyes, Alex and Harris, Kenneth D.},
  date = {2010-01-29},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {327},
  number = {5965},
  pages = {587--590},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1179850},
  url = {https://www.science.org/doi/10.1126/science.1179850},
  urldate = {2023-08-22},
  abstract = {Columns, Connections, and Correlations                            What is the nature of interactions between neurons in neural circuits? The prevalent hypothesis suggests that dense local connectivity causes nearby cortical neurons to receive substantial amounts of common input, which in turn leads to strong correlations between them. Now two studies challenge this view, which impacts our fundamental understanding of coding in the cortex.                                Ecker                 et al.                              (p.               584               ) investigated the statistics of correlated firing in pairs of neurons from area V1 of awake macaque monkeys. In contrast to previous studies, correlations turned out to be very low, irrespective of the stimulus being shown to the animals, the distances of the recording sites, and the similarity of the neuron's receptive fields or response properties. In an accompanying modeling and recording paper,                                Renart                 et al.                              (p.               587               ) demonstrate how it is possible to have zero noise correlation, even among cells with common input.                        ,              A general theoretical description of correlations in highly connected recurrent neuronal circuits.           ,              Correlated spiking is often observed in cortical circuits, but its functional role is controversial. It is believed that correlations are a consequence of shared inputs between nearby neurons and could severely constrain information decoding. Here we show theoretically that recurrent neural networks can generate an asynchronous state characterized by arbitrarily low mean spiking correlations despite substantial amounts of shared input. In this state, spontaneous fluctuations in the activity of excitatory and inhibitory populations accurately track each other, generating negative correlations in synaptic currents which cancel the effect of shared input. Near-zero mean correlations were seen experimentally in recordings from rodent neocortex in vivo. Our results suggest a reexamination of the sources underlying observed correlations and their functional consequences for information processing.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\P54JTKS2\Renart et al. - 2010 - The Asynchronous State in Cortical Circuits.pdf}
}

@article{renartMeanDrivenFluctuationDrivenPersistent2007,
  title = {Mean-{{Driven}} and {{Fluctuation-Driven Persistent Activity}} in {{Recurrent Networks}}},
  author = {Renart, Alfonso and Moreno-Bote, Rubén and Wang, Xiao-Jing and Parga, Néstor},
  date = {2007-01-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {19},
  number = {1},
  pages = {1--46},
  issn = {0899-7667},
  doi = {10.1162/neco.2007.19.1.1},
  url = {https://doi.org/10.1162/neco.2007.19.1.1},
  urldate = {2022-10-21},
  abstract = {Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this “balanced” state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LJLRG8NJ\\Renart et al. - 2007 - Mean-Driven and Fluctuation-Driven Persistent Acti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GNCJZTFV\\Mean-Driven-and-Fluctuation-Driven-Persistent.html}
}

@article{reppertCoordinationCircadianTiming2002,
  title = {✅ {{Coordination}} of Circadian Timing in Mammals},
  author = {Reppert, Steven M. and Weaver, David R.},
  date = {2002-08},
  journaltitle = {Nature},
  volume = {418},
  number = {6901},
  pages = {935--941},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature00965},
  url = {https://www.nature.com/articles/nature00965},
  urldate = {2023-02-16},
  abstract = {Time in the biological sense is measured by cycles that range from milliseconds to years. Circadian rhythms, which measure time on a scale of 24\,h, are generated by one of the most ubiquitous and well-studied timing systems. At the core of this timing mechanism is an intricate molecular mechanism that ticks away in many different tissues throughout the body. However, these independent rhythms are tamed by a master clock in the brain, which coordinates tissue-specific rhythms according to light input it receives from the outside world.},
  issue = {6901},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5HIRGXKF\Reppert and Weaver - 2002 - Coordination of circadian timing in mammals.pdf}
}

@article{reynoldsCompetitiveMechanismsSubserve1999,
  title = {Competitive {{Mechanisms Subserve Attention}} in {{Macaque Areas V2}} and {{V4}}},
  author = {Reynolds, John H. and Chelazzi, Leonardo and Desimone, Robert},
  date = {1999-03-01},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {19},
  number = {5},
  pages = {1736--1753},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.19-05-01736.1999},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.19-05-01736.1999},
  urldate = {2023-08-07},
  abstract = {It is well established that attention modulates visual processing in extrastriate cortex. However, the underlying neural mechanisms are unknown. A consistent observation is that attention has its greatest impact on neuronal responses when multiple stimuli appear together within a cell’s receptive field. One way to explain this is to assume that multiple stimuli activate competing populations of neurons and that attention biases this competition in favor of the attended stimulus. In the absence of competing stimuli, there is no competition to be resolved. Accordingly, attention has a more limited effect on the neuronal response to a single stimulus. To test this interpretation, we measured the responses of neurons in macaque areas V2 and V4 using a behavioral paradigm that allowed us to isolate automatic sensory processing mechanisms from attentional effects. First, we measured each cell’s response to a single stimulus presented alone inside the receptive field or paired with a second receptive field stimulus, while the monkey attended to a location outside the receptive field. Adding the second stimulus typically caused the neuron’s response to move toward the response that was elicited by the second stimulus alone. Then, we directed the monkey’s attention to one element of the pair. This drove the neuron’s response toward the response elicited when the attended stimulus appeared alone. These findings are consistent with the idea that attention biases competitive interactions among neurons, causing them to respond primarily to the attended stimulus. A quantitative neural model of attention is proposed to account for these results.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Z8A45FGY\Reynolds et al. - 1999 - Competitive Mechanisms Subserve Attention in Macaq.pdf}
}

@article{reynoldsNormalizationModelAttention2009,
  title = {The {{Normalization Model}} of {{Attention}}},
  author = {Reynolds, John H. and Heeger, David J.},
  date = {2009-01-29},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {61},
  number = {2},
  eprint = {19186161},
  eprinttype = {pmid},
  pages = {168--185},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.01.002},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(09)00003-8},
  urldate = {2023-01-16},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DAX5B7AV\Reynolds and Heeger - 2009 - The Normalization Model of Attention.pdf}
}

@article{reynoldsNormalizationModelAttention2009a,
  title = {The {{Normalization Model}} of {{Attention}}},
  author = {Reynolds, John H. and Heeger, David J.},
  date = {2009-01-29},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {61},
  number = {2},
  pages = {168--185},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2009.01.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627309000038},
  urldate = {2023-01-18},
  abstract = {Attention has been found to have a wide variety of effects on the responses of neurons in visual cortex. We describe a model of attention that exhibits each of these different forms of attentional modulation, depending on the stimulus conditions and the spread (or selectivity) of the attention field in the model. The model helps reconcile proposals that have been taken to represent alternative theories of attention. We argue that the variety and complexity of the results reported in the literature emerge from the variety of empirical protocols that were used, such that the results observed in any one experiment depended on the stimulus conditions and the subject's attentional strategy, a notion that we define precisely in terms of the attention field in the model, but that has not typically been completely under experimental control.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\R5WVQQUM\\Reynolds and Heeger - 2009 - The Normalization Model of Attention.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WQE8BCQW\\S0896627309000038.html}
}

@article{reynoldsRoleNeuralMechanisms1999,
  title = {The {{Role}} of {{Neural Mechanisms}} of {{Attention}} in {{Solving}} the {{Binding Problem}}},
  author = {Reynolds, John H. and Desimone, Robert},
  date = {1999-09-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {24},
  number = {1},
  eprint = {10677024},
  eprinttype = {pmid},
  pages = {19--29},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/S0896-6273(00)80819-3},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(00)80819-3},
  urldate = {2023-01-18},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6HL7GWUW\Reynolds and Desimone - 1999 - The Role of Neural Mechanisms of Attention in Solv.pdf}
}

@article{richardsDendriticSolutionsCredit2019,
  title = {Dendritic Solutions to the Credit Assignment Problem},
  author = {Richards, Blake A and Lillicrap, Timothy P},
  date = {2019-02},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  volume = {54},
  pages = {28--36},
  issn = {09594388},
  doi = {10.1016/j.conb.2018.08.003},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0959438818300485},
  urldate = {2020-08-29},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\85TNZ67Y\Richards and Lillicrap - 2019 - Dendritic solutions to the credit assignment probl.pdf}
}

@report{rimehaugUncoveringCircuitMechanisms2022,
  type = {preprint},
  title = {Uncovering Circuit Mechanisms of Current Sinks and Sources with Biophysical Simulations of Primary Visual Cortex},
  author = {Rimehaug, Atle E. and Stasik, Alexander J. and Hagen, Espen and Billeh, Yazan N. and Siegle, Joshua H. and Dai, Kael and Olsen, Shawn R. and Koch, Christof and Einevoll, Gaute T. and Arkhipov, Anton},
  date = {2022-02-25},
  institution = {Neuroscience},
  doi = {10.1101/2022.02.22.481540},
  url = {http://biorxiv.org/lookup/doi/10.1101/2022.02.22.481540},
  urldate = {2023-01-09},
  abstract = {Abstract           Local field potential (LFP) recordings reflect the dynamics of the current source density (CSD) in brain tissue. The synaptic, cellular and circuit contributions to current sinks and sources are ill-understood. We investigated these in mouse primary visual cortex using public Neuropixels recordings and a detailed circuit model based on simulating the Hodgkin-Huxley dynamics of numerous cortical neurons belonging to 17 cell types. The model simultaneously captured spiking and CSD responses and demonstrated a two-way dissociation: Firing rates are altered with minor effects on the CSD pattern by adjusting synaptic weights, and CSD is altered with minor effects on firing rates by adjusting synaptic placement on the dendrites. We describe how thalamocortical inputs and recurrent connections sculpt specific sinks and sources early in the visual response, whereas cortical feedback crucially alters them in later stages. Our findings show that CSD analysis provides powerful constraints for modeling beyond those from considering spikes.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QAM8VKIY\Rimehaug et al. - 2022 - Uncovering circuit mechanisms of current sinks and.pdf}
}

@article{ritzau-jostUltrafastActionPotentials2014,
  title = {Ultrafast {{Action Potentials Mediate Kilohertz Signaling}} at a {{Central Synapse}}},
  author = {Ritzau-Jost, Andreas and Delvendahl, Igor and Rings, Annika and Byczkowicz, Niklas and Harada, Harumi and Shigemoto, Ryuichi and Hirrlinger, Johannes and Eilers, Jens and Hallermann, Stefan},
  date = {2014-10-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {84},
  number = {1},
  pages = {152--163},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.08.036},
  url = {http://www.sciencedirect.com/science/article/pii/S0896627314007375},
  urldate = {2020-11-10},
  abstract = {Fast synaptic transmission is important for rapid information processing. To explore the maximal rate of neuronal signaling and to analyze the presynaptic mechanisms, we focused on the input layer of the cerebellar cortex, where exceptionally high action potential (AP) frequencies have been reported in~vivo. With paired recordings between presynaptic cerebellar mossy fiber boutons and postsynaptic granule cells, we demonstrate reliable neurotransmission up~to ∼1 kHz. Presynaptic APs are ultrafast, with ∼100~μs half-duration. Both Kv1 and Kv3 potassium channels mediate the fast repolarization, rapidly inactivating sodium channels ensure metabolic efficiency, and little AP broadening occurs during bursts of up to 1.5 kHz. Presynaptic Cav2.1 (P/Q-type) calcium channels open efficiently during ultrafast APs. Furthermore, a subset of synaptic vesicles is tightly coupled to Ca2+ channels, and vesicles are rapidly recruited to the release site. These data reveal mechanisms of presynaptic AP generation and transmitter release underlying neuronal kHz signaling.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6KSPEUFF\Ritzau-Jost et al. - 2014 - Ultrafast Action Potentials Mediate Kilohertz Sign.pdf}
}

@article{robinsonSkippingAheadCircuit2021,
  title = {Skipping Ahead: {{A}} Circuit for Representing the Past, Present, and Future},
  shorttitle = {Skipping Ahead},
  author = {Robinson, Jennifer C and Brandon, Mark P},
  editor = {Colgin, Laura L},
  date = {2021-10-14},
  journaltitle = {eLife},
  volume = {10},
  pages = {e68795},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.68795},
  url = {https://doi.org/10.7554/eLife.68795},
  urldate = {2023-03-24},
  abstract = {Envisioning the future is intuitively linked to our ability to remember the past. Within the memory system, substantial work has demonstrated the involvement of the prefrontal cortex and the hippocampus in representing the past and present. Recent data shows that both the prefrontal cortex and the hippocampus encode future trajectories, which are segregated in time by alternating cycles of the theta rhythm. Here, we discuss how information is temporally organized by these brain regions supported by the medial septum, nucleus reuniens, and parahippocampal regions. Finally, we highlight a brain circuit that we predict is essential for the temporal segregation of future scenarios.},
  keywords = {cycle skipping,hippocampus,memory,prefrontal cortex,theta sequences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CPVH5UGJ\Robinson and Brandon - 2021 - Skipping ahead A circuit for representing the pas.pdf}
}

@article{rodgersSensorimotorStrategiesNeuronal2021,
  title = {Sensorimotor Strategies and Neuronal Representations for Shape Discrimination},
  author = {Rodgers, Chris C. and Nogueira, Ramon and Pil, B. Christina and Greeman, Esther A. and Park, Jung M. and Hong, Y. Kate and Fusi, Stefano and Bruno, Randy M.},
  date = {2021-07-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {14},
  pages = {2308-2325.e10},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.05.019},
  url = {https://www.sciencedirect.com/science/article/pii/S089662732100372X},
  urldate = {2023-04-12},
  abstract = {Humans and other animals can identify objects by active touch, requiring the coordination of exploratory motion and tactile sensation. Both the motor strategies and neural representations employed could depend on the subject’s goals. We developed a shape discrimination task that challenged head-fixed mice to discriminate concave from convex shapes. Behavioral decoding revealed that mice did this by comparing contacts across whiskers. In contrast, a separate group of mice performing a shape detection task simply summed up contacts over whiskers. We recorded populations of neurons in the barrel cortex, which processes whisker input, and found that individual neurons across the cortical layers encoded touch, whisker motion, and task-related signals. Sensory representations were task-specific: during shape discrimination, but not detection, neurons responded most to behaviorally relevant whiskers, overriding somatotopy. Thus, sensory cortex employs task-specific representations compatible with behaviorally relevant computations.},
  langid = {english},
  keywords = {active sensing,barrel cortex,behavior,behavioral decoding,electrophysiology,encoding models,generalized linear model,modeling,shape discrimination,somatosensory cortex,whiskers},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CYXU8VMA\\Rodgers et al. - 2021 - Sensorimotor strategies and neuronal representatio.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WW5USKSS\\S089662732100372X.html}
}

@article{rodgersSensorimotorStrategiesNeuronal2021a,
  title = {Sensorimotor Strategies and Neuronal Representations for Shape Discrimination},
  author = {Rodgers, Chris C. and Nogueira, Ramon and Pil, B. Christina and Greeman, Esther A. and Park, Jung M. and Hong, Y. Kate and Fusi, Stefano and Bruno, Randy M.},
  date = {2021-07-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {14},
  eprint = {34133944},
  eprinttype = {pmid},
  pages = {2308-2325.e10},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.05.019},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(21)00372-X},
  urldate = {2023-04-12},
  langid = {english},
  keywords = {active sensing,barrel cortex,behavior,behavioral decoding,electrophysiology,encoding models,generalized linear model,modeling,shape discrimination,somatosensory cortex,whiskers},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2EHAELLK\Rodgers et al. - 2021 - Sensorimotor strategies and neuronal representatio.pdf}
}

@article{rodriguesKuramotoModelComplex2016,
  title = {The {{Kuramoto}} Model in Complex Networks},
  author = {Rodrigues, Francisco A. and Peron, Thomas K. DM. and Ji, Peng and Kurths, Jürgen},
  date = {2016-01-26},
  journaltitle = {Physics Reports},
  shortjournal = {Physics Reports},
  series = {The {{Kuramoto}} Model in Complex Networks},
  volume = {610},
  pages = {1--98},
  issn = {0370-1573},
  doi = {10.1016/j.physrep.2015.10.008},
  url = {http://www.sciencedirect.com/science/article/pii/S0370157315004408},
  urldate = {2020-10-06},
  abstract = {Synchronization of an ensemble of oscillators is an emergent phenomenon present in several complex systems, ranging from social and physical to biological and technological systems. The most successful approach to describe how coherent behavior emerges in these complex systems is given by the paradigmatic Kuramoto model. This model has been traditionally studied in complete graphs. However, besides being intrinsically dynamical, complex systems present very heterogeneous structure, which can be represented as complex networks. This report is dedicated to review main contributions in the field of synchronization in networks of Kuramoto oscillators. In particular, we provide an overview of the impact of network patterns on the local and global dynamics of coupled phase oscillators. We cover many relevant topics, which encompass a description of the most used analytical approaches and the analysis of several numerical results. Furthermore, we discuss recent developments on variations of the Kuramoto model in networks, including the presence of noise and inertia. The rich potential for applications is discussed for special fields in engineering, neuroscience, physics and Earth science. Finally, we conclude by discussing problems that remain open after the last decade of intensive research on the Kuramoto model and point out some promising directions for future research.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SG4U2JQZ\\Rodrigues et al. - 2016 - The Kuramoto model in complex networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\X3SDT4JP\\S0370157315004408.html}
}

@article{roelfsemaAttentiongatedReinforcementLearning2005,
  title = {✅ {{Attention-gated}} Reinforcement Learning of Internal Representations for Classification},
  author = {Roelfsema, Pieter R. and van Ooyen, Arjen},
  options = {useprefix=true},
  date = {2005-10},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput},
  volume = {17},
  number = {10},
  eprint = {16105222},
  eprinttype = {pmid},
  pages = {2176--2214},
  issn = {0899-7667},
  doi = {10.1162/0899766054615699},
  abstract = {Animal learning is associated with changes in the efficacy of connections between neurons. The rules that govern this plasticity can be tested in neural networks. Rules that train neural networks to map stimuli onto outputs are given by supervised learning and reinforcement learning theories. Supervised learning is efficient but biologically implausible. In contrast, reinforcement learning is biologically plausible but comparatively inefficient. It lacks a mechanism that can identify units at early processing levels that play a decisive role in the stimulus-response mapping. Here we show that this so-called credit assignment problem can be solved by a new role for attention in learning. There are two factors in our new learning scheme that determine synaptic plasticity: (1) a reinforcement signal that is homogeneous across the network and depends on the amount of reward obtained after a trial, and (2) an attentional feedback signal from the output layer that limits plasticity to those units at earlier processing levels that are crucial for the stimulus-response mapping. The new scheme is called attention-gated reinforcement learning (AGREL). We show that it is as efficient as supervised learning in classification tasks. AGREL is biologically realistic and integrates the role of feedback connections, attention effects, synaptic plasticity, and reinforcement learning signals into a coherent framework.},
  langid = {english},
  keywords = {Animals,Attention,Feedback,Generalization Psychological,Humans,Learning,Models Neurological,Neural Networks Computer,Neuronal Plasticity,Neurons,Reinforcement Psychology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KCBNT9FG\Roelfsema and van Ooyen - 2005 - Attention-gated reinforcement learning of internal.pdf}
}

@article{roelfsemaControlSynapticPlasticity2018,
  title = {Control of Synaptic Plasticity in Deep Cortical Networks},
  author = {Roelfsema, Pieter R. and Holtmaat, Anthony},
  date = {2018-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {3},
  pages = {166--180},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2018.6},
  url = {https://www.nature.com/articles/nrn.2018.6},
  urldate = {2023-01-13},
  abstract = {In addition to presynaptic and postsynaptic mechanisms, synaptic plasticity depends on neuromodulatory substances and feedback connections from higher-order cortical and thalamic brain regionsSynaptic plasticity in the brain depends on reward-prediction errors and on selective attention. Neuromodulatory systems code for the reward-prediction errors, and feedback connections from the response-selection stage mediate top-down attention effectsThe combined influence of feedback connections and neuromodulatory substances on plasticity enables powerful learning rules for the training of 'deep', multilayered neuronal networksFeedback connections project to cortical layers that are distinct from feedforward input, where they impinge on distal dendritic segments, separate excitatory neuronal populations or inhibitory interneuronsFeedback connections gate plasticity in cortical pyramidal neurons by promoting NMDA-receptor-driven calcium entry into dendrites and by disinhibiting the cortical column through activation of vasoactive-intestinal-peptide-positive interneurons (among others)Synaptic tags are biochemical processes that make synapses eligible for plasticity. Neuromodulators released later can interact with tagged synapses to increase or decrease synaptic strength},
  issue = {3},
  langid = {english},
  keywords = {Cortex,Neurotransmitters,Spike-timing-dependent plasticity,Synaptic plasticity,Thalamus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NXSGAZA2\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf}
}

@article{roelfsemaControlSynapticPlasticity2018a,
  title = {Control of Synaptic Plasticity in Deep Cortical Networks},
  author = {Roelfsema, Pieter R. and Holtmaat, Anthony},
  date = {2018-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {3},
  pages = {166--180},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2018.6},
  url = {https://www.nature.com/articles/nrn.2018.6},
  urldate = {2023-01-19},
  abstract = {In addition to presynaptic and postsynaptic mechanisms, synaptic plasticity depends on neuromodulatory substances and feedback connections from higher-order cortical and thalamic brain regionsSynaptic plasticity in the brain depends on reward-prediction errors and on selective attention. Neuromodulatory systems code for the reward-prediction errors, and feedback connections from the response-selection stage mediate top-down attention effectsThe combined influence of feedback connections and neuromodulatory substances on plasticity enables powerful learning rules for the training of 'deep', multilayered neuronal networksFeedback connections project to cortical layers that are distinct from feedforward input, where they impinge on distal dendritic segments, separate excitatory neuronal populations or inhibitory interneuronsFeedback connections gate plasticity in cortical pyramidal neurons by promoting NMDA-receptor-driven calcium entry into dendrites and by disinhibiting the cortical column through activation of vasoactive-intestinal-peptide-positive interneurons (among others)Synaptic tags are biochemical processes that make synapses eligible for plasticity. Neuromodulators released later can interact with tagged synapses to increase or decrease synaptic strength},
  issue = {3},
  langid = {english},
  keywords = {Cortex,Neurotransmitters,Spike-timing-dependent plasticity,Synaptic plasticity,Thalamus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\4QRDZJJJ\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf}
}

@article{roelfsemaControlSynapticPlasticity2018b,
  title = {Control of Synaptic Plasticity in Deep Cortical Networks},
  author = {Roelfsema, Pieter R. and Holtmaat, Anthony},
  date = {2018-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {19},
  number = {3},
  pages = {166--180},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn.2018.6},
  url = {https://www.nature.com/articles/nrn.2018.6},
  urldate = {2023-08-03},
  abstract = {In addition to presynaptic and postsynaptic mechanisms, synaptic plasticity depends on neuromodulatory substances and feedback connections from higher-order cortical and thalamic brain regionsSynaptic plasticity in the brain depends on reward-prediction errors and on selective attention. Neuromodulatory systems code for the reward-prediction errors, and feedback connections from the response-selection stage mediate top-down attention effectsThe combined influence of feedback connections and neuromodulatory substances on plasticity enables powerful learning rules for the training of 'deep', multilayered neuronal networksFeedback connections project to cortical layers that are distinct from feedforward input, where they impinge on distal dendritic segments, separate excitatory neuronal populations or inhibitory interneuronsFeedback connections gate plasticity in cortical pyramidal neurons by promoting NMDA-receptor-driven calcium entry into dendrites and by disinhibiting the cortical column through activation of vasoactive-intestinal-peptide-positive interneurons (among others)Synaptic tags are biochemical processes that make synapses eligible for plasticity. Neuromodulators released later can interact with tagged synapses to increase or decrease synaptic strength},
  issue = {3},
  langid = {english},
  keywords = {Cortex,Neurotransmitters,Spike-timing-dependent plasticity,Synaptic plasticity,Thalamus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RS5DPFVH\Roelfsema and Holtmaat - 2018 - Control of synaptic plasticity in deep cortical ne.pdf}
}

@article{roelfsemaNeuronalMechanismsObjectbased2022,
  title = {The Neuronal Mechanisms for Object-Based Attention and How They Solve the Binding Problem},
  author = {Roelfsema, Pieter},
  date = {2022-12-05},
  journaltitle = {Journal of Vision},
  shortjournal = {Journal of Vision},
  volume = {22},
  number = {14},
  pages = {3188},
  issn = {1534-7362},
  doi = {10.1167/jov.22.14.3188},
  url = {https://doi.org/10.1167/jov.22.14.3188},
  urldate = {2023-01-22},
  abstract = {Our visual system groups image elements of objects and segregates them from other objects and the background. I will discuss the neuronal mechanisms for these grouping operations, proposing that there are two processes for perceptual grouping. The first is ‘base grouping’, which is a process that relies on neurons tuned to feature conjunctions and occurs in parallel across the visual scene. If there are no neurons tuned to the required feature conjunctions, a second process, called ‘incremental grouping’, comes into play. Incremental grouping is a time-consuming and capacity-limited process, which relies on the gradual spread of enhanced neuronal activity across the distributed representation of an object in the visual cortex, during a delayed phase of the neuronal responses. Incremental grouping can occur for only one object at any one time. The spread of enhanced activity corresponds to the spread of object-based attention at the psychological level of description. Hence, we found that the binding problem is solved by labelling the representation of image elements in the visual cortex with enhanced activity and we did not obtain any evidence for a role of neuronal synchronization. Inhibition of the late-phase activity in primary visual cortex completely blocked figure-ground perception, demonstrating a causal link between enhanced neuronal activity and perceptual organization. These neuronal mechanisms for perceptual grouping account for many of the perceptual demonstrations by the Gestalt psychologists.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CLHP6T5K\article.html}
}

@article{roelfsemaSolutionsBindingProblem1998,
  title = {Solutions for the {{Binding Problem}}},
  author = {Roelfsema, Pieter R.},
  date = {1998-08-01},
  journaltitle = {Zeitschrift für Naturforschung C},
  volume = {53},
  number = {7-8},
  pages = {691--715},
  publisher = {De Gruyter},
  issn = {1865-7125},
  doi = {10.1515/znc-1998-7-822},
  url = {https://www.degruyter.com/document/doi/10.1515/znc-1998-7-822/html},
  urldate = {2023-01-23},
  abstract = {Visual cortical neurons are broadly tuned to one or a few feature dimensions, like color and motion. This is advantageous because broadly tuned neurons can contribute to the repre­sentation of many visual scenes. However, if there are multiple objects in a visual scene, the cortex is at risk to combine features of different objects as if they belong to a single object. The term “binding problem” was introduced to refer to the difficulties that may occur in sorting out those responses that are evoked by a single perceptual object. The present article reviews proposals suggesting that the binding problem is solved by labelling an assembly of neurons that is responsive to a single perceptual obejct. Evidence is reviewed in favor of two possible assembly-labels: rate enhancement due to visual attention and neuronal synchrony. Assembly-labels should be spread through the cortical network to all neurons that have to participate in an assembly The present article tries to shed light on the mechanisms that subserve such a selective spread of assembly labels. Moreover, it is suggested that assembly labels may fulfill an equivalent role in the motor system, since binding problems can also occur during the generation of useful patterns of motor activity.},
  langid = {english},
  keywords = {Cell Assemblies,Motor Cortex,Neuronal Synchrony,Visual Attention,Visual Cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WUNYKR4P\Roelfsema - 1998 - Solutions for the Binding Problem.pdf}
}

@article{rogersFlexibleGeneralizableRepresentations2023,
  title = {Flexible and Generalizable Representations of Touch},
  author = {Rogers, Jake},
  date = {2023-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {24},
  number = {3},
  pages = {132--132},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-023-00679-9},
  url = {https://www.nature.com/articles/s41583-023-00679-9},
  urldate = {2023-04-11},
  abstract = {The representational geometry of neural population activity in the somatosensory cortex of mice allows for high flexibility needed to perform complex tasks and for generalization to novel tasks at the same time.},
  issue = {3},
  langid = {english},
  keywords = {Neural decoding,Perception}
}

@article{rosenbaumRelationshipPredictiveCoding2022,
  title = {On the Relationship between Predictive Coding and Backpropagation},
  author = {Rosenbaum, Robert},
  date = {2022-03-31},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {17},
  number = {3},
  pages = {e0266102},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0266102},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0266102},
  urldate = {2023-04-01},
  abstract = {Artificial neural networks are often interpreted as abstract models of biological neuronal networks, but they are typically trained using the biologically unrealistic backpropagation algorithm and its variants. Predictive coding has been proposed as a potentially more biologically realistic alternative to backpropagation for training neural networks. This manuscript reviews and extends recent work on the mathematical relationship between predictive coding and backpropagation for training feedforward artificial neural networks on supervised learning tasks. Implications of these results for the interpretation of predictive coding and deep neural networks as models of biological learning are discussed along with a repository of functions, Torch2PC, for performing predictive coding with PyTorch neural network models.},
  langid = {english},
  keywords = {Algorithms,Artificial neural networks,Coding mechanisms,Coding theory,Convolutional coding,Covariance,Feedforward neural networks,Neural networks},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Y9GSBFF6\Rosenbaum - 2022 - On the relationship between predictive coding and .pdf}
}

@article{rosenbaumSpatialStructureCorrelated2017,
  title = {The Spatial Structure of Correlated Neuronal Variability},
  author = {Rosenbaum, Robert and Smith, Matthew A. and Kohn, Adam and Rubin, Jonathan E. and Doiron, Brent},
  date = {2017-01},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {1},
  pages = {107--114},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4433},
  url = {https://www.nature.com/articles/nn.4433},
  urldate = {2023-08-28},
  abstract = {The activity of cortical neurons is extremely noisy. This study builds a mathematical theory linking the spatial scales of cortical wiring to how noise is generated and distributed over a population of neurons. Predictions from the theory are validated using population recordings in primate visual area V1.},
  issue = {1},
  langid = {english},
  keywords = {Network models,Neural circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ME93SRDZ\Rosenbaum et al. - 2017 - The spatial structure of correlated neuronal varia.pdf}
}

@report{rossbroichSynapticDynamicsConvolutional2020,
  type = {preprint},
  title = {Synaptic {{Dynamics}} as {{Convolutional Units}}},
  author = {Rossbroich, Julian and Trotter, Daniel and Tóth, Katalin and Naud, Richard},
  date = {2020-06-05},
  institution = {Neuroscience},
  doi = {10.1101/2020.06.04.133892},
  url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.04.133892},
  urldate = {2020-10-08},
  abstract = {Synaptic dynamics differ markedly across connections and strongly regulate how action potentials are being communicated. To model the range of synaptic dynamics observed in experiments, we develop a flexible mathematical framework based on a linear-nonlinear operation. This model can capture various experimentally observed features of synaptic dynamics and different types of heteroskedasticity. Despite its conceptual simplicity, we show it is more adaptable than previous models. Combined with a standard maximum likelihood approach, synaptic dynamics can be accurately and efficiently characterized using naturalistic stimulation patterns. These results make explicit that synaptic processing bears algorithmic similarities with information processing in convolutional neural networks.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\M74KY9B4\Rossbroich et al. - 2020 - Synaptic Dynamics as Convolutional Units.pdf}
}

@article{rothensteinAttentionalModulationSelection2014,
  title = {Attentional Modulation and Selection--an Integrated Approach},
  author = {Rothenstein, Albert L. and Tsotsos, John K.},
  date = {2014},
  journaltitle = {PloS One},
  shortjournal = {PLoS One},
  volume = {9},
  number = {6},
  eprint = {24963827},
  eprinttype = {pmid},
  pages = {e99681},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0099681},
  abstract = {Various models of the neural mechanisms of attentional modulation in the visual cortex have been proposed. In general, these models assume that an 'attention' parameter is provided separately. Its value as well as the selection of neuron(s) to which it applies are assumed, but its source and the selection mechanism are unspecified. Here we show how the Selective Tuning model of visual attention can account for the modulation of the firing rate at the single neuron level, and for the temporal pattern of attentional modulations in the visual cortex, in a self-contained formulation that simultaneously determines the stimulus elements to be attended while modulating the relevant neural processes.},
  langid = {english},
  pmcid = {PMC4070899},
  keywords = {Animals,Attention,Humans,Macaca,Models Neurological,Nerve Net,Visual Cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\W5KHD9MU\Rothenstein and Tsotsos - 2014 - Attentional modulation and selection--an integrate.pdf}
}

@article{roudiPairwiseMaximumEntropy2009,
  title = {Pairwise {{Maximum Entropy Models}} for {{Studying Large Biological Systems}}: {{When They Can Work}} and {{When They Can}}'t},
  shorttitle = {Pairwise {{Maximum Entropy Models}} for {{Studying Large Biological Systems}}},
  author = {Roudi, Yasser and Nirenberg, Sheila and Latham, Peter E.},
  date = {2009-05-08},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {5},
  number = {5},
  pages = {e1000380},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000380},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000380},
  urldate = {2023-04-14},
  abstract = {One of the most critical problems we face in the study of biological systems is building accurate statistical descriptions of them. This problem has been particularly challenging because biological systems typically contain large numbers of interacting elements, which precludes the use of standard brute force approaches. Recently, though, several groups have reported that there may be an alternate strategy. The reports show that reliable statistical models can be built without knowledge of all the interactions in a system; instead, pairwise interactions can suffice. These findings, however, are based on the analysis of small subsystems. Here, we ask whether the observations will generalize to systems of realistic size, that is, whether pairwise models will provide reliable descriptions of true biological systems. Our results show that, in most cases, they will not. The reason is that there is a crossover in the predictive power of pairwise models: If the size of the subsystem is below the crossover point, then the results have no predictive power for large systems. If the size is above the crossover point, then the results may have predictive power. This work thus provides a general framework for determining the extent to which pairwise models can be used to predict the behavior of large biological systems. Applied to neural data, the size of most systems studied so far is below the crossover point.},
  langid = {english},
  keywords = {Behavior,Distance measurement,Entropy,Extrapolation,Neurons,Probability distribution,Protein folding,Soil perturbation},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\V3DRSNN9\Roudi et al. - 2009 - Pairwise Maximum Entropy Models for Studying Large.pdf}
}

@article{roudiStatisticalPhysicsPairwise2009,
  title = {Statistical Physics of Pairwise Probability Models},
  author = {Roudi, Yasser and Aurell, Erik and Hertz, John},
  date = {2009},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {3},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/neuro.10.022.2009},
  urldate = {2023-04-14},
  abstract = {Statistical models for describing the probability distribution over the states of biological systems are commonly used for dimensional reduction. Among these models, pairwise models are very attractive in part because they can be fit using a reasonable amount of data: knowledge of the mean values and correlations between pairs of elements in the system is sufficient. Not surprisingly, then, using pairwise models for studying neural data has been the focus of many studies in recent years. In this paper, we describe how tools from statistical physics can be employed for studying and using pairwise models. We build on our previous work on the subject and study the relation between different methods for fitting these models and evaluating their quality. In particular, using data from simulated cortical networks we study how the quality of various approximate methods for inferring the parameters in a pairwise model depends on the time bin chosen for binning the data. We also study the effect of the size of the time bin on the model quality itself, again using simulated data. We show that using finer time bins increases the quality of the pairwise model. We offer new ways of deriving the expressions reported in our previous work for assessing the quality of pairwise models.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7ZRFXL7B\Roudi et al. - 2009 - Statistical physics of pairwise probability models.pdf}
}

@article{ruffAttentionIncreasesSpike2016,
  title = {Attention {{Increases Spike Count Correlations}} between {{Visual Cortical Areas}}},
  author = {Ruff, Douglas A. and Cohen, Marlene R.},
  date = {2016-07-13},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {36},
  number = {28},
  eprint = {27413161},
  eprinttype = {pmid},
  pages = {7523--7534},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0610-16.2016},
  url = {https://www.jneurosci.org/content/36/28/7523},
  urldate = {2022-12-21},
  abstract = {Visual attention, which improves perception of attended locations or objects, has long been known to affect many aspects of the responses of neuronal populations in visual cortex. There are two nonmutually exclusive hypotheses concerning the neuronal mechanisms that underlie these perceptual improvements. The first hypothesis, that attention improves the information encoded by a population of neurons in a particular cortical area, has considerable physiological support. The second hypothesis is that attention improves perception by selectively communicating relevant visual information. This idea has been tested primarily by measuring interactions between neurons on very short timescales, which are mathematically nearly independent of neuronal interactions on longer timescales. We tested the hypothesis that attention changes the way visual information is communicated between cortical areas on longer timescales by recording simultaneously from neurons in primary visual cortex (V1) and the middle temporal area (MT) in rhesus monkeys. We used two independent and complementary approaches. Our correlative experiment showed that attention increases the trial-to-trial response variability that is shared between the two areas. In our causal experiment, we electrically microstimulated V1 and found that attention increased the effect of stimulation on MT responses. Together, our results suggest that attention affects both the way visual stimuli are encoded within a cortical area and the extent to which visual information is communicated between areas on behaviorally relevant timescales. SIGNIFICANCE STATEMENT Visual attention dramatically improves the perception of attended stimuli. Attention has long been thought to act by selecting relevant visual information for further processing. It has been hypothesized that this selection is accomplished by increasing communication between neurons that encode attended information in different cortical areas. We recorded simultaneously from neurons in primary visual cortex and the middle temporal area while rhesus monkeys performed an attention task. We found that attention increased shared variability between neurons in the two areas and that attention increased the effect of microstimulation in V1 on the firing rates of MT neurons. Our results provide support for the hypothesis that attention increases communication between neurons in different brain areas on behaviorally relevant timescales.},
  langid = {english},
  keywords = {attention,middle temporal area,primary visual cortex,variability},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YMZ4YLWI\Ruff and Cohen - 2016 - Attention Increases Spike Count Correlations betwe.pdf}
}

@article{ruffLowRankMechanisms2020,
  title = {Low Rank Mechanisms Underlying Flexible Visual Representations},
  author = {Ruff, Douglas A. and Xue, Cheng and Kramer, Lily E. and Baqai, Faisal and Cohen, Marlene R.},
  date = {2020-11-24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {117},
  number = {47},
  pages = {29321--29329},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2005797117},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2005797117},
  urldate = {2022-12-21},
  abstract = {Neuronal population responses to sensory stimuli are remarkably flexible. The responses of neurons in visual cortex have heterogeneous dependence on stimulus properties (e.g., contrast), processes that affect all stages of visual processing (e.g., adaptation), and cognitive processes (e.g., attention or task switching). Understanding whether these processes affect similar neuronal populations and whether they have similar effects on entire populations can provide insight into whether they utilize analogous mechanisms. In particular, it has recently been demonstrated that attention has low rank effects on the covariability of populations of visual neurons, which impacts perception and strongly constrains mechanistic models. We hypothesized that measuring changes in population covariability associated with other sensory and cognitive processes could clarify whether they utilize similar mechanisms or computations. Our experimental design included measurements in multiple visual areas using four distinct sensory and cognitive processes. We found that contrast, adaptation, attention, and task switching affect the variability of responses of populations of neurons in primate visual cortex in a similarly low rank way. These results suggest that a given circuit may use similar mechanisms to perform many forms of modulation and likely reflects a general principle that applies to a wide range of brain areas and sensory, cognitive, and motor processes.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Z6LMCDS3\Ruff et al. - 2020 - Low rank mechanisms underlying flexible visual rep.pdf}
}

@article{ruleSelfhealingCodesHow2022,
  title = {Self-Healing Codes: {{How}} Stable Neural Populations Can Track Continually Reconfiguring Neural Representations},
  shorttitle = {Self-Healing Codes},
  author = {Rule, Michael E. and O’Leary, Timothy},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {7},
  pages = {e2106692119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2106692119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2106692119},
  urldate = {2022-09-30},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\S4P6STWA\Rule and O’Leary - 2022 - Self-healing codes How stable neural populations .pdf}
}

@article{rustPriorityCodingVisual2022,
  title = {Priority Coding in the Visual System},
  author = {Rust, Nicole C. and Cohen, Marlene R.},
  date = {2022-06},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {23},
  number = {6},
  pages = {376--388},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00582-9},
  url = {https://www.nature.com/articles/s41583-022-00582-9},
  urldate = {2022-12-23},
  abstract = {Although we are continuously bombarded with visual input, only a fraction of incoming visual events is perceived, remembered or acted on. The neural underpinnings of various forms of visual priority coding, including perceptual expertise, goal-directed attention, visual salience, image memorability and preferential looking, have been studied. Here, we synthesize information from these different examples to review recent developments in our understanding of visual priority coding and its neural correlates, with a focus on the role of behaviour to evaluate candidate correlates. We propose that the brain combines different types of priority into a unified priority signal while also retaining the ability to differentiate between them, and that this happens by leveraging partially overlapping low-dimensional neural subspaces for each type of priority that are shared with the downstream neural populations involved in decision-making. Finally, we describe the gulfs in understanding that have resulted from different research approaches, and we point towards future directions that will lead to fundamental insights about neural coding and how prioritization influences visually guided behaviours.},
  issue = {6},
  langid = {english},
  keywords = {Extrastriate cortex,Neural encoding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7N88UA2E\Rust and Cohen - 2022 - Priority coding in the visual system.pdf}
}

@article{rustPriorityCodingVisual2022a,
  title = {Priority Coding in the Visual System},
  author = {Rust, Nicole C. and Cohen, Marlene R.},
  date = {2022-06},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {23},
  number = {6},
  pages = {376--388},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-022-00582-9},
  url = {https://www.nature.com/articles/s41583-022-00582-9},
  urldate = {2023-01-21},
  abstract = {Although we are continuously bombarded with visual input, only a fraction of incoming visual events is perceived, remembered or acted on. The neural underpinnings of various forms of visual priority coding, including perceptual expertise, goal-directed attention, visual salience, image memorability and preferential looking, have been studied. Here, we synthesize information from these different examples to review recent developments in our understanding of visual priority coding and its neural correlates, with a focus on the role of behaviour to evaluate candidate correlates. We propose that the brain combines different types of priority into a unified priority signal while also retaining the ability to differentiate between them, and that this happens by leveraging partially overlapping low-dimensional neural subspaces for each type of priority that are shared with the downstream neural populations involved in decision-making. Finally, we describe the gulfs in understanding that have resulted from different research approaches, and we point towards future directions that will lead to fundamental insights about neural coding and how prioritization influences visually guided behaviours.},
  issue = {6},
  langid = {english},
  keywords = {Extrastriate cortex,Neural encoding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ZNXSZPL7\Rust and Cohen - 2022 - Priority coding in the visual system.pdf}
}

@article{rutishauserCollectiveStabilityNetworks2011,
  title = {Collective {{Stability}} of {{Networks}} of {{Winner-Take-All Circuits}}},
  author = {Rutishauser, Ueli and Douglas, Rodney J. and Slotine, Jean-Jacques},
  date = {2011-03-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {23},
  number = {3},
  pages = {735--773},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00091},
  url = {https://doi.org/10.1162/NECO_a_00091},
  urldate = {2023-06-15},
  abstract = {The neocortex has a remarkably uniform neuronal organization, suggesting that common principles of processing are employed throughout its extent. In particular, the patterns of connectivity observed in the superficial layers of the visual cortex are consistent with the recurrent excitation and inhibitory feedback required for cooperative-competitive circuits such as the soft winner-take-all (WTA). WTA circuits offer interesting computational properties such as selective amplification, signal restoration, and decision making. But these properties depend on the signal gain derived from positive feedback, and so there is a critical trade-off between providing feedback strong enough to support the sophisticated computations while maintaining overall circuit stability. The issue of stability is all the more intriguing when one considers that the WTAs are expected to be densely distributed through the superficial layers and that they are at least partially interconnected. We consider how to reason about stability in very large distributed networks of such circuits. We approach this problem by approximating the regular cortical architecture as many interconnected cooperative-competitive modules. We demonstrate that by properly understanding the behavior of this small computational module, one can reason over the stability and convergence of very large networks composed of these modules. We obtain parameter ranges in which the WTA circuit operates in a high-gain regime, is stable, and can be aggregated arbitrarily to form large, stable networks. We use nonlinear contraction theory to establish conditions for stability in the fully nonlinear case and verify these solutions using numerical simulations. The derived bounds allow modes of operation in which the WTA network is multistable and exhibits state-dependent persistent activities. Our approach is sufficiently general to reason systematically about the stability of any network, biological or technological, composed of networks of small modules that express competition through shared inhibition.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DBJSJDTP\\Rutishauser et al. - 2011 - Collective Stability of Networks of Winner-Take-Al.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WKUTICDV\\Collective-Stability-of-Networks-of-Winner-Take.html}
}

@inproceedings{sacramentoDendriticCorticalMicrocircuits2018,
  title = {Dendritic Cortical Microcircuits Approximate the Backpropagation Algorithm},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sacramento, João and Ponte Costa, Rui and Bengio, Yoshua and Senn, Walter},
  date = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2018/hash/1dc3a89d0d440ba31729b0ba74b93a33-Abstract.html},
  urldate = {2023-01-20},
  abstract = {Deep learning has seen remarkable developments over the last years, many of them inspired by neuroscience. However, the main learning mechanism behind these advances – error backpropagation – appears to be at odds with neurobiology. Here, we introduce a multilayer neuronal network model with simplified dendritic compartments in which error-driven synaptic plasticity adapts the network towards a global desired output. In contrast to previous work our model does not require separate phases and synaptic learning is driven by local dendritic prediction errors continuously in time. Such errors originate at apical dendrites and occur due to a mismatch between predictive input from lateral interneurons and activity from actual top-down feedback. Through the use of simple dendritic compartments and different cell-types our model can represent both error and normal activity within a pyramidal neuron. We demonstrate the learning capabilities of the model in regression and classification tasks, and show analytically that it approximates the error backpropagation algorithm. Moreover, our framework is consistent with recent observations of learning between brain areas and the architecture of cortical microcircuits. Overall, we introduce a novel view of learning on dendritic cortical circuits and on how the brain may solve the long-standing synaptic credit assignment problem.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\G23JASLD\Sacramento et al. - 2018 - Dendritic cortical microcircuits approximate the b.pdf}
}

@article{sakmannHighfrequencySpikeBursts,
  title = {High-Frequency Spike Bursts in Cortical Layer 5 Thick Tufted Pyramds Provide a Brian-Wide Signal to Encode Exploratory Touch},
  author = {Sakmann, Kock},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\Z4PXBR88\Sakmann - High-frequency spike bursts in cortical layer 5 th.pdf}
}

@article{sakmannSingleCellsSingle2017,
  title = {From Single Cells and Single Columns to Cortical Networks: Dendritic Excitability, Coincidence Detection and Synaptic Transmission in Brain Slices and Brains},
  shorttitle = {From Single Cells and Single Columns to Cortical Networks},
  author = {Sakmann, Bert},
  date = {2017},
  journaltitle = {Experimental Physiology},
  volume = {102},
  number = {5},
  pages = {489--521},
  issn = {1469-445X},
  doi = {10.1113/EP085776},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1113/EP085776},
  urldate = {2023-08-01},
  abstract = {Although patch pipettes were initially designed to record extracellularly the elementary current events from muscle and neuron membranes, the whole-cell and loose cell-attached recording configurations proved to be useful tools for examination of signalling within and between nerve cells. In this Paton Prize Lecture, I will initially summarize work on electrical signalling within single neurons, describing communication between the dendritic compartments, soma and nerve terminals via forward- and backward-propagating action potentials. The newly discovered dendritic excitability endows neurons with the capacity for coincidence detection of spatially separated subthreshold inputs. When these are occurring during a time window of tens of milliseconds, this information is broadcast to other cells by the initiation of bursts of action potentials (AP bursts). The occurrence of AP bursts critically impacts signalling between neurons that are controlled by target-cell-specific transmitter release mechanisms at downstream synapses even in different terminals of the same neuron. This can, in turn, induce mechanisms that underly synaptic plasticity when AP bursts occur within a short time window, both presynaptically in terminals and postsynaptically in dendrites. A fundamental question that arises from these findings is: ‘what are the possible functions of active dendritic excitability with respect to network dynamics in the intact cortex of behaving animals?’ To answer this question, I highlight in this review the functional and anatomical architectures of an average cortical column in the vibrissal (whisker) field of the somatosensory cortex (vS1), with an emphasis on the functions of layer 5 thick-tufted cells (L5tt) embedded in this structure. Sensory-evoked synaptic and action potential responses of these major cortical output neurons are compared with responses in the afferent pathway, viz. the neurons in primary somatosensory thalamus and in one of their efferent targets, the secondary somatosensory thalamus. Coincidence-detection mechanisms appear to be implemented in vivo as judged from the occurrence of AP bursts. Three-dimensional reconstructions of anatomical projections suggest that inputs of several combinations of thalamocortical projections and intra- and transcolumnar connections, specifically those from infragranular layers, could trigger active dendritic mechanisms that generate AP bursts. Finally, recordings from target cells of a column reveal the importance of AP bursts for signal transfer to these cells. The observations lead to the hypothesis that in vS1 cortex, the sensory afferent sensory code is transformed, at least in part, from a rate to an interval (burst) code that broadcasts the occurrence of whisker touch to different targets of L5tt cells. In addition, the occurrence of pre- and postsynaptic AP bursts may, in the long run, alter touch representation in cortex.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8MXXSETA\Sakmann - 2017 - From single cells and single columns to cortical n.pdf}
}

@article{salinasCorrelatedNeuronalActivity2001,
  title = {✅  {{Correlated}} Neuronal Activity and the Flow of Neural Information},
  author = {Salinas, Emilio and Sejnowski, Terrence J.},
  date = {2001-08},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {2},
  number = {8},
  pages = {539--550},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/35086012},
  url = {https://www.nature.com/articles/35086012},
  urldate = {2023-03-22},
  abstract = {For years we have known that cortical neurons collectively have synchronous or oscillatory patterns of activity, the frequencies and temporal dynamics of which are associated with distinct behavioural states. Although the function of these oscillations has remained obscure, recent experimental and theoretical results indicate that correlated fluctuations might be important for cortical processes, such as attention, that control the flow of information in the brain.},
  issue = {8},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SAKE38AG\Salinas and Sejnowski - 2001 - Correlated neuronal activity and the flow of neura.pdf}
}

@article{santelloAstrocyteFunctionInformation2019,
  title = {Astrocyte Function from Information Processing to Cognition and Cognitive Impairment},
  author = {Santello, Mirko and Toni, Nicolas and Volterra, Andrea},
  date = {2019-02},
  journaltitle = {Nature Neuroscience},
  volume = {22},
  number = {2},
  pages = {154--166},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-018-0325-8},
  url = {https://www.nature.com/articles/s41593-018-0325-8},
  urldate = {2020-11-21},
  abstract = {Astrocytes serve important roles that affect recruitment and function of neurons at the local and network levels. Here we review the contributions of astrocyte signaling to synaptic plasticity, neuronal network oscillations, and memory function. The roles played by astrocytes are not fully understood, but astrocytes seem to contribute to memory consolidation and seem to mediate the effects of vigilance and arousal on memory performance. Understanding the role of astrocytes in cognitive processes may also advance our understanding of how these processes go awry in pathological conditions. Indeed, abnormal astrocytic signaling can cause or contribute to synaptic and network imbalances, leading to cognitive impairment. We discuss evidence for this from animal models of Alzheimer’s disease and multiple sclerosis and from animal studies of sleep deprivation and drug abuse and addiction. Understanding the emerging roles of astrocytes in cognitive function and dysfunction will open up a large array of new therapeutic opportunities.},
  issue = {2},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CK2ZG4NV\\Santello et al. - 2019 - Astrocyte function from information processing to .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\24AM7V7M\\s41593-018-0325-8.html}
}

@article{santosTopologicalPhaseTransitions2019,
  title = {Topological Phase Transitions in Functional Brain Networks},
  author = {Santos, Fernando A. N. and Raposo, Ernesto P. and Coutinho-Filho, Maurício D. and Copelli, Mauro and Stam, Cornelis J. and Douw, Linda},
  date = {2019-09-30},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {100},
  number = {3},
  pages = {032414},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.100.032414},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.100.032414},
  urldate = {2022-10-02},
  abstract = {Functional brain networks are often constructed by quantifying correlations between time series of activity of brain regions. Their topological structure includes nodes, edges, triangles, and even higher-dimensional objects. Topological data analysis (TDA) is the emerging framework to process data sets under this perspective. In parallel, topology has proven essential for understanding fundamental questions in physics. Here we report the discovery of topological phase transitions in functional brain networks by merging concepts from TDA, topology, geometry, physics, and network theory. We show that topological phase transitions occur when the Euler entropy has a singularity, which remarkably coincides with the emergence of multidimensional topological holes in the brain network. The geometric nature of the transitions can be interpreted, under certain hypotheses, as an extension of percolation to high-dimensional objects. Due to the universal character of phase transitions and noise robustness of TDA, our findings open perspectives toward establishing reliable topological and geometrical markers for group and possibly individual differences in functional brain network organization.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ACHSARAE\Santos et al. - 2019 - Topological phase transitions in functional brain .pdf}
}

@article{sassiCoupledNonlinearOscillators,
  title = {Coupled {{Nonlinear Oscillators}}},
  author = {Sassi, Roberto},
  pages = {26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UUSGGFIA\Sassi - Coupled Nonlinear Oscillators.pdf}
}

@article{saxenaNeuralPopulationDoctrine2019,
  title = {✅  {{Towards}} the Neural Population Doctrine},
  author = {Saxena, Shreya and Cunningham, John P},
  date = {2019-04-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Machine {{Learning}}, {{Big Data}}, and {{Neuroscience}}},
  volume = {55},
  pages = {103--111},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2019.02.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438818300990},
  urldate = {2023-03-31},
  abstract = {Across neuroscience, large-scale data recording and population-level analysis methods have experienced explosive growth. While the underlying hardware and computational techniques have been well reviewed, we focus here on the novel science that these technologies have enabled. We detail four areas of the field where the joint analysis of neural populations has significantly furthered our understanding of computation in the brain: correlated variability, decoding, neural dynamics, and artificial neural networks. Together, these findings suggest an exciting trend towards a new era where neural populations are understood to be the essential unit of computation in many brain regions, a classic idea that has been given new life.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\5CHDMCC2\\Saxena and Cunningham - 2019 - Towards the neural population doctrine.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9LAM5RG4\\S0959438818300990.html}
}

@article{schmidt-hieberActiveDendriticIntegration2017,
  title = {Active Dendritic Integration as a Mechanism for Robust and Precise Grid Cell Firing},
  author = {Schmidt-Hieber, Christoph and Toleikyte, Gabija and Aitchison, Laurence and Roth, Arnd and Clark, Beverley A. and Branco, Tiago and Häusser, Michael},
  date = {2017-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {20},
  number = {8},
  pages = {1114--1121},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4582},
  url = {https://www.nature.com/articles/nn.4582},
  urldate = {2022-09-30},
  abstract = {Combining electrophysiology and computational modeling, the authors show that the dendrites of entorhinal cortex stellate and pyramidal cells are electrically excitable and that this improves the robustness of grid cell firing. The results suggest that active dendrites are critical for spatial navigation, a fundamental computation in the brain.},
  issue = {8},
  langid = {english},
  keywords = {Biophysical models,Dendritic excitability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RG368HBJ\\Schmidt-Hieber et al. - 2017 - Active dendritic integration as a mechanism for ro.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RIQHMAL8\\nn.html}
}

@article{schmutzMesoscopicPopulationEquations2020,
  title = {Mesoscopic Population Equations for Spiking Neural Networks with Synaptic Short-Term Plasticity},
  author = {Schmutz, Valentin and Gerstner, Wulfram and Schwalger, Tilo},
  date = {2020-04-06},
  journaltitle = {The Journal of Mathematical Neuroscience},
  shortjournal = {The Journal of Mathematical Neuroscience},
  volume = {10},
  number = {1},
  pages = {5},
  issn = {2190-8567},
  doi = {10.1186/s13408-020-00082-z},
  url = {https://doi.org/10.1186/s13408-020-00082-z},
  urldate = {2020-11-16},
  abstract = {Coarse-graining microscopic models of biological neural networks to obtain mesoscopic models of neural activities is an essential step towards multi-scale models of the brain. Here, we extend a recent theory for mesoscopic population dynamics with static synapses to the case of dynamic synapses exhibiting short-term plasticity (STP). The extended theory offers an approximate mean-field dynamics for the synaptic input currents arising from populations of spiking neurons and synapses undergoing Tsodyks–Markram STP. The approximate mean-field dynamics accounts for both finite number of synapses and correlation between the two synaptic variables of the model (utilization and available resources) and its numerical implementation is simple. Comparisons with Monte Carlo simulations of the microscopic model show that in both feedforward and recurrent networks, the mesoscopic mean-field model accurately reproduces the first- and second-order statistics of the total synaptic input into a postsynaptic neuron and accounts for stochastic switches between Up and Down states and for population spikes. The extended mesoscopic population theory of spiking neural networks with STP may be useful for a systematic reduction of detailed biophysical models of cortical microcircuits to numerically efficient and mathematically tractable mean-field models.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IPLSBJ3D\\Schmutz et al. - 2020 - Mesoscopic population equations for spiking neural.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\A9YIWBE5\\s13408-020-00082-z.html}
}

@article{schneiderNeuromodulationReducesInterindividual2022,
  title = {Neuromodulation {{Reduces Interindividual Variability}} of {{Neuronal Output}}},
  author = {Schneider, Anna C. and Itani, Omar and Bucher, Dirk and Nadim, Farzan},
  date = {2022-07-01},
  journaltitle = {eNeuro},
  shortjournal = {eNeuro},
  volume = {9},
  number = {4},
  eprint = {35853725},
  eprinttype = {pmid},
  publisher = {Society for Neuroscience},
  issn = {2373-2822},
  doi = {10.1523/ENEURO.0166-22.2022},
  url = {https://www.eneuro.org/content/9/4/ENEURO.0166-22.2022},
  urldate = {2022-10-17},
  abstract = {Visual Abstract {$<$}img class="highwire-fragment fragment-image" alt="Figure" src="https://www.eneuro.org/content/eneuro/9/4/ENEURO.0166-22.2022/F1.medium.gif" width="440" height="240"/{$>$}Download figureOpen in new tabDownload powerpoint In similar states, neural circuits produce similar outputs across individuals despite substantial interindividual variability in neuronal ionic conductances and synapses. Circuit states are largely shaped by neuromodulators that tune ionic conductances. It is therefore possible that, in addition to producing flexible circuit output, neuromodulators also contribute to output similarity despite varying ion channel expression. We studied whether neuromodulation at saturating concentrations can increase the output similarity of a single identified neuron across individual animals. Using the lateral pyloric (LP) neuron of the crab stomatogastric ganglion, we compared the variability of f–I (frequency–current) curves and rebound properties in the presence of neuropeptides. The two neuropeptides we used converge to activate the same target current, which increases neuronal excitability. Output variability was lower in the presence of the neuropeptides, regardless of whether the neuropeptides significantly changed the mean of the corresponding parameter or not. However, the addition of the second neuropeptide did not add further to the reduction of variability. With a family of computational LP-like models, we explored how increased excitability and target variability contribute to output similarity and found two mechanisms: saturation of the responses and a differential increase in baseline activity. Saturation alone can reduce the interindividual variability only if the population shares a similar ceiling for the responses. In contrast, the reduction of variability due to the increase in baseline activity is independent of ceiling effects.},
  langid = {english},
  keywords = {bursting neuron,central pattern generator,stomatogastric,variability},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\MGPDJMNT\\Schneider et al. - 2022 - Neuromodulation Reduces Interindividual Variabilit.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JMWIEHBY\\ENEURO.0166-22.html}
}

@article{schneidmanNetworkInformationConnected2003,
  title = {Network {{Information}} and {{Connected Correlations}}},
  author = {Schneidman, Elad and Still, Susanne and Berry, Michael J. and Bialek, William},
  date = {2003-12-02},
  journaltitle = {Physical Review Letters},
  shortjournal = {Phys. Rev. Lett.},
  volume = {91},
  number = {23},
  pages = {238701},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.91.238701},
  url = {https://link.aps.org/doi/10.1103/PhysRevLett.91.238701},
  urldate = {2022-10-05},
  abstract = {Entropy and information provide natural measures of correlation among elements in a network. We construct here the information theoretic analog of connected correlation functions: irreducible N-point correlation is measured by a decrease in entropy for the joint distribution of N variables relative to the maximum entropy allowed by all the observed N−1 variable distributions. We calculate the “connected information” terms for several examples and show that it also enables the decomposition of the information that is carried by a population of elements about an outside source.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z3KXXWQN\\Schneidman et al. - 2003 - Network Information and Connected Correlations.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IADYYTXC\\PhysRevLett.91.html}
}

@article{schneidmanNetworkInformationConnected2003a,
  title = {Network {{Information}} and {{Connected Correlations}}},
  author = {Schneidman, Elad and Still, Susanne and Ii, Michael J Berry and Bialek, William},
  date = {2003},
  journaltitle = {PHYSICAL REVIEW LETTERS},
  volume = {91},
  number = {23},
  pages = {4},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\B62KWLW3\Schneidman et al. - 2003 - Network Information and Connected Correlations.pdf}
}

@article{semedoCorticalAreasInteract2019,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-23},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FFK9FGES\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CZGNQX33\\S0896627319300534.html}
}

@article{semedoCorticalAreasInteract2019a,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-23},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\A64QE4P7\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf}
}

@article{semedoCorticalAreasInteract2019b,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2022-09-25},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  langid = {english},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CA44E9F7\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZVB4WYEX\\S0896627319300534.html}
}

@article{semedoCorticalAreasInteract2019c,
  title = {Cortical {{Areas Interact}} through a {{Communication Subspace}}},
  author = {Semedo, João D. and Zandvakili, Amin and Machens, Christian K. and Yu, Byron M. and Kohn, Adam},
  date = {2019-04-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {102},
  number = {1},
  pages = {249-259.e4},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2019.01.026},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627319300534},
  urldate = {2024-07-15},
  abstract = {Most brain functions involve interactions among multiple, distinct areas or nuclei. For instance, visual processing in primates requires the appropriate relaying of signals across many distinct cortical areas. Yet our understanding of how populations of neurons in interconnected brain areas communicate is in its infancy. Here we investigate how trial-to-trial fluctuations of population responses in primary visual cortex (V1) are related to simultaneously recorded population responses in area V2. Using dimensionality reduction methods, we find that V1-V2 interactions occur through a communication subspace: V2 fluctuations are related to a small subset of V1 population activity patterns, distinct from the largest fluctuations shared among neurons within V1. In~contrast, interactions between subpopulations within V1 are less selective. We propose that the communication subspace may be a general, population-level mechanism by which activity can be selectively routed across brain areas.},
  keywords = {area V2,corticocortical,dimensionality reduction,inter-areal communication,macaque,neural population,neural variability,primary visual cortex,vision,visual cortex},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TDILMVVN\\Semedo et al. - 2019 - Cortical Areas Interact through a Communication Su.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E8PX4AT5\\S0896627319300534.html}
}

@article{semedoFeedforwardFeedbackInteractions2022,
  title = {Feedforward and Feedback Interactions between Visual Cortical Areas Use Different Population Activity Patterns},
  author = {Semedo, João D. and Jasper, Anna I. and Zandvakili, Amin and Krishna, Aravind and Aschner, Amir and Machens, Christian K. and Kohn, Adam and Yu, Byron M.},
  date = {2022-03-01},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {1099},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-28552-w},
  url = {https://www.nature.com/articles/s41467-022-28552-w},
  urldate = {2022-09-23},
  abstract = {Brain function relies on the coordination of activity across multiple, recurrently connected brain areas. For instance, sensory information encoded in early sensory areas is relayed to, and further processed by, higher cortical areas and then fed back. However, the way in which feedforward and feedback signaling interact with one another is incompletely understood. Here we investigate this question by leveraging simultaneous neuronal population recordings in early and midlevel visual areas (V1–V2 and V1–V4). Using a dimensionality reduction approach, we find that population interactions are feedforward-dominated shortly after stimulus onset and feedback-dominated during spontaneous activity. The population activity patterns most correlated across areas were distinct during feedforward- and feedback-dominated periods. These results suggest that feedforward and feedback signaling rely on separate “channels”, which allows feedback signals to not directly affect activity that is fed forward.},
  issue = {1},
  langid = {english},
  keywords = {Computational neuroscience,Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DTE3TDXI\\Semedo et al. - 2022 - Feedforward and feedback interactions between visu.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BIPSZ6TL\\s41467-022-28552-w.html}
}

@article{seriesTuningCurveSharpening2004,
  title = {Tuning Curve Sharpening for Orientation Selectivity: Coding Efficiency and the Impact of Correlations},
  shorttitle = {Tuning Curve Sharpening for Orientation Selectivity},
  author = {Seriès, Peggy and Latham, Peter E. and Pouget, Alexandre},
  date = {2004-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {7},
  number = {10},
  pages = {1129--1135},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn1321},
  url = {https://www.nature.com/articles/nn1321},
  urldate = {2023-04-05},
  abstract = {Several studies have shown that the information conveyed by bell-shaped tuning curves increases as their width decreases, leading to the notion that sharpening of tuning curves improves population codes. This notion, however, is based on assumptions that the noise distribution is independent among neurons and independent of the tuning curve width. Here we reexamine these assumptions in networks of spiking neurons by using orientation selectivity as an example. We compare two principal classes of model: one in which the tuning curves are sharpened through cortical lateral interactions, and one in which they are not. We report that sharpening through lateral interactions does not improve population codes but, on the contrary, leads to a severe loss of information. In addition, the sharpening models generate complicated codes that rely extensively on pairwise correlations. Our study generates several experimental predictions that can be used to distinguish between these two classes of model.},
  issue = {10},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KBUSM2AD\Seriès et al. - 2004 - Tuning curve sharpening for orientation selectivit.pdf}
}

@online{SerotoninNeuronsModulate,
  title = {✅ {{Serotonin}} Neurons Modulate Learning Rate through Uncertainty: {{Current Biology}}},
  url = {https://www.cell.com/current-biology/fulltext/S0960-9822(21)01682-1?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0960982221016821%3Fshowall%3Dtrue},
  urldate = {2023-04-19},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S8LHHHKA\\Serotonin neurons modulate learning rate through u.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYQ2G22S\\1-s2.0-S0960982221016821-mmc1.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CJQZITLE\\S0960-9822(21)01682-1.html}
}

@online{sezenerRapidEfficientLearning2022,
  title = {A Rapid and Efficient Learning Rule for Biological Neural Circuits},
  author = {Sezener, Eren and Grabska-Barwińska, Agnieszka and Kostadinov, Dimitar and Beau, Maxime and Krishnagopal, Sanjukta and Budden, David and Hutter, Marcus and Veness, Joel and Botvinick, Matthew and Clopath, Claudia and Häusser, Michael and Latham, Peter E.},
  date = {2022-08-17},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2021.03.10.434756},
  doi = {10.1101/2021.03.10.434756},
  url = {https://www.biorxiv.org/content/10.1101/2021.03.10.434756v2},
  urldate = {2023-03-22},
  abstract = {The dominant view in neuroscience is that changes in synaptic weights underlie learning. It is unclear, however, how the brain is able to determine which synapses should change, and by how much. This uncertainty stands in sharp contrast to deep learning, where changes in weights are explicitly engineered to optimize performance. However, the main tool for that, backpropagation, has two problems. One is neuro-science related: it is not biologically plausible. The other is inherent: networks trained with this rule tend to forget old tasks when learning new ones. Here we introduce the Dendritic Gated Network (DGN), a variant of the Gated Linear Network, which offers a biologically plausible alternative to backpropagation. DGNs combine dendritic ‘gating’ (whereby interneurons target dendrites to shape neuronal responses) with local learning rules to yield provably efficient performance. They are significantly more data efficient than conventional artificial networks, and are highly resistant to forgetting. Consequently, they perform well on a variety of tasks, in some cases better than backpropagation. Importantly, DGNs have structural and functional similarities to the cerebellum, a link that we strengthen by using in vivo two-photon calcium imaging to show that single interneurons suppress activity in individual dendritic branches of Purkinje cells, a key feature of the model. Thus, DGNs leverage targeted dendritic inhibition and local learning – two features ubiquitous in the brain – to achieve fast and efficient learning.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\797ZK94Q\Sezener et al. - 2022 - A rapid and efficient learning rule for biological.pdf}
}

@article{shahidiHighorderCoordinationCortical2019,
  title = {High-Order Coordination of Cortical Spiking Activity Modulates Perceptual Accuracy},
  author = {Shahidi, Neda and Andrei, Ariana R. and Hu, Ming and Dragoi, Valentin},
  date = {2019-07},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {22},
  number = {7},
  pages = {1148--1158},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0406-3},
  url = {https://www.nature.com/articles/s41593-019-0406-3},
  urldate = {2023-01-03},
  abstract = {The accurate relay of electrical signals within cortical networks is key to perception and cognitive function. Theoretically, it has long been proposed that temporal coordination of neuronal spiking activity controls signal transmission and behavior. However, whether and how temporally precise neuronal coordination in population activity influences perception are unknown. Here, we recorded populations of neurons in early and mid-level visual cortex (areas V1 and V4) simultaneously to discover that the precise temporal coordination between the spiking activity of three or more cells carries information about visual perception in the absence of firing rate modulation. The accuracy of perceptual responses correlated with high-order spiking coordination within V4, but not V1, and with feedforward coordination between V1 and V4. These results indicate that while visual stimuli are encoded in the discharge rates of neurons, perceptual accuracy is related to temporally precise spiking coordination within and between cortical networks.},
  issue = {7},
  langid = {english},
  keywords = {Neural circuits,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RDIJVQ3B\Shahidi et al. - 2019 - High-order coordination of cortical spiking activi.pdf}
}

@article{shenDistinctOrganizationTwo2022,
  title = {Distinct Organization of Two Cortico-Cortical Feedback Pathways},
  author = {Shen, Shan and Jiang, Xiaolong and Scala, Federico and Fu, Jiakun and Fahey, Paul and Kobak, Dmitry and Tan, Zhenghuan and Zhou, Na and Reimer, Jacob and Sinz, Fabian and Tolias, Andreas S.},
  date = {2022-10-27},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {6389},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-33883-9},
  url = {https://www.nature.com/articles/s41467-022-33883-9},
  urldate = {2023-08-01},
  abstract = {Neocortical feedback is critical for attention, prediction, and learning. To mechanically understand its function requires deciphering its cell-type wiring. Recent studies revealed that feedback between primary motor to primary somatosensory areas in mice is disinhibitory, targeting vasoactive intestinal peptide-expressing interneurons, in addition to pyramidal cells. It is unknown whether this circuit motif represents a general cortico-cortical feedback organizing principle. Here we show that in contrast to this wiring rule, feedback between higher-order lateromedial visual area to primary visual cortex preferentially activates somatostatin-expressing interneurons. Functionally, both feedback circuits temporally sharpen feed-forward excitation eliciting a transient increase–followed by a prolonged decrease–in pyramidal cell activity under sustained feed-forward input. However, under feed-forward transient input, the primary motor to primary somatosensory cortex feedback facilitates bursting while lateromedial area to primary visual cortex feedback increases time precision. Our findings argue for multiple cortico-cortical feedback motifs implementing different dynamic non-linear operations.},
  issue = {1},
  langid = {english},
  keywords = {Barrel cortex,Extrastriate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MT2GYQNW\Shen et al. - 2022 - Distinct organization of two cortico-cortical feed.pdf}
}

@article{shermanThalamocorticalInteractions2012,
  title = {✅ {{Thalamocortical}} Interactions},
  author = {Sherman, S Murray},
  date = {2012-08-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Microcircuits},
  volume = {22},
  number = {4},
  pages = {575--579},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2012.03.005},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438812000438},
  urldate = {2023-08-01},
  abstract = {Glutamatergic pathways dominate information processing in the brain, but these are not homogeneous. They include two distinct types: Class 1, which carries the main information for processing, and Class 2, which serves a modulatory role. Identifying the Class 1 inputs in a circuit can lead to a better understanding of its function. Also, identifying Class 1 inputs to a thalamic nucleus tells us its main function (e.g. the lateral geniculate nucleus, or LGN, is the relay of retinal Class 1 input), and such identification leads to a division of thalamic relays into first and higher order: the former receives Class 1 inputs from subcortical sources; the latter, from layer 5 of cortex, which it then relays to another cortical area. When a cortical area directly connects with another, it often has a parallel, transthalamic connection through these higher order relays. This leads to a novel appreciation of cortical functioning and raises many new questions.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WJKRT2P3\\Sherman - 2012 - Thalamocortical interactions.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GIPTFYM2\\S0959438812000438.html}
}

@article{shewAdaptationSensoryInput2015,
  title = {Adaptation to Sensory Input Tunes Visual Cortex to Criticality},
  author = {Shew, Woodrow L. and Clawson, Wesley P. and Pobst, Jeff and Karimipanah, Yahya and Wright, Nathaniel C. and Wessel, Ralf},
  date = {2015-08},
  journaltitle = {Nature Physics},
  shortjournal = {Nature Phys},
  volume = {11},
  number = {8},
  pages = {659--663},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/nphys3370},
  url = {https://www.nature.com/articles/nphys3370},
  urldate = {2022-10-01},
  abstract = {Sensory nervous systems adapt to their environment—a mechanism thought to ensure network dynamics remain critical. Visual cortex experiments show that adaptation maintains criticality even as sensory input drives the system away from this regime.},
  issue = {8},
  langid = {english},
  keywords = {Biological physics},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\XNQK5H2L\\Shew et al. - 2015 - Adaptation to sensory input tunes visual cortex to.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PSRLQPUF\\nphys3370.html}
}

@unpublished{shiComparisonTaskDriven2019,
  title = {Comparison {{Against Task Driven Artificial Neural Networks Reveals Functional Organization}} of {{Mouse Visual Cortex}}},
  author = {Shi, Jianghong and Shea-Brown, Eric and Buice, Michael A.},
  date = {2019-11-18},
  eprint = {1911.07986},
  eprinttype = {arXiv},
  eprintclass = {q-bio},
  url = {http://arxiv.org/abs/1911.07986},
  urldate = {2020-10-08},
  abstract = {Partially inspired by features of computation in visual cortex, deep neural networks compute hierarchical representations of their inputs. While these networks have been highly successful in machine learning, it remains unclear to what extent they can aid our understanding of cortical function. Several groups have developed metrics that provide a quantitative comparison between representations computed by networks and representations measured in cortex. At the same time, neuroscience is well into an unprecedented phase of large-scale data collection, as evidenced by projects such as the Allen Brain Observatory. Despite the magnitude of these efforts, in a given experiment only a fraction of units are recorded, limiting the information available about the cortical representation. Moreover, only a finite number of stimuli can be shown to an animal over the course of a realistic experiment. These limitations raise the question of how and whether metrics that compare representations of deep networks are meaningful on these datasets. Here, we empirically quantify the capabilities and limitations of these metrics due to limited image presentations and neuron samples. We find that the comparison procedure is robust to different choices of stimuli set and the level of subsampling that one might expect in a large-scale brain survey with thousands of neurons. Using these results, we compare the representations measured in the Allen Brain Observatory in response to natural image presentations to deep neural network. We show that the visual cortical areas are relatively high order representations (in that they map to deeper layers of convolutional neural networks). Furthermore, we see evidence of a broad, more parallel organization rather than a sequential hierarchy, with the primary area VISp(V1) being lower order relative to the other areas.},
  keywords = {Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\AKT8V8NC\\Shi et al. - 2019 - Comparison Against Task Driven Artificial Neural N.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WYLHR5I9\\1911.html}
}

@inproceedings{shiComparisonTaskDriven2019a,
  title = {Comparison {{Against Task Driven Artificial Neural Networks Reveals Functional Properties}} in {{Mouse Visual Cortex}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Shi, Jianghong and Shea-Brown, Eric and Buice, Michael},
  date = {2019},
  volume = {32},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/748d6b6ed8e13f857ceaa6cfbdca14b8-Abstract.html},
  urldate = {2024-06-18},
  abstract = {Partially inspired by features of computation in visual cortex, deep neural networks compute hierarchical representations of their inputs.  While these networks have been highly successful in machine learning, it is still unclear to what extent they can aid our understanding of cortical function.  Several groups have developed metrics that provide a quantitative comparison between representations computed by networks and representations measured in cortex.  At the same time, neuroscience is well into an unprecedented phase of large-scale data collection, as evidenced by projects such as the Allen Brain Observatory.  Despite the magnitude of these efforts, in a given experiment only a fraction of units are recorded, limiting the information available about the cortical representation.  Moreover, only a finite number of stimuli can be shown to an animal over the course of a realistic experiment.  These limitations raise the question of how and whether metrics that compare representations of deep networks are meaningful on these data sets.  Here, we empirically quantify the capabilities and limitations of these metrics due to limited image and neuron sample spaces.  We find that the comparison procedure is robust to different choices of stimuli set and the level of sub-sampling that one might expect in a large scale brain survey with thousands of neurons.  Using these results, we compare the representations measured in the Allen Brain Observatory in response to natural image presentations.  We show that the visual cortical areas are relatively high order representations (in that they map to deeper layers of convolutional neural networks).  Furthermore, we see evidence of a broad, more parallel organization rather than a sequential hierarchy, with the primary area VisP (V1) being lower order relative to the other areas.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3ZPAHACZ\Shi et al. - 2019 - Comparison Against Task Driven Artificial Neural N.pdf}
}

@article{shiCorticalStateDynamics2022,
  title = {✅ {{Cortical}} State Dynamics and Selective Attention Define the Spatial Pattern of Correlated Variability in Neocortex},
  author = {Shi, Yan-Liang and Steinmetz, Nicholas A. and Moore, Tirin and Boahen, Kwabena and Engel, Tatiana A.},
  date = {2022-01-10},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  pages = {44},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-27724-4},
  url = {https://www.nature.com/articles/s41467-021-27724-4},
  urldate = {2022-12-28},
  abstract = {Correlated activity fluctuations in the neocortex influence sensory responses and behavior. Neural correlations reflect anatomical connectivity but also change dynamically with cognitive states such as attention. Yet, the network mechanisms defining the population structure of correlations remain unknown. We measured correlations within columns in the visual cortex. We show that the magnitude of correlations, their attentional modulation, and dependence on lateral distance are explained by columnar On-Off dynamics, which are synchronous activity fluctuations reflecting cortical state. We developed a network model in which the On-Off dynamics propagate across nearby columns generating spatial correlations with the extent controlled by attentional inputs. This mechanism, unlike previous proposals, predicts spatially non-uniform changes in correlations during attention. We confirm this prediction in our columnar recordings by showing that in superficial layers the largest changes in correlations occur at intermediate lateral distances. Our results reveal how spatially structured patterns of correlated variability emerge through interactions of cortical state dynamics, anatomical connectivity, and attention.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Network models,Neural circuits,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EUE4TIV8\Shi et al. - 2022 - Cortical state dynamics and selective attention de.pdf}
}

@article{shihImprovedStimulusRepresentation2011,
  title = {Improved Stimulus Representation by Short Interspike Intervals in Primary Auditory Cortex},
  author = {Shih, Jonathan Y. and Atencio, Craig A. and Schreiner, Christoph E.},
  date = {2011-04},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J Neurophysiol},
  volume = {105},
  number = {4},
  eprint = {21307320},
  eprinttype = {pmid},
  pages = {1908--1917},
  issn = {0022-3077},
  doi = {10.1152/jn.01055.2010},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3075280/},
  urldate = {2023-01-16},
  abstract = {We analyzed the receptive field information conveyed by interspike intervals (ISIs) in the auditory cortex. In the visual system, different ISIs may both code for different visual features and convey differing amounts of stimulus information. To determine their potential role in auditory signal processing, we obtained extracellular recordings in the primary auditory cortex (AI) of the cat while presenting a dynamic moving ripple stimulus and then used the responses to construct spectrotemporal receptive fields (STRFs). For each neuron, we constructed three STRFs, one for short-ISI events (ISI {$<$} 15 ms); one for isolated, long-ISI events (ISI {$>$} 15 ms); and one including all events. To characterize stimulus encoding, we calculated the feature selectivity and event information for each of the STRFs. Short-ISI spikes were more feature selective and conveyed information more efficiently. The different ISI regimens of AI neurons did not represent different stimulus features, but short-ISI spike events did contribute over-proportionately to the full spike train STRF information. Thus short-ISIs constitute a robust representation of auditory features, and they are particularly effective at driving postsynaptic activity. This suggests that short-ISI events are especially suited to provide noise immunity and high-fidelity information transmission in AI.},
  pmcid = {PMC3075280}
}

@online{shiSpatialTemporalCorrelations2022,
  title = {Spatial and Temporal Correlations in Neural Networks with Structured Connectivity},
  author = {Shi, Yan-Liang and Zeraati, Roxana and Levina, Anna and Engel, Tatiana A.},
  date = {2022-07-16},
  eprint = {2207.07930},
  eprinttype = {arXiv},
  eprintclass = {cond-mat, q-bio},
  doi = {10.48550/arXiv.2207.07930},
  url = {http://arxiv.org/abs/2207.07930},
  urldate = {2023-01-03},
  abstract = {Correlated fluctuations in the activity of neural populations reflect the network's dynamics and connectivity. The temporal and spatial dimensions of neural correlations are interdependent. However, prior theoretical work mainly analyzed correlations in either spatial or temporal domains, oblivious to their interplay. We show that the network dynamics and connectivity jointly define the spatiotemporal profile of neural correlations. We derive analytical expressions for pairwise correlations in networks of binary units with spatially arranged connectivity in one and two dimensions. We find that spatial interactions among units generate multiple timescales in auto- and cross-correlations. Each timescale is associated with fluctuations at a particular spatial frequency, making a hierarchical contribution to the correlations. External inputs can modulate the correlation timescales when spatial interactions are nonlinear, and the modulation effect depends on the operating regime of network dynamics. These theoretical results open new ways to relate connectivity and dynamics in cortical networks via measurements of spatiotemporal neural correlations.},
  pubstate = {prepublished},
  keywords = {Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Statistical Mechanics,Quantitative Biology - Neurons and Cognition},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8PEHBVBW\\Shi et al. - 2022 - Spatial and temporal correlations in neural networ.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IV7NGPYR\\2207.html}
}

@article{siegleReconcilingFunctionalDifferences2021,
  title = {Reconciling Functional Differences in Populations of Neurons Recorded with Two-Photon Imaging and Electrophysiology},
  author = {Siegle, Joshua H and Ledochowitsch, Peter and Jia, Xiaoxuan and Millman, Daniel J and Ocker, Gabriel K and Caldejon, Shiella and Casal, Linzy and Cho, Andy and Denman, Daniel J and Durand, Séverine and Groblewski, Peter A and Heller, Gregg and Kato, India and Kivikas, Sara and Lecoq, Jérôme and Nayan, Chelsea and Ngo, Kiet and Nicovich, Philip R and North, Kat and Ramirez, Tamina K and Swapp, Jackie and Waughman, Xana and Williford, Ali and Olsen, Shawn R and Koch, Christof and Buice, Michael A and de Vries, Saskia EJ},
  editor = {Calabrese, Ronald L and Pachitariu, Marius},
  options = {useprefix=true},
  date = {2021-07-16},
  journaltitle = {eLife},
  volume = {10},
  pages = {e69068},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.69068},
  url = {https://doi.org/10.7554/eLife.69068},
  urldate = {2024-06-17},
  abstract = {Extracellular electrophysiology and two-photon calcium imaging are widely used methods for measuring physiological activity with single-cell resolution across large populations of cortical neurons. While each of these two modalities has distinct advantages and disadvantages, neither provides complete, unbiased information about the underlying neural population. Here, we compare evoked responses in visual cortex recorded in awake mice under highly standardized conditions using either imaging of genetically expressed GCaMP6f or electrophysiology with silicon probes. Across all stimulus conditions tested, we observe a larger fraction of responsive neurons in electrophysiology and higher stimulus selectivity in calcium imaging, which was partially reconciled by applying a spikes-to-calcium forward model to the electrophysiology data. However, the forward model could only reconcile differences in responsiveness when restricted to neurons with low contamination and an event rate above a minimum threshold. This work established how the biases of these two modalities impact functional metrics that are fundamental for characterizing sensory-evoked responses.},
  keywords = {calcium imaging,extracellular electrophysiology,in vivo physiology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QPD9JHET\Siegle et al. - 2021 - Reconciling functional differences in populations .pdf}
}

@article{siegleSurveySpikingMouse2021,
  title = {Survey of Spiking in the Mouse Visual System Reveals Functional Hierarchy},
  author = {Siegle, Joshua H. and Jia, Xiaoxuan and Durand, Séverine and Gale, Sam and Bennett, Corbett and Graddis, Nile and Heller, Greggory and Ramirez, Tamina K. and Choi, Hannah and Luviano, Jennifer A. and Groblewski, Peter A. and Ahmed, Ruweida and Arkhipov, Anton and Bernard, Amy and Billeh, Yazan N. and Brown, Dillan and Buice, Michael A. and Cain, Nicolas and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Chvilicek, Maggie and Cox, Timothy C. and Dai, Kael and Denman, Daniel J. and de Vries, Saskia E. J. and Dietzman, Roald and Esposito, Luke and Farrell, Colin and Feng, David and Galbraith, John and Garrett, Marina and Gelfand, Emily C. and Hancock, Nicole and Harris, Julie A. and Howard, Robert and Hu, Brian and Hytnen, Ross and Iyer, Ramakrishnan and Jessett, Erika and Johnson, Katelyn and Kato, India and Kiggins, Justin and Lambert, Sophie and Lecoq, Jerome and Ledochowitsch, Peter and Lee, Jung Hoon and Leon, Arielle and Li, Yang and Liang, Elizabeth and Long, Fuhui and Mace, Kyla and Melchior, Jose and Millman, Daniel and Mollenkopf, Tyler and Nayan, Chelsea and Ng, Lydia and Ngo, Kiet and Nguyen, Thuyahn and Nicovich, Philip R. and North, Kat and Ocker, Gabriel Koch and Ollerenshaw, Doug and Oliver, Michael and Pachitariu, Marius and Perkins, Jed and Reding, Melissa and Reid, David and Robertson, Miranda and Ronellenfitch, Kara and Seid, Sam and Slaughterbeck, Cliff and Stoecklin, Michelle and Sullivan, David and Sutton, Ben and Swapp, Jackie and Thompson, Carol and Turner, Kristen and Wakeman, Wayne and Whitesell, Jennifer D. and Williams, Derric and Williford, Ali and Young, Rob and Zeng, Hongkui and Naylor, Sarah and Phillips, John W. and Reid, R. Clay and Mihalas, Stefan and Olsen, Shawn R. and Koch, Christof},
  options = {useprefix=true},
  date = {2021-04},
  journaltitle = {Nature},
  volume = {592},
  number = {7852},
  pages = {86--92},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-03171-x},
  url = {https://www.nature.com/articles/s41586-020-03171-x},
  urldate = {2024-02-22},
  abstract = {The anatomy of the mammalian visual system, from the retina to the neocortex, is organized hierarchically1. However, direct observation of cellular-level functional interactions across this hierarchy is lacking due to the challenge of simultaneously recording activity across numerous regions. Here we describe a large, open dataset—part of the Allen Brain Observatory2—that surveys spiking from tens of thousands of units in six cortical and two thalamic regions in the brains of mice responding to a battery of visual stimuli. Using cross-correlation analysis, we reveal that the organization of inter-area functional connectivity during visual stimulation mirrors the anatomical hierarchy from the Allen Mouse Brain Connectivity Atlas3. We find that four classical hierarchical measures—response latency, receptive-field size, phase-locking to drifting gratings and response decay timescale—are all correlated with the hierarchy. Moreover, recordings obtained during a visual task reveal that the correlation between neural activity and behavioural choice also increases along the hierarchy. Our study provides a foundation for understanding coding and signal propagation across hierarchically organized cortical and thalamic visual areas.},
  issue = {7852},
  langid = {english},
  keywords = {Neural circuits,Sensory processing,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HMFFME6B\Siegle et al. - 2021 - Survey of spiking in the mouse visual system revea.pdf}
}

@article{siegleSurveySpikingMouse2021a,
  title = {✅  {{Survey}} of Spiking in the Mouse Visual System Reveals Functional Hierarchy},
  author = {Siegle, Joshua H. and Jia, Xiaoxuan and Durand, Séverine and Gale, Sam and Bennett, Corbett and Graddis, Nile and Heller, Greggory and Ramirez, Tamina K. and Choi, Hannah and Luviano, Jennifer A. and Groblewski, Peter A. and Ahmed, Ruweida and Arkhipov, Anton and Bernard, Amy and Billeh, Yazan N. and Brown, Dillan and Buice, Michael A. and Cain, Nicolas and Caldejon, Shiella and Casal, Linzy and Cho, Andrew and Chvilicek, Maggie and Cox, Timothy C. and Dai, Kael and Denman, Daniel J. and de Vries, Saskia E. J. and Dietzman, Roald and Esposito, Luke and Farrell, Colin and Feng, David and Galbraith, John and Garrett, Marina and Gelfand, Emily C. and Hancock, Nicole and Harris, Julie A. and Howard, Robert and Hu, Brian and Hytnen, Ross and Iyer, Ramakrishnan and Jessett, Erika and Johnson, Katelyn and Kato, India and Kiggins, Justin and Lambert, Sophie and Lecoq, Jerome and Ledochowitsch, Peter and Lee, Jung Hoon and Leon, Arielle and Li, Yang and Liang, Elizabeth and Long, Fuhui and Mace, Kyla and Melchior, Jose and Millman, Daniel and Mollenkopf, Tyler and Nayan, Chelsea and Ng, Lydia and Ngo, Kiet and Nguyen, Thuyahn and Nicovich, Philip R. and North, Kat and Ocker, Gabriel Koch and Ollerenshaw, Doug and Oliver, Michael and Pachitariu, Marius and Perkins, Jed and Reding, Melissa and Reid, David and Robertson, Miranda and Ronellenfitch, Kara and Seid, Sam and Slaughterbeck, Cliff and Stoecklin, Michelle and Sullivan, David and Sutton, Ben and Swapp, Jackie and Thompson, Carol and Turner, Kristen and Wakeman, Wayne and Whitesell, Jennifer D. and Williams, Derric and Williford, Ali and Young, Rob and Zeng, Hongkui and Naylor, Sarah and Phillips, John W. and Reid, R. Clay and Mihalas, Stefan and Olsen, Shawn R. and Koch, Christof},
  options = {useprefix=true},
  date = {2021-04},
  journaltitle = {Nature},
  volume = {592},
  number = {7852},
  pages = {86--92},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-03171-x},
  url = {https://www.nature.com/articles/s41586-020-03171-x},
  urldate = {2024-07-08},
  abstract = {The anatomy of the mammalian visual system, from the retina to the neocortex, is organized hierarchically1. However, direct observation of cellular-level functional interactions across this hierarchy is lacking due to the challenge of simultaneously recording activity across numerous regions. Here we describe a large, open dataset—part of the Allen Brain Observatory2—that surveys spiking from tens of thousands of units in six cortical and two thalamic regions in the brains of mice responding to a battery of visual stimuli. Using cross-correlation analysis, we reveal that the organization of inter-area functional connectivity during visual stimulation mirrors the anatomical hierarchy from the Allen Mouse Brain Connectivity Atlas3. We find that four classical hierarchical measures—response latency, receptive-field size, phase-locking to drifting gratings and response decay timescale—are all correlated with the hierarchy. Moreover, recordings obtained during a visual task reveal that the correlation between neural activity and behavioural choice also increases along the hierarchy. Our study provides a foundation for understanding coding and signal propagation across hierarchically organized cortical and thalamic visual areas.},
  langid = {english},
  keywords = {Neural circuits,Sensory processing,Visual system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J737DTSB\Siegle et al. - 2021 - Survey of spiking in the mouse visual system revea.pdf}
}

@article{sinhaActiveDendritesLocal2022,
  title = {Active {{Dendrites}} and {{Local Field Potentials}}: {{Biophysical Mechanisms}} and {{Computational Explorations}}},
  shorttitle = {Active {{Dendrites}} and {{Local Field Potentials}}},
  author = {Sinha, Manisha and Narayanan, Rishikesh},
  date = {2022-05-01},
  journaltitle = {Neuroscience},
  shortjournal = {Neuroscience},
  series = {Dendritic Contributions to Biological and Artificial Computations},
  volume = {489},
  pages = {111--142},
  issn = {0306-4522},
  doi = {10.1016/j.neuroscience.2021.08.035},
  url = {https://www.sciencedirect.com/science/article/pii/S0306452221004504},
  urldate = {2022-09-02},
  abstract = {Neurons and glial cells are endowed with membranes that express a rich repertoire of ion channels, transporters, and receptors. The constant flux of ions across the neuronal and glial membranes results in voltage fluctuations that can be recorded from the extracellular matrix. The high frequency components of this voltage signal contain information about the spiking activity, reflecting the output from the neurons surrounding the recording location. The low frequency components of the signal, referred to as the local field potential (LFP), have been traditionally thought to provide information about the synaptic inputs that impinge on the large dendritic trees of various neurons. In this review, we discuss recent computational and experimental studies pointing to a critical role of several active dendritic mechanisms that can influence the genesis and the location-dependent spectro-temporal dynamics of LFPs, spanning different brain regions. We strongly emphasize the need to account for the several fast and slow dendritic events and associated active mechanisms — including gradients in their expression profiles, inter- and intra-cellular spatio-temporal interactions spanning neurons and glia, heterogeneities and degeneracy across scales, neuromodulatory influences, and activitydependent plasticity — towards gaining important insights about the origins of LFP under different behavioral states in health and disease. We provide simple but essential guidelines on how to model LFPs taking into account these dendritic mechanisms, with detailed methodology on how to account for various heterogeneities and electrophysiological properties of neurons and synapses while studying LFPs.},
  langid = {english},
  keywords = {computational models,degeneracy,heterogeneity,ion channels,neural plasticity,oscillations},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\CH26RKTL\Sinha and Narayanan - 2022 - Active Dendrites and Local Field Potentials Bioph.pdf}
}

@article{smithDendriticSpikesEnhance2013,
  title = {Dendritic Spikes Enhance Stimulus Selectivity in Cortical Neurons in Vivo},
  author = {Smith, Spencer L. and Smith, Ikuko T. and Branco, Tiago and Häusser, Michael},
  date = {2013-11},
  journaltitle = {Nature},
  volume = {503},
  number = {7474},
  pages = {115--120},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature12600},
  url = {https://www.nature.com/articles/nature12600},
  urldate = {2022-09-30},
  abstract = {Neuronal dendrites are not passive cables, but whether their excitability contributes to computation at the cell’s soma has been uncertain; by observing and interfering with dendritic ‘spikes’ during sensory stimulation, it is now shown that active dendritic processing enhances somatic orientation selectivity, a fundamental brain computation.},
  issue = {7474},
  langid = {english},
  keywords = {Visual system},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T2NMJFT4\\Smith et al. - 2013 - Dendritic spikes enhance stimulus selectivity in c.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9IG5YU32\\nature12600.html}
}

@article{smithRecentAdvancesApplication2021,
  title = {Recent Advances in the Application of Predictive Coding and Active Inference Models within Clinical Neuroscience},
  author = {Smith, Ryan and Badcock, Paul and Friston, Karl J.},
  date = {2021},
  journaltitle = {Psychiatry and Clinical Neurosciences},
  volume = {75},
  number = {1},
  pages = {3--13},
  issn = {1440-1819},
  doi = {10.1111/pcn.13138},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/pcn.13138},
  urldate = {2023-03-30},
  abstract = {Research in clinical neuroscience is founded on the idea that a better understanding of brain (dys)function will improve our ability to diagnose and treat neurological and psychiatric disorders. In recent years, neuroscience has converged on the notion that the brain is a ‘prediction machine,’ in that it actively predicts the sensory input that it will receive if one or another course of action is chosen. These predictions are used to select actions that will (most often, and in the long run) maintain the body within the narrow range of physiological states consistent with survival. This insight has given rise to an area of clinical computational neuroscience research that focuses on characterizing neural circuit architectures that can accomplish these predictive functions, and on how the associated processes may break down or become aberrant within clinical conditions. Here, we provide a brief review of examples of recent work on the application of predictive processing models of brain function to study clinical (psychiatric) disorders, with the aim of highlighting current directions and their potential clinical utility. We offer examples of recent conceptual models, formal mathematical models, and applications of such models in empirical research in clinical populations, with a focus on making this material accessible to clinicians without expertise in computational neuroscience. In doing so, we aim to highlight the potential insights and opportunities that understanding the brain as a prediction machine may offer to clinical research and practice.},
  langid = {english},
  keywords = {active inference,computational neuroscience,computational psychiatry,emotion,predictive coding},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8AT4AV54\\Smith et al. - 2021 - Recent advances in the application of predictive c.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NXJR2IE3\\pcn.html}
}

@article{smithSpatialTemporalScales2008,
  title = {Spatial and {{Temporal Scales}} of {{Neuronal Correlation}} in {{Primary Visual Cortex}}},
  author = {Smith, Matthew A. and Kohn, Adam},
  date = {2008-11-26},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {28},
  number = {48},
  eprint = {19036953},
  eprinttype = {pmid},
  pages = {12591--12603},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2929-08.2008},
  url = {https://www.jneurosci.org/content/28/48/12591},
  urldate = {2023-01-06},
  abstract = {The spiking activity of cortical neurons is correlated. For instance, trial-to-trial fluctuations in response strength are shared between neurons, and spikes often occur synchronously. Understanding the properties and mechanisms that generate these forms of correlation is critical for determining their role in cortical processing. We therefore investigated the spatial extent and functional specificity of correlated spontaneous and evoked activity. Because feedforward, recurrent, and feedback pathways have distinct extents and specificity, we reasoned that these measurements could elucidate the contribution of each type of input. We recorded single unit activity with microelectrode arrays which allowed us to measure correlation in many hundreds of pairings, across a large range of spatial scales. Our data show that correlated evoked activity is generated by two mechanisms that link neurons with similar orientation preferences on different spatial scales: one with high temporal precision and a limited spatial extent (∼3 mm), and a second that gives rise to correlation on a slow time scale and extends as far as we were able to measure (10 mm). The former is consistent with common input provided by horizontal connections; the latter likely involves feedback from extrastriate cortex. Spontaneous activity was correlated over a similar spatial extent, but approximately twice as strongly as evoked activity. Visual stimuli thus caused a substantial decrease in correlation, particularly at response onset. These properties and the circuit mechanism they imply provide new constraints on the functional role that correlation may play in visual processing.},
  langid = {english},
  keywords = {array,cross-correlogram,multielectrode recordings,noise correlation,population coding,signal correlation,spontaneous activity,synchrony},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\P38MLYFV\Smith and Kohn - 2008 - Spatial and Temporal Scales of Neuronal Correlatio.pdf}
}

@article{smoutAttentionPromotesNeural2019,
  title = {Attention Promotes the Neural Encoding of Prediction Errors},
  author = {Smout, Cooper A. and Tang, Matthew F. and Garrido, Marta I. and Mattingley, Jason B.},
  date = {2019-02-27},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {17},
  number = {2},
  pages = {e2006812},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.2006812},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006812},
  urldate = {2023-03-30},
  abstract = {The encoding of sensory information in the human brain is thought to be optimised by two principal processes: ‘prediction’ uses stored information to guide the interpretation of forthcoming sensory events, and ‘attention’ prioritizes these events according to their behavioural relevance. Despite the ubiquitous contributions of attention and prediction to various aspects of perception and cognition, it remains unknown how they interact to modulate information processing in the brain. A recent extension of predictive coding theory suggests that attention optimises the expected precision of predictions by modulating the synaptic gain of prediction error units. Because prediction errors code for the difference between predictions and sensory signals, this model would suggest that attention increases the selectivity for mismatch information in the neural response to a surprising stimulus. Alternative predictive coding models propose that attention increases the activity of prediction (or ‘representation’) neurons and would therefore suggest that attention and prediction synergistically modulate selectivity for ‘feature information’ in the brain. Here, we applied forward encoding models to neural activity recorded via electroencephalography (EEG) as human observers performed a simple visual task to test for the effect of attention on both mismatch and feature information in the neural response to surprising stimuli. Participants attended or ignored a periodic stream of gratings, the orientations of which could be either predictable, surprising, or unpredictable. We found that surprising stimuli evoked neural responses that were encoded according to the difference between predicted and observed stimulus features, and that attention facilitated the encoding of this type of information in the brain. These findings advance our understanding of how attention and prediction modulate information processing in the brain, as well as support the theory that attention optimises precision expectations during hierarchical inference by increasing the gain of prediction errors.},
  langid = {english},
  keywords = {Attention,Coding mechanisms,Electroencephalography,Event-related potentials,Forecasting,Permutation,Sensory perception,Vision},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QUANLFEC\Smout et al. - 2019 - Attention promotes the neural encoding of predicti.pdf}
}

@article{snyderDistinctPopulationCodes2018,
  title = {Distinct Population Codes for Attention in the Absence and Presence of Visual Stimulation},
  author = {Snyder, Adam C. and Yu, Byron M. and Smith, Matthew A.},
  date = {2018-10-22},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {9},
  number = {1},
  pages = {4382},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-06754-5},
  url = {https://www.nature.com/articles/s41467-018-06754-5},
  urldate = {2022-12-19},
  abstract = {Visual neurons respond more vigorously to an attended stimulus than an unattended one. How the brain prepares for response gain in anticipation of that stimulus is not well understood. One prominent proposal is that anticipation is characterized by gain-like modulations of spontaneous activity similar to gains in stimulus responses. Here we test an alternative idea: anticipation is characterized by a mixture of both increases and decreases of spontaneous firing rates. Such a strategy would be adaptive as it supports a simple linear scheme for disentangling internal, modulatory signals from external, sensory inputs. We recorded populations of V4 neurons in monkeys performing an attention task, and found that attention states are signaled by different mixtures of neurons across the population in the presence or absence of a stimulus. Our findings support a move from a stimulation-invariant account of anticipation towards a richer view of attentional modulation in a diverse neuronal population.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Neural decoding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SQBR6DY6\Snyder et al. - 2018 - Distinct population codes for attention in the abs.pdf}
}

@article{snyderStablePopulationCode2021,
  title = {A {{Stable Population Code}} for {{Attention}} in {{Prefrontal Cortex Leads}} a {{Dynamic Attention Code}} in {{Visual Cortex}}},
  author = {Snyder, Adam C. and Yu, Byron M. and Smith, Matthew A.},
  date = {2021-11-03},
  journaltitle = {The Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {41},
  number = {44},
  pages = {9163--9176},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0608-21.2021},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0608-21.2021},
  urldate = {2023-01-16},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PKMZPKWD\Snyder et al. - 2021 - A Stable Population Code for Attention in Prefront.pdf}
}

@article{soleEvolutionBrainsComputers2022,
  title = {Evolution of {{Brains}} and {{Computers}}: {{The Roads Not Taken}}},
  shorttitle = {Evolution of {{Brains}} and {{Computers}}},
  author = {Solé, Ricard and Seoane, Luís F.},
  date = {2022-05},
  journaltitle = {Entropy},
  volume = {24},
  number = {5},
  pages = {665},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1099-4300},
  doi = {10.3390/e24050665},
  url = {https://www.mdpi.com/1099-4300/24/5/665},
  urldate = {2023-01-11},
  abstract = {When computers started to become a dominant part of technology around the 1950s, fundamental questions about reliable designs and robustness were of great relevance. Their development gave rise to the exploration of new questions, such as what made brains reliable (since neurons can die) and how computers could get inspiration from neural systems. In parallel, the first artificial neural networks came to life. Since then, the comparative view between brains and computers has been developed in new, sometimes unexpected directions. With the rise of deep learning and the development of connectomics, an evolutionary look at how both hardware and neural complexity have evolved or designed is required. In this paper, we argue that important similarities have resulted both from convergent evolution (the inevitable outcome of architectural constraints) and inspiration of hardware and software principles guided by toy pictures of neurobiology. Moreover, dissimilarities and gaps originate from the lack of major innovations that have paved the way to biological computing (including brains) that are completely absent within the artificial domain. As it occurs within synthetic biocomputation, we can also ask whether alternative minds can emerge from A.I. designs. Here, we take an evolutionary view of the problem and discuss the remarkable convergences between living and artificial designs and what are the pre-conditions to achieve artificial intelligence.},
  issue = {5},
  langid = {english},
  keywords = {artificial intelligence,brains,deep learning,embodiment,evolution,neural networks,neurorobotics},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\MM4FBKA8\Solé and Seoane - 2022 - Evolution of Brains and Computers The Roads Not T.pdf}
}

@article{soltanizangbarThetaOscillationsHippocampal2020,
  title = {Theta {{Oscillations Through Hippocampal}}/{{Prefrontal Pathway}}: {{Importance}} in {{Cognitive Performances}}},
  shorttitle = {Theta {{Oscillations Through Hippocampal}}/{{Prefrontal Pathway}}},
  author = {Soltani Zangbar, Hamid and Ghadiri, Tahereh and Seyedi Vafaee, Manuchehr and Ebrahimi Kalan, Abbas and Fallahi, Solmaz and Ghorbani, Meysam and Shahabi, Parviz},
  date = {2020-05},
  journaltitle = {Brain Connectivity},
  volume = {10},
  number = {4},
  pages = {157--169},
  publisher = {Mary Ann Liebert, Inc., publishers},
  issn = {2158-0014},
  doi = {10.1089/brain.2019.0733},
  url = {https://www.liebertpub.com/doi/abs/10.1089/brain.2019.0733},
  urldate = {2023-03-24},
  abstract = {Among various hippocampal rhythms, including sharp-wave ripples, gamma, and theta, theta rhythm is crucial for cognitive processing, particularly learning and memory. Theta oscillations are observable in both humans and rodents during spatial navigations. However, the hippocampus (Hip) is well known as the generator of current rhythm. Other brain areas, such as prefrontal cortex (PFC), can be affected by theta rhythm, too. The PFC is a core structure for the execution of diverse higher cortical functions defined as cognition. This region is connected to the hippocampus through the hippocampal/prefrontal pathway; hereby, theta oscillations convey hippocampal inputs to the PFC and simultaneously synchronize the activity of these two regions during memory, learning and other cognitive tasks. Importantly, thalamic nucleus reunions (nRE) and basolateral amygdala are salient relay structures modulating the synchronization, firing rate, and phase-locking of the hippocampal/prefrontal oscillations. Herein, we summarized experimental studies, chiefly animal researches in which the theta rhythm of the Hip-PFC axis was investigated using either electrophysiological assessments in rodent or integrated diffusion-weighted imaging and electroencephalography in human cases under memory-based tasks. Moreover, we briefly reviewed alterations of theta rhythm in some CNS diseases with the main feature of cognitive disturbance. Interestingly, animal studies implied the interruption of theta synchronization in psychiatric disorders such as schizophrenia and depression. To disclose the precise role of theta rhythm fluctuations through the Hip-PFC axis in cognitive performances, further studies are needed.},
  keywords = {cognition,hippocampal/prefrontal pathway,memory,theta rhythm}
}

@inproceedings{songCanBrainBackpropagation2020,
  title = {Can the {{Brain Do Backpropagation}}? — {{Exact Implementation}} of {{Backpropagation}} in {{Predictive Coding Networks}}},
  shorttitle = {Can the {{Brain Do Backpropagation}}?},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Song, Yuhang and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  date = {2020},
  volume = {33},
  pages = {22566--22579},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/fec87a37cdeec1c6ecf8181c0aa2d3bf-Abstract.html},
  urldate = {2024-01-16},
  abstract = {Backpropagation (BP) has been the most successful algorithm used to train artificial neural networks. However, there are several gaps between BP and learning in biologically plausible neuronal networks of the brain (learning in the brain, or simply BL, for short), in particular, (1) it has been unclear to date, if BP can be implemented exactly via BL, (2) there is a lack of local plasticity in BP, i.e., weight updates require information that is not locally available, while BL utilizes only locally available information, and (3)\textasciitilde there is a lack of autonomy in BP, i.e., some external control over the neural network is required (e.g., switching between prediction and learning stages requires changes to dynamics and synaptic plasticity rules), while BL works fully autonomously. Bridging such gaps, i.e., understanding how BP can be approximated by BL, has been of major interest in both neuroscience and machine learning. Despite tremendous efforts, however, no previous model has bridged the gaps at a degree of demonstrating an equivalence to BP, instead, only approximations to BP have been shown. Here, we present for the first time a framework within BL that bridges the above crucial gaps. We propose a BL model that (1) produces \textbackslash emph\{exactly the same\} updates of the neural weights as\textasciitilde BP, while (2)\textasciitilde employing local plasticity, i.e., all neurons perform only local computations, done simultaneously. We then modify it to an alternative BL model that (3) also works fully autonomously. Overall, our work provides important evidence for the debate on the long-disputed question whether the brain can perform\textasciitilde BP.}
}

@article{songInferringNeuralActivity2024,
  title = {Inferring Neural Activity before Plasticity as a Foundation for Learning beyond Backpropagation},
  author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  date = {2024-01-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  pages = {1--11},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01514-1},
  url = {https://www.nature.com/articles/s41593-023-01514-1},
  urldate = {2024-01-08},
  abstract = {For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
  langid = {english},
  keywords = {Learning algorithms,Machine learning,Network models},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X5YKAWZK\Song et al. - 2024 - Inferring neural activity before plasticity as a f.pdf}
}

@article{songInferringNeuralActivity2024a,
  title = {Inferring Neural Activity before Plasticity as a Foundation for Learning beyond Backpropagation},
  author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  date = {2024-01-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  pages = {1--11},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-023-01514-1},
  url = {https://www.nature.com/articles/s41593-023-01514-1},
  urldate = {2024-01-08},
  abstract = {For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
  langid = {english},
  keywords = {Learning algorithms,Machine learning,Network models},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WZCCNM8F\Song et al. - 2024 - Inferring neural activity before plasticity as a f.pdf}
}

@article{songInferringNeuralActivity2024b,
  title = {Inferring Neural Activity before Plasticity as a Foundation for Learning beyond Backpropagation},
  author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  date = {2024-01-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-023-01514-1},
  url = {https://www.nature.com/articles/s41593-023-01514-1},
  urldate = {2024-01-09},
  abstract = {Abstract             For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JVTFC4PX\Song et al. - 2024 - Inferring neural activity before plasticity as a f.pdf}
}

@article{songInferringNeuralActivity2024c,
  title = {Inferring Neural Activity before Plasticity as a Foundation for Learning beyond Backpropagation},
  author = {Song, Yuhang and Millidge, Beren and Salvatori, Tommaso and Lukasiewicz, Thomas and Xu, Zhenghua and Bogacz, Rafal},
  date = {2024-01-03},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/s41593-023-01514-1},
  url = {https://www.nature.com/articles/s41593-023-01514-1},
  urldate = {2024-01-10},
  abstract = {Abstract             For both humans and machines, the essence of learning is to pinpoint which components in its information processing pipeline are responsible for an error in its output, a challenge that is known as ‘credit assignment’. It has long been assumed that credit assignment is best solved by backpropagation, which is also the foundation of modern machine learning. Here, we set out a fundamentally different principle on credit assignment called ‘prospective configuration’. In prospective configuration, the network first infers the pattern of neural activity that should result from learning, and then the synaptic weights are modified to consolidate the change in neural activity. We demonstrate that this distinct mechanism, in contrast to backpropagation, (1) underlies learning in a well-established family of models of cortical circuits, (2) enables learning that is more efficient and effective in many contexts faced by biological organisms and (3) reproduces surprising patterns of neural activity and behavior observed in diverse human and rat learning experiments.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QKKSQYJU\Song et al. - 2024 - Inferring neural activity before plasticity as a f.pdf}
}

@article{sorensenLeveragingSpikingDeep2022,
  title = {Leveraging {{Spiking Deep Neural Networks}} to {{Understand}} the {{Neural Mechanisms Underlying Selective Attention}}},
  author = {Sörensen, Lynn K. A. and Zambrano, Davide and Slagter, Heleen A. and Bohté, Sander M. and Scholte, H. Steven},
  date = {2022-03-05},
  journaltitle = {Journal of Cognitive Neuroscience},
  volume = {34},
  number = {4},
  pages = {655--674},
  issn = {0898-929X, 1530-8898},
  doi = {10.1162/jocn_a_01819},
  url = {https://direct.mit.edu/jocn/article/34/4/655/109216/Leveraging-Spiking-Deep-Neural-Networks-to},
  urldate = {2023-01-19},
  abstract = {Abstract             Spatial attention enhances sensory processing of goal-relevant information and improves perceptual sensitivity. Yet, the specific neural mechanisms underlying the effects of spatial attention on performance are still contested. Here, we examine different attention mechanisms in spiking deep convolutional neural networks. We directly contrast effects of precision (internal noise suppression) and two different gain modulation mechanisms on performance on a visual search task with complex real-world images. Unlike standard artificial neurons, biological neurons have saturating activation functions, permitting implementation of attentional gain as gain on a neuron's input or on its outgoing connection. We show that modulating the connection is most effective in selectively enhancing information processing by redistributing spiking activity and by introducing additional task-relevant information, as shown by representational similarity analyses. Precision only produced minor attentional effects in performance. Our results, which mirror empirical findings, show that it is possible to adjudicate between attention mechanisms using more biologically realistic models and natural stimuli.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T8ZUIPUL\Sörensen et al. - 2022 - Leveraging Spiking Deep Neural Networks to Underst.pdf}
}

@article{speedSpatialAttentionEnhances2020,
  title = {Spatial Attention Enhances Network, Cellular and Subthreshold Responses in Mouse Visual Cortex},
  author = {Speed, Anderson and Del Rosario, Joseph and Mikail, Navid and Haider, Bilal},
  date = {2020-01-24},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {11},
  number = {1},
  pages = {505},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-14355-4},
  url = {https://www.nature.com/articles/s41467-020-14355-4},
  urldate = {2023-01-10},
  abstract = {Internal brain states strongly modulate sensory processing during behaviour. Studies of visual processing in primates show that attention to space selectively improves behavioural and neural responses to stimuli at the attended locations. Here we develop a visual spatial task for mice that elicits behavioural improvements consistent with the effects of spatial attention, and simultaneously measure network, cellular, and subthreshold activity in primary visual cortex. During trial-by-trial behavioural improvements, local field potential (LFP) responses to stimuli detected inside the receptive field (RF) strengthen. Moreover, detection inside the RF selectively enhances excitatory and inhibitory neuron responses to task-irrelevant stimuli and suppresses noise correlations and low frequency LFP fluctuations. Whole-cell patch-clamp recordings reveal that detection inside the RF increases synaptic activity that depolarizes membrane potential responses at the behaviorally relevant location. Our study establishes that mice display fundamental signatures of visual spatial attention spanning behavioral, network, cellular, and synaptic levels, providing new insight into rapid cognitive enhancement of sensory signals in visual cortex.},
  issue = {1},
  langid = {english},
  keywords = {Neural circuits,Sensory processing,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WMCUFIXA\Speed et al. - 2020 - Spatial attention enhances network, cellular and s.pdf}
}

@online{SpikingBurstinessWorking,
  title = {Spiking Burstiness and Working Memory in the Human Medial Temporal Lobe | {{Cerebral Cortex Communications}} | {{Oxford Academic}}},
  url = {https://academic.oup.com/cercorcomms/article/3/4/tgac039/6763343?login=false},
  urldate = {2023-01-16},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\64AYNG8B\6763343.html}
}

@online{SpontaneousRecoveryDynamical,
  title = {Spontaneous Recovery in Dynamical Networks | {{Nature Physics}}},
  url = {https://www.nature.com/articles/nphys2819},
  urldate = {2022-10-03},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2NHPU6AD\nphys2819.html}
}

@article{spratlingCorticalRegionInteractions2002,
  title = {Cortical Region Interactions and the Functional Role of Apical Dendrites},
  author = {Spratling, M. W.},
  date = {2002-09},
  journaltitle = {Behavioral and Cognitive Neuroscience Reviews},
  shortjournal = {Behav Cogn Neurosci Rev},
  volume = {1},
  number = {3},
  eprint = {17715594},
  eprinttype = {pmid},
  pages = {219--228},
  issn = {1534-5823},
  doi = {10.1177/1534582302001003003},
  abstract = {The basal and distal apical dendrites of pyramidal cells occupy distinct cortical layers and are targeted by axons originating in different cortical regions. Hence, apical and basal dendrites receive information from distinct sources. Physiological evidence suggests that this anatomically observed segregation of input sources may have functional significance. This possibility has been explored in various connectionist models that employ neurons with functionally distinct apical and basal compartments. A neuron in which separate sets of inputs can be integrated independently has the potential to operate in a variety of ways not possible for the conventional neuron model, in which all inputs are treated equally. This article thus considers how functionally distinct apical and basal dendrites can contribute to the information-processing capacities of single neurons and, in particular, how information from different cortical regions could have disparate effects on neural activity and learning.},
  langid = {english},
  keywords = {Animals,Attention,Cerebral Cortex,Dendrites,Humans,Learning,Models Neurological,Nerve Net,Neural Pathways,Pyramidal Cells},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KC8RZXAY\Spratling - 2002 - Cortical region interactions and the functional ro.pdf}
}

@article{spratlingDendriticInhibitionEnhances2001,
  title = {Dendritic {{Inhibition Enhances Neural Coding Properties}}},
  author = {Spratling, M.W. and Johnson, M.H.},
  date = {2001-12-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {11},
  number = {12},
  pages = {1144--1149},
  issn = {1047-3211},
  doi = {10.1093/cercor/11.12.1144},
  url = {https://doi.org/10.1093/cercor/11.12.1144},
  urldate = {2023-08-04},
  abstract = {The presence of a large number of inhibitory contacts at the soma and axon initial segment of cortical pyramidal cells has inspired a large and influential class of neural network model that use post-integration lateral inhibition as a mechanism for competition between nodes. However, inhibitory synapses also target the dendrites of pyramidal cells. The role of this dendritic inhibition in competition between neurons has not previously been addressed. We demonstrate, using a simple computational model, that such pre-integration lateral inhibition provides networks of neurons with useful representational and computational properties that are not provided by post-integration inhibition.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BGGEN2SF\\Spratling and Johnson - 2001 - Dendritic Inhibition Enhances Neural Coding Proper.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WFMGKZAG\\492318.html}
}

@article{spratlingFeedbackModelVisual,
  title = {A {{Feedback Model}} of {{Visual Attention}}},
  author = {Spratling, M W and Johnson, M H},
  volume = {16},
  number = {2},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BX5VLHL6\Spratling and Johnson - A Feedback Model of Visual Attention.pdf}
}

@article{spratlingPredictiveCodingModel2008,
  title = {Predictive Coding as a Model of Biased Competition in Visual Attention},
  author = {Spratling, M. W.},
  date = {2008-06-01},
  journaltitle = {Vision Research},
  shortjournal = {Vision Research},
  volume = {48},
  number = {12},
  pages = {1391--1408},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2008.03.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0042698908001466},
  urldate = {2023-03-30},
  abstract = {Attention acts, through cortical feedback pathways, to enhance the response of cells encoding expected or predicted information. Such observations are inconsistent with the predictive coding theory of cortical function which proposes that feedback acts to suppress information predicted by higher-level cortical regions. Despite this discrepancy, this article demonstrates that the predictive coding model can be used to simulate a number of the effects of attention. This is achieved via a simple mathematical rearrangement of the predictive coding model, which allows it to be interpreted as a form of biased competition model. Nonlinear extensions to the model are proposed that enable it to explain a wider range of data.},
  langid = {english},
  keywords = {Attention,Binding problem,Cortical circuits,Cortical feedback,Neural networks},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\3RKJII49\Spratling - 2008 - Predictive coding as a model of biased competition.pdf}
}

@article{spratlingPreintegrationLateralInhibition2002,
  title = {Preintegration Lateral Inhibition Enhances Unsupervised Learning},
  author = {Spratling, M. W. and Johnson, M. H.},
  date = {2002-09},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput},
  volume = {14},
  number = {9},
  eprint = {12184846},
  eprinttype = {pmid},
  pages = {2157--2179},
  issn = {0899-7667},
  doi = {10.1162/089976602320264033},
  abstract = {A large and influential class of neural network architectures uses postintegration lateral inhibition as a mechanism for competition. We argue that these algorithms are computationally deficient in that they fail to generate, or learn, appropriate perceptual representations under certain circumstances. An alternative neural network architecture is presented here in which nodes compete for the right to receive inputs rather than for the right to generate outputs. This form of competition, implemented through preintegration lateral inhibition, does provide appropriate coding properties and can be used to learn such representations efficiently. Furthermore, this architecture is consistent with both neuroanatomical and neurophysiological data. We thus argue that preintegration lateral inhibition has computational advantages over conventional neural network architectures while remaining equally biologically plausible.},
  langid = {english},
  keywords = {Algorithms,Artificial Intelligence,Humans,Neural Inhibition,Neural Networks Computer,Neural Pathways,Neurons,Synapses},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FVDDL4RN\Spratling and Johnson - 2002 - Preintegration lateral inhibition enhances unsuper.pdf}
}

@article{sprekelerExtensionSlowFeature2014,
  title = {An {{Extension}} of {{Slow Feature Analysis}} for {{Nonlinear Blind Source Separation}}},
  author = {Sprekeler, Henning and Zito, Tiziano and Wiskott, Laurenz},
  date = {2014},
  journaltitle = {Journal of Machine Learning Research},
  volume = {15},
  number = {26},
  pages = {921--947},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v15/sprekeler14a.html},
  urldate = {2023-03-05},
  abstract = {We present and test an extension of slow feature analysis as a novel approach to nonlinear blind source separation. The algorithm relies on temporal correlations and iteratively reconstructs a set of statistically independent sources from arbitrary nonlinear instantaneous mixtures. Simulations show that it is able to invert a complicated nonlinear mixture of two audio signals with a high reliability. The algorithm is based on a mathematical analysis of slow feature analysis for the case of input data that are generated from statistically independent sources.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AW3BEXJN\Sprekeler et al. - 2014 - An Extension of Slow Feature Analysis for Nonlinea.pdf}
}

@incollection{sprustonDendriticSignalIntegration2009,
  title = {Dendritic {{Signal Integration}}},
  booktitle = {Encyclopedia of {{Neuroscience}}},
  author = {Spruston, N.},
  editor = {Squire, Larry R.},
  date = {2009-01-01},
  pages = {445--452},
  publisher = {Academic Press},
  location = {Oxford},
  doi = {10.1016/B978-008045046-9.01648-X},
  url = {http://www.sciencedirect.com/science/article/pii/B978008045046901648X},
  urldate = {2020-10-29},
  abstract = {Neurons integrate inputs from a large number of synapses in a process called synaptic integration. The term ‘dendritic integration’ refers to aspects of synaptic integration that occur in dendrites. To understand dendritic integration, it is necessary to understand basic principles of synaptic integration, as well as the ways in which branching dendrites affect synaptic integration. This article reviews what is known about these processes, beginning with simple examples of interactions between excitatory synapses and progressing to more complex cases, including dendritically localized excitatory and inhibitory synapses and the influence of dendritic voltage-gated channels on dendritic integration.},
  isbn = {978-0-08-045046-9},
  langid = {english},
  keywords = {Action potential,Axon,Dendrite,EPSP,Ion channel,IPSP,Synapse,Synaptic potential},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\5LLI3CH2\B978008045046901648X.html}
}

@article{sprustonPyramidalNeuronsDendritic2008,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {9},
  number = {3},
  pages = {206--221},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn2286},
  url = {http://www.nature.com/articles/nrn2286},
  urldate = {2022-09-02},
  abstract = {Pyramidal neurons are characterized by their distinct apical and basal dendritic trees and the pyramidal shape of their soma. They are found in several regions of the CNS and, although the reasons for their abundance remain unclear, functional studies — especially of CA1 hippocampal and layer V neocortical pyramidal neurons — have offered insights into the functions of their unique cellular architecture. Pyramidal neurons are not all identical, but some shared functional principles can be identified. In particular, the existence of dendritic domains with distinct synaptic inputs, excitability, modulation and plasticity appears to be a common feature that allows synapses throughout the dendritic tree to contribute to actionpotential generation. These properties support a variety of coincidence-detection mechanisms, which are likely to be crucial for synaptic integration and plasticity.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UNRPNYEG\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf}
}

@article{sprustonPyramidalNeuronsDendritic2008a,
  title = {Pyramidal Neurons: Dendritic Structure and Synaptic Integration},
  shorttitle = {Pyramidal Neurons},
  author = {Spruston, Nelson},
  date = {2008-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {9},
  number = {3},
  pages = {206--221},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn2286},
  url = {https://www.nature.com/articles/nrn2286},
  urldate = {2020-09-25},
  abstract = {Pyramidal neurons have basal and apical dendrites, including an apical tuft. This preserved core structure suggests that they have conserved core functions, whereas structural variation in other areas suggests additional functional specialization.A number of new methods for studying pyramidal-cell activation and circuitry are available. These include in vivo patch-clamp recording, optical activation and transgenic methods for activating, inactivating or labelling neurons and their connections.Synaptic inputs from distinct sources occur onto separate dendritic domains. Defining the degree to which synapses that carry different kinds of information are segregated onto different dendritic domains remains an important challenge.Most excitatory synapses onto pyramidal neurons occur on dendritic spines, but the structure of the synapses they receive differs between dendritic domains.Dendritic integration of synaptic input depends on the dendritic domain that is targeted. Synapses distant from the soma tend to produce less synaptic depolarization, but this might be countered by increasing the conductance of distal synapses or by activating voltage-gated channels in dendrites. Synapses on small-diameter dendrites cause larger local voltage changes, which reduce the effectiveness of synaptic scaling but increase the activation of voltage-gated conductances.Inhibitory synapses specifically target the axon, soma or different dendritic domains. Integration of inhibitory inputs also differs across cellular domains.The intrinsic firing properties of pyramidal neurons vary considerably. Along with variation in dendritic structure and channel distributions, such variability suggests that different pyramidal neurons might carry out specialized functions.Pyramidal-neuron dendrites contain voltage-gated channels that can influence synaptic integration. These channels can also support backpropagating action potentials and dendritically initiated spikes. Dendritic excitability is a general property of all pyramidal neurons studied so far, but the details differ between different types of pyramidal neurons. Although there is some evidence for dendritic excitability in vivo, much more work is needed in this area.Activation of a small fraction of the tens of thousands of excitatory synapses on a pyramidal neuron can probably evoke dendritic spikes, but these events do not always propagate to the soma and the axon. The coupling of dendritic spikes to axonal action-potential firing probably depends on the pattern of synaptic activation. This results in forms of coincidence detection that are determined by dendritic structure and excitability.Backpropagating action potentials and dendritic spikes are important signals for the induction of synaptic plasticity. Even single dendritic spikes can result in significant long-term potentiation or long-term depression.Neurotransmitters can modulate pyramidal-neuron function. At least some forms of modulation affect various dendritic domains and their synaptic inputs in different ways.Domain-specific properties in excitatory and inhibitory synaptic inputs, voltage-gated channels, dendritic excitability and neuromodulation all point to a multi-compartment model of pyramidal-neuron function. Elaborating simple models of pyramidal-neuron function based on these dendritic-domain-specific properties is a central challenge for the study of cortical function.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LI46IXAV\\Spruston - 2008 - Pyramidal neurons dendritic structure and synapti.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BPSPCV3A\\nrn2286.html}
}

@article{spyropoulosThetaRhythmMacaque2018,
  title = {A Theta Rhythm in Macaque Visual Cortex and Its Attentional Modulation},
  author = {Spyropoulos, Georgios and Bosman, Conrado Arturo and Fries, Pascal},
  date = {2018-06-12},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {24},
  pages = {E5614-E5623},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1719433115},
  url = {https://www.pnas.org/doi/10.1073/pnas.1719433115},
  urldate = {2023-03-24},
  abstract = {Theta rhythms govern rodent sniffing and whisking, and human language processing. Human psychophysics suggests a role for theta also in visual attention. However, little is known about theta in visual areas and its attentional modulation. We used electrocorticography (ECoG) to record local field potentials (LFPs) simultaneously from areas V1, V2, V4, and TEO of two macaque monkeys performing a selective visual attention task. We found a ≈4-Hz theta rhythm within both the V1–V2 and the V4–TEO region, and theta synchronization between them, with a predominantly feedforward directed influence. ECoG coverage of large parts of these regions revealed a surprising spatial correspondence between theta and visually induced gamma. Furthermore, gamma power was modulated with theta phase. Selective attention to the respective visual stimulus strongly reduced these theta-rhythmic processes, leading to an unusually strong attention effect for V1. Microsaccades (MSs) were partly locked to theta. However, neuronal theta rhythms tended to be even more pronounced for epochs devoid of MSs. Thus, we find an MS-independent theta rhythm specific to visually driven parts of V1–V2, which rhythmically modulates local gamma and entrains V4–TEO, and which is strongly reduced by attention. We propose that the less theta-rhythmic and thereby more continuous processing of the attended stimulus serves the exploitation of this behaviorally most relevant information. The theta-rhythmic and thereby intermittent processing of the unattended stimulus likely reflects the ecologically important exploration of less relevant sources of information.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TCASY2HT\Spyropoulos et al. - 2018 - A theta rhythm in macaque visual cortex and its at.pdf}
}

@article{srinathAttentionImprovesInformation2021,
  title = {Attention Improves Information Flow between Neuronal Populations without Changing the Communication Subspace},
  author = {Srinath, Ramanujan and Ruff, Douglas A. and Cohen, Marlene R.},
  date = {2021-12-06},
  journaltitle = {Current Biology},
  shortjournal = {Current Biology},
  volume = {31},
  number = {23},
  pages = {5299-5313.e4},
  issn = {0960-9822},
  doi = {10.1016/j.cub.2021.09.076},
  url = {https://www.sciencedirect.com/science/article/pii/S0960982221013440},
  urldate = {2023-04-08},
  abstract = {Visual attention allows observers to change the influence of different parts of a visual scene on their behavior, suggesting that information can be flexibly shared between visual cortex and neurons involved in decision making. We investigated the neural substrate of flexible information routing by analyzing the activity of populations of visual neurons in the medial temporal area (MT) and oculo-motor neurons in the superior colliculus (SC) while rhesus monkeys switched spatial attention. We demonstrated that attention increases the efficacy of visuomotor communication: trial-to-trial variability in SC population activity could be better predicted by the activity of the MT population (and vice versa) when attention was directed toward their joint receptive fields. Surprisingly, this improvement in prediction was not explained by changes in the dimensionality of the shared subspace or in the magnitude of local or shared pairwise noise correlations. These results lay a foundation for future theoretical and experimental studies into how visual attention can flexibly change information flow between sensory and decision neurons.},
  langid = {english},
  keywords = {communication subspace,functional communication,spatial attention,visual representations},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RPTV2RC2\\Srinath et al. - 2021 - Attention improves information flow between neuron.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P4EZK5C9\\S0960982221013440.html}
}

@article{staigerNeuronalCircuitsBarrel2021,
  title = {✅ {{Neuronal Circuits}} in {{Barrel Cortex}} for {{Whisker Sensory Perception}}},
  author = {Staiger, Jochen F. and Petersen, Carl C. H.},
  date = {2021-01},
  journaltitle = {Physiological Reviews},
  volume = {101},
  number = {1},
  pages = {353--415},
  publisher = {American Physiological Society},
  issn = {0031-9333},
  doi = {10.1152/physrev.00019.2019},
  url = {https://journals.physiology.org/doi/full/10.1152/physrev.00019.2019},
  urldate = {2023-04-11},
  abstract = {Download figureDownload PowerPoint},
  keywords = {barrel cortex,GABAergic neurons,principal cells,sensory perception,synaptic circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UC4GP2F5\Staiger and Petersen - 2021 - Neuronal Circuits in Barrel Cortex for Whisker Sen.pdf}
}

@article{stefaniniDistributedNeuralCode2020,
  title = {✅ {{A Distributed Neural Code}} in the {{Dentate Gyrus}} and in {{CA1}}},
  author = {Stefanini, Fabio and Kushnir, Lyudmila and Jimenez, Jessica C. and Jennings, Joshua H. and Woods, Nicholas I. and Stuber, Garret D. and Kheirbek, Mazen A. and Hen, René and Fusi, Stefano},
  date = {2020-08-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {107},
  number = {4},
  eprint = {32521223},
  eprinttype = {pmid},
  pages = {703-716.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2020.05.022},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(20)30391-3},
  urldate = {2023-04-17},
  langid = {english},
  keywords = {calcium imaging,correlated activity,decoding,dentate gyrus,distributed representations,hippocampus,mixed selectivity,place cells,population coding},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NTLYXIV6\Stefanini et al. - 2020 - A Distributed Neural Code in the Dentate Gyrus and.pdf}
}

@article{steinmetzEyeMovementPreparation2014,
  title = {Eye {{Movement Preparation Modulates Neuronal Responses}} in {{Area V4 When Dissociated}} from {{Attentional Demands}}},
  author = {Steinmetz, Nicholas A. and Moore, Tirin},
  date = {2014-07-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {83},
  number = {2},
  eprint = {25033188},
  eprinttype = {pmid},
  pages = {496--506},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.06.014},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(14)00536-4},
  urldate = {2023-01-03},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\B9ZSX936\Steinmetz and Moore - 2014 - Eye Movement Preparation Modulates Neuronal Respon.pdf}
}

@article{steinmetzEyeMovementPreparation2014a,
  title = {Eye {{Movement Preparation Modulates Neuronal Responses}} in {{Area V4 When Dissociated}} from {{Attentional Demands}}},
  author = {Steinmetz, Nicholas A. and Moore, Tirin},
  date = {2014-07-16},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {83},
  number = {2},
  eprint = {25033188},
  eprinttype = {pmid},
  pages = {496--506},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.06.014},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(14)00536-4},
  urldate = {2023-01-05},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\73B3ECYS\Steinmetz and Moore - 2014 - Eye Movement Preparation Modulates Neuronal Respon.pdf}
}

@article{steinNeuronalVariabilityNoise2005,
  title = {Neuronal Variability: Noise or Part of the Signal?},
  shorttitle = {Neuronal Variability},
  author = {Stein, Richard B. and Gossen, E. Roderich and Jones, Kelvin E.},
  date = {2005-05},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {6},
  number = {5},
  pages = {389--397},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/nrn1668},
  url = {https://www.nature.com/articles/nrn1668},
  urldate = {2022-10-20},
  abstract = {Traditionally, the rate of nerve impulses (spikes) over time was considered to be the main carrier of information in the nervous system. Therefore, any variability in the rate of response to a steady stimulus would reduce the information conveyed by a nerve cell. Many nerve cells fire with considerable variability, which would limit their ability to carry information to 2 or 3 bits in 1 s.With time-varying inputs containing the range of frequencies that the neuron responds to, values of information transmission of approximately 1 bit per spike have been calculated. For a neuron that fires tens or hundreds of spikes per second, much higher bit rates are possible than with steady inputs.Variability might also offer distinct advantages in preventing the entrainment of neurons to high-frequency signals. Enhanced sensitivity to weak signals has been proposed, which is known as 'stochastic resonance', as well as a role of variability in the method of Bayesian inference. Recent work on various sensory systems has emphasized the importance of timing, particularly that of first spikes, rather than the rate of firing over time.Rate coding might be more important in the motor system than precise timing. The variability in rate fluctuates with the mean rate (signal-dependent noise). The variability in the motor output in the presence of this noise can be minimized using optimal control theory.Optimal control theory predicts the form of many movements if a specific rule is assumed that relates the standard deviation in rate to the mean rate. This rule is not observed experimentally for either motor neurons or the motor cortex. However, the relationship between the standard deviation in muscle force and the mean force obeys the rule.The reason for the difference between the neural responses and the force output arises from the Henneman size principle. This states that the first recruited motor units are small and, hence, produce minor variations in force. Later motor units are larger and produce greater variations with the magnitude required by the optimal control theory.In the central nervous system, large excitatory postsynaptic potentials (EPSPs) can cause the near synchronous firing of groups of cells that might be important in attention, as well as learning and memory. Interactions in some areas, such as the hippocampus, between ongoing oscillations and spike activity might be used by 'place neurons' to locate the position of the body in external space. Therefore, variability in the firing rate of individual neurons is not simply noise, but might have a range of functions in neurons throughout the nervous system.},
  issue = {5},
  langid = {english},
  keywords = {Animal Genetics and Genomics,Behavioral Sciences,Biological Techniques,Biomedicine,general,Neurobiology,Neurosciences},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SPPANQV7\Stein et al. - 2005 - Neuronal variability noise or part of the signal.pdf}
}

@article{stephensBayesianInferenceComputational,
  title = {Bayesian {{Inference}}, {{Computational Methods}} and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  journaltitle = {Monte Carlo},
  pages = {641},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2BIY5RK6\Stephens - Bayesian Inference, Computational Methods and Mont.pdf}
}

@article{stephensMATH598Bayesian,
  title = {{{MATH}} 598 - {{Bayesian Inference}}, {{Computational Methods}}   and {{Monte Carlo}}},
  author = {Stephens, Dr David A},
  pages = {251},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YXUD8S3Z\Stephens - MATH 598 - Bayesian Inference, Computational Metho.pdf}
}

@article{stringerHighdimensionalGeometryPopulation2019,
  title = {High-Dimensional Geometry of Population Responses in Visual Cortex},
  author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Carandini, Matteo and Harris, Kenneth D.},
  date = {2019-07},
  journaltitle = {Nature},
  volume = {571},
  number = {7765},
  pages = {361--365},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-019-1346-5},
  url = {https://www.nature.com/articles/s41586-019-1346-5},
  urldate = {2020-09-22},
  abstract = {A neuronal population encodes information most efficiently when its stimulus responses are high-dimensional and uncorrelated, and most robustly when they are lower-dimensional and correlated. Here we analysed the dimensionality of the encoding of natural images by large populations of neurons in the visual cortex of awake mice. The evoked population activity was high-dimensional, and correlations obeyed an unexpected power law: the nth principal component variance scaled as 1/n. This scaling was not inherited from the power law spectrum of natural images, because it persisted after stimulus whitening. We proved mathematically that if the variance spectrum was to decay more slowly then the population code could not be smooth, allowing small changes in input to dominate population activity. The theory also predicts larger power-law exponents for lower-dimensional stimulus ensembles, which we validated experimentally. These results suggest that coding smoothness may represent a fundamental constraint that determines correlations in neural population codes.},
  issue = {7765},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KZ4KXAA4\\Stringer et al. - 2019 - High-dimensional geometry of population responses .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B7ZDPWID\\s41586-019-1346-5.html}
}

@article{stringerSpontaneousBehaviorsDrive2019,
  title = {Spontaneous Behaviors Drive Multidimensional, Brainwide Activity},
  author = {Stringer, Carsen and Pachitariu, Marius and Steinmetz, Nicholas and Reddy, Charu Bai and Carandini, Matteo and Harris, Kenneth D.},
  date = {2019-04-19},
  journaltitle = {Science},
  volume = {364},
  number = {6437},
  pages = {eaav7893},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aav7893},
  url = {https://www.science.org/doi/full/10.1126/science.aav7893},
  urldate = {2024-07-03},
  abstract = {Neuronal populations in sensory cortex produce variable responses to sensory stimuli and exhibit intricate spontaneous activity even without external sensory input. Cortical variability and spontaneous activity have been variously proposed to represent random noise, recall of prior experience, or encoding of ongoing behavioral and cognitive variables. Recording more than 10,000 neurons in mouse visual cortex, we observed that spontaneous activity reliably encoded a high-dimensional latent state, which was partially related to the mouse’s ongoing behavior and was represented not just in visual cortex but also across the forebrain. Sensory inputs did not interrupt this ongoing signal but added onto it a representation of external stimuli in orthogonal dimensions. Thus, visual cortical population activity, despite its apparently noisy structure, reliably encodes an orthogonal fusion of sensory and multidimensional behavioral information.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LR8B5MMA\Stringer et al. - 2019 - Spontaneous behaviors drive multidimensional, brai.pdf}
}

@article{strogatzHumanSleepCircadian1987,
  title = {Human Sleep and Circadian Rhythms: A Simple Model Based on Two Coupled Oscillators},
  shorttitle = {Human Sleep and Circadian Rhythms},
  author = {Strogatz, Steven H.},
  date = {1987-07-01},
  journaltitle = {Journal of Mathematical Biology},
  shortjournal = {J. Math. Biology},
  volume = {25},
  number = {3},
  pages = {327--347},
  issn = {1432-1416},
  doi = {10.1007/BF00276440},
  url = {https://doi.org/10.1007/BF00276440},
  urldate = {2023-01-26},
  abstract = {We propose a model of the human circadian system. The sleep-wake and body temperature rhythms are assumed to be driven by a pair of coupled nonlinear oscillators described by phase variables alone. The novel aspect of the model is that its equations may be solved analytically. Computer simulations are used to test the model against sleep-wake data pooled from 15 studies of subjects living for weeks in unscheduled, time-free environments. On these tests the model performs about as well as the existing models, although its mathematical structure is far simpler.},
  langid = {english}
}

@online{StructuresFunctionsCorrelations,
  title = {The Structures and Functions of Correlations in Neural Population Codes | {{Nature Reviews Neuroscience}}},
  url = {https://www.nature.com/articles/s41583-022-00606-4},
  urldate = {2023-03-31},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DVLF6IC9\\The structures and functions of correlations in ne.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4CG454G6\\s41583-022-00606-4.html}
}

@article{stuartDendriticIntegration602015,
  title = {Dendritic Integration: 60 Years of Progress},
  shorttitle = {Dendritic Integration},
  author = {Stuart, Greg J and Spruston, Nelson},
  date = {2015-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {12},
  pages = {1713--1721},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn.4157},
  url = {http://www.nature.com/articles/nn.4157},
  urldate = {2022-09-02},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LLV9TE6Q\Stuart and Spruston - 2015 - Dendritic integration 60 years of progress.pdf}
}

@article{suzukiHowDeepBrain2023,
  title = {How Deep Is the Brain? {{The}} Shallow Brain Hypothesis},
  shorttitle = {How Deep Is the Brain?},
  author = {Suzuki, Mototaka and Pennartz, Cyriel M. A. and Aru, Jaan},
  date = {2023-12},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat. Rev. Neurosci.},
  volume = {24},
  number = {12},
  pages = {778--791},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-023-00756-z},
  url = {https://www.nature.com/articles/s41583-023-00756-z},
  urldate = {2023-11-21},
  abstract = {Deep learning and predictive coding architectures commonly assume that inference in neural networks is hierarchical. However, largely neglected in deep learning and predictive coding architectures is the neurobiological evidence that all hierarchical cortical areas, higher or lower, project to and receive signals directly from subcortical areas. Given these neuroanatomical facts, today’s dominance of cortico-centric, hierarchical architectures in deep learning and predictive coding networks is highly questionable; such architectures are likely to be~missing essential computational principles the brain uses. In this Perspective, we present the shallow brain hypothesis: hierarchical cortical processing is integrated with a massively parallel process to which subcortical areas substantially contribute. This shallow architecture exploits the computational capacity of cortical microcircuits and thalamo-cortical loops that are not included in typical hierarchical deep learning and predictive coding networks. We argue that the shallow brain architecture provides several critical benefits over deep hierarchical structures and a more complete depiction of how mammalian brains achieve fast and flexible computational capabilities.},
  issue = {12},
  langid = {english},
  keywords = {Computational neuroscience,Neural circuits,Neurophysiology,Sensorimotor processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\UC6T5QRQ\Suzuki et al. - 2023 - How deep is the brain The shallow brain hypothesi.pdf}
}

@article{takahashiActiveCorticalDendrites2016,
  title = {Active Cortical Dendrites Modulate Perception},
  author = {Takahashi, Naoya and Oertner, Thomas G. and Hegemann, Peter and Larkum, Matthew E.},
  date = {2016-12-23},
  journaltitle = {Science},
  volume = {354},
  number = {6319},
  pages = {1587--1590},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aah6066},
  url = {https://www.science.org/doi/10.1126/science.aah6066},
  urldate = {2023-02-08},
  abstract = {There is as yet no consensus concerning the neural basis of perception and how it operates at a mechanistic level. We found that Ca2+ activity in the apical dendrites of a subset of layer 5 (L5) pyramidal neurons in primary somatosensory cortex (S1) in mice is correlated with the threshold for perceptual detection of whisker deflections. Manipulating the activity of apical dendrites shifted the perceptual threshold, demonstrating that an active dendritic mechanism is causally linked to perceptual detection.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SS43BLPN\Takahashi et al. - 2016 - Active cortical dendrites modulate perception.pdf}
}

@article{takahashiActiveCorticalDendrites2016a,
  title = {✅  {{Active}} Cortical Dendrites Modulate Perception},
  author = {Takahashi, Naoya and Oertner, Thomas G. and Hegemann, Peter and Larkum, Matthew E.},
  date = {2016-12-23},
  journaltitle = {Science},
  volume = {354},
  number = {6319},
  pages = {1587--1590},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aah6066},
  url = {https://www.science.org/doi/10.1126/science.aah6066},
  urldate = {2023-02-09},
  abstract = {There is as yet no consensus concerning the neural basis of perception and how it operates at a mechanistic level. We found that Ca2+ activity in the apical dendrites of a subset of layer 5 (L5) pyramidal neurons in primary somatosensory cortex (S1) in mice is correlated with the threshold for perceptual detection of whisker deflections. Manipulating the activity of apical dendrites shifted the perceptual threshold, demonstrating that an active dendritic mechanism is causally linked to perceptual detection.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FV2MAT2X\Takahashi et al. - 2016 - Active cortical dendrites modulate perception.pdf}
}

@article{takahashiActiveDendriticCurrents2020,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-10},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {23},
  number = {10},
  pages = {1277--1285},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2023-04-11},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  issue = {10},
  langid = {english},
  keywords = {Neuronal physiology,Neuroscience,Sensory processing,Somatosensory system},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\QT9MC7GH\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf}
}

@article{takahashiActiveDendriticCurrents2020a,
  title = {Active Dendritic Currents Gate Descending Cortical Outputs in Perception},
  author = {Takahashi, Naoya and Ebner, Christian and Sigl-Glöckner, Johanna and Moberg, Sara and Nierwetberg, Svenja and Larkum, Matthew E.},
  date = {2020-08-03},
  journaltitle = {Nature Neuroscience},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0677-8},
  url = {https://www.nature.com/articles/s41593-020-0677-8},
  urldate = {2020-09-22},
  abstract = {The output of cortical columns is routed to different downstream targets via distinct pathways: cortico-cortical and cortico-subcortical. It is as yet unclear what roles these pathways play in perception, and which cellular and circuit mechanisms regulate their gating. We recently showed that activation of the apical dendrites of layer 5 (L5) pyramidal neurons correlates with the threshold for perception, but these neurons come in two classes that target either other cortical or subcortical areas. In the present study, we took advantage of transgenic mouse lines for these L5 subclasses to determine their relative contributions to the perceptual process. We found that the activation of apical dendrites in neurons of the somatosensory cortex, which project to subcortical regions, almost exclusively determined the detection of tactile stimuli in mice. Our results suggest that dendritic activation drives context-dependent interactions between cortex and subcortical regions, including the higher-order thalamus, superior colliculus and striatum, which are crucial for perception.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HZSBVY3S\\Takahashi et al. - 2020 - Active dendritic currents gate descending cortical.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6RF7LAZU\\s41593-020-0677-8.html}
}

@article{talpalarDualmodeOperationNeuronal2013,
  title = {Dual-Mode Operation of Neuronal Networks Involved in Left–Right Alternation},
  author = {Talpalar, Adolfo E. and Bouvier, Julien and Borgius, Lotta and Fortin, Gilles and Pierani, Alessandra and Kiehn, Ole},
  date = {2013-08},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {500},
  number = {7460},
  pages = {85--88},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature12286},
  url = {http://www.nature.com/articles/nature12286},
  urldate = {2023-03-17},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\2DT6NWN7\Talpalar et al. - 2013 - Dual-mode operation of neuronal networks involved .pdf}
}

@inproceedings{tamSignalProcessingMultiplexing1990,
  title = {Signal {{Processing}} by {{Multiplexing}} and {{Demultiplexing}} in {{Neurons}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Tam, David},
  date = {1990},
  volume = {3},
  publisher = {Morgan-Kaufmann},
  url = {https://papers.nips.cc/paper/1990/hash/c5ff2543b53f4cc0ad3819a36752467b-Abstract.html},
  urldate = {2023-03-05},
  abstract = {to},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\85BZ983B\Tam - 1990 - Signal Processing by Multiplexing and Demultiplexi.pdf}
}

@article{tangIntroductionFocusIssue2020,
  title = {Introduction to {{Focus Issue}}: {{When}} Machine Learning Meets Complex Systems: {{Networks}}, Chaos, and Nonlinear Dynamics},
  shorttitle = {Introduction to {{Focus Issue}}},
  author = {Tang, Yang and Kurths, Jürgen and Lin, Wei and Ott, Edward and Kocarev, Ljupco},
  date = {2020-06},
  journaltitle = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  shortjournal = {Chaos},
  volume = {30},
  number = {6},
  pages = {063151},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0016505},
  url = {http://aip.scitation.org/doi/10.1063/5.0016505},
  urldate = {2020-09-30},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7WXCVSQ8\Tang et al. - 2020 - Introduction to Focus Issue When machine learning.pdf}
}

@article{tangRecurrentPredictiveCoding2023,
  title = {Recurrent Predictive Coding Models for Associative Memory Employing Covariance Learning},
  author = {Tang, Mufeng and Salvatori, Tommaso and Millidge, Beren and Song, Yuhang and Lukasiewicz, Thomas and Bogacz, Rafal},
  date = {2023-04-14},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {19},
  number = {4},
  pages = {e1010719},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1010719},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010719},
  urldate = {2024-01-11},
  abstract = {The computational principles adopted by the hippocampus in associative memory (AM) tasks have been one of the most studied topics in computational and theoretical neuroscience. Recent theories suggested that AM and the predictive activities of the hippocampus could be described within a unitary account, and that predictive coding underlies the computations supporting AM in the hippocampus. Following this theory, a computational model based on classical hierarchical predictive networks was proposed and was shown to perform well in various AM tasks. However, this fully hierarchical model did not incorporate recurrent connections, an architectural component of the CA3 region of the hippocampus that is crucial for AM. This makes the structure of the model inconsistent with the known connectivity of CA3 and classical recurrent models such as Hopfield Networks, which learn the covariance of inputs through their recurrent connections to perform AM. Earlier PC models that learn the covariance information of inputs explicitly via recurrent connections seem to be a solution to these issues. Here, we show that although these models can perform AM, they do it in an implausible and numerically unstable way. Instead, we propose alternatives to these earlier covariance-learning predictive coding networks, which learn the covariance information implicitly and plausibly, and can use dendritic structures to encode prediction errors. We show analytically that our proposed models are perfectly equivalent to the earlier predictive coding model learning covariance explicitly, and encounter no numerical issues when performing AM tasks in practice. We further show that our models can be combined with hierarchical predictive coding networks to model the hippocampo-neocortical interactions. Our models provide a biologically plausible approach to modelling the hippocampal network, pointing to a potential computational mechanism during hippocampal memory formation and recall, which employs both predictive coding and covariance learning based on the recurrent network structure of the hippocampus.},
  langid = {english},
  keywords = {Covariance,Hippocampus,Learning,Memory,Neural networks,Neuronal dendrites,Neurons,Sensory perception},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NSD5XM6H\Tang et al. - 2023 - Recurrent predictive coding models for associative.pdf}
}

@article{teradaTemporalRateCoding2017,
  title = {Temporal and {{Rate Coding}} for {{Discrete Event Sequences}} in the {{Hippocampus}}},
  author = {Terada, Satoshi and Sakurai, Yoshio and Nakahara, Hiroyuki and Fujisawa, Shigeyoshi},
  date = {2017-06-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {94},
  number = {6},
  eprint = {28602691},
  eprinttype = {pmid},
  pages = {1248-1262.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2017.05.024},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(17)30462-2},
  urldate = {2023-03-27},
  langid = {english},
  keywords = {episodic event sequences,hippocampus,large-scale extracellular unit recording,phase precession,theta oscillation},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\47C6JT4S\Terada et al. - 2017 - Temporal and Rate Coding for Discrete Event Sequen.pdf}
}

@online{ThetaphaseDependentNeuronal,
  title = {Theta-Phase Dependent Neuronal Coding during Sequence Learning in Human Single Neurons | {{Nature Communications}}},
  url = {https://www.nature.com/articles/s41467-021-25150-0},
  urldate = {2023-01-22},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\GCFAZ2LD\s41467-021-25150-0.html}
}

@article{thieleNeuromodulationAttention2018,
  title = {Neuromodulation of {{Attention}}},
  author = {Thiele, Alexander and Bellgrove, Mark A.},
  date = {2018-02-21},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {97},
  number = {4},
  pages = {769--785},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.01.008},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627318300114},
  urldate = {2022-10-17},
  abstract = {Attention is critical to high-level cognition and attention deficits are a hallmark of neurologic and neuropsychiatric disorders. Although years of research indicates that distinct neuromodulators influence attentional control, a mechanistic account that traverses levels of analysis (cells, circuits, behavior) is missing. However, such an account is critical to guide the development of next-generation pharmacotherapies aimed at forestalling or remediating the global burden associated with disorders of attention. Here, we summarize current neuroscientific understanding of how attention affects single neurons and networks of neurons. We then review key results that have informed our understanding of how neuromodulation shapes these neuron and network properties and thereby enables the appropriate allocation of attention to relevant external or internal events. Finally, we highlight areas where we believe hypotheses can be formulated and tackled experimentally in the near future, thereby critically increasing our mechanistic understanding of how attention is implemented at the cellular and network levels.},
  langid = {english},
  keywords = {attention,attractor networks,neuromodulators,pharmacology,population coding,top-down},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LSKXKFB4\\Thiele and Bellgrove - 2018 - Neuromodulation of Attention.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\E3L8UDQP\\S0896627318300114.html}
}

@online{timcheckIntelNeuromorphicDNS2023,
  title = {The {{Intel Neuromorphic DNS Challenge}}},
  author = {Timcheck, Jonathan and Shrestha, Sumit Bam and Rubin, Daniel Ben Dayan and Kupryjanow, Adam and Orchard, Garrick and Pindor, Lukasz and Shea, Timothy and Davies, Mike},
  date = {2023-03-17},
  eprint = {2303.09503},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.09503},
  urldate = {2023-03-30},
  abstract = {A critical enabler for progress in neuromorphic computing research is the ability to transparently evaluate different neuromorphic solutions on important tasks and to compare them to state-of-the-art conventional solutions. The Intel Neuromorphic Deep Noise Suppression Challenge (Intel N-DNS Challenge), inspired by the Microsoft DNS Challenge, tackles a ubiquitous and commercially relevant task: real-time audio denoising. Audio denoising is likely to reap the benefits of neuromorphic computing due to its low-bandwidth, temporal nature and its relevance for low-power devices. The Intel N-DNS Challenge consists of two tracks: a simulation-based algorithmic track to encourage algorithmic innovation, and a neuromorphic hardware (Loihi 2) track to rigorously evaluate solutions. For both tracks, we specify an evaluation methodology based on energy, latency, and resource consumption in addition to output audio quality. We make the Intel N-DNS Challenge dataset scripts and evaluation code freely accessible, encourage community participation with monetary prizes, and release a neuromorphic baseline solution which shows promising audio quality, high power efficiency, and low resource consumption when compared to Microsoft NsNet2 and a proprietary Intel denoising model used in production. We hope the Intel N-DNS Challenge will hasten innovation in neuromorphic algorithms research, especially in the area of training tools and methods for real-time signal processing. We expect the winners of the challenge will demonstrate that for problems like audio denoising, significant gains in power and resources can be realized on neuromorphic devices available today compared to conventional state-of-the-art solutions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UECYS5UT\\Timcheck et al. - 2023 - The Intel Neuromorphic DNS Challenge.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JE5P2IQF\\2303.html}
}

@article{tippingProbabilisticPrincipalComponent1999,
  title = {Probabilistic {{Principal Component Analysis}}},
  author = {Tipping, Michael E. and Bishop, Christopher M.},
  date = {1999-09-01},
  journaltitle = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  shortjournal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {61},
  number = {3},
  pages = {611--622},
  issn = {1369-7412},
  doi = {10.1111/1467-9868.00196},
  url = {https://doi.org/10.1111/1467-9868.00196},
  urldate = {2024-07-16},
  abstract = {Principal component analysis (PCA) is a ubiquitous technique for data analysis and processing, but one which is not based on a probability model. We demonstrate how the principal axes of a set of observed data vectors may be determined through maximum likelihood estimation of parameters in a latent variable model that is closely related to factor analysis. We consider the properties of the associated likelihood function, giving an EM algorithm for estimating the principal subspace iteratively, and discuss, with illustrative examples, the advantages conveyed by this probabilistic approach to PCA.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\9H28MU4V\\Tipping and Bishop - 1999 - Probabilistic Principal Component Analysis.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\GB86NM3N\\7083217.html}
}

@article{tkacikOptimizingInformationFlow2009,
  title = {Optimizing Information Flow in Small Genetic Networks},
  author = {Tkačik, Gašper and Walczak, Aleksandra M. and Bialek, William},
  date = {2009-09-29},
  journaltitle = {Physical Review E},
  shortjournal = {Phys. Rev. E},
  volume = {80},
  number = {3},
  pages = {031920},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.80.031920},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.80.031920},
  urldate = {2024-01-08},
  abstract = {In order to survive, reproduce, and (in multicellular organisms) differentiate, cells must control the concentrations of the myriad different proteins that are encoded in the genome. The precision of this control is limited by the inevitable randomness of individual molecular events. Here we explore how cells can maximize their control power in the presence of these physical limits; formally, we solve the theoretical problem of maximizing the information transferred from inputs to outputs when the number of available molecules is held fixed. We start with the simplest version of the problem, in which a single transcription factor protein controls the readout of one or more genes by binding to DNA. We further simplify by assuming that this regulatory network operates in steady state, that the noise is small relative to the available dynamic range, and that the target genes do not interact. Even in this simple limit, we find a surprisingly rich set of optimal solutions. Importantly, for each locally optimal regulatory network, all parameters are determined once the physical constraints on the number of available molecules are specified. Although we are solving an oversimplified version of the problem facing real cells, we see parallels between the structure of these optimal solutions and the behavior of actual genetic regulatory networks. Subsequent papers will discuss more complete versions of the problem.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P2DFS7UL\\Tkačik et al. - 2009 - Optimizing information flow in small genetic netwo.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T5HY5SIM\\PhysRevE.80.html}
}

@article{toiVivoDirectImaging2022,
  title = {In Vivo Direct Imaging of Neuronal Activity at High Temporospatial Resolution},
  author = {Toi, Phan Tan and Jang, Hyun Jae and Min, Kyeongseon and Kim, Sung-Phil and Lee, Seung-Kyun and Lee, Jongho and Kwag, Jeehyun and Park, Jang-Yeon},
  date = {2022-10-14},
  journaltitle = {Science},
  volume = {378},
  number = {6616},
  pages = {160--168},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.abh4340},
  url = {https://www.science.org/doi/10.1126/science.abh4340},
  urldate = {2022-10-21},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LTCEHWJJ\Toi et al. - 2022 - In vivo direct imaging of neuronal activity at hig.pdf}
}

@article{tokerConsciousnessSupportedNearcritical2022,
  title = {Consciousness Is Supported by Near-Critical Slow Cortical Electrodynamics},
  author = {Toker, Daniel and Pappas, Ioannis and Lendner, Janna D. and Frohlich, Joel and Mateos, Diego M. and Muthukumaraswamy, Suresh and Carhart-Harris, Robin and Paff, Michelle and Vespa, Paul M. and Monti, Martin M. and Sommer, Friedrich T. and Knight, Robert T. and D’Esposito, Mark},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {7},
  pages = {e2024455119},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2024455119},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2024455119},
  urldate = {2022-10-06},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LESIMU5S\Toker et al. - 2022 - Consciousness is supported by near-critical slow c.pdf}
}

@article{tokerConsciousnessSupportedNearcritical2022a,
  title = {Consciousness Is Supported by Near-Critical Slow Cortical Electrodynamics},
  author = {Toker, Daniel and Pappas, Ioannis and Lendner, Janna D. and Frohlich, Joel and Mateos, Diego M. and Muthukumaraswamy, Suresh and Carhart-Harris, Robin and Paff, Michelle and Vespa, Paul M. and Monti, Martin M. and Sommer, Friedrich T. and Knight, Robert T. and D’Esposito, Mark},
  date = {2022-02-15},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {119},
  number = {7},
  pages = {e2024455119},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2024455119},
  url = {https://pnas.org/doi/full/10.1073/pnas.2024455119},
  urldate = {2022-10-06},
  abstract = {Significance             What changes in the brain when we lose consciousness? One possibility is that the loss of consciousness corresponds to a transition of the brain’s electric activity away from edge-of-chaos criticality, or the knife’s edge in between stability and chaos. Recent mathematical developments have produced tools for testing this hypothesis, which we apply to cortical recordings from diverse brain states. We show that the electric activity of the cortex is indeed poised near the boundary between stability and chaos during conscious states and transitions away from this boundary during unconsciousness and that this transition disrupts cortical information processing.           ,              Mounting evidence suggests that during conscious states, the electrodynamics of the cortex are poised near a critical point or phase transition and that this near-critical behavior supports the vast flow of information through cortical networks during conscious states. Here, we empirically identify a mathematically specific critical point near which waking cortical oscillatory dynamics operate, which is known as the edge-of-chaos critical point, or the boundary between stability and chaos. We do so by applying the recently developed modified 0-1 chaos test to electrocorticography (ECoG) and magnetoencephalography (MEG) recordings from the cortices of humans and macaques across normal waking, generalized seizure, anesthesia, and psychedelic states. Our evidence suggests that cortical information processing is disrupted during unconscious states because of a transition of low-frequency cortical electric oscillations away from this critical point; conversely, we show that psychedelics may increase the information richness of cortical activity by tuning low-frequency cortical oscillations closer to this critical point. Finally, we analyze clinical electroencephalography (EEG) recordings from patients with disorders of consciousness (DOC) and show that assessing the proximity of slow cortical oscillatory electrodynamics to the edge-of-chaos critical point may be useful as an index of consciousness in the clinical setting.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DLUVJ82W\Toker et al. - 2022 - Consciousness is supported by near-critical slow c.pdf}
}

@article{tokudaConceptualModelsEntrainment2020,
  title = {Conceptual {{Models}} of {{Entrainment}}, {{Jet Lag}}, and {{Seasonality}}},
  author = {Tokuda, Isao T. and Schmal, Christoph and Ananthasubramaniam, Bharath and Herzel, Hanspeter},
  date = {2020},
  journaltitle = {Frontiers in Physiology},
  volume = {11},
  issn = {1664-042X},
  url = {https://www.frontiersin.org/articles/10.3389/fphys.2020.00334},
  urldate = {2023-01-26},
  abstract = {Understanding entrainment of circadian rhythms is a central goal of chronobiology. Many factors, such as period, amplitude, Zeitgeber strength, and daylength, govern entrainment ranges and phases of entrainment. We have tested whether simple amplitude-phase models can provide insight into the control of entrainment phases. Using global optimization, we derived conceptual models with just three free parameters (period, amplitude, and relaxation rate) that reproduce known phenotypic features of vertebrate clocks: phase response curves (PRCs) with relatively small phase shifts, fast re-entrainment after jet lag, and seasonal variability to track light onset or offset. Since optimization found multiple sets of model parameters, we could study this model ensemble to gain insight into the underlying design principles. We found complex associations between model parameters and entrainment features. Arnold onions of representative models visualize strong dependencies of entrainment on periods, relative Zeitgeber strength, and photoperiods. Our results support the use of oscillator theory as a framework for understanding the entrainment of circadian clocks.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J2WQM6XK\Tokuda et al. - 2020 - Conceptual Models of Entrainment, Jet Lag, and Sea.pdf}
}

@article{tomarVariabilityRandomnessInstantaneous2021,
  title = {Variability and {{Randomness}} of the {{Instantaneous Firing Rate}}},
  author = {Tomar, Rimjhim and Kostal, Lubomir},
  date = {2021},
  journaltitle = {Frontiers in Computational Neuroscience},
  volume = {15},
  issn = {1662-5188},
  url = {https://www.frontiersin.org/articles/10.3389/fncom.2021.620410},
  urldate = {2022-10-17},
  abstract = {The apparent stochastic nature of neuronal activity significantly affects the reliability of neuronal coding. To quantify the encountered fluctuations, both in neural data and simulations, the notions of variability and randomness of inter-spike intervals have been proposed and studied. In this article we focus on the concept of the instantaneous firing rate, which is also based on the spike timing. We use several classical statistical models of neuronal activity and we study the corresponding probability distributions of the instantaneous firing rate. To characterize the firing rate variability and randomness under different spiking regimes, we use different indices of statistical dispersion. We find that the relationship between the variability of interspike intervals and the instantaneous firing rate is not straightforward in general. Counter-intuitively, an increase in the randomness (based on entropy) of spike times may either decrease or increase the randomness of instantaneous firing rate, in dependence on the neuronal firing model. Finally, we apply our methods to experimental data, establishing that instantaneous rate analysis can indeed provide additional information about the spiking activity.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7QXQ6WKF\Tomar and Kostal - 2021 - Variability and Randomness of the Instantaneous Fi.pdf}
}

@article{toosiBrainlikeFlexibleVisual,
  title = {Brain-like {{Flexible Visual Inference}} by {{Harnessing Feedback-Feedforward Alignment}}},
  author = {Toosi, Tahereh and Issa, Elias B},
  abstract = {In natural vision, feedback connections support versatile visual inference capabilities such as making sense of the occluded or noisy bottom-up sensory information or mediating pure top-down processes such as imagination. However, the mechanisms by which the feedback pathway learns to give rise to these capabilities flexibly are not clear. We propose that top-down effects emerge through alignment between feedforward and feedback pathways, each optimizing its own objectives. To achieve this co-optimization, we introduce Feedback-Feedforward Alignment (FFA), a learning algorithm that leverages feedback and feedforward pathways as mutual credit assignment computational graphs, enabling alignment. In our study, we demonstrate the effectiveness of FFA in co-optimizing classification and reconstruction tasks on widely used MNIST and CIFAR10 datasets. Notably, the alignment mechanism in FFA endows feedback connections with emergent visual inference functions, including denoising, resolving occlusions, hallucination, and imagination. Moreover, FFA offers bio-plausibility compared to traditional backpropagation (BP) methods in implementation. By repurposing the computational graph of credit assignment into a goal-driven feedback pathway, FFA alleviates weight transport problems encountered in BP, enhancing the bio-plausibility of the learning algorithm. Our study presents FFA as a promising proof-of-concept for the mechanisms underlying how feedback connections in the visual cortex support flexible visual functions. This work also contributes to the broader field of visual inference underlying perceptual phenomena and has implications for developing more biologically inspired learning algorithms.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DCJAN3QN\Toosi and Issa - Brain-like Flexible Visual Inference by Harnessing.pdf}
}

@online{TopdownModulationSensory,
  title = {Top-down Modulation of Sensory Cortex Gates Perceptual Learning},
  doi = {10.1073/pnas.1712305114},
  url = {https://www.pnas.org/doi/10.1073/pnas.1712305114},
  urldate = {2023-08-07},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\EU9GQXGA\Top-down modulation of sensory cortex gates percep.pdf}
}

@article{treismanFeatureintegrationTheoryAttention1980,
  title = {A Feature-Integration Theory of Attention},
  author = {Treisman, Anne M. and Gelade, Garry},
  date = {1980-01-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {12},
  number = {1},
  pages = {97--136},
  issn = {0010-0285},
  doi = {10.1016/0010-0285(80)90005-5},
  url = {https://www.sciencedirect.com/science/article/pii/0010028580900055},
  urldate = {2023-01-30},
  abstract = {A new hypothesis about the role of focused attention is proposed. The feature-integration theory of attention suggests that attention must be directed serially to each stimulus in a display whenever conjunctions of more than one separable feature are needed to characterize or distinguish the possible objects presented. A number of predictions were tested in a variety of paradigms including visual search, texture segregation, identification and localization, and using both separable dimensions (shape and color) and local elements or parts of figures (lines, curves, etc. in letters) as the features to be integrated into complex wholes. The results were in general consistent with the hypothesis. They offer a new set of criteria for distinguishing separable from integral features and a new rationale for predicting which tasks will show attention limits and which will not.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6TU93IRF\\Treisman and Gelade - 1980 - A feature-integration theory of attention.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LD7TNNZ2\\0010028580900055.html}
}

@article{tremblaySingleTrialDecodingVisual2015,
  title = {Single-{{Trial Decoding}} of {{Visual Attention}} from {{Local Field Potentials}} in the {{Primate Lateral Prefrontal Cortex Is Frequency-Dependent}}},
  author = {Tremblay, S. and Doucet, G. and Pieper, F. and Sachs, A. and Martinez-Trujillo, J.},
  date = {2015-06-17},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {Journal of Neuroscience},
  volume = {35},
  number = {24},
  pages = {9038--9049},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1041-15.2015},
  url = {https://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.1041-15.2015},
  urldate = {2022-10-03},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NMKZVHYC\Tremblay et al. - 2015 - Single-Trial Decoding of Visual Attention from Loc.pdf}
}

@article{treueFeaturebasedAttentionInfluences1999,
  title = {Feature-Based Attention Influences Motion Processing Gain in Macaque Visual Cortex},
  author = {Treue, Stefan and Trujillo, Julio C. Martínez},
  date = {1999-06},
  journaltitle = {Nature},
  volume = {399},
  number = {6736},
  pages = {575--579},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/21176},
  url = {https://www.nature.com/articles/21176},
  urldate = {2023-01-30},
  abstract = {Changes in neural responses based on spatial attention have been demonstrated in many areas of visual cortex1,2,3,4, indicating that the neural correlate of attention is an enhanced response to stimuli at an attended location and reduced responses to stimuli elsewhere. Here we demonstrate non-spatial, feature-based attentional modulation of visual motion processing, and show that attention increases the gain of direction-selective neurons in visual cortical area MT without narrowing the direction-tuning curves. These findings place important constraints on the neural mechanisms of attention and we propose to unify the effects of spatial location, direction of motion and other features of the attended stimuli in a ‘feature similarity gain model’ of attention.},
  issue = {6736},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\JG82BEX4\Treue and Trujillo - 1999 - Feature-based attention influences motion processi.pdf}
}

@article{treueFeaturebasedAttentionInfluences1999a,
  title = {Feature-Based Attention Influences Motion Processing Gain in Macaque Visual Cortex},
  author = {Treue, Stefan and Trujillo, Julio C. Martínez},
  date = {1999-06},
  journaltitle = {Nature},
  volume = {399},
  number = {6736},
  pages = {575--579},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/21176},
  url = {https://www.nature.com/articles/21176},
  urldate = {2023-02-13},
  abstract = {Changes in neural responses based on spatial attention have been demonstrated in many areas of visual cortex1,2,3,4, indicating that the neural correlate of attention is an enhanced response to stimuli at an attended location and reduced responses to stimuli elsewhere. Here we demonstrate non-spatial, feature-based attentional modulation of visual motion processing, and show that attention increases the gain of direction-selective neurons in visual cortical area MT without narrowing the direction-tuning curves. These findings place important constraints on the neural mechanisms of attention and we propose to unify the effects of spatial location, direction of motion and other features of the attended stimuli in a ‘feature similarity gain model’ of attention.},
  issue = {6736},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SBNWCWX7\Treue and Trujillo - 1999 - Feature-based attention influences motion processi.pdf}
}

@article{truccoloPointProcessFramework2005,
  title = {A {{Point Process Framework}} for {{Relating Neural Spiking Activity}} to {{Spiking History}}, {{Neural Ensemble}}, and {{Extrinsic Covariate Effects}}},
  author = {Truccolo, Wilson and Eden, Uri T. and Fellows, Matthew R. and Donoghue, John P. and Brown, Emery N.},
  date = {2005-02},
  journaltitle = {Journal of Neurophysiology},
  volume = {93},
  number = {2},
  pages = {1074--1089},
  publisher = {American Physiological Society},
  issn = {0022-3077},
  doi = {10.1152/jn.00697.2004},
  url = {https://journals.physiology.org/doi/full/10.1152/jn.00697.2004},
  urldate = {2024-07-16},
  abstract = {Multiple factors simultaneously affect the spiking activity of individual neurons. Determining the effects and relative importance of these factors is a challenging problem in neurophysiology. We propose a statistical framework based on the point process likelihood function to relate a neuron's spiking probability to three typical covariates: the neuron's own spiking history, concurrent ensemble activity, and extrinsic covariates such as stimuli or behavior. The framework uses parametric models of the conditional intensity function to define a neuron's spiking probability in terms of the covariates. The discrete time likelihood function for point processes is used to carry out model fitting and model analysis. We show that, by modeling the logarithm of the conditional intensity function as a linear combination of functions of the covariates, the discrete time point process likelihood function is readily analyzed in the generalized linear model (GLM) framework. We illustrate our approach for both GLM and non-GLM likelihood functions using simulated data and multivariate single-unit activity data simultaneously recorded from the motor cortex of a monkey performing a visuomotor pursuit-tracking task. The point process framework provides a flexible, computationally efficient approach for maximum likelihood estimation, goodness-of-fit assessment, residual analysis, model selection, and neural decoding. The framework thus allows for the formulation and analysis of point process models of neural spiking activity that readily capture the simultaneous effects of multiple covariates and enables the assessment of their relative importance.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\HQWYG6AL\Truccolo et al. - 2005 - A Point Process Framework for Relating Neural Spik.pdf}
}

@article{tsotsosModelingVisualAttention1995,
  title = {Modeling Visual Attention via Selective Tuning},
  author = {Tsotsos, John K. and Culhane, Scan M. and Kei Wai, Winky Yan and Lai, Yuzhong and Davis, Neal and Nuflo, Fernando},
  date = {1995-10-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  series = {Special {{Volume}} on {{Computer Vision}}},
  volume = {78},
  number = {1},
  pages = {507--545},
  issn = {0004-3702},
  doi = {10.1016/0004-3702(95)00025-9},
  url = {https://www.sciencedirect.com/science/article/pii/0004370295000259},
  urldate = {2023-01-23},
  abstract = {A model for aspects of visual attention based on the concept of selective tuning is presented. It provides for a solution to the problems of selection in an image, information routing through the visual processing hierarchy and task-specific attentional bias. The central thesis is that attention acts to optimize the search procedure inherent in a solution to vision. It does so by selectively tuning the visual processing network which is accomplished by a top-down hierarchy of winner-take-all processes embedded within the visual processing pyramid. Comparisons to other major computational models of attention and to the relevant neurobiology are included in detail throughout the paper. The model has been implemented; several examples of its performance are shown. This model is a hypothesis for primate visual attention, but it also outperforms existing computational solutions for attention in machine vision and is highly appropriate to solving the problem in a robot vision system.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\IZXLLGNP\\Tsotsos et al. - 1995 - Modeling visual attention via selective tuning.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\UT5SAS3Z\\0004370295000259.html}
}

@article{udrescuAIFeynmanPhysicsinspired2020,
  title = {{{AI Feynman}}: {{A}} Physics-Inspired Method for Symbolic Regression},
  shorttitle = {{{AI Feynman}}},
  author = {Udrescu, Silviu-Marian and Tegmark, Max},
  date = {2020-04-17},
  journaltitle = {Science Advances},
  shortjournal = {Sci. Adv.},
  volume = {6},
  number = {16},
  pages = {eaay2631},
  issn = {2375-2548},
  doi = {10.1126/sciadv.aay2631},
  url = {https://www.science.org/doi/10.1126/sciadv.aay2631},
  urldate = {2023-02-07},
  abstract = {Our physics-inspired algorithm for symbolic regression is able to discover complex physics equations from mere tables of numbers.           ,                             A core challenge for both physics and artificial intelligence (AI) is symbolic regression: finding a symbolic expression that matches data from an unknown function. Although this problem is likely to be NP-hard in principle, functions of practical interest often exhibit symmetries, separability, compositionality, and other simplifying properties. In this spirit, we develop a recursive multidimensional symbolic regression algorithm that combines neural network fitting with a suite of physics-inspired techniques. We apply it to 100 equations from the               Feynman Lectures on Physics               , and it discovers all of them, while previous publicly available software cracks only 71; for a more difficult physics-based test set, we improve the state-of-the-art success rate from 15 to 90\%.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\AJRYIRZ5\Udrescu and Tegmark - 2020 - AI Feynman A physics-inspired method for symbolic.pdf}
}

@article{uhlhaasNeuralSynchronyBrain2006,
  title = {Neural {{Synchrony}} in {{Brain Disorders}}: {{Relevance}} for {{Cognitive Dysfunctions}} and {{Pathophysiology}}},
  shorttitle = {Neural {{Synchrony}} in {{Brain Disorders}}},
  author = {Uhlhaas, Peter J. and Singer, Wolf},
  date = {2006-10-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {52},
  number = {1},
  pages = {155--168},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2006.09.020},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627306007276},
  urldate = {2023-03-22},
  abstract = {Following the discovery of context-dependent synchronization of oscillatory neuronal responses in the visual system, novel methods of time series analysis have been developed for the examination of task- and performance-related oscillatory activity and its synchronization. Studies employing these advanced techniques revealed that synchronization of oscillatory responses in the β- and γ-band is involved in a variety of cognitive functions, such as perceptual grouping, attention-dependent stimulus selection, routing of signals across distributed cortical networks, sensory-motor integration, working memory, and perceptual awareness. Here, we review evidence that certain brain disorders, such as schizophrenia, epilepsy, autism, Alzheimer's disease, and Parkinson's are associated with abnormal neural synchronization. The data suggest close correlations between abnormalities in neuronal synchronization and cognitive dysfunctions, emphasizing the importance of temporal coordination. Thus, focused search for abnormalities in temporal patterning may be of considerable clinical relevance.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\P6VT3EWL\Uhlhaas and Singer - 2006 - Neural Synchrony in Brain Disorders Relevance for.pdf}
}

@article{uhlhaasNeuralSynchronyBrain2006a,
  title = {Neural {{Synchrony}} in {{Brain Disorders}}: {{Relevance}} for {{Cognitive Dysfunctions}} and {{Pathophysiology}}},
  shorttitle = {Neural {{Synchrony}} in {{Brain Disorders}}},
  author = {Uhlhaas, Peter J. and Singer, Wolf},
  date = {2006-10-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {52},
  number = {1},
  pages = {155--168},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2006.09.020},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627306007276},
  urldate = {2023-03-22},
  abstract = {Following the discovery of context-dependent synchronization of oscillatory neuronal responses in the visual system, novel methods of time series analysis have been developed for the examination of task- and performance-related oscillatory activity and its synchronization. Studies employing these advanced techniques revealed that synchronization of oscillatory responses in the β- and γ-band is involved in a variety of cognitive functions, such as perceptual grouping, attention-dependent stimulus selection, routing of signals across distributed cortical networks, sensory-motor integration, working memory, and perceptual awareness. Here, we review evidence that certain brain disorders, such as schizophrenia, epilepsy, autism, Alzheimer's disease, and Parkinson's are associated with abnormal neural synchronization. The data suggest close correlations between abnormalities in neuronal synchronization and cognitive dysfunctions, emphasizing the importance of temporal coordination. Thus, focused search for abnormalities in temporal patterning may be of considerable clinical relevance.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\B9J8THFL\Uhlhaas and Singer - 2006 - Neural Synchrony in Brain Disorders Relevance for.pdf}
}

@article{uhlhaasNeuralSynchronyCortical2009,
  title = {Neural Synchrony in Cortical Networks: History, Concept and Current Status},
  shorttitle = {Neural Synchrony in Cortical Networks},
  author = {Uhlhaas, Peter and Pipa, Gordon and Lima, Bruss and Melloni, Lucia and Neuenschwander, Sergio and Nikolić, Danko and Singer, Wolf},
  date = {2009},
  journaltitle = {Frontiers in Integrative Neuroscience},
  volume = {3},
  issn = {1662-5145},
  url = {https://www.frontiersin.org/articles/10.3389/neuro.07.017.2009},
  urldate = {2023-03-22},
  abstract = {Following the discovery of context-dependent synchronization of oscillatory neuronal responses in the visual system, the role of neural synchrony in cortical networks has been expanded to provide a general mechanism for the coordination of distributed neural activity patterns. In the current paper, we present an update of the status of this hypothesis through summarizing recent results from our laboratory that suggest important new insights regarding the mechanisms, function and relevance of this phenomenon. In the first part, we present recent results derived from animal experiments and mathematical simulations that provide novel explanations and mechanisms for zero and nero-zero phase lag synchronization. In the second part, we shall discuss the role of neural synchrony for expectancy during perceptual organization and its role in conscious experience. This will be followed by evidence that indicates that in addition to supporting conscious cognition, neural synchrony is abnormal in major brain disorders, such as schizophrenia and autism spectrum disorders. We conclude this paper with suggestions for further research as well as with critical issues that need to be addressed in future studies.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XU64IAJE\Uhlhaas et al. - 2009 - Neural synchrony in cortical networks history, co.pdf}
}

@article{umakanthaBridgingNeuronalCorrelations2021,
  title = {Bridging Neuronal Correlations and Dimensionality Reduction},
  author = {Umakantha, Akash and Morina, Rudina and Cowley, Benjamin R. and Snyder, Adam C. and Smith, Matthew A. and Yu, Byron M.},
  date = {2021-09-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {17},
  pages = {2740-2754.e12},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2021.06.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627321004694},
  urldate = {2023-01-13},
  abstract = {Two commonly used approaches to study interactions among neurons are spike count correlation, which describes pairs of neurons, and dimensionality reduction, applied to a population of neurons. Although both approaches have been used to study trial-to-trial neuronal variability correlated among neurons, they are often used in isolation and have not been directly related. We first established concrete mathematical and empirical relationships between pairwise correlation and metrics of population-wide covariability based on dimensionality reduction. Applying these insights to macaque V4 population recordings, we found that the previously reported decrease in mean pairwise correlation associated with attention stemmed from three distinct changes in population-wide covariability. Overall, our work builds the intuition and formalism to bridge between pairwise correlation and population-wide covariability and presents a cautionary tale about the inferences one can make about population activity by using a single statistic, whether it be mean pairwise correlation or dimensionality.},
  langid = {english},
  keywords = {dimensionality reduction,neuronal population,spatial attention,spike count correlation,visual area V4},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\J495QWHK\\Umakantha et al. - 2021 - Bridging neuronal correlations and dimensionality .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BHPI4WFQ\\S0896627321004694.html}
}

@online{UnifiedTheoryEfficient,
  title = {✅ {{Toward}} a Unified Theory of Efficient, Predictive, and Sparse Coding},
  doi = {10.1073/pnas.1711114115},
  url = {https://www.pnas.org/doi/10.1073/pnas.1711114115},
  urldate = {2023-05-19},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KM746HFY\\pnas.1711114115.sapp.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\WIPDHQ4C\\Toward a unified theory of efficient, predictive, .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RZER7YE8\\pnas.html}
}

@online{UniversalExplorationNature,
  title = {Universal Exploration | {{Nature Physics}}},
  url = {https://www.nature.com/articles/nphys3445},
  urldate = {2022-10-05},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Z9CZ3C37\\Universal exploration  Nature Physics.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\T6ESA2L7\\nphys3445.html}
}

@article{unossonSpatiotemporalModelReveal2021,
  title = {A Spatio-Temporal Model to Reveal Oscillator Phenotypes in Molecular Clocks: {{Parameter}} Estimation Elucidates Circadian Gene Transcription Dynamics in Single-Cells},
  shorttitle = {A Spatio-Temporal Model to Reveal Oscillator Phenotypes in Molecular Clocks},
  author = {Unosson, Måns and Brancaccio, Marco and Hastings, Michael and Johansen, Adam M. and Finkenstädt, Bärbel},
  date = {2021-12-17},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {17},
  number = {12},
  pages = {e1009698},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009698},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009698},
  urldate = {2023-02-17},
  abstract = {We propose a stochastic distributed delay model together with a Markov random field prior and a measurement model for bioluminescence-reporting to analyse spatio-temporal gene expression in intact networks of cells. The model describes the oscillating time evolution of molecular mRNA counts through a negative transcriptional-translational feedback loop encoded in a chemical Langevin equation with a probabilistic delay distribution. The model is extended spatially by means of a multiplicative random effects model with a first order Markov random field prior distribution. Our methodology effectively separates intrinsic molecular noise, measurement noise, and extrinsic noise and phenotypic variation driving cell heterogeneity, while being amenable to parameter identification and inference. Based on the single-cell model we propose a novel computational stability analysis that allows us to infer two key characteristics, namely the robustness of the oscillations, i.e. whether the reaction network exhibits sustained or damped oscillations, and the profile of the regulation, i.e. whether the inhibition occurs over time in a more distributed versus a more direct manner, which affects the cells’ ability to phase-shift to new schedules. We show how insight into the spatio-temporal characteristics of the circadian feedback loop in the suprachiasmatic nucleus (SCN) can be gained by applying the methodology to bioluminescence-reported expression of the circadian core clock gene Cry1 across mouse SCN tissue. We find that while (almost) all SCN neurons exhibit robust cell-autonomous oscillations, the parameters that are associated with the regulatory transcription profile give rise to a spatial division of the tissue between the central region whose oscillations are resilient to perturbation in the sense that they maintain a high degree of synchronicity, and the dorsal region which appears to phase shift in a more diversified way as a response to large perturbations and thus could be more amenable to entrainment.},
  langid = {english},
  keywords = {Algorithms,Circadian oscillators,Circadian rhythms,Entropy,Gene expression,Messenger RNA,Neurons,Transcriptional control},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\D2IR4TEF\Unosson et al. - 2021 - A spatio-temporal model to reveal oscillator pheno.pdf}
}

@article{urbainWhiskingRelatedChangesNeuronal2015,
  title = {Whisking-{{Related Changes}} in {{Neuronal Firing}} and {{Membrane Potential Dynamics}} in the {{Somatosensory Thalamus}} of {{Awake Mice}}},
  author = {Urbain, Nadia and Salin, Paul A. and Libourel, Paul-Antoine and Comte, Jean-Christophe and Gentet, Luc J. and Petersen, Carl C. H.},
  date = {2015-10-27},
  journaltitle = {Cell Reports},
  shortjournal = {Cell Reports},
  volume = {13},
  number = {4},
  eprint = {26489463},
  eprinttype = {pmid},
  pages = {647--656},
  publisher = {Elsevier},
  issn = {2211-1247},
  doi = {10.1016/j.celrep.2015.09.029},
  url = {https://www.cell.com/cell-reports/abstract/S2211-1247(15)01040-2},
  urldate = {2024-07-08},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J92PBG8A\Urbain et al. - 2015 - Whisking-Related Changes in Neuronal Firing and Me.pdf}
}

@article{urbanczikLearningDendriticPrediction2014,
  title = {Learning by the {{Dendritic Prediction}} of {{Somatic Spiking}}},
  author = {Urbanczik, Robert and Senn, Walter},
  date = {2014-02-05},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {81},
  number = {3},
  pages = {521--528},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.11.030},
  url = {https://www.sciencedirect.com/science/article/pii/S0896627313011276},
  urldate = {2023-04-03},
  abstract = {Recent modeling of spike-timing-dependent plasticity indicates that plasticity involves as a third factor a local dendritic potential, besides pre- and postsynaptic firing times. We present a simple compartmental neuron model together with a non-Hebbian, biologically plausible learning rule for dendritic synapses where plasticity is modulated by these three factors. In functional terms, the rule seeks to minimize discrepancies between somatic firings and a local dendritic potential. Such prediction errors can arise in our model from stochastic fluctuations as well as from synaptic input, which directly targets the soma. Depending on the nature of this direct input, our plasticity rule subserves supervised or unsupervised learning. When a reward signal modulates the learning rate, reinforcement learning results. Hence a single plasticity rule supports diverse learning paradigms.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DV6ACPH6\\1-s2.0-S0896627313011276-mmc1.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HEAX2HDL\\Urbanczik and Senn - 2014 - Learning by the Dendritic Prediction of Somatic Sp.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JMVANM5W\\S0896627313011276.html}
}

@article{usreyCorticofugalCircuitsCommunication2019,
  title = {Corticofugal {{Circuits}}: {{Communication Lines}} from the {{Cortex}} to the {{Rest}} of the {{Brain}}},
  shorttitle = {Corticofugal {{Circuits}}},
  author = {Usrey, W. Martin and Sherman, S. Murray},
  date = {2019-02-15},
  journaltitle = {The Journal of comparative neurology},
  shortjournal = {J Comp Neurol},
  volume = {527},
  number = {3},
  eprint = {29524229},
  eprinttype = {pmid},
  pages = {640--650},
  issn = {0021-9967},
  doi = {10.1002/cne.24423},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6131091/},
  urldate = {2023-08-01},
  abstract = {Pyramidal cells in cortical layers 5 and 6 are the only cells in the cerebral cortex with axons that leave the cortex to influence the thalamus. Layer 6 cells provide modulatory feedback input to all thalamic nuclei. Layer 5 cells provide driving input to higher order thalamic nuclei and do not innervate first order nuclei, which get their driving inputs from subcortical sources. Higher order nuclei innervated by layer 5 cells thus seem to be involved with cortico-thalamo-cortical communication. The layer 5 axons branch to also target additional subcortical structures that mediate interactions with the external environment. These corticofugal pathways represent the only means by which the cortex influences the rest of the neuraxis and thus are essential for proper cortical function and species survival. Here we review current understanding of the corticofugal pathways from layers 5 and 6 and speculate on their functional contributions to neural processing and behavior.,  , Pyramidal cells in cortical layers 5 and 6 are the only cells in the cerebral cortex with axons that leave the cortex to influence the thalamus. Layer 6 cells provide modulatory feedback input to all thalamic nuclei, whereas layer 5 cells provide driving input to higher order thalamic nuclei. Here, we review current understanding of the corticofugal pathways and speculate on their functional contributions to neural processing and behavior.},
  pmcid = {PMC6131091},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\U5A4P9ZX\Usrey and Sherman - 2019 - Corticofugal Circuits Communication Lines from th.pdf}
}

@article{vankempenTopdownCoordinationLocal2021,
  title = {Top-down Coordination of Local Cortical State during Selective Attention},
  author = {van Kempen, Jochem and Gieselmann, Marc A. and Boyd, Michael and Steinmetz, Nicholas A. and Moore, Tirin and Engel, Tatiana A. and Thiele, Alexander},
  options = {useprefix=true},
  date = {2021-03},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {109},
  number = {5},
  pages = {894-904.e8},
  issn = {08966273},
  doi = {10.1016/j.neuron.2020.12.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627320309958},
  urldate = {2021-03-11},
  abstract = {Spontaneous fluctuations in cortical excitability influence sensory processing and behavior. These fluctuations, long thought to reflect global changes in cortical state, were recently found to be modulated locally within a retinotopic map during spatially selective attention. We report that periods of vigorous (On) and faint (Off) spiking activity, the signature of cortical state fluctuations, are coordinated across brain areas with retinotopic precision. Top-down attention enhanced interareal local state coordination, traversing along the reverse cortical hierarchy. The extent of local state coordination between areas was predictive of behavioral performance. Our results show that cortical state dynamics are shared across brain regions, modulated by cognitive demands and relevant for behavior.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\M9VZXM8Y\van Kempen et al. - 2021 - Top-down coordination of local cortical state duri.pdf}
}

@article{vankerkoerleLayerspecificityEffectsAttention2017,
  title = {Layer-Specificity in the Effects of Attention and Working Memory on Activity in Primary Visual Cortex},
  author = {van Kerkoerle, Timo and Self, Matthew W. and Roelfsema, Pieter R.},
  options = {useprefix=true},
  date = {2017-01-05},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {13804},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/ncomms13804},
  url = {https://www.nature.com/articles/ncomms13804},
  urldate = {2023-01-23},
  abstract = {Neuronal activity in early visual cortex depends on attention shifts but the contribution to working memory has remained unclear. Here, we examine neuronal activity in the different layers of the primary visual cortex (V1) in an attention-demanding and a working memory task. A current-source density analysis reveales top-down inputs in the superficial layers and layer 5, and an increase in neuronal firing rates most pronounced in the superficial and deep layers and weaker in input layer 4. This increased activity is strongest in the attention task but it is also highly reliable during working memory delays. A visual mask erases the V1 memory activity, but it reappeares at a later point in time. These results provide new insights in the laminar circuits involved in the top-down modulation of activity in early visual cortex in the presence and absence of visual stimuli.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RWKZW6DI\van Kerkoerle et al. - 2017 - Layer-specificity in the effects of attention and .pdf}
}

@article{vankerkoerleLayerspecificityEffectsAttention2017a,
  title = {Layer-Specificity in the Effects of Attention and Working Memory on Activity in Primary Visual Cortex},
  author = {van Kerkoerle, Timo and Self, Matthew W. and Roelfsema, Pieter R.},
  options = {useprefix=true},
  date = {2017-01-05},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {8},
  number = {1},
  pages = {13804},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/ncomms13804},
  url = {https://www.nature.com/articles/ncomms13804},
  urldate = {2023-01-31},
  abstract = {Neuronal activity in early visual cortex depends on attention shifts but the contribution to working memory has remained unclear. Here, we examine neuronal activity in the different layers of the primary visual cortex (V1) in an attention-demanding and a working memory task. A current-source density analysis reveales top-down inputs in the superficial layers and layer 5, and an increase in neuronal firing rates most pronounced in the superficial and deep layers and weaker in input layer 4. This increased activity is strongest in the attention task but it is also highly reliable during working memory delays. A visual mask erases the V1 memory activity, but it reappeares at a later point in time. These results provide new insights in the laminar circuits involved in the top-down modulation of activity in early visual cortex in the presence and absence of visual stimuli.},
  issue = {1},
  langid = {english},
  keywords = {Attention,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FKT2NQ9F\van Kerkoerle et al. - 2017 - Layer-specificity in the effects of attention and .pdf}
}

@article{vanrullenTimeCourseVisual2001,
  title = {✅ {{The}} Time Course of Visual Processing: From Early Perception to Decision-Making},
  shorttitle = {The Time Course of Visual Processing},
  author = {VanRullen, R. and Thorpe, S. J.},
  date = {2001-05-15},
  journaltitle = {Journal of Cognitive Neuroscience},
  shortjournal = {J Cogn Neurosci},
  volume = {13},
  number = {4},
  eprint = {11388919},
  eprinttype = {pmid},
  pages = {454--461},
  issn = {0898-929X},
  doi = {10.1162/08989290152001880},
  abstract = {Experiments investigating the mechanisms involved in visual processing often fail to separate low-level encoding mechanisms from higher-level behaviorally relevant ones. Using an alternating dual-task event-related potential (ERP) experimental paradigm (animals or vehicles categorization) where targets of one task are intermixed among distractors of the other, we show that visual categorization of a natural scene involves different mechanisms with different time courses: a perceptual, task-independent mechanism, followed by a task-related, category-independent process. Although average ERP responses reflect the visual category of the stimulus shortly after visual processing has begun (e.g. 75-80 msec), this difference is not correlated with the subject's behavior until 150 msec poststimulus.},
  langid = {english},
  keywords = {Adult,Animals,Behavior,Decision Making,Evoked Potentials Visual,Female,Humans,Male,Mental Processes,Middle Aged,Perceptual Masking,Reaction Time,Transportation,Visual Perception},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8DSYIS3S\VanRullen and Thorpe - 2001 - The time course of visual processing from early p.pdf}
}

@article{vansoestNonlinearPhenomenaModels2020,
  title = {Nonlinear Phenomena in Models of the Circadian Clock},
  author = {van Soest, Inge and del Olmo, Marta and Schmal, Christoph and Herzel, Hanspeter},
  options = {useprefix=true},
  date = {2020-09-30},
  journaltitle = {Journal of The Royal Society Interface},
  volume = {17},
  number = {170},
  pages = {20200556},
  publisher = {Royal Society},
  doi = {10.1098/rsif.2020.0556},
  url = {https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0556},
  urldate = {2023-01-26},
  abstract = {The mammalian circadian clock is well-known to be important for our sleep–wake cycles, as well as other daily rhythms such as temperature regulation, hormone release or feeding–fasting cycles. Under normal conditions, these daily cyclic events follow 24 h limit cycle oscillations, but under some circumstances, more complex nonlinear phenomena, such as the emergence of chaos, or the splitting of physiological dynamics into oscillations with two different periods, can be observed. These nonlinear events have been described at the organismic and tissue level, but whether they occur at the cellular level is still unknown. Our results show that period-doubling, chaos and splitting appear in different models of the mammalian circadian clock with interlocked feedback loops and in the absence of external forcing. We find that changes in the degradation of clock genes and proteins greatly alter the dynamics of the system and can induce complex nonlinear events. Our findings highlight the role of degradation rates in determining the oscillatory behaviour of clock components, and can contribute to the understanding of molecular mechanisms of circadian dysregulation.},
  keywords = {bifurcation,circadian clock,feedback regulation,mathematical modelling,nonlinear phenomena},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8V2BXZDH\van Soest et al. - 2020 - Nonlinear phenomena in models of the circadian clo.pdf}
}

@article{vargaDendriticCodingMultiple2011,
  title = {Dendritic Coding of Multiple Sensory Inputs in Single Cortical Neurons in Vivo},
  author = {Varga, Zsuzsanna and Jia, Hongbo and Sakmann, Bert and Konnerth, Arthur},
  date = {2011-09-13},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {37},
  pages = {15420--15425},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1112355108},
  url = {https://www.pnas.org/doi/10.1073/pnas.1112355108},
  urldate = {2022-09-30},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8ADSB5LC\Varga et al. - 2011 - Dendritic coding of multiple sensory inputs in sin.pdf}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-03-22},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\CWYG4JY9\\Vaswani et al. - 2017 - Attention Is All You Need.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P8F4SKQW\\1706.html}
}

@article{veinanteCorticothalamicProjectionsLayer2000,
  title = {Corticothalamic Projections from Layer 5 of the Vibrissal Barrel Cortex in the Rat},
  author = {Veinante, Pierre and Lavallée, Philippe and Deschênes, Martin},
  date = {2000},
  journaltitle = {Journal of Comparative Neurology},
  volume = {424},
  number = {2},
  pages = {197--204},
  issn = {1096-9861},
  doi = {10.1002/1096-9861(20000821)424:2<197::AID-CNE1>3.0.CO;2-6},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/1096-9861%2820000821%29424%3A2%3C197%3A%3AAID-CNE1%3E3.0.CO%3B2-6},
  urldate = {2023-04-11},
  abstract = {This study bears on the projections of layer 5 cells of the vibrissal sensory cortex to the somatosensory thalamus in rats. Small groups of cells were labeled with biotinylated dextran amine (BDA), and their axonal arborizations were individually reconstructed from horizontal sections counterstained for cytochrome oxidase. Results show that the vast majority (∼95\%) of layer 5 axons that innervate the somatosensory thalamus are collaterals of corticofugal fibers that project to the brainstem. The anterior pretectal nucleus, the deep layers of the superior colliculus, and the pontine nuclei are among the structures most often coinnervated. In the thalamus, layer 5 axons terminate exclusively in the dorsal part of the posterior group (Po), where they form clusters of large terminations. Because dorsal Po projects to multiple cortical areas, we sought to determine whether all recipient areas return a layer 5 projection to this part of the thalamus. Additional experiments using fluoro-gold and BDA injections provided evidence that the primary somatosensory area is the sole source of layer 5 projections to dorsal Po but that this thalamic region receives convergent layer 6 projections from the primary and second somatosensory areas and from the motor and insular cortices. These results show that layer 5 projections do not overlap in associative thalamic nuclei, thus defining area-related subdivisions. Furthermore, the coinnervation of brainstem nuclei by layer 5 CT axons suggests that this pathway conveys to the thalamus a copy of the cortical output aimed at brainstem structures. J. Comp. Neurol. 424:197–204, 2000. © 2000 Wiley-Liss, Inc.},
  langid = {english},
  keywords = {association thalamic nuclei,pontine nuclei,posterior group nucleus,pyramidal cells,superior colliculus,whiskers},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XC5HDZ3F\1096-9861(20000821)4242197AID-CNE13.0.html}
}

@online{venessOnlineLearningGated2017,
  title = {Online {{Learning}} with {{Gated Linear Networks}}},
  author = {Veness, Joel and Lattimore, Tor and Bhoopchand, Avishkar and Grabska-Barwinska, Agnieszka and Mattern, Christopher and Toth, Peter},
  date = {2017-12-05},
  eprint = {1712.01897},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1712.01897},
  urldate = {2023-03-23},
  abstract = {This paper describes a family of probabilistic architectures designed for online learning under the logarithmic loss. Rather than relying on non-linear transfer functions, our method gains representational power by the use of data conditioning. We state under general conditions a learnable capacity theorem that shows this approach can in principle learn any bounded Borel-measurable function on a compact subset of euclidean space; the result is stronger than many universality results for connectionist architectures because we provide both the model and the learning procedure for which convergence is guaranteed.},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Theory,Computer Science - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2TWU4GRV\\Veness et al. - 2017 - Online Learning with Gated Linear Networks.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\P7IY5AIZ\\1712.html}
}

@article{viaenePropertiesThalamicProjection2011,
  title = {Properties of the Thalamic Projection from the Posterior Medial Nucleus to Primary and Secondary Somatosensory Cortices in the Mouse},
  author = {Viaene, Angela N. and Petrof, Iraklis and Sherman, S. Murray},
  date = {2011-11},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {44},
  pages = {18156--18161},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1114828108},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.1114828108},
  urldate = {2023-08-02},
  abstract = {Primary somatosensory cortex (S1) receives two distinct classes of thalamocortical input via the lemniscal and paralemniscal pathways, the former via ventral posterior medial nucleus (VPM), and the latter, from the posterior medial nucleus (POm). These projections have been described as parallel thalamocortical pathways. Although the VPM thalamocortical projection has been studied in depth, several details of the POm projection to S1 are unknown. We studied the synaptic properties and anatomical features in the mouse of the projection from POm to all layers of S1 and to layer 4 of secondary somatosensory cortex (S2). Neurons in S1 responded to stimulation of POm with what has been termed Class 2 properties (paired-pulse facilitation, small initial excitatory postsynaptic potentials (EPSPs), a graded activation profile, and a metabotropic receptor component; thought to be modulatory), whereas neurons in layer 4 of S2 responded with Class 1A properties (paired-pulse depression, large initial EPSPs, an all-or-none activation profile, and no metabotropic receptor component, thought to be a main information input). Also, labeling from POm produced small boutons in S1, whereas both small and large boutons were found in S2. Our data suggest that the lemniscal and paralemniscal projections should not be thought of as parallel information pathways to S1 and that the paralemniscal projection may instead provide modulatory inputs to S1.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SA3NFXI9\Viaene et al. - 2011 - Properties of the thalamic projection from the pos.pdf}
}

@article{vilelaAreInputParameters2009,
  title = {Are the Input Parameters of White Noise Driven Integrate and Fire Neurons Uniquely Determined by Rate and {{CV}}?},
  author = {Vilela, Rafael D. and Lindner, Benjamin},
  date = {2009-03-07},
  journaltitle = {Journal of Theoretical Biology},
  shortjournal = {Journal of Theoretical Biology},
  volume = {257},
  number = {1},
  pages = {90--99},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2008.11.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0022519308005833},
  urldate = {2022-10-21},
  abstract = {Integrate and fire (IF) neurons have found widespread applications in computational neuroscience. Particularly important are stochastic versions of these models where the driving consists of a synaptic input modeled as white Gaussian noise with mean μ and noise intensity D. Different IF models have been proposed, the firing statistics of which depends nontrivially on the input parameters μ and D. In order to compare these models among each other, one must first specify the correspondence between their parameters. This can be done by determining which set of parameters (μ,D) of each model is associated with a given set of basic firing statistics as, for instance, the firing rate and the coefficient of variation (CV) of the interspike interval (ISI). However, it is not clear a priori whether for a given firing rate and CV there is only one unique choice of input parameters for each model. Here we review the dependence of rate and CV on input parameters for the perfect, leaky, and quadratic IF neuron models and show analytically that indeed in these three models the firing rate and the CV uniquely determine the input parameters.},
  langid = {english},
  keywords = {Neuronal models},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\B99MXWT8\\Vilela and Lindner - 2009 - Are the input parameters of white noise driven int.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\SGPRNI8P\\S0022519308005833.html}
}

@article{viswanathanOptimizingSuccessRandom1999,
  title = {Optimizing the Success of Random Searches},
  author = {Viswanathan, G. M. and Buldyrev, Sergey V. and Havlin, Shlomo and da Luz, M. G. E. and Raposo, E. P. and Stanley, H. Eugene},
  options = {useprefix=true},
  date = {1999-10},
  journaltitle = {Nature},
  volume = {401},
  number = {6756},
  pages = {911--914},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/44831},
  url = {https://www.nature.com/articles/44831},
  urldate = {2024-04-20},
  abstract = {We address the general question of what is the best statistical strategy to adapt in order to search efficiently for randomly located objects (‘target sites’). It is often assumed in foraging theory that the flight lengths of a forager have a characteristic scale: from this assumption gaussian, Rayleigh and other classical distributions with well-defined variances have arisen. However, such theories cannot explain the long-tailed power-law distributions1,2 of flight lengths or flight times3,4,5,6 that are observed experimentally. Here we study how the search efficiency depends on the probability distribution of flight lengths taken by a forager that can detect target sites only in its limited vicinity. We show that, when the target sites are sparse and can be visited any number of times, an inverse square power-law distribution of flight lengths, corresponding to Lévy flight motion, is an optimal strategy. We test the theory by analysing experimental foraging data on selected insect, mammal and bird species, and find that they are consistent with the predicted inverse square power-law distributions.},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DYSDXZM2\Viswanathan et al. - 1999 - Optimizing the success of random searches.pdf}
}

@article{vogelsNeuralNetworkDynamics2005,
  title = {Neural {{Network Dynamics}}},
  author = {Vogels, Tim P. and Rajan, Kanaka and Abbott, L.F.},
  date = {2005},
  journaltitle = {Annual Review of Neuroscience},
  volume = {28},
  number = {1},
  eprint = {16022600},
  eprinttype = {pmid},
  pages = {357--376},
  doi = {10.1146/annurev.neuro.28.061604.135637},
  url = {https://doi.org/10.1146/annurev.neuro.28.061604.135637},
  urldate = {2023-12-17},
  abstract = {Neural network modeling is often concerned with stimulus-driven responses, but most of the activity in the brain is internally generated. Here, we review network models of internally generated activity, focusing on three types of network dynamics: (a) sustained responses to transient stimuli, which provide a model of working memory; (b) oscillatory network activity; and (c) chaotic activity, which models complex patterns of background spiking in cortical and other circuits. We also review propagation of stimulus-driven activity through spontaneously active networks. Exploring these aspects of neural network dynamics is critical for understanding how neural circuits produce cognitive function.},
  keywords = {balance,memory,signal propagation,states,sustained activity},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\7YPBEJVB\Vogels et al. - 2005 - Neural Network Dynamics.pdf}
}

@article{vogelsNEURALNETWORKDYNAMICS2005,
  title = {{{NEURAL NETWORK DYNAMICS}}},
  author = {Vogels, Tim P. and Rajan, Kanaka and Abbott, L.F.},
  date = {2005-07-21},
  journaltitle = {Annual Review of Neuroscience},
  shortjournal = {Annu. Rev. Neurosci.},
  volume = {28},
  number = {1},
  pages = {357--376},
  issn = {0147-006X, 1545-4126},
  doi = {10.1146/annurev.neuro.28.061604.135637},
  url = {https://www.annualreviews.org/doi/10.1146/annurev.neuro.28.061604.135637},
  urldate = {2023-12-17},
  abstract = {Neural network modeling is often concerned with stimulus-driven responses, but most of the activity in the brain is internally generated. Here, we review network models of internally generated activity, focusing on three types of network dynamics: (a) sustained responses to transient stimuli, which provide a model of working memory; (b) oscillatory network activity; and (c) chaotic activity, which models complex patterns of background spiking in cortical and other circuits. We also review propagation of stimulus-driven activity through spontaneously active networks. Exploring these aspects of neural network dynamics is critical for understanding how neural circuits produce cognitive function.},
  langid = {english}
}

@article{vogelsSignalPropagationLogic2005,
  title = {Signal Propagation and Logic Gating in Networks of Integrate-and-Fire Neurons},
  author = {Vogels, Tim P. and Abbott, L. F.},
  date = {2005-11-16},
  journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  shortjournal = {J Neurosci},
  volume = {25},
  number = {46},
  eprint = {16291952},
  eprinttype = {pmid},
  pages = {10786--10795},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.3508-05.2005},
  abstract = {Transmission of signals within the brain is essential for cognitive function, but it is not clear how neural circuits support reliable and accurate signal propagation over a sufficiently large dynamic range. Two modes of propagation have been studied: synfire chains, in which synchronous activity travels through feedforward layers of a neuronal network, and the propagation of fluctuations in firing rate across these layers. In both cases, a sufficient amount of noise, which was added to previous models from an external source, had to be included to support stable propagation. Sparse, randomly connected networks of spiking model neurons can generate chaotic patterns of activity. We investigate whether this activity, which is a more realistic noise source, is sufficient to allow for signal transmission. We find that, for rate-coded signals but not for synfire chains, such networks support robust and accurate signal reproduction through up to six layers if appropriate adjustments are made in synaptic strengths. We investigate the factors affecting transmission and show that multiple signals can propagate simultaneously along different pathways. Using this feature, we show how different types of logic gates can arise within the architecture of the random network through the strengthening of specific synapses.},
  langid = {english},
  pmcid = {PMC6725859},
  keywords = {Action Potentials,Ion Channel Gating,Logic,Models Neurological,Neural Networks Computer,Neural Pathways,Neurons,Signal Transduction},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\KVBY9LXW\Vogels and Abbott - 2005 - Signal propagation and logic gating in networks of.pdf}
}

@article{volohCellTypeSpecificBurst2018a,
  title = {Cell-{{Type Specific Burst Firing Interacts}} with {{Theta}} and {{Beta Activity}} in {{Prefrontal Cortex During Attention States}}},
  author = {Voloh, B and Womelsdorf, T},
  date = {2018-12-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {28},
  number = {12},
  pages = {4348--4364},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhx287},
  url = {https://doi.org/10.1093/cercor/bhx287},
  urldate = {2023-01-17},
  abstract = {Population-level theta and beta band activity in anterior cingulate and prefrontal cortices (ACC/PFC) are prominent signatures of self-controlled, adaptive behaviors. But how these rhythmic activities are linked to cell-type specific activity has remained unclear. Here, we suggest such a cell-to-systems level linkage. We found that the rate of burst spiking events is enhanced particularly during attention states and that attention-specific burst spikes have a unique temporal relationship to local theta and beta band population-level activities. For the 5–10 Hz theta frequency range, bursts coincided with transient increases of local theta power relative to nonbursts, particularly for bursts of putative interneurons. For the 16–30 Hz beta frequency, bursts of putative interneurons phase synchronized stronger than nonbursts, and were associated with larger beta power modulation. In contrast, burst of putative pyramidal cells showed similar beta power modulation as nonbursts, but were accompanied by stronger beta power only when they occurred early in the beta cycle. These findings suggest that in the ACC/PFC during attention states, mechanisms underlying burst firing are intimately linked to narrow band population-level activities, providing a cell-type specific window into rhythmic inhibitory gating and the emergence of rhythmically coherent network states during goal directed behavior.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\S5P7ITHJ\\Voloh and Womelsdorf - 2018 - Cell-Type Specific Burst Firing Interacts with The.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JG53UWXW\\4608049.html}
}

@article{vuLectureEntropyMutual,
  title = {Lecture 2: {{Entropy}} and Mutual Information},
  author = {Vu, Mai},
  journaltitle = {Electrical and Computer Engineering},
  pages = {8},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\IGNQUY2E\Vu - Lecture 2 Entropy and mutual information.pdf}
}

@article{wangAllenMouseBrain2020,
  title = {The {{Allen Mouse Brain Common Coordinate Framework}}: {{A 3D Reference Atlas}}},
  shorttitle = {The {{Allen Mouse Brain Common Coordinate Framework}}},
  author = {Wang, Quanxin and Ding, Song-Lin and Li, Yang and Royall, Josh and Feng, David and Lesnar, Phil and Graddis, Nile and Naeemi, Maitham and Facer, Benjamin and Ho, Anh and Dolbeare, Tim and Blanchard, Brandon and Dee, Nick and Wakeman, Wayne and Hirokawa, Karla E. and Szafer, Aaron and Sunkin, Susan M. and Oh, Seung Wook and Bernard, Amy and Phillips, John W. and Hawrylycz, Michael and Koch, Christof and Zeng, Hongkui and Harris, Julie A. and Ng, Lydia},
  date = {2020-05-14},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {181},
  number = {4},
  pages = {936-953.e20},
  issn = {0092-8674},
  doi = {10.1016/j.cell.2020.04.007},
  url = {https://www.sciencedirect.com/science/article/pii/S0092867420304025},
  urldate = {2023-01-09},
  abstract = {Recent large-scale collaborations are generating major surveys of cell types and connections in the mouse brain, collecting large amounts of data across modalities, spatial scales, and brain areas. Successful integration of these data requires a standard 3D reference atlas. Here, we present the Allen Mouse Brain Common Coordinate Framework (CCFv3) as such a resource. We constructed an average template brain at 10~μm voxel resolution by interpolating high resolution in-plane serial two-photon tomography images with 100~μm z-sampling from 1,675 young adult C57BL/6J mice. Then, using multimodal reference data, we parcellated the entire brain directly in 3D, labeling every voxel with a brain structure spanning 43 isocortical areas and their layers, 329 subcortical gray matter structures, 81 fiber tracts, and 8 ventricular structures. CCFv3 can be used to analyze, visualize, and integrate multimodal and multiscale datasets in 3D and is openly accessible (https://atlas.brain-map.org/).},
  langid = {english},
  keywords = {3D brain atlas,average mouse brain,brain anatomy,brain parcellation,CCFv3,common coordinate framework,fiber tracts,mouse cortex,reference atlas,transgenic mice},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\YMNMSIL6\\Wang et al. - 2020 - The Allen Mouse Brain Common Coordinate Framework.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\C733IGKW\\S0092867420304025.html}
}

@article{wangControlFiringMode1993,
  title = {Control of Firing Mode of Corticotectal and Corticopontine Layer {{V}} Burst-Generating Neurons by Norepinephrine, Acetylcholine, and {{1S}},{{3R- ACPD}}},
  author = {Wang, Z. and McCormick, D. A.},
  date = {1993-05-01},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {13},
  number = {5},
  eprint = {8386756},
  eprinttype = {pmid},
  pages = {2199--2216},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.13-05-02199.1993},
  url = {https://www.jneurosci.org/content/13/5/2199},
  urldate = {2023-01-16},
  abstract = {The ionic mechanisms by which the firing mode of layer V burst- generating neurons is modulated by noradrenergic, cholinergic, and glutamate metabotropic receptors were investigated with intracellular and extracellular recordings obtained in slices of guinea pig sensorimotor and primary visual cortices maintained in vitro. Extracellular and intracellular recordings revealed that a subset of layer V cells spontaneously generated bursts of three to six action potentials with an interburst frequency of 0.2–4 Hz. Depolarization of these cells with the intracellular injection of current inhibited burst firing and switched the cells to the tonic, single-spike mode of action potential generation. Intracellular recording from retrogradely labeled layer V pyramidal cells that project to either the superior colliculus or pontine nuclei revealed that a substantial portion of these are burst-generating cells. Application of norepinephrine (NE), the glutamate metabotropic receptor agonist 1S,3R-aminocyclopentane-1,3- dicarboxylic acid (ACPD), or ACh to layer V burst-generating cells resulted in depolarization and a subsequent shift in firing pattern from spontaneously bursting to single-spike activity. Pharmacological analysis of these responses indicated that they are mediated by the alpha 1-adrenoceptor for NE and the muscarinic subtype for ACh. Thus, the NE response was mimicked by the alpha-agonist phenylephrine but not by the beta-agonist isoprenaline, and was completely blocked by the alpha 1-antagonist prazosin but not by the alpha 2-antagonist yohimbine or the beta-antagonist propranolol. Finally, the ACh effect could be mimicked by the muscarinic agonist acetyl-beta-methylcholine (MCh) and was blocked by the muscarinic antagonist scopolamine. Intracellular recordings revealed that the NE-, MCh-, and ACPD-induced responses in bursting neurons are due to the direct activation of receptors on these cells, since block of synaptic transmission with local application of TTX or bath application of low [Ca2+]o and raised [Mg2+]o did not block the postsynaptic responses. Voltage-clamp analysis of the currents involved in the depolarizing responses of bursting cells revealed that activation of alpha 1-adrenergic, muscarinic, or glutamate metabotropic receptors resulted in a decrease in a potassium conductance that consisted of both a voltage-independent component and a voltage- and Ca(2+)-sensitive component. These results suggest that increased activity in noradrenergic, cholinergic, and glutamatergic pathways may control the firing mode of layer V corticotectal and corticopontine pyramidal cells by determining the resting membrane potential through modulation of both voltage-dependent and voltage-independent K+ conductances.(ABSTRACT TRUNCATED AT 400 WORDS)},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PBXH94RQ\Wang and McCormick - 1993 - Control of firing mode of corticotectal and cortic.pdf}
}

@article{wangDisconnectionHippocampalprefrontalCortical2006,
  title = {Disconnection of the Hippocampal-Prefrontal Cortical Circuits Impairs Spatial Working Memory Performance in Rats},
  author = {Wang, Gong-Wu and Cai, Jing-Xia},
  date = {2006-12-15},
  journaltitle = {Behavioural Brain Research},
  shortjournal = {Behav Brain Res},
  volume = {175},
  number = {2},
  eprint = {17045348},
  eprinttype = {pmid},
  pages = {329--336},
  issn = {0166-4328},
  doi = {10.1016/j.bbr.2006.09.002},
  abstract = {There is a unidirectional, ipsilateral and monosynaptic projection from the hippocampus to the prefrontal cortex. The cognitive function of hippocampal-prefrontal cortical circuit is not well established. In this paper, we use muscimol treated rats to investigate the roles of the hippocampal-prefrontal cortical circuits in spatial working memory, as assessed with a delayed spatial alternation task. First of all, the effect of muscimol on EEG power of infusion area was observed for confirmation of the dosage of muscimol to inhibit the function of infusion area. The results show that the EEG power of the ventral hippocampus and the prelimbic area of the prefrontal cortex were inhibited by local infusion of muscimol (0.5 microg in 0.25 microl PBS) into the above areas, respectively. Delayed alternation performance was significantly impaired when muscimol at this dosage was infused (1) bilaterally into the ventral hippocampus, (2) bilaterally into the prelimbic area, (3) unilaterally into the ventral hippocampus and simultaneously contralaterally into the prelimbic area. Infusion of muscimol either unilaterally into the ventral hippocampus or unilaterally into the prelimbic area did not impair delayed alternation performance. The present results suggest that any structures in this circuit is damaged or inhibited bilaterally, the spatial working memory will be disrupted. It means the hippocampal-prefrontal cortical circuit plays an important role in spatial working memory.},
  langid = {english},
  keywords = {Animals,Discrimination Learning,Electroencephalography,Functional Laterality,GABA Agonists,Hippocampus,Maze Learning,Memory Short-Term,Microinjections,Muscimol,Neural Pathways,Prefrontal Cortex,Rats,Rats Wistar,Space Perception,Spatial Behavior}
}

@article{wangThetaSequencesAre2015,
  title = {Theta Sequences Are Essential for Internally Generated Hippocampal Firing Fields},
  author = {Wang, Yingxue and Romani, Sandro and Lustig, Brian and Leonardo, Anthony and Pastalkova, Eva},
  date = {2015-02},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {18},
  number = {2},
  pages = {282--288},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3904},
  url = {https://www.nature.com/articles/nn.3904},
  urldate = {2023-03-25},
  abstract = {Wang and colleagues find that weakening hippocampal theta in a familiar environment reduces the performance of rats in a spatial memory task, decreases the number of theta sequences and degrades internally generated hippocampal episode cell firing, while leaving place cell firing intact. The same weakening of theta also prevents the formation of a precise spatial representation in a novel environment unless proximal cues are present. Together these results suggest that the mechanisms underlying internally generated hippocampal sequences of activity are crucial for episodic memory.},
  issue = {2},
  langid = {english},
  keywords = {Hippocampus,Navigation,Spatial memory},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XCL9MKWA\Wang et al. - 2015 - Theta sequences are essential for internally gener.pdf}
}

@article{weaverSuprachiasmaticNucleus25year1998,
  title = {The Suprachiasmatic Nucleus: A 25-Year Retrospective},
  shorttitle = {The Suprachiasmatic Nucleus},
  author = {Weaver, D. R.},
  date = {1998-04},
  journaltitle = {Journal of Biological Rhythms},
  shortjournal = {J Biol Rhythms},
  volume = {13},
  number = {2},
  eprint = {9554572},
  eprinttype = {pmid},
  pages = {100--112},
  issn = {0748-7304},
  doi = {10.1177/074873098128999952},
  abstract = {The suprachiasmatic nuclei (SCN) of the anterior hypothalamus contain the master circadian pacemaker in mammals. On the occasion of the 25th anniversary of the discovery of the SCN as the circadian clock, Charles A. Czeisler and Steven M. Reppert organized a meeting to review milestones and recent developments in the study of the SCN. The discovery that the SCN contain tissue necessary for generation of circadian rhythmicity was established by lesion studies published in 1972. The second phase of study demonstrated unequivocally that the SCN contain an autonomous circadian pacemaker. The principal studies in this period showed the presence of metabolic and electrical activity rhythms in the SCN in vivo and progressed to studies showing that the SCN maintain rhythmicity in vitro, demonstrating that the transplanted SCN can restore circadian function following destruction of the host SCN and ultimately showing that single SCN "clock cells" exhibit independent rhythms in firing rate. The third phase of study, aimed at identifying the biochemical and molecular mechanisms responsible for rhythmicity within the SCN, has begun with the identification of circadian mutants (tau mutant hamsters and Clock mutant mice) and the isolation of the Clock gene. This report traces the important steps forward in our understanding of the suprachiasmatic circadian clock by recounting the information presented at the SCN Silver Anniversary Celebration.},
  langid = {english},
  keywords = {Animals,Circadian Rhythm,Cricetinae,Mice,Mutation,Rodentia,Suprachiasmatic Nucleus},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\WXV78S8A\Weaver - 1998 - The suprachiasmatic nucleus a 25-year retrospecti.pdf}
}

@article{wekselblattLargescaleImagingCortical2016,
  title = {Large-Scale Imaging of Cortical Dynamics during Sensory Perception and Behavior},
  author = {Wekselblatt, Joseph B. and Flister, Erik D. and Piscopo, Denise M. and Niell, Cristopher M.},
  date = {2016-06},
  journaltitle = {Journal of Neurophysiology},
  volume = {115},
  number = {6},
  pages = {2852--2866},
  publisher = {American Physiological Society},
  issn = {0022-3077},
  doi = {10.1152/jn.01056.2015},
  url = {https://journals.physiology.org/doi/full/10.1152/jn.01056.2015},
  urldate = {2024-06-12},
  abstract = {Sensory-driven behaviors engage a cascade of cortical regions to process sensory input and generate motor output. To investigate the temporal dynamics of neural activity at this global scale, we have improved and integrated tools to perform functional imaging across large areas of cortex using a transgenic mouse expressing the genetically encoded calcium sensor GCaMP6s, together with a head-fixed visual discrimination behavior. This technique allows imaging of activity across the dorsal surface of cortex, with spatial resolution adequate to detect differential activity in local regions at least as small as 100 μm. Imaging during an orientation discrimination task reveals a progression of activity in different cortical regions associated with different phases of the task. After cortex-wide patterns of activity are determined, we demonstrate the ability to select a region that displayed conspicuous responses for two-photon microscopy and find that activity in populations of individual neurons in that region correlates with locomotion in trained mice. We expect that this paradigm will be a useful probe of information flow and network processing in brain-wide circuits involved in many sensory and cognitive processes.},
  keywords = {functional imaging,orientation selectivity,visual cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\TWNSZQR5\Wekselblatt et al. - 2016 - Large-scale imaging of cortical dynamics during se.pdf}
}

@article{welshSuprachiasmaticNucleusCell2010,
  title = {Suprachiasmatic {{Nucleus}}: {{Cell Autonomy}} and {{Network Properties}}},
  shorttitle = {Suprachiasmatic {{Nucleus}}},
  author = {Welsh, David K. and Takahashi, Joseph S. and Kay, Steve A.},
  date = {2010},
  journaltitle = {Annual review of physiology},
  shortjournal = {Annu Rev Physiol},
  volume = {72},
  eprint = {20148688},
  eprinttype = {pmid},
  pages = {551--577},
  issn = {0066-4278},
  doi = {10.1146/annurev-physiol-021909-135919},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3758475/},
  urldate = {2023-02-22},
  abstract = {The suprachiasmatic nucleus (SCN) is the primary circadian pacemaker in mammals. Individual SCN neurons in dispersed culture can generate independent circadian oscillations of clock gene expression and neuronal firing. However, SCN rhythmicity depends on sufficient membrane depolarization and levels of intracellular calcium and cAMP. In the intact SCN, cellular oscillations are synchronized and reinforced by rhythmic synaptic input from other cells, resulting in a reproducible topographic pattern of distinct phases and amplitudes specified by SCN circuit organization. The SCN network synchronizes its component cellular oscillators, reinforces their oscillations, responds to light input by altering their phase distribution, increases their robustness to genetic perturbations, and enhances their precision. Thus, even though individual SCN neurons can be cell-autonomous circadian oscillators, neuronal network properties are integral to normal function of the SCN.},
  pmcid = {PMC3758475},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J2QNZIKR\Welsh et al. - 2010 - Suprachiasmatic Nucleus Cell Autonomy and Network.pdf}
}

@article{whittingtonApproximationErrorBackpropagation2017,
  title = {An {{Approximation}} of the {{Error Backpropagation Algorithm}} in a {{Predictive Coding Network}} with {{Local Hebbian Synaptic Plasticity}}},
  author = {Whittington, James C. R. and Bogacz, Rafal},
  date = {2017-05-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {29},
  number = {5},
  pages = {1229--1262},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00949},
  url = {https://doi.org/10.1162/NECO_a_00949},
  urldate = {2023-04-01},
  abstract = {To efficiently learn from feedback, cortical networks need to update synaptic weights on multiple levels of cortical hierarchy. An effective and well-known algorithm for computing such changes in synaptic weights is the error backpropagation algorithm. However, in this algorithm, the change in synaptic weights is a complex function of weights and activities of neurons not directly connected with the synapse being modified, whereas the changes in biological synapses are determined only by the activity of presynaptic and postsynaptic neurons. Several models have been proposed that approximate the backpropagation algorithm with local synaptic plasticity, but these models require complex external control over the network or relatively complex plasticity rules. Here we show that a network developed in the predictive coding framework can efficiently perform supervised learning fully autonomously, employing only simple local Hebbian plasticity. Furthermore, for certain parameters, the weight change in the predictive coding model converges to that of the backpropagation algorithm. This suggests that it is possible for cortical networks with simple Hebbian synaptic plasticity to implement efficient learning algorithms in which synapses in areas on multiple levels of hierarchy are modified to minimize the error on the output.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J67BJGN6\Whittington and Bogacz - 2017 - An Approximation of the Error Backpropagation Algo.pdf}
}

@article{whittingtonApproximationErrorBackpropagation2017a,
  title = {An {{Approximation}} of the {{Error Backpropagation Algorithm}} in a {{Predictive Coding Network}} with {{Local Hebbian Synaptic Plasticity}}},
  author = {Whittington, James C. R. and Bogacz, Rafal},
  date = {2017-05-01},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Computation},
  volume = {29},
  number = {5},
  pages = {1229--1262},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00949},
  url = {https://doi.org/10.1162/NECO_a_00949},
  urldate = {2024-01-16},
  abstract = {To efficiently learn from feedback, cortical networks need to update synaptic weights on multiple levels of cortical hierarchy. An effective and well-known algorithm for computing such changes in synaptic weights is the error backpropagation algorithm. However, in this algorithm, the change in synaptic weights is a complex function of weights and activities of neurons not directly connected with the synapse being modified, whereas the changes in biological synapses are determined only by the activity of presynaptic and postsynaptic neurons. Several models have been proposed that approximate the backpropagation algorithm with local synaptic plasticity, but these models require complex external control over the network or relatively complex plasticity rules. Here we show that a network developed in the predictive coding framework can efficiently perform supervised learning fully autonomously, employing only simple local Hebbian plasticity. Furthermore, for certain parameters, the weight change in the predictive coding model converges to that of the backpropagation algorithm. This suggests that it is possible for cortical networks with simple Hebbian synaptic plasticity to implement efficient learning algorithms in which synapses in areas on multiple levels of hierarchy are modified to minimize the error on the output.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\Y63Q6K99\\Whittington and Bogacz - 2017 - An Approximation of the Error Backpropagation Algo.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZB3XSV27\\neco_a_00949.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\DIJZ888J\\An-Approximation-of-the-Error-Backpropagation.html}
}

@article{whittingtonApproximationErrorBackpropagation2017b,
  title = {An {{Approximation}} of the {{Error Backpropagation Algorithm}} in a {{Predictive Coding Network}} with {{Local Hebbian Synaptic Plasticity}}},
  author = {Whittington, James C. R. and Bogacz, Rafal},
  date = {2017-05},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput},
  volume = {29},
  number = {5},
  eprint = {28333583},
  eprinttype = {pmid},
  pages = {1229--1262},
  issn = {1530-888X},
  doi = {10.1162/NECO_a_00949},
  abstract = {To efficiently learn from feedback, cortical networks need to update synaptic weights on multiple levels of cortical hierarchy. An effective and well-known algorithm for computing such changes in synaptic weights is the error backpropagation algorithm. However, in this algorithm, the change in synaptic weights is a complex function of weights and activities of neurons not directly connected with the synapse being modified, whereas the changes in biological synapses are determined only by the activity of presynaptic and postsynaptic neurons. Several models have been proposed that approximate the backpropagation algorithm with local synaptic plasticity, but these models require complex external control over the network or relatively complex plasticity rules. Here we show that a network developed in the predictive coding framework can efficiently perform supervised learning fully autonomously, employing only simple local Hebbian plasticity. Furthermore, for certain parameters, the weight change in the predictive coding model converges to that of the backpropagation algorithm. This suggests that it is possible for cortical networks with simple Hebbian synaptic plasticity to implement efficient learning algorithms in which synapses in areas on multiple levels of hierarchy are modified to minimize the error on the output.},
  langid = {english},
  pmcid = {PMC5467749},
  keywords = {Algorithms,Cerebral Cortex,Feedback Physiological,Humans,Learning,Models Neurological,Neural Networks Computer,Neuronal Plasticity,Neurons},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\T3R45HIU\Whittington and Bogacz - 2017 - An Approximation of the Error Backpropagation Algo.pdf}
}

@article{williamsDendriticSubstrateCholinergic2019,
  title = {A {{Dendritic Substrate}} for the {{Cholinergic Control}} of {{Neocortical Output Neurons}}},
  author = {Williams, Stephen R. and Fletcher, Lee N.},
  date = {2019-02-06},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {101},
  number = {3},
  eprint = {30594427},
  eprinttype = {pmid},
  pages = {486-499.e4},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2018.11.035},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(18)31044-4},
  urldate = {2024-03-15},
  langid = {english},
  keywords = {acetylcholine,circuit computation,dendrite,neuromodulation},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\X3CKBPNH\Williams and Fletcher - 2019 - A Dendritic Substrate for the Cholinergic Control .pdf}
}

@article{williamsHigherOrderThalamocorticalInputs2019,
  title = {Higher-{{Order Thalamocortical Inputs Gate Synaptic Long-Term Potentiation}} via {{Disinhibition}}},
  author = {Williams, Leena E. and Holtmaat, Anthony},
  date = {2019-01},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {101},
  number = {1},
  pages = {91-102.e4},
  issn = {08966273},
  doi = {10.1016/j.neuron.2018.10.049},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0896627318309577},
  urldate = {2023-08-03},
  abstract = {Sensory experience and perceptual learning changes receptive field properties of cortical pyramidal neurons (PNs), largely mediated by synaptic long-term potentiation (LTP). The circuit mechanisms underlying cortical LTP remain unclear. In the mouse somatosensory cortex, LTP can be elicited in layer 2/3 PNs by rhythmic whisker stimulation. We dissected the synaptic circuitry underlying this type of plasticity in thalamocortical slices. We found that projections from higher-order, posterior medial thalamic complex (POm) are key to eliciting N-methyl-D-aspartate receptor (NMDAR)-dependent LTP of intracortical synapses. Paired activation of cortical and higher-order thalamocortical inputs increased vasoactive intestinal peptide (VIP) and parvalbumin (PV) interneuron (IN) activity and decreased somatostatin (SST) IN activity, which together disinhibited the PNs. VIP INmediated disinhibition was critical for inducing LTP. This study reveals a circuit motif in which higher-order thalamic inputs gate synaptic plasticity via disinhibition. This motif may allow contextual feedback to shape synaptic circuits that process first-order sensory information.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\YCAKIRBA\Williams and Holtmaat - 2019 - Higher-Order Thalamocortical Inputs Gate Synaptic .pdf}
}

@article{williamsInformationTheoreticAnalysis,
  title = {An {{Information Theoretic Analysis}} of {{Neural Multiplexing}}},
  author = {Williams, Ezekiel},
  pages = {94},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\S6XESADU\Williams - An Information Theoretic Analysis of Neural Multip.pdf}
}

@article{williamsNeuralBurstCodes2021,
  title = {Neural Burst Codes Disguised as Rate Codes},
  author = {Williams, Ezekiel and Payeur, Alexandre and Gidon, Albert and Naud, Richard},
  date = {2021-08-05},
  journaltitle = {Scientific Reports},
  shortjournal = {Scientific Reports},
  volume = {11},
  number = {1},
  pages = {15910},
  issn = {2045-2322},
  doi = {10.1038/s41598-021-95037-z},
  url = {https://doi.org/10.1038/s41598-021-95037-z},
  abstract = {The burst coding hypothesis posits that the occurrence of sudden high-frequency patterns of action potentials constitutes a salient syllable of the neural code. Many neurons, however, do not produce clearly demarcated bursts, an observation invoked to rule out the pervasiveness of this coding scheme across brain areas and cell types. Here we ask how detrimental ambiguous spike patterns, those that are neither clearly bursts nor isolated spikes, are for neuronal information transfer. We addressed this question using information theory and computational simulations. By quantifying how information transmission depends on firing statistics, we found that the information transmitted is not strongly influenced by the presence of clearly demarcated modes in the interspike interval distribution, a feature often used to identify the presence of burst coding. Instead, we found that neurons having unimodal interval distributions were still able to ascribe different meanings to bursts and isolated spikes. In this regime, information transmission depends on dynamical properties of the synapses as well as the length and relative frequency of bursts. Furthermore, we found that common metrics used to quantify burstiness were unable to predict the degree with which bursts could be used to carry information. Our results provide guiding principles for the implementation of coding strategies based on spike-timing patterns, and show that even unimodal firing statistics can be consistent with a bivariate neural code.}
}

@article{williamsonScalingPropertiesDimensionality2016,
  title = {Scaling {{Properties}} of {{Dimensionality Reduction}} for {{Neural Populations}} and {{Network Models}}},
  author = {Williamson, Ryan C. and Cowley, Benjamin R. and Litwin-Kumar, Ashok and Doiron, Brent and Kohn, Adam and Smith, Matthew A. and Yu, Byron M.},
  date = {2016-12-07},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {12},
  number = {12},
  pages = {e1005141},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005141},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005141},
  urldate = {2023-11-22},
  abstract = {Recent studies have applied dimensionality reduction methods to understand how the multi-dimensional structure of neural population activity gives rise to brain function. It is unclear, however, how the results obtained from dimensionality reduction generalize to recordings with larger numbers of neurons and trials or how these results relate to the underlying network structure. We address these questions by applying factor analysis to recordings in the visual cortex of non-human primates and to spiking network models that self-generate irregular activity through a balance of excitation and inhibition. We compared the scaling trends of two key outputs of dimensionality reduction—shared dimensionality and percent shared variance—with neuron and trial count. We found that the scaling properties of networks with non-clustered and clustered connectivity differed, and that the in vivo recordings were more consistent with the clustered network. Furthermore, recordings from tens of neurons were sufficient to identify the dominant modes of shared variability that generalize to larger portions of the network. These findings can help guide the interpretation of dimensionality reduction outputs in regimes of limited neuron and trial sampling and help relate these outputs to the underlying network structure.},
  langid = {english},
  keywords = {Action potentials,Covariance,Eigenvectors,Macaque,Network analysis,Neural networks,Neurons,Single neuron function},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\DWRQU467\Williamson et al. - 2016 - Scaling Properties of Dimensionality Reduction for.pdf}
}

@article{wolpertInternalModelsCerebellum1998,
  title = {Internal Models in the Cerebellum},
  author = {Wolpert, Daniel M. and Miall, R. Chris and Kawato, Mitsuo},
  date = {1998-09-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {2},
  number = {9},
  eprint = {21227230},
  eprinttype = {pmid},
  pages = {338--347},
  publisher = {Elsevier},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/S1364-6613(98)01221-2},
  url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(98)01221-2},
  urldate = {2023-04-23},
  langid = {english},
  keywords = {cerebellum,forward model,internal model,inverse model,motor control},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\6XZI7AV8\Wolpert et al. - 1998 - Internal models in the cerebellum.pdf}
}

@article{womelsdorfDynamicCircuitMotifs2014,
  title = {Dynamic Circuit Motifs Underlying Rhythmic Gain Control, Gating and Integration},
  author = {Womelsdorf, Thilo and Valiante, Taufik A. and Sahin, Ned T. and Miller, Kai J. and Tiesinga, Paul},
  date = {2014-08},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {17},
  number = {8},
  pages = {1031--1039},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.3764},
  url = {https://www.nature.com/articles/nn.3764},
  urldate = {2023-01-03},
  abstract = {In this paper, Womelsdorf and colleagues review the recent advances in our understanding of how rhythmic activity across multiple frequency bands and brain areas affects neural computations. The authors suggest a dynamic tripartite motif framework that links the activity signatures of given circuits with their structural elements and the proposed computational output.},
  issue = {8},
  langid = {english},
  keywords = {Attention,Dynamical systems,Neurophysiology,Psychology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ITTCIEBL\Womelsdorf et al. - 2014 - Dynamic circuit motifs underlying rhythmic gain co.pdf}
}

@article{womelsdorfModulationNeuronalInteractions2007,
  title = {Modulation of {{Neuronal Interactions Through Neuronal Synchronization}}},
  author = {Womelsdorf, Thilo and Schoffelen, Jan-Mathijs and Oostenveld, Robert and Singer, Wolf and Desimone, Robert and Engel, Andreas K. and Fries, Pascal},
  date = {2007-06-15},
  journaltitle = {Science},
  volume = {316},
  number = {5831},
  pages = {1609--1612},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1139597},
  url = {https://www.science.org/doi/10.1126/science.1139597},
  urldate = {2023-01-17},
  abstract = {Brain processing depends on the interactions between neuronal groups. Those interactions are governed by the pattern of anatomical connections and by yet unknown mechanisms that modulate the effective strength of a given connection. We found that the mutual influence among neuronal groups depends on the phase relation between rhythmic activities within the groups. Phase relations supporting interactions between the groups preceded those interactions by a few milliseconds, consistent with a mechanistic role. These effects were specific in time, frequency, and space, and we therefore propose that the pattern of synchronization flexibly determines the pattern of neuronal interactions.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\99CYABJF\Womelsdorf et al. - 2007 - Modulation of Neuronal Interactions Through Neuron.pdf}
}

@article{womelsdorfRoleNeuronalSynchronization2007,
  title = {The Role of Neuronal Synchronization in Selective Attention},
  author = {Womelsdorf, Thilo and Fries, Pascal},
  date = {2007-04-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Cognitive Neuroscience},
  volume = {17},
  number = {2},
  pages = {154--160},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2007.02.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438807000268},
  urldate = {2023-03-27},
  abstract = {Attention selectively enhances the influence of neuronal responses conveying information about relevant sensory attributes. Accumulating evidence suggests that this selective neuronal modulation relies on rhythmic synchronization at local and long-range spatial scales: attention selectively synchronizes the rhythmic responses of those neurons that are tuned to the spatial and featural attributes of the attended sensory input. The strength of synchronization is thereby functionally related to perceptual accuracy and behavioural efficiency. Complementing this synchronization at a local level, attention has recently been demonstrated to regulate which locally synchronized neuronal groups phase-synchronize their rhythmic activity across long-range connections. These results point to a general computational role for selective synchronization in dynamically controlling which neurons communicate information about sensory inputs effectively.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\HZ3MQ9CY\\Womelsdorf and Fries - 2007 - The role of neuronal synchronization in selective .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\32FTH7SQ\\S0959438807000268.html}
}

@article{womelsdorfRoleNeuronalSynchronization2007a,
  title = {✅ {{The}} Role of Neuronal Synchronization in Selective Attention},
  author = {Womelsdorf, Thilo and Fries, Pascal},
  date = {2007-04-01},
  journaltitle = {Current Opinion in Neurobiology},
  shortjournal = {Current Opinion in Neurobiology},
  series = {Cognitive Neuroscience},
  volume = {17},
  number = {2},
  pages = {154--160},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2007.02.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0959438807000268},
  urldate = {2023-04-04},
  abstract = {Attention selectively enhances the influence of neuronal responses conveying information about relevant sensory attributes. Accumulating evidence suggests that this selective neuronal modulation relies on rhythmic synchronization at local and long-range spatial scales: attention selectively synchronizes the rhythmic responses of those neurons that are tuned to the spatial and featural attributes of the attended sensory input. The strength of synchronization is thereby functionally related to perceptual accuracy and behavioural efficiency. Complementing this synchronization at a local level, attention has recently been demonstrated to regulate which locally synchronized neuronal groups phase-synchronize their rhythmic activity across long-range connections. These results point to a general computational role for selective synchronization in dynamically controlling which neurons communicate information about sensory inputs effectively.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6IRCXVYR\\Womelsdorf and Fries - 2007 - The role of neuronal synchronization in selective .pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\TZNFM2JB\\S0959438807000268.html}
}

@article{woodStatisticalInferenceNoisy2010,
  title = {Statistical Inference for Noisy Nonlinear Ecological Dynamic Systems},
  author = {Wood, Simon N.},
  date = {2010-08},
  journaltitle = {Nature},
  shortjournal = {Nature},
  volume = {466},
  number = {7310},
  pages = {1102--1104},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature09319},
  url = {http://www.nature.com/articles/nature09319},
  urldate = {2020-10-26},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\369DUHQK\Wood - 2010 - Statistical inference for noisy nonlinear ecologic.pdf}
}

@inproceedings{wuUnsupervisedFeatureLearning2018,
  title = {Unsupervised {{Feature Learning}} via {{Non-parametric Instance Discrimination}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},
  date = {2018-06},
  pages = {3733--3742},
  publisher = {IEEE},
  location = {Salt Lake City, UT},
  doi = {10.1109/CVPR.2018.00393},
  url = {https://ieeexplore.ieee.org/document/8578491/},
  urldate = {2024-06-18},
  abstract = {Neural net classifiers trained on data with annotated class labels can also capture apparent visual similarity among categories without being directed to do so. We study whether this observation can be extended beyond the conventional domain of supervised learning: Can we learn a good feature representation that captures apparent similarity among instances, instead of classes, by merely asking the feature to be discriminative of individual instances? We formulate this intuition as a non-parametric classification problem at the instance-level, and use noisecontrastive estimation to tackle the computational challenges imposed by the large number of instance classes.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\FNPUHEGH\Wu et al. - 2018 - Unsupervised Feature Learning via Non-parametric I.pdf}
}

@online{wyboDendriticModulationEnables2022,
  title = {Dendritic Modulation Enables Multitask Representation Learning in Hierarchical Sensory Processing Pathways},
  author = {Wybo, Willem A. M. and Tsai, Matthias C. and Tran, Viet Anh Khoa and Illing, Bernd and Jordan, Jakob and Morrison, Abigail and Senn, Walter},
  date = {2022-11-26},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2022.11.25.517941},
  doi = {10.1101/2022.11.25.517941},
  url = {https://www.biorxiv.org/content/10.1101/2022.11.25.517941v1},
  urldate = {2023-03-22},
  abstract = {While sensory representations in the brain depend on context, it remains unclear how such modulations are implemented at the biophysical level, and how processing layers further in the hierarchy can extract useful features for each possible contextual state. Here, we first demonstrate that thin dendritic branches are well suited to implementing contextual modulation of feedforward processing. Such neuron-specific modulations exploit prior knowledge, encoded in stable feedforward weights, to achieve transfer learning across contexts. In a network of biophysically realistic neuron models with context-independent feedforward weights, we show that modulatory inputs to thin dendrites can solve linearly non-separable learning problems with a Hebbian, error-modulated learning rule. Finally, we demonstrate that local prediction of whether representations originate either from different inputs, or from different contextual modulations of the same input, results in representation learning of hierarchical feedforward weights across processing layers that accommodate a multitude of contexts.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ILQ3I4D6\Wybo et al. - 2022 - Dendritic modulation enables multitask representat.pdf}
}

@article{xiaoFeatureselectiveResponsesMacaque2024,
  title = {Feature-Selective Responses in Macaque Visual Cortex Follow Eye Movements during Natural Vision},
  author = {Xiao, Will and Sharma, Saloni and Kreiman, Gabriel and Livingstone, Margaret S.},
  date = {2024-06},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {27},
  number = {6},
  pages = {1157--1166},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-024-01631-5},
  url = {https://www.nature.com/articles/s41593-024-01631-5},
  urldate = {2024-07-03},
  abstract = {In natural vision, primates actively move their eyes several times per second via saccades. It remains unclear whether, during this active looking, visual neurons exhibit classical retinotopic properties, anticipate gaze shifts or mirror the stable quality of perception, especially in complex natural scenes. Here, we let 13 monkeys freely view thousands of natural images across 4.6\,million fixations, recorded 883\,h of neuronal responses in six areas spanning primary visual to anterior inferior temporal cortex and analyzed spatial, temporal and featural selectivity in these responses. Face neurons tracked their receptive field contents, indicated by category-selective responses. Self-consistency analysis showed that general feature-selective responses also followed eye movements and remained gaze-dependent over seconds of viewing the same image. Computational models of feature-selective responses located retinotopic receptive fields during free viewing. We found limited evidence for feature-selective predictive remapping and no viewing-history integration. Thus, ventral visual neurons represent the world in a predominantly eye-centered reference frame during natural vision.},
  langid = {english},
  keywords = {Extrastriate cortex,Neural encoding,Sensory processing,Striate cortex},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\ISAHW5P2\Xiao et al. - 2024 - Feature-selective responses in macaque visual cort.pdf}
}

@online{xieDiffusionTheoryDeep2021,
  title = {A {{Diffusion Theory For Deep Learning Dynamics}}: {{Stochastic Gradient Descent Exponentially Favors Flat Minima}}},
  shorttitle = {A {{Diffusion Theory For Deep Learning Dynamics}}},
  author = {Xie, Zeke and Sato, Issei and Sugiyama, Masashi},
  date = {2021-01-15},
  eprint = {2002.03495},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2002.03495},
  urldate = {2024-01-08},
  abstract = {Stochastic Gradient Descent (SGD) and its variants are mainstream methods for training deep networks in practice. SGD is known to find a flat minimum that often generalizes well. However, it is mathematically unclear how deep learning can select a flat minimum among so many minima. To answer the question quantitatively, we develop a density diffusion theory (DDT) to reveal how minima selection quantitatively depends on the minima sharpness and the hyperparameters. To the best of our knowledge, we are the first to theoretically and empirically prove that, benefited from the Hessian-dependent covariance of stochastic gradient noise, SGD favors flat minima exponentially more than sharp minima, while Gradient Descent (GD) with injected white noise favors flat minima only polynomially more than sharp minima. We also reveal that either a small learning rate or large-batch training requires exponentially many iterations to escape from minima in terms of the ratio of the batch size and learning rate. Thus, large-batch training cannot search flat minima efficiently in a realistic computational time.},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JS9ESI7U\\Xie et al. - 2021 - A Diffusion Theory For Deep Learning Dynamics Sto.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\PCQ6RDB8\\2002.html}
}

@article{xieNewInsightsCircadian2019,
  title = {New {{Insights Into}} the {{Circadian Rhythm}} and {{Its Related Diseases}}},
  author = {Xie, Yanling and Tang, Qingming and Chen, Guangjin and Xie, Mengru and Yu, Shaoling and Zhao, Jiajia and Chen, Lili},
  date = {2019},
  journaltitle = {Frontiers in Physiology},
  volume = {10},
  issn = {1664-042X},
  url = {https://www.frontiersin.org/articles/10.3389/fphys.2019.00682},
  urldate = {2023-01-26},
  abstract = {Circadian rhythms (CR) are a series of endogenous autonomous oscillators generated by the molecular circadian clock which acting on coordinating internal time with the external environment in a 24-h daily cycle. The circadian clock system is a major regulatory factor for nearly all physiological activities and its disorder has severe consequences on human health. CR disruption is a common issue in modern society, and researches about people with jet lag or shift works have revealed that CR disruption can cause cognitive impairment, psychiatric illness, metabolic syndrome, dysplasia, and cancer. In this review, we summarized the synchronizers and the synchronization methods used in experimental research, and introduced CR monitoring and detection methods. Moreover, we evaluated conventional CR databases, and analyzed experiments that characterized the underlying causes of CR disorder. Finally, we further discussed the latest developments in understanding of CR disruption, and how it may be relevant to health and disease. Briefly, this review aimed to synthesize previous studies to aid in future studies of CR and CR-related diseases.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\VYK2B9CR\Xie et al. - 2019 - New Insights Into the Circadian Rhythm and Its Rel.pdf}
}

@article{xueSpatialAttentionReduces2017,
  title = {Spatial {{Attention Reduces Burstiness}} in {{Macaque Visual Cortical Area MST}}},
  author = {Xue, Cheng and Kaping, Daniel and Ray, Sonia Baloni and Krishna, B. Suresh and Treue, Stefan},
  date = {2017-01-01},
  journaltitle = {Cerebral Cortex},
  shortjournal = {Cerebral Cortex},
  volume = {27},
  number = {1},
  pages = {83--91},
  issn = {1047-3211},
  doi = {10.1093/cercor/bhw326},
  url = {https://doi.org/10.1093/cercor/bhw326},
  urldate = {2023-01-03},
  abstract = {Visual attention modulates the firing rate of neurons in many primate cortical areas. In V4, a cortical area in the ventral visual pathway, spatial attention has also been shown to reduce the tendency of neurons to fire closely separated spikes (burstiness). A recent model proposes that a single mechanism accounts for both the firing rate enhancement and the burstiness reduction in V4, but this has not been empirically tested. It is also unclear if the burstiness reduction by spatial attention is found in other visual areas and for other attentional types. We therefore recorded from single neurons in the medial superior temporal area (MST), a key motion-processing area along the dorsal visual pathway, of two rhesus monkeys while they performed a task engaging both spatial and feature-based attention. We show that in MST, spatial attention is associated with a clear reduction in burstiness that is independent of the concurrent enhancement of firing rate. In contrast, feature-based attention enhances firing rate but is not associated with a significant reduction in burstiness. These results establish burstiness reduction as a widespread effect of spatial attention. They also suggest that in contrast to the recently proposed model, the effects of spatial attention on burstiness and firing rate emerge from different mechanisms.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\NDXS42YR\\Xue et al. - 2017 - Spatial Attention Reduces Burstiness in Macaque Vi.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\6QC6GG36\\2557336.html}
}

@article{xuNonlinearDendriticIntegration2012,
  title = {Nonlinear Dendritic Integration of Sensory and Motor Input during an Active Sensing Task},
  author = {Xu, Ning-long and Harnett, Mark T. and Williams, Stephen R. and Huber, Daniel and O’Connor, Daniel H. and Svoboda, Karel and Magee, Jeffrey C.},
  date = {2012-12},
  journaltitle = {Nature},
  volume = {492},
  number = {7428},
  pages = {247--251},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature11601},
  url = {https://www.nature.com/articles/nature11601},
  urldate = {2023-04-11},
  abstract = {Recordings from cortical neuron dendrites of head-fixed mice during an object-localization task provide direct evidence that a novel global nonlinearity has a role in integrating sensory and motor information during a behaviour-related computation.},
  issue = {7428},
  langid = {english},
  keywords = {Neuronal physiology},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SFPYGMIV\Xu et al. - 2012 - Nonlinear dendritic integration of sensory and mot.pdf}
}

@article{yangEfficientSpikeDrivenLearning2021,
  title = {Efficient {{Spike-Driven Learning With Dendritic Event-Based Processing}}},
  author = {Yang, Shuangming and Gao, Tian and Wang, Jiang and Deng, Bin and Lansdell, Benjamin and Linares-Barranco, Bernabe},
  date = {2021},
  journaltitle = {Frontiers in Neuroscience},
  volume = {15},
  issn = {1662-453X},
  url = {https://www.frontiersin.org/articles/10.3389/fnins.2021.601109},
  urldate = {2023-01-20},
  abstract = {A critical challenge in neuromorphic computing is to present computationally efficient algorithms of learning. When implementing gradient-based learning, error information must be routed through the network, such that each neuron knows its contribution to output, and thus how to adjust its weight. This is known as the credit assignment problem. Exactly implementing a solution like backpropagation involves weight sharing, which requires additional bandwidth and computations in a neuromorphic system. Instead, models of learning from neuroscience can provide inspiration for how to communicate error information efficiently, without weight sharing. Here we present a novel dendritic event-based processing (DEP) algorithm, using a two-compartment leaky integrate-and-fire neuron with partially segregated dendrites that effectively solves the credit assignment problem. In order to optimize the proposed algorithm, a dynamic fixed-point representation method and piecewise linear approximation approach are presented, while the synaptic events are binarized during learning. The presented optimization makes the proposed DEP algorithm very suitable for implementation in digital or mixed-signal neuromorphic hardware. The experimental results show that spiking representations can rapidly learn, achieving high performance by using the proposed DEP algorithm. We find the learning capability is affected by the degree of dendritic segregation, and the form of synaptic feedback connections. This study provides a bridge between the biological learning and neuromorphic learning, and is meaningful for the real-time applications in the field of artificial intelligence.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\J8H7EYFR\Yang et al. - 2021 - Efficient Spike-Driven Learning With Dendritic Eve.pdf}
}

@article{yanTwoAntiphaseOscillations2005,
  title = {Two {{Antiphase Oscillations Occur}} in {{Each Suprachiasmatic Nucleus}} of {{Behaviorally Split Hamsters}}},
  author = {Yan, Lily and Foley, Nicholas C. and Bobula, Jessica M. and Kriegsfeld, Lance J. and Silver, Rae},
  date = {2005-09-28},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  volume = {25},
  number = {39},
  eprint = {16192393},
  eprinttype = {pmid},
  pages = {9017--9026},
  publisher = {Society for Neuroscience},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.2538-05.2005},
  url = {https://www.jneurosci.org/content/25/39/9017},
  urldate = {2023-02-22},
  abstract = {The suprachiasmatic nuclei (SCNs) control circadian rhythms of numerous behavioral and physiological responses. In hamsters, constant light causes “splitting” of circadian rhythms, such that a single daily bout of activity separates into two components, 12 h apart, with antiphase circadian oscillations in the left and right SCN. Given the phenotypic and functional heterogeneity of the SCN, in which ventrolateral but not dorsomedial neurons are retinorecipient, we asked how these two compartments respond to the constant lighting conditions that produce splitting, using three different phase markers of neuronal activity: PER1 (Period 1), c-FOS, and pERK (phosphorylated extracellular signal-regulated kinase). We report the emergence of a coherent novel network in which each side of the SCN exhibits two antiphase oscillating subregions, here termed “core-like” and “shell-like,” in addition to the known antiphase oscillation between the right and left SCN. The novel SCN response entails a coherent rhythm in a core-like region of the SCN, which otherwise is not cycling. A mathematical model is presented, and this model interprets the observed changes in the proportion of in-phase and antiphase populations of SCN oscillators and suggests novel testable hypotheses. Finally, the functional significance of this network was explored by investigating the adjacent hypothalamus. Activation of the paraventricular nucleus is in-phase with the ipsilateral core-like SCN, whereas activation of the lateral subparaventricular zone is in-phase with the ipsilateral shell-like SCN, pointing to a multiplicity of SCN output signals. These results suggest a neural basis for internal coincidence of SCN oscillators, and a novel mechanism of plasticity in SCN neural networks and outputs.},
  langid = {english},
  keywords = {behavioral splitting,circadian rhythms,oscillator model,PER1,SCN,SCN efferents},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\G76RD288\Yan et al. - 2005 - Two Antiphase Oscillations Occur in Each Suprachia.pdf}
}

@article{yooNeuralInterfaceSystems2021,
  title = {Neural Interface Systems with On-Device Computing: Machine Learning and Neuromorphic Architectures},
  shorttitle = {Neural Interface Systems with On-Device Computing},
  author = {Yoo, Jerald and Shoaran, Mahsa},
  date = {2021-12-01},
  journaltitle = {Current Opinion in Biotechnology},
  shortjournal = {Current Opinion in Biotechnology},
  series = {Tissue, {{Cell}} and {{Pathway Engineering}}},
  volume = {72},
  pages = {95--101},
  issn = {0958-1669},
  doi = {10.1016/j.copbio.2021.10.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0958166921001993},
  urldate = {2022-10-26},
  abstract = {Development of neural interface and brain-machine interface (BMI) systems enables the treatment of neurological disorders including cognitive, sensory, and motor dysfunctions. While neural interfaces have steadily decreased in form factor, recent developments target pervasive implantables. Along with advances in electrodes, neural recording, and neurostimulation circuits, integration of disease biomarkers and machine learning algorithms enables real-time and on-site processing of neural activity with no need for power-demanding telemetry. This recent trend on combining artificial intelligence and machine learning with modern neural interfaces will lead to a new generation of low-power, smart, and miniaturized therapeutic devices for a wide range of neurological and psychiatric disorders. This paper reviews the recent development of the ‘on-chip’ machine learning and neuromorphic architectures, which is one of the key puzzles in devising next-generation clinically viable neural interface systems.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\BEDHMESH\\Yoo and Shoaran - 2021 - Neural interface systems with on-device computing.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7UFDVLA9\\S0958166921001993.html}
}

@article{yotsumotoDefiningLinkPerceptual2008,
  title = {Defining a {{Link}} between {{Perceptual Learning}} and {{Attention}}},
  author = {Yotsumoto, Yuko and Watanabe, Takeo},
  date = {2008-08-26},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {6},
  number = {8},
  pages = {e221},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.0060221},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0060221},
  urldate = {2023-08-07},
  abstract = {Takeo Watanabe and Yuko Yotsumoto explore the implications of a new study that shows that for perceptual learning of visual features involving multiple stimuli to occur, the brain needs to temporally "tag" the features, a learning process that requires paying attention.},
  langid = {english},
  keywords = {Attention,Cognition,Learning,Perceptual learning,Sensory perception,Signal processing,Vision,Visual signals},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\S6Z8EYSR\Yotsumoto and Watanabe - 2008 - Defining a Link between Perceptual Learning and At.pdf}
}

@article{yuGaussianProcessFactorAnalysis2009,
  title = {Gaussian-{{Process Factor Analysis}} for {{Low-Dimensional Single-Trial Analysis}} of {{Neural Population Activity}}},
  author = {Yu, Byron M. and Cunningham, John P. and Santhanam, Gopal and Ryu, Stephen I. and Shenoy, Krishna V. and Sahani, Maneesh},
  date = {2009-07},
  journaltitle = {Journal of Neurophysiology},
  volume = {102},
  number = {1},
  pages = {614--635},
  publisher = {American Physiological Society},
  issn = {0022-3077},
  doi = {10.1152/jn.90941.2008},
  url = {https://journals.physiology.org/doi/full/10.1152/jn.90941.2008},
  urldate = {2022-09-23},
  abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SYE4T6G6\Yu et al. - 2009 - Gaussian-Process Factor Analysis for Low-Dimension.pdf}
}

@article{yuGaussianProcessFactorAnalysis2009a,
  title = {Gaussian-{{Process Factor Analysis}} for {{Low-Dimensional Single-Trial Analysis}} of {{Neural Population Activity}}},
  author = {Yu, Byron M. and Cunningham, John P. and Santhanam, Gopal and Ryu, Stephen I. and Shenoy, Krishna V. and Sahani, Maneesh},
  date = {2009-07},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J Neurophysiol},
  volume = {102},
  number = {1},
  eprint = {19357332},
  eprinttype = {pmid},
  pages = {614--635},
  issn = {0022-3077},
  doi = {10.1152/jn.90941.2008},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2712272/},
  urldate = {2022-09-26},
  abstract = {We consider the problem of extracting smooth, low-dimensional neural trajectories that summarize the activity recorded simultaneously from many neurons on individual experimental trials. Beyond the benefit of visualizing the high-dimensional, noisy spiking activity in a compact form, such trajectories can offer insight into the dynamics of the neural circuitry underlying the recorded activity. Current methods for extracting neural trajectories involve a two-stage process: the spike trains are first smoothed over time, then a static dimensionality-reduction technique is applied. We first describe extensions of the two-stage methods that allow the degree of smoothing to be chosen in a principled way and that account for spiking variability, which may vary both across neurons and across time. We then present a novel method for extracting neural trajectories—Gaussian-process factor analysis (GPFA)—which unifies the smoothing and dimensionality-reduction operations in a common probabilistic framework. We applied these methods to the activity of 61 neurons recorded simultaneously in macaque premotor and motor cortices during reach planning and execution. By adopting a goodness-of-fit metric that measures how well the activity of each neuron can be predicted by all other recorded neurons, we found that the proposed extensions improved the predictive ability of the two-stage methods. The predictive ability was further improved by going to GPFA. From the extracted trajectories, we directly observed a convergence in neural state during motor planning, an effect that was shown indirectly by previous studies. We then show how such methods can be a powerful tool for relating the spiking activity across a neural population to the subject's behavior on a single-trial basis. Finally, to assess how well the proposed methods characterize neural population activity when the underlying time course is known, we performed simulations that revealed that GPFA performed tens of percent better than the best two-stage method.},
  pmcid = {PMC2712272},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\SRNKXC5C\Yu et al. - 2009 - Gaussian-Process Factor Analysis for Low-Dimension.pdf}
}

@article{yuImprovedToolsStudy2020,
  title = {Improved Tools to Study Astrocytes},
  author = {Yu, Xinzhu and Nagai, Jun and Khakh, Baljit S.},
  date = {2020-03},
  journaltitle = {Nature Reviews Neuroscience},
  volume = {21},
  number = {3},
  pages = {121--138},
  publisher = {Nature Publishing Group},
  issn = {1471-0048},
  doi = {10.1038/s41583-020-0264-8},
  url = {https://www.nature.com/articles/s41583-020-0264-8},
  urldate = {2020-11-20},
  abstract = {Astrocytes are a type of glial cell that tile the CNS. They interact with multiple cell types, including neurons, glial cells and blood vessels, and are involved or implicated in brain disorders. Progress has been made in understanding astrocytes, but the field lacks detailed information concerning how they perform their multifarious functions, and how and when they influence the operations of the neural circuits with which they interact. One recognized bottleneck to progress has been the paucity of reliable tools with which to explore astrocytes within the adult vertebrate CNS in vivo. However, improved tools for molecular, genetic, morphological and physiological assessments have been developed recently or have been adapted from their original purposes to study neurons and are now being used to systematically document and interrogate astrocyte biology in vivo. These tools, their uses and limitations, and the insights that they afford are summarized in this Review.},
  issue = {3},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\RZ28HLLC\\Yu et al. - 2020 - Improved tools to study astrocytes.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\2EWD3J5K\\s41583-020-0264-8.html;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\8VP7T2B5\\s41583-020-0264-8.html}
}

@article{yuLayerFastspikingInterneurons2016,
  title = {Layer 4 Fast-Spiking Interneurons Filter Thalamocortical Signals during Active Somatosensation},
  author = {Yu, Jianing and Gutnisky, Diego A. and Hires, S. Andrew and Svoboda, Karel},
  date = {2016-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {19},
  number = {12},
  pages = {1647--1657},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/nn.4412},
  url = {https://www.nature.com/articles/nn.4412},
  urldate = {2023-04-12},
  abstract = {During tactile exploration, neural activity related to movement of digits or whiskers is suppressed to facilitate high signal-to-noise ratio encoding of touch. The authors show that in mouse this computation occurs in layer 4 of the barrel cortex and is mediated by fast-spiking interneurons.},
  issue = {12},
  langid = {english},
  keywords = {Barrel cortex,Neural circuits},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\LYC8H2CV\Yu et al. - 2016 - Layer 4 fast-spiking interneurons filter thalamoco.pdf}
}

@article{yusteCommunitybasedTranscriptomicsClassification2020,
  title = {A Community-Based Transcriptomics Classification and Nomenclature of Neocortical Cell Types},
  author = {Yuste, Rafael and Hawrylycz, Michael and Aalling, Nadia and Aguilar-Valles, Argel and Arendt, Detlev and Arnedillo, Ruben Armananzas and Ascoli, Giorgio A. and Bielza, Concha and Bokharaie, Vahid and Bergmann, Tobias Borgtoft and Bystron, Irina and Capogna, Marco and Chang, Yoonjeung and Clemens, Ann and de Kock, Christiaan P. J. and DeFelipe, Javier and Dos Santos, Sandra Esmeralda and Dunville, Keagan and Feldmeyer, Dirk and Fiáth, Richárd and Fishell, Gordon James and Foggetti, Angelica and Gao, Xuefan and Ghaderi, Parviz and Goriounova, Natalia A. and Güntürkün, Onur and Hagihara, Kenta and Hall, Vanessa Jane and Helmstaedter, Moritz and Herculano, Suzana and Hilscher, Markus M. and Hirase, Hajime and Hjerling-Leffler, Jens and Hodge, Rebecca and Huang, Josh and Huda, Rafiq and Khodosevich, Konstantin and Kiehn, Ole and Koch, Henner and Kuebler, Eric S. and Kühnemund, Malte and Larrañaga, Pedro and Lelieveldt, Boudewijn and Louth, Emma Louise and Lui, Jan H. and Mansvelder, Huibert D. and Marin, Oscar and Martinez-Trujillo, Julio and Moradi Chameh, Homeira and Nath, Alok and Nedergaard, Maiken and Němec, Pavel and Ofer, Netanel and Pfisterer, Ulrich Gottfried and Pontes, Samuel and Redmond, William and Rossier, Jean and Sanes, Joshua R. and Scheuermann, Richard and Serrano-Saiz, Esther and Steiger, Jochen F. and Somogyi, Peter and Tamás, Gábor and Tolias, Andreas Savas and Tosches, Maria Antonietta and García, Miguel Turrero and Vieira, Hermany Munguba and Wozny, Christian and Wuttke, Thomas V. and Yong, Liu and Yuan, Juan and Zeng, Hongkui and Lein, Ed},
  options = {useprefix=true},
  date = {2020-08-24},
  journaltitle = {Nature Neuroscience},
  pages = {1--13},
  publisher = {Nature Publishing Group},
  issn = {1546-1726},
  doi = {10.1038/s41593-020-0685-8},
  url = {https://www.nature.com/articles/s41593-020-0685-8},
  urldate = {2020-08-31},
  abstract = {To understand the function of cortical circuits, it is necessary to catalog their cellular diversity. Past attempts to do so using anatomical, physiological or molecular features of cortical cells have not resulted in a unified taxonomy of neuronal or glial cell types, partly due to limited data. Single-cell transcriptomics is enabling, for the first time, systematic high-throughput measurements of cortical cells and generation of datasets that hold the promise of being complete, accurate and permanent. Statistical analyses of these data reveal clusters that often correspond to cell types previously defined by morphological or physiological criteria and that appear conserved across cortical areas and species. To capitalize on these new methods, we propose the adoption of a transcriptome-based taxonomy of cell types for mammalian neocortex. This classification should be hierarchical and use a standardized nomenclature. It should be based on a probabilistic definition of a cell type and incorporate data from different approaches, developmental stages and species. A community-based classification and data aggregation model, such as a knowledge graph, could provide a common foundation for the study of cortical circuits. This community-based classification, nomenclature and data aggregation could serve as an example for cell type atlases in other parts of the body.},
  langid = {english},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\ZUITQXWX\\Yuste et al. - 2020 - A community-based transcriptomics classification a.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\LS9FFTT6\\s41593-020-0685-8.html}
}

@article{yusteNeuronDoctrineNeural2015,
  title = {✅  {{From}} the Neuron Doctrine to Neural Networks},
  author = {Yuste, Rafael},
  date = {2015-08},
  journaltitle = {Nature Reviews Neuroscience},
  shortjournal = {Nat Rev Neurosci},
  volume = {16},
  number = {8},
  pages = {487--497},
  issn = {1471-003X, 1471-0048},
  doi = {10.1038/nrn3962},
  url = {http://www.nature.com/articles/nrn3962},
  urldate = {2023-04-05},
  abstract = {For over a century, the neuron doctrine — which states that the neuron is the structural and functional unit of the nervous system — has provided a conceptual foundation for neuroscience. This viewpoint reflects its origins in a time when the use of single-neuron anatomical and physiological techniques was prominent. However, newer multineuronal recording methods have revealed that ensembles of neurons, rather than individual cells, can form physiological units and generate emergent functional properties and states. As a new paradigm for neuroscience, neural network models have the potential to incorporate knowledge acquired with single-neuron approaches to help us understand how emergent functional states generate behaviour, cognition and mental disease.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\BK6874VV\Yuste - 2015 - From the neuron doctrine to neural networks.pdf}
}

@article{yuUncertaintyNeuromodulationAttention2005,
  title = {Uncertainty, Neuromodulation, and Attention},
  author = {Yu, Angela J. and Dayan, Peter},
  date = {2005-05-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {46},
  number = {4},
  eprint = {15944135},
  eprinttype = {pmid},
  pages = {681--692},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2005.04.026},
  abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain's implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic.},
  langid = {english},
  keywords = {Acetylcholine,Algorithms,Animals,Attention,Bayes Theorem,Computer Simulation,Dose-Response Relationship Drug,Generalization Psychological,Humans,Learning,Likelihood Functions,Maze Learning,Models Neurological,Muscarinic Antagonists,Nicotine,Nicotinic Agonists,Norepinephrine,Rats,Scopolamine,Signal Detection Psychological,Time Factors,Uncertainty},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\388MGXBW\Yu and Dayan - 2005 - Uncertainty, neuromodulation, and attention.pdf}
}

@article{yuUncertaintyNeuromodulationAttention2005a,
  title = {Uncertainty, {{Neuromodulation}}, and {{Attention}}},
  author = {Yu, Angela J. and Dayan, Peter},
  date = {2005-05-19},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  volume = {46},
  number = {4},
  eprint = {15944135},
  eprinttype = {pmid},
  pages = {681--692},
  publisher = {Elsevier},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2005.04.026},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(05)00362-4},
  urldate = {2023-01-20},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\B7MBSI2M\Yu and Dayan - 2005 - Uncertainty, Neuromodulation, and Attention.pdf}
}

@article{zadorCritiquePureLearning2019,
  title = {A Critique of Pure Learning and What Artificial Neural Networks Can Learn from Animal Brains},
  author = {Zador, Anthony M.},
  date = {2019-08-21},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {10},
  number = {1},
  pages = {3770},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-11786-6},
  url = {https://www.nature.com/articles/s41467-019-11786-6},
  urldate = {2024-03-14},
  abstract = {Artificial neural networks (ANNs) have undergone a revolution, catalyzed by better supervised learning algorithms. However, in stark contrast to young animals (including humans), training such networks requires enormous numbers of labeled examples, leading to the belief that animals must rely instead mainly on unsupervised learning. Here we argue that most animal behavior is not the result of clever learning algorithms—supervised or unsupervised—but is encoded in the genome. Specifically, animals are born with highly structured brain connectivity, which enables them to learn very rapidly. Because the wiring diagram is far too complex to be specified explicitly in the genome, it must be compressed through a “genomic bottleneck”. The genomic bottleneck suggests a path toward ANNs capable of rapid learning.},
  langid = {english},
  keywords = {Computer science,Network models},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\W9SSHDEA\Zador - 2019 - A critique of pure learning and what artificial ne.pdf}
}

@article{zeiselMolecularArchitectureMouse2018,
  title = {Molecular {{Architecture}} of the {{Mouse Nervous System}}},
  author = {Zeisel, Amit and Hochgerner, Hannah and Lönnerberg, Peter and Johnsson, Anna and Memic, Fatima and van der Zwan, Job and Häring, Martin and Braun, Emelie and Borm, Lars E. and La Manno, Gioele and Codeluppi, Simone and Furlan, Alessandro and Lee, Kawai and Skene, Nathan and Harris, Kenneth D. and Hjerling-Leffler, Jens and Arenas, Ernest and Ernfors, Patrik and Marklund, Ulrika and Linnarsson, Sten},
  options = {useprefix=true},
  date = {2018-08},
  journaltitle = {Cell},
  shortjournal = {Cell},
  volume = {174},
  number = {4},
  pages = {999-1014.e22},
  issn = {00928674},
  doi = {10.1016/j.cell.2018.06.021},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S009286741830789X},
  urldate = {2020-09-02},
  abstract = {The mammalian nervous system executes complex behaviors controlled by specialized, precisely positioned, and interacting cell types. Here, we used RNA sequencing of half a million single cells to create a detailed census of cell types in the mouse nervous system. We mapped cell types spatially and derived a hierarchical, data-driven taxonomy. Neurons were the most diverse and were grouped by developmental anatomical units and by the expression of neurotransmitters and neuropeptides. Neuronal diversity was driven by genes encoding cell identity, synaptic connectivity, neurotransmission, and membrane conductance. We discovered seven distinct, regionally restricted astrocyte types that obeyed developmental boundaries and correlated with the spatial distribution of key glutamate and glycine neurotransmitters. In contrast, oligodendrocytes showed a loss of regional identity followed by a secondary diversification. The resource presented here lays a solid foundation for understanding the molecular architecture of the mammalian nervous system and enables genetic manipulation of specific cell types.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8V6QUQWJ\Zeisel et al. - 2018 - Molecular Architecture of the Mouse Nervous System.pdf}
}

@article{zemlaHippocampalFunctionRodents2017,
  title = {Hippocampal Function in Rodents},
  author = {Zemla, Roland and Basu, Jayeeta},
  date = {2017-04},
  journaltitle = {Current opinion in neurobiology},
  shortjournal = {Curr Opin Neurobiol},
  volume = {43},
  eprint = {28477511},
  eprinttype = {pmid},
  pages = {187--197},
  issn = {0959-4388},
  doi = {10.1016/j.conb.2017.04.005},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5690575/},
  urldate = {2023-04-15},
  abstract = {The hippocampus is crucial for the formation and recall of long-term memories about people, places, objects, and events. Capitalizing on high-resolution microscopy, in vivo electrophysiology, and genetic manipulation, recent research in rodents provides evidence for hippocampal ensemble coding on the spatial, episodic, and contextual dimensions. Here we highlight the functional contribution of newly described long-range connections between hippocampus and cortical areas, and the relative impact of inhibitory and excitatory dynamics in generating behaviorally relevant population activity. Our goal is to provide an integrated view of hippocampal circuit function to understand mnemonic computations at the systems and cellular levels that underlie adaptive learned behaviors.},
  pmcid = {PMC5690575},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\7MSIYFBG\\Zemla and Basu - 2017 - Hippocampal function in rodents.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\JIDT345V\\zemla2017.pdf}
}

@article{zenkeDiverseSynapticPlasticity2015,
  title = {Diverse Synaptic Plasticity Mechanisms Orchestrated to Form and Retrieve Memories in Spiking Neural Networks},
  author = {Zenke, Friedemann and Agnes, Everton J. and Gerstner, Wulfram},
  date = {2015-04-21},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {6},
  number = {1},
  pages = {6922},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/ncomms7922},
  url = {https://www.nature.com/articles/ncomms7922},
  urldate = {2022-10-21},
  abstract = {Synaptic plasticity, the putative basis of learning and memory formation, manifests in various forms and across different timescales. Here we show that the interaction of Hebbian homosynaptic plasticity with rapid non-Hebbian heterosynaptic plasticity is, when complemented with slower homeostatic changes and consolidation, sufficient for assembly formation and memory recall in a spiking recurrent network model of excitatory and inhibitory neurons. In the model, assemblies were formed during repeated sensory stimulation and characterized by strong recurrent excitatory connections. Even days after formation, and despite ongoing network activity and synaptic plasticity, memories could be recalled through selective delay activity following the brief stimulation of a subset of assembly neurons. Blocking any component of plasticity prevented stable functioning as a memory network. Our modelling results suggest that the diversity of plasticity phenomena in the brain is orchestrated towards achieving common functional goals.},
  issue = {1},
  langid = {english},
  keywords = {Learning and memory,Neural circuits,Synaptic plasticity},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\352AERJF\\Zenke et al. - 2015 - Diverse synaptic plasticity mechanisms orchestrate.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\KBFFA46F\\ncomms7922.html}
}

@article{zeraatiAttentionalModulationIntrinsic2021,
  title = {Attentional Modulation of Intrinsic Timescales in Visual Cortex and Spatial Networks},
  author = {Zeraati, Roxana and Shi, Yan-Liang and Steinmetz, Nicholas A. and Gieselmann, Marc A. and Thiele, Alexander and Moore, Tirin and Levina, Anna and Engel, Tatiana A.},
  date = {2021},
  journaltitle = {bioRxiv},
  publisher = {Cold Spring Harbor Laboratory}
}

@article{zhangConvolutionalNeuralNetwork2019,
  title = {Convolutional Neural Network Models of {{V1}} Responses to Complex Patterns},
  author = {Zhang, Yimeng and Lee, Tai Sing and Li, Ming and Liu, Fang and Tang, Shiming},
  date = {2019-02-01},
  journaltitle = {Journal of Computational Neuroscience},
  shortjournal = {J Comput Neurosci},
  volume = {46},
  number = {1},
  pages = {33--54},
  issn = {1573-6873},
  doi = {10.1007/s10827-018-0687-7},
  url = {https://doi.org/10.1007/s10827-018-0687-7},
  urldate = {2020-10-08},
  abstract = {In this study, we evaluated the convolutional neural network (CNN) method for modeling V1 neurons of awake macaque monkeys in response to a large set of complex pattern stimuli. CNN models outperformed all the other baseline models, such as Gabor-based standard models for V1 cells and various variants of generalized linear models. We then systematically dissected different components of the CNN and found two key factors that made CNNs outperform other models: thresholding nonlinearity and convolution. In addition, we fitted our data using a pre-trained deep CNN via transfer learning. The deep CNN’s higher layers, which encode more complex patterns, outperformed lower ones, and this result was consistent with our earlier work on the complexity of V1 neural code. Our study systematically evaluates the relative merits of different CNN components in the context of V1 neuron modeling.},
  langid = {english},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RTJIZRDF\Zhang et al. - 2019 - Convolutional neural network models of V1 response.pdf}
}

@article{zhangHighorderThalamicInputs2019,
  title = {High-Order Thalamic Inputs to Primary Somatosensory Cortex Are Stronger and Longer Lasting than Cortical Inputs},
  author = {Zhang, Wanying and Bruno, Randy M},
  editor = {Calabrese, Ronald L},
  date = {2019-02-11},
  journaltitle = {eLife},
  volume = {8},
  pages = {e44158},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.44158},
  url = {https://doi.org/10.7554/eLife.44158},
  urldate = {2023-08-01},
  abstract = {Layer (L) 2/3 pyramidal neurons in the primary somatosensory cortex (S1) are sparsely active, spontaneously and during sensory stimulation. Long-range inputs from higher areas may gate L2/3 activity. We investigated their in vivo impact by expressing channelrhodopsin in three main sources of feedback to rat S1: primary motor cortex, secondary somatosensory cortex, and secondary somatosensory thalamic nucleus (the posterior medial nucleus, POm). Inputs from cortical areas were relatively weak. POm, however, more robustly depolarized L2/3 cells and, when paired with peripheral stimulation, evoked action potentials. POm triggered not only a stronger fast-onset depolarization but also a delayed all-or-none persistent depolarization, lasting up to 1 s and exhibiting alpha/beta-range oscillations. Inactivating POm somata abolished persistent but not initial depolarization, indicating a recurrent circuit mechanism. We conclude that secondary thalamus can enhance L2/3 responsiveness over long periods. Such timescales could provide a potential modality-specific substrate for attention, working memory, and plasticity.},
  keywords = {barrel cortex,POm,thalamus,whole-cell},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\NQQJHP8U\Zhang and Bruno - 2019 - High-order thalamic inputs to primary somatosensor.pdf}
}

@article{zhangLongrangeLocalCircuits2014,
  title = {Long-Range and Local Circuits for Top-down Modulation of Visual Cortex Processing},
  author = {Zhang, Siyu and Xu, Min and Kamigaki, Tsukasa and Hoang Do, Johnny Phong and Chang, Wei-Cheng and Jenvay, Sean and Miyamichi, Kazunari and Luo, Liqun and Dan, Yang},
  date = {2014-08-08},
  journaltitle = {Science},
  volume = {345},
  number = {6197},
  pages = {660--665},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1254126},
  url = {https://www.science.org/doi/abs/10.1126/science.1254126},
  urldate = {2023-04-10},
  abstract = {Top-down modulation of sensory processing allows the animal to select inputs most relevant to current tasks. We found that the cingulate (Cg) region of the mouse frontal cortex powerfully influences sensory processing in the primary visual cortex (V1) through long-range projections that activate local γ-aminobutyric acid–ergic (GABAergic) circuits. Optogenetic activation of Cg neurons enhanced V1 neuron responses and improved visual discrimination. Focal activation of Cg axons in V1 caused a response increase at the activation site but a decrease at nearby locations (center-surround modulation). Whereas somatostatin-positive GABAergic interneurons contributed preferentially to surround suppression, vasoactive intestinal peptide-positive interneurons were crucial for center facilitation. Long-range corticocortical projections thus act through local microcircuits to exert spatially specific top-down modulation of sensory processing.},
  file = {C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\4HL26RPL\\zhang2014.pdf;C\:\\Users\\Zach Friedenberger\\Zotero\\storage\\FTDEUHCD\\Zhang et al. - 2014 - Long-range and local circuits for top-down modulat.pdf}
}

@article{zhangMotorCortexGates2023,
  title = {Motor Cortex Gates Distractor Stimulus Encoding in Sensory Cortex},
  author = {Zhang, Zhaoran and Zagha, Edward},
  date = {2023-04-13},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {14},
  number = {1},
  pages = {2097},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-023-37848-4},
  url = {https://www.nature.com/articles/s41467-023-37848-4},
  urldate = {2023-08-01},
  abstract = {Suppressing responses to distractor stimuli is a fundamental cognitive function, essential for performing goal-directed tasks. A common framework for the neuronal implementation of distractor suppression is the attenuation of distractor stimuli from early sensory to higher-order processing. However, details of the localization and mechanisms of attenuation are poorly understood. We trained mice to selectively respond to target stimuli in one whisker field and ignore distractor stimuli in the opposite whisker field. During expert task performance, optogenetic inhibition of whisker motor cortex increased the overall tendency to respond and the detection of distractor whisker stimuli. Within sensory cortex, optogenetic inhibition of whisker motor cortex enhanced the propagation of distractor stimuli into target-preferring neurons. Single unit analyses revealed that whisker motor cortex (wMC) decorrelates target and distractor stimulus encoding in target-preferring primary somatosensory cortex (S1) neurons, which likely improves selective target stimulus detection by downstream readers. Moreover, we observed proactive top-down modulation from wMC to S1, through the differential activation of putative excitatory and inhibitory neurons before stimulus onset. Overall, our studies support a contribution of motor cortex to sensory selection, in suppressing behavioral responses to distractor stimuli by gating distractor stimulus propagation within sensory cortex.},
  issue = {1},
  langid = {english},
  keywords = {Barrel cortex,Neural circuits,Sensory processing},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\8BFZH78P\Zhang and Zagha - 2023 - Motor cortex gates distractor stimulus encoding in.pdf}
}

@article{zhangTopdownNeuralAttention2016,
  title = {Top-down Neural Attention by Excitation Backprop},
  author = {Zhang, Jianming and Lin, Zhe and Brandt, Jonathan and Shen, Xiaohui and Sclaroff, Stan and Bargal, Sarah Adel},
  date = {2016},
  publisher = {Springer International Publishing},
  doi = {10.1007/s11263-017-1059-x},
  url = {https://open.bu.edu/handle/2144/26686},
  urldate = {2023-01-23},
  abstract = {We aim to model the top-down attention of a Convolutional Neural Network (CNN) classifier for generating task-specific attention maps. Inspired by a top-down human visual attention model, we propose a new backpropagation scheme, called Excitation Backprop, to pass along top-down signals downwards in the network hierarchy via a probabilistic Winner-Take-All process. Furthermore, we introduce the concept of contrastive attention to make the top-down attention maps more discriminative. In experiments, we demonstrate the accuracy and generalizability of our method in weakly supervised localization tasks on the MS COCO, PASCAL VOC07 and ImageNet datasets. The usefulness of our method is further validated in the text-to-region association task. On the Flickr30k Entities dataset, we achieve promising performance in phrase localization by leveraging the top-down attention of a CNN model that has been trained on weakly labeled web images.},
  langid = {english},
  annotation = {Accepted: 2018-02-05T18:18:20Z},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PQD7RNBJ\Zhang et al. - 2016 - Top-down neural attention by excitation backprop.pdf}
}

@online{zhongDistinctStreamsSupervised2024,
  title = {Distinct Streams for Supervised and Unsupervised Learning in the Visual Cortex},
  author = {Zhong, Lin and Baptista, Scott and Gattoni, Rachel and Arnold, Jon and Flickinger, Daniel and Stringer, Carsen and Pachitariu, Marius},
  date = {2024-02-27},
  eprinttype = {bioRxiv},
  eprintclass = {New Results},
  pages = {2024.02.25.581990},
  doi = {10.1101/2024.02.25.581990},
  url = {https://www.biorxiv.org/content/10.1101/2024.02.25.581990v1},
  urldate = {2024-03-11},
  abstract = {Representation learning in neural networks may be implemented with supervised or unsupervised algorithms, distinguished by the availability of feedback. In sensory cortex, perceptual learning drives neural plasticity, but it is not known if this is due to supervised or unsupervised learning. Here we recorded populations of up to 90,000 neurons simultaneously from the primary visual cortex (V1) and higher visual areas (HVA), while mice learned multiple tasks as well as during unrewarded exposure to the same stimuli. Similar to previous studies, we found that neural changes in task mice were correlated with their behavioral learning. However, the neural changes were mostly replicated in mice with unrewarded exposure, suggesting that the changes were in fact due to unsupervised learning. The neural plasticity was concentrated in the medial HVAs and obeyed visual, rather than spatial, learning rules. In task mice only, we found a ramping reward prediction signal in anterior HVAs, potentially involved in supervised learning. Our neural results predict that unsupervised learning may accelerate subsequent task learning, a prediction which we validated with behavioral experiments.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\RTH52V35\Zhong et al. - 2024 - Distinct streams for supervised and unsupervised l.pdf}
}

@inproceedings{zhouLearningIdentifiableInterpretable2020,
  title = {Learning Identifiable and Interpretable Latent Models of High-Dimensional Neural Activity Using Pi-{{VAE}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Zhou, Ding and Wei, Xue-Xin},
  date = {2020},
  volume = {33},
  pages = {7234--7247},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2020/hash/510f2318f324cf07fce24c3a4b89c771-Abstract.html},
  urldate = {2023-03-05},
  abstract = {The ability to record activities from hundreds of neurons simultaneously in the brain has placed an increasing demand for developing appropriate statistical techniques to analyze such data. Recently, deep generative models have been proposed to fit neural population responses. While these methods are flexible and expressive, the downside is that they can be difficult to interpret and identify. To address this problem, we propose a method that integrates key ingredients from latent models and traditional neural encoding models. Our method, pi-VAE, is inspired by recent progress on identifiable variational auto-encoder, which we adapt to make appropriate for neuroscience applications. Specifically, we propose to construct latent variable models of neural activity while simultaneously modeling the relation between the latent and task variables (non-neural variables, e.g. sensory, motor, and other externally observable states). The incorporation of task variables results in models that are not only more constrained, but also show qualitative improvements in interpretability and identifiability. We validate pi-VAE using synthetic data, and apply it to analyze neurophysiological datasets from rat hippocampus and macaque motor cortex. We demonstrate that pi-VAE not only fits the data better, but also provides unexpected novel insights into the structure of the neural codes.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\PDVXUWXV\Zhou and Wei - 2020 - Learning identifiable and interpretable latent mod.pdf}
}

@article{zhuangUnsupervisedNeuralNetwork2021,
  title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
  author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
  date = {2021-01-19},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {3},
  pages = {e2014196118},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2014196118},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2014196118},
  urldate = {2024-06-17},
  abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today’s best supervised methods and that the mapping of these neural network models’ hidden layers is neuroanatomically consistent across the ventral stream. Strikingly, we find that these methods produce brain-like representations even when trained solely with real human child developmental data collected from head-mounted cameras, despite the fact that these datasets are noisy and limited. We also find that semisupervised deep contrastive embeddings can leverage small numbers of labeled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results illustrate a use of unsupervised learning to provide a quantitative model of a multiarea cortical brain system and present a strong candidate for a biologically plausible computational theory of primate sensory learning.},
  file = {C:\Users\Zach Friedenberger\Zotero\storage\XN5N9XUU\Zhuang et al. - 2021 - Unsupervised neural network models of the ventral .pdf}
}
